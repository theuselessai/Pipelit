{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#pipelit","title":"Pipelit","text":"<p>Build, connect, and orchestrate LLM-powered agents \u2014 visually.</p> <p>Pipelit is a self-hosted workflow automation platform for designing LLM agent pipelines on a drag-and-drop canvas. Wire up triggers, agents, tools, and routing logic \u2014 then watch them execute in real time.</p> <p>Get Started View on GitHub</p>"},{"location":"#visual-canvas","title":"Visual Canvas","text":"<p>Drag-and-drop React Flow editor with node palette, config panel, and live execution badges showing running/success/failed status on every node.</p>"},{"location":"#multi-trigger","title":"Multi-Trigger","text":"<p>Telegram, webhooks, chat, scheduled intervals, manual \u2014 all unified as first-class workflow nodes on the canvas.</p>"},{"location":"#llm-agents","title":"LLM Agents","text":"<p>LangGraph ReAct agents with tool-calling: shell commands, HTTP requests, web search, calculator, datetime, and more.</p>"},{"location":"#conditional-routing","title":"Conditional Routing","text":"<p>Switch nodes evaluate rules and route to different branches via conditional edges. AI routers classify and direct traffic.</p>"},{"location":"#scheduled-execution","title":"Scheduled Execution","text":"<p>Recurring runs with configurable intervals, retry with exponential backoff, pause/resume, and automatic crash recovery.</p>"},{"location":"#real-time-updates","title":"Real-time Updates","text":"<p>Single global WebSocket pushes node status, execution events, and canvas mutations \u2014 zero polling.</p>"},{"location":"#cost-tracking","title":"Cost Tracking","text":"<p>Per-execution token counting and USD cost calculation with Epic-level budget enforcement. Know exactly what your agents spend.</p>"},{"location":"#conversation-memory","title":"Conversation Memory","text":"<p>Optional per-agent conversation persistence across executions. Global memory system with facts, episodes, and procedures.</p>"},{"location":"#self-improving-agents","title":"Self-Improving Agents","text":"<p>Agents can read epics/tasks, spawn child workflows, modify their own graphs, and schedule future work \u2014 autonomously.</p>"},{"location":"#tech-stack","title":"Tech Stack","text":"Layer Technologies Backend FastAPI, SQLAlchemy 2.0, Alembic, Pydantic, RQ (Redis Queue) Frontend React, Vite, TypeScript, Shadcn/ui, React Flow (@xyflow/react v12), TanStack Query Execution LangGraph, LangChain, Redis pub/sub, WebSocket Auth Bearer token API keys, TOTP-based MFA"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code>git clone git@github.com:theuselessai/Pipelit.git\ncd Pipelit\n\n# Backend\npython3 -m venv .venv &amp;&amp; source .venv/bin/activate\npip install -r platform/requirements.txt\n\n# Frontend\ncd platform/frontend &amp;&amp; npm install\n</code></pre> <p>Then follow the full Getting Started guide to configure and launch Pipelit.</p>"},{"location":"#license","title":"License","text":"<p>MIT</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to Pipelit will be documented here.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"[Unreleased]","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Documentation site with MkDocs Material</li> <li>Full component reference for all 42+ node types</li> <li>API reference documentation</li> <li>Architecture documentation with Mermaid diagrams</li> <li>Getting started guide and tutorials</li> <li>Deployment guides for Docker, production, and reverse proxy setups</li> </ul> <p>For the full commit history, see the GitHub repository.</p>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#faq","title":"FAQ","text":""},{"location":"faq/#general","title":"General","text":""},{"location":"faq/#what-is-pipelit","title":"What is Pipelit?","text":"<p>Pipelit is a self-hosted visual workflow automation platform for building LLM-powered agent pipelines. You design workflows on a drag-and-drop canvas, connecting triggers, agents, tools, and routing logic, then execute them with real-time status updates.</p>"},{"location":"faq/#is-pipelit-open-source","title":"Is Pipelit open source?","text":"<p>Yes. Pipelit is released under the MIT license.</p>"},{"location":"faq/#what-llm-providers-are-supported","title":"What LLM providers are supported?","text":"<p>Pipelit works with any provider supported by LangChain, including OpenAI, Anthropic, Google, Mistral, Groq, and local models via Ollama or vLLM. You configure providers through the Credentials page.</p>"},{"location":"faq/#does-pipelit-require-an-internet-connection","title":"Does Pipelit require an internet connection?","text":"<p>Only for LLM API calls to cloud providers. If you use local models (e.g., Ollama), Pipelit can run fully offline.</p>"},{"location":"faq/#setup-installation","title":"Setup &amp; Installation","text":""},{"location":"faq/#why-does-pipelit-require-redis-80","title":"Why does Pipelit require Redis 8.0+?","text":"<p>Redis 8.0+ includes RediSearch natively, which Pipelit uses for fuzzy search in the memory system. Older Redis versions will fail with <code>unknown command 'FT._LIST'</code>. See the Redis setup guide for installation instructions.</p>"},{"location":"faq/#can-i-use-postgresql-instead-of-sqlite","title":"Can I use PostgreSQL instead of SQLite?","text":"<p>Yes. Set <code>DATABASE_URL</code> in your <code>.env</code> file to a PostgreSQL connection string. SQLite is the default for development; PostgreSQL is recommended for production. See Database deployment.</p>"},{"location":"faq/#what-happens-if-i-lose-my-field_encryption_key","title":"What happens if I lose my <code>FIELD_ENCRYPTION_KEY</code>?","text":"<p>All stored credentials (API keys, tokens) become unrecoverable. Back up this key securely.</p>"},{"location":"faq/#workflows","title":"Workflows","text":""},{"location":"faq/#can-a-workflow-have-multiple-triggers","title":"Can a workflow have multiple triggers?","text":"<p>Yes. A single workflow can have multiple trigger nodes (e.g., a chat trigger and a Telegram trigger). Each trigger scopes its own execution \u2014 only nodes reachable downstream from the firing trigger are compiled and run.</p>"},{"location":"faq/#what-happens-to-nodes-not-connected-to-a-trigger","title":"What happens to nodes not connected to a trigger?","text":"<p>Unconnected nodes are ignored during execution. The builder only compiles the subgraph reachable from the firing trigger via BFS traversal. This allows you to keep unused or in-progress nodes on the canvas without causing errors.</p>"},{"location":"faq/#how-do-i-pass-data-between-nodes","title":"How do I pass data between nodes?","text":"<p>Nodes communicate through typed ports. Connect an output port to an input port via edges on the canvas. You can also reference upstream outputs using Jinja2 expressions (<code>{{ nodeId.portName }}</code>) in system prompts and config fields.</p>"},{"location":"faq/#agents","title":"Agents","text":""},{"location":"faq/#what-is-conversation-memory","title":"What is conversation memory?","text":"<p>When enabled on an agent node, conversation memory persists the chat history across executions using a SQLite checkpointer. The same user talking to the same workflow continues their conversation. Toggle it in the agent's config panel.</p>"},{"location":"faq/#can-agents-call-multiple-tools","title":"Can agents call multiple tools?","text":"<p>Yes. Connect as many tool nodes as you want to an agent's \"tools\" handle (green diamond). The agent can invoke any connected tool during its reasoning loop.</p>"},{"location":"faq/#how-do-i-give-an-agent-access-to-the-platform-api","title":"How do I give an agent access to the platform API?","text":"<p>Connect the <code>Platform API</code>, <code>WhoAmI</code>, and other self-awareness tools to the agent. These let the agent make authenticated requests to the Pipelit REST API, inspect its own identity, and modify workflows.</p>"},{"location":"faq/#execution","title":"Execution","text":""},{"location":"faq/#why-is-my-execution-stuck-in-running","title":"Why is my execution stuck in \"running\"?","text":"<p>Executions that run longer than <code>ZOMBIE_EXECUTION_THRESHOLD_SECONDS</code> (default: 15 minutes) are considered stuck. Check the Troubleshooting page for diagnosis steps. Common causes include LLM API timeouts, infinite tool loops, or RQ worker crashes.</p>"},{"location":"faq/#can-i-cancel-a-running-execution","title":"Can I cancel a running execution?","text":"<p>Yes, via the API (<code>POST /api/v1/executions/{id}/cancel/</code>) or the Executions page in the UI.</p>"},{"location":"faq/#how-does-cost-tracking-work","title":"How does cost tracking work?","text":"<p>Pipelit automatically counts input and output tokens per execution and calculates USD costs based on model pricing. You can set token or USD budgets on Epics \u2014 the orchestrator checks the budget before each node execution.</p>"},{"location":"faq/#deployment","title":"Deployment","text":""},{"location":"faq/#can-i-run-pipelit-in-docker","title":"Can I run Pipelit in Docker?","text":"<p>Yes. See the Docker deployment guide for Dockerfile and docker-compose.yml examples.</p>"},{"location":"faq/#do-i-need-a-separate-frontend-server-in-production","title":"Do I need a separate frontend server in production?","text":"<p>No. Run <code>npm run build</code> in <code>platform/frontend/</code> once, and FastAPI serves the built SPA directly. No Vite dev server needed in production.</p>"},{"location":"faq/#how-do-i-set-up-websocket-proxying","title":"How do I set up WebSocket proxying?","text":"<p>Your reverse proxy must forward WebSocket upgrade requests. See the Reverse Proxy guide for Nginx and Caddy configurations.</p>"},{"location":"troubleshooting/","title":"Troubleshooting","text":""},{"location":"troubleshooting/#troubleshooting","title":"Troubleshooting","text":"<p>Common issues and their solutions.</p>"},{"location":"troubleshooting/#redis-connection-errors","title":"Redis Connection Errors","text":""},{"location":"troubleshooting/#unknown-command-ft_list","title":"<code>unknown command 'FT._LIST'</code>","text":"<p>Cause: Your Redis version doesn't include RediSearch.</p> <p>Solution: Upgrade to Redis 8.0+ which includes RediSearch natively:</p> <pre><code># Docker\ndocker run -d --name redis -p 6379:6379 redis:8\n\n# Verify\nredis-cli MODULE LIST  # Should include 'search' module\n</code></pre> <p>See the full Redis setup guide.</p>"},{"location":"troubleshooting/#connection-refused-on-redis","title":"<code>Connection refused</code> on Redis","text":"<p>Cause: Redis is not running or is on a different port.</p> <p>Solution:</p> <pre><code># Check if Redis is running\nredis-cli ping\n\n# Start Redis\nsudo systemctl start redis\n# or\ndocker start redis\n</code></pre> <p>Verify <code>REDIS_URL</code> in your <code>.env</code> matches the actual Redis address.</p>"},{"location":"troubleshooting/#zombie-executions-stuck-in-running","title":"Zombie Executions (Stuck in \"Running\")","text":""},{"location":"troubleshooting/#symptom","title":"Symptom","text":"<p>Executions stay in \"running\" status indefinitely and never complete.</p>"},{"location":"troubleshooting/#common-causes","title":"Common Causes","text":"<ol> <li>RQ worker crashed \u2014 The worker processing the execution died mid-run</li> <li>LLM API timeout \u2014 The LLM provider took too long to respond</li> <li>Infinite tool loop \u2014 An agent keeps calling tools without converging</li> <li>Redis disconnection \u2014 Worker lost connection to Redis during execution</li> </ol>"},{"location":"troubleshooting/#diagnosis","title":"Diagnosis","text":"<pre><code># Check for stuck executions (running &gt; 15 minutes)\ncurl -H \"Authorization: Bearer YOUR_KEY\" \\\n  \"http://localhost:8000/api/v1/executions/?status=running\"\n\n# Check RQ worker status\nrq info --url redis://localhost:6379/0\n\n# Check worker logs for errors\n</code></pre>"},{"location":"troubleshooting/#solutions","title":"Solutions","text":"<ol> <li> <p>Cancel stuck executions via API:    </p><pre><code>curl -X POST -H \"Authorization: Bearer YOUR_KEY\" \\\n  \"http://localhost:8000/api/v1/executions/{id}/cancel/\"\n</code></pre><p></p> </li> <li> <p>Restart the RQ worker: </p><pre><code># Kill existing worker\npkill -f \"rq worker\"\n\n# Restart\ncd platform &amp;&amp; rq worker workflows --with-scheduler\n</code></pre><p></p> </li> <li> <p>Adjust the zombie threshold in <code>.env</code>:    </p><pre><code>ZOMBIE_EXECUTION_THRESHOLD_SECONDS=1800  # 30 minutes\n</code></pre><p></p> </li> <li> <p>Use the System Health tool \u2014 Connect the <code>system_health</code> tool to an agent and ask it to diagnose infrastructure issues.</p> </li> </ol>"},{"location":"troubleshooting/#authentication-errors","title":"Authentication Errors","text":""},{"location":"troubleshooting/#401-unauthorized","title":"<code>401 Unauthorized</code>","text":"<p>Cause: Missing or invalid Bearer token.</p> <p>Solution: Ensure your request includes the correct header:</p> <pre><code>Authorization: Bearer your-api-key-here\n</code></pre> <p>Common Mistakes</p> <ul> <li>Using <code>Token</code> instead of <code>Bearer</code></li> <li>Including extra whitespace</li> <li>Using an expired or revoked API key</li> </ul>"},{"location":"troubleshooting/#setup-wizard-doesnt-appear","title":"Setup wizard doesn't appear","text":"<p>Cause: An admin user already exists.</p> <p>Solution: Check setup status:</p> <pre><code>curl http://localhost:8000/api/v1/auth/setup-status/\n</code></pre> <p>If <code>{\"needs_setup\": false}</code>, an admin was already created. Log in with those credentials.</p>"},{"location":"troubleshooting/#database-issues","title":"Database Issues","text":""},{"location":"troubleshooting/#operationalerror-database-is-locked","title":"<code>OperationalError: database is locked</code>","text":"<p>Cause: Multiple processes writing to SQLite simultaneously.</p> <p>Solution: This is a SQLite limitation with concurrent writes.</p> <ul> <li>For development: ensure only one RQ worker is running</li> <li>For production: switch to PostgreSQL:   <pre><code>DATABASE_URL=postgresql://user:pass@localhost:5432/pipelit\n</code></pre></li> </ul>"},{"location":"troubleshooting/#migration-errors","title":"Migration errors","text":"<p>Cause: Conflicting Alembic migration heads or corrupted migration state.</p> <p>Solution:</p> <pre><code>cd platform\n\n# Check for multiple heads\nalembic heads\n\n# If multiple heads exist, merge them\nalembic merge heads -m \"merge migration heads\"\n\n# Apply migrations\nalembic upgrade head\n</code></pre>"},{"location":"troubleshooting/#frontend-issues","title":"Frontend Issues","text":""},{"location":"troubleshooting/#blank-page-after-login","title":"Blank page after login","text":"<p>Cause: Frontend build is outdated or missing.</p> <p>Solution:</p> <pre><code>cd platform/frontend\nnpm run build\n</code></pre> <p>Then access via <code>http://localhost:8000</code> (not the Vite dev server).</p>"},{"location":"troubleshooting/#websocket-connection-failed","title":"WebSocket connection failed","text":"<p>Cause: WebSocket connection can't be established.</p> <p>Solutions:</p> <ol> <li>Check that the backend is running on the expected port</li> <li>If behind a reverse proxy, ensure WebSocket upgrade headers are forwarded</li> <li>Check browser console for specific error messages</li> <li>Verify the API key is valid (WebSocket auth uses <code>?token=&lt;key&gt;</code>)</li> </ol>"},{"location":"troubleshooting/#execution-issues","title":"Execution Issues","text":""},{"location":"troubleshooting/#agent-not-using-tools","title":"Agent not using tools","text":"<p>Cause: Tools are not properly connected to the agent.</p> <p>Solution:</p> <ol> <li>Verify tool nodes are connected to the agent's tools handle (green diamond at the bottom)</li> <li>Check that the edge label is <code>tool</code></li> <li>Validate the workflow: <code>POST /api/v1/workflows/{slug}/validate/</code></li> </ol>"},{"location":"troubleshooting/#node-shows-failed-status","title":"Node shows \"failed\" status","text":"<p>Cause: The node encountered an error during execution.</p> <p>Solution:</p> <ol> <li>Click the red \"error\" link on the failed node to see the error details</li> <li>Check the execution logs: <code>GET /api/v1/executions/{id}/</code></li> <li>Common errors:</li> <li>Missing LLM credential on AI model node</li> <li>Invalid system prompt (Jinja2 syntax error)</li> <li>Tool execution failure (network error, permission denied)</li> </ol>"},{"location":"troubleshooting/#getting-help","title":"Getting Help","text":"<p>If your issue isn't listed here:</p> <ol> <li>Check the execution logs for detailed error messages</li> <li>Use the <code>system_health</code> tool to diagnose infrastructure issues</li> <li>Open an issue on GitHub</li> </ol>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#api-reference","title":"API Reference","text":"<p>The Pipelit platform exposes a RESTful API under the <code>/api/v1/</code> prefix. All endpoints accept and return JSON.</p>"},{"location":"api/#base-url","title":"Base URL","text":"<pre><code>http://localhost:8000/api/v1/\n</code></pre>"},{"location":"api/#authentication","title":"Authentication","text":"<p>All API endpoints (except <code>/auth/setup-status/</code> and <code>/auth/setup/</code>) require a Bearer token in the <code>Authorization</code> header.</p> <pre><code>Authorization: Bearer &lt;api_key&gt;\n</code></pre> <p>Obtain a token by calling POST /api/v1/auth/token/ with your username and password. If multi-factor authentication (MFA) is enabled on the account, an additional step via POST /api/v1/auth/mfa/login-verify/ is required.</p> <p>Requests without a valid token receive a <code>401 Unauthorized</code> response.</p>"},{"location":"api/#pagination","title":"Pagination","text":"<p>All list endpoints accept <code>limit</code> and <code>offset</code> query parameters and return a paginated envelope:</p> Parameter Type Default Description <code>limit</code> int 50 Maximum number of items to return <code>offset</code> int 0 Number of items to skip <p>Response format:</p> <pre><code>{\n  \"items\": [ ... ],\n  \"total\": 123\n}\n</code></pre> <ul> <li><code>items</code> -- array of resource objects for the current page.</li> <li><code>total</code> -- total count of matching resources (before pagination).</li> </ul>"},{"location":"api/#request-format","title":"Request Format","text":"<ul> <li>Content-Type: <code>application/json</code></li> <li>Request bodies use JSON. Fields marked as optional can be omitted.</li> <li>PATCH endpoints accept partial updates -- only include the fields you want to change.</li> </ul>"},{"location":"api/#response-format","title":"Response Format","text":"<p>All successful responses return JSON. Single-resource endpoints return the resource object directly. List endpoints return the paginated envelope described above.</p>"},{"location":"api/#error-codes","title":"Error Codes","text":"HTTP Status Meaning <code>400</code> Bad request -- invalid input or business rule violation <code>401</code> Unauthorized -- missing or invalid Bearer token <code>403</code> Forbidden -- action not allowed (e.g., MFA reset from non-localhost) <code>404</code> Not found -- resource does not exist <code>409</code> Conflict -- resource already exists (e.g., setup already completed) <code>422</code> Validation error -- schema validation failed or edge type mismatch <code>500</code> Internal server error <p>Error response body:</p> <pre><code>{\n  \"detail\": \"Human-readable error message\"\n}\n</code></pre> <p>For validation errors (422), the <code>detail</code> field may contain a structured object:</p> <pre><code>{\n  \"detail\": {\n    \"validation_errors\": [\n      \"Source type 'trigger_chat' output 'text' is not compatible with target input 'model'\"\n    ]\n  }\n}\n</code></pre>"},{"location":"api/#api-sections","title":"API Sections","text":"Section Prefix Description Authentication <code>/api/v1/auth/</code> Login, setup, MFA, user info Workflows <code>/api/v1/workflows/</code> Workflow CRUD, validation, node types Nodes <code>/api/v1/workflows/{slug}/nodes/</code> Node CRUD within a workflow Edges <code>/api/v1/workflows/{slug}/edges/</code> Edge (connection) CRUD within a workflow Executions <code>/api/v1/executions/</code> Execution list, detail, cancel Chat <code>/api/v1/workflows/{slug}/chat/</code> Chat trigger messaging and history Credentials <code>/api/v1/credentials/</code> API key and credential management Schedules <code>/api/v1/schedules/</code> Scheduled job CRUD and control Memory <code>/api/v1/memories/</code> Facts, episodes, procedures, users, checkpoints Epics <code>/api/v1/epics/</code> Epic project management Tasks <code>/api/v1/tasks/</code> Task management within epics Users <code>/api/v1/users/</code> Agent user management WebSocket <code>/ws/</code> Real-time event streaming"},{"location":"api/auth/","title":"Authentication","text":""},{"location":"api/auth/#authentication","title":"Authentication","text":"<p>Authentication endpoints for login, user info, initial setup, and multi-factor authentication (MFA).</p> <p>All endpoints are under <code>/api/v1/auth/</code>.</p>"},{"location":"api/auth/#post-apiv1authtoken","title":"POST /api/v1/auth/token/","text":"<p>Authenticate with username and password. Returns an API key for subsequent Bearer token auth.</p> <p>If MFA is enabled on the account, the response returns <code>requires_mfa: true</code> with an empty key. The client must then call POST /api/v1/auth/mfa/login-verify/ to complete authentication.</p> <p>Authentication: None required.</p> <p>Request body:</p> Field Type Required Description <code>username</code> string yes Username <code>password</code> string yes Password <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/auth/token/ \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"username\": \"admin\", \"password\": \"secret\"}'\n</code></pre> <p>Response (200) -- no MFA:</p> <pre><code>{\n  \"key\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n  \"requires_mfa\": false\n}\n</code></pre> <p>Response (200) -- MFA enabled:</p> <pre><code>{\n  \"key\": \"\",\n  \"requires_mfa\": true\n}\n</code></pre> <p>Error (401):</p> <pre><code>{\n  \"detail\": \"Invalid credentials.\"\n}\n</code></pre>"},{"location":"api/auth/#get-apiv1authme","title":"GET /api/v1/auth/me/","text":"<p>Return the currently authenticated user's profile information.</p> <p>Authentication: Bearer token required.</p> <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/auth/me/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"username\": \"admin\",\n  \"mfa_enabled\": false\n}\n</code></pre>"},{"location":"api/auth/#get-apiv1authsetup-status","title":"GET /api/v1/auth/setup-status/","text":"<p>Check whether the platform needs initial setup (i.e., no users exist yet).</p> <p>Authentication: None required.</p> <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/auth/setup-status/\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"needs_setup\": true\n}\n</code></pre>"},{"location":"api/auth/#post-apiv1authsetup","title":"POST /api/v1/auth/setup/","text":"<p>Create the first admin user. This endpoint only works when no users exist in the database.</p> <p>Authentication: None required.</p> <p>Request body:</p> Field Type Required Description <code>username</code> string yes Admin username <code>password</code> string yes Admin password <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/auth/setup/ \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"username\": \"admin\", \"password\": \"mypassword\"}'\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"key\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n  \"requires_mfa\": false\n}\n</code></pre> <p>Error (409):</p> <pre><code>{\n  \"detail\": \"Setup already completed.\"\n}\n</code></pre>"},{"location":"api/auth/#mfa-endpoints","title":"MFA Endpoints","text":"<p>Multi-factor authentication (MFA) uses TOTP (Time-based One-Time Passwords). Users can set up MFA with any TOTP-compatible authenticator app.</p>"},{"location":"api/auth/#post-apiv1authmfasetup","title":"POST /api/v1/auth/mfa/setup/","text":"<p>Generate a TOTP secret for the current user. Does not enable MFA until verified.</p> <p>Authentication: Bearer token required.</p> <p>Response (200):</p> <pre><code>{\n  \"secret\": \"JBSWY3DPEHPK3PXP\",\n  \"provisioning_uri\": \"otpauth://totp/Pipelit:admin?secret=JBSWY3DPEHPK3PXP&amp;issuer=Pipelit\"\n}\n</code></pre> <p>Error (400): <code>\"MFA is already enabled.\"</code></p>"},{"location":"api/auth/#post-apiv1authmfaverify","title":"POST /api/v1/auth/mfa/verify/","text":"<p>Verify a TOTP code and enable MFA on the account.</p> <p>Authentication: Bearer token required.</p> <p>Request body:</p> Field Type Required Description <code>code</code> string yes 6-digit TOTP code <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/auth/mfa/verify/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"code\": \"123456\"}'\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"mfa_enabled\": true\n}\n</code></pre>"},{"location":"api/auth/#post-apiv1authmfadisable","title":"POST /api/v1/auth/mfa/disable/","text":"<p>Disable MFA after verifying a TOTP code.</p> <p>Authentication: Bearer token required.</p> <p>Request body:</p> Field Type Required Description <code>code</code> string yes 6-digit TOTP code <p>Response (200):</p> <pre><code>{\n  \"mfa_enabled\": false\n}\n</code></pre>"},{"location":"api/auth/#get-apiv1authmfastatus","title":"GET /api/v1/auth/mfa/status/","text":"<p>Return current MFA status for the authenticated user.</p> <p>Authentication: Bearer token required.</p> <p>Response (200):</p> <pre><code>{\n  \"mfa_enabled\": false\n}\n</code></pre>"},{"location":"api/auth/#post-apiv1authmfalogin-verify","title":"POST /api/v1/auth/mfa/login-verify/","text":"<p>Complete MFA login. Called after <code>POST /token/</code> returns <code>requires_mfa: true</code>.</p> <p>Authentication: None required.</p> <p>Request body:</p> Field Type Required Description <code>username</code> string yes Username <code>code</code> string yes 6-digit TOTP code <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/auth/mfa/login-verify/ \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"username\": \"admin\", \"code\": \"123456\"}'\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"key\": \"a1b2c3d4-e5f6-7890-abcd-ef1234567890\",\n  \"requires_mfa\": false\n}\n</code></pre> <p>Error (401): <code>\"Invalid credentials.\"</code> or <code>\"Invalid TOTP code.\"</code></p>"},{"location":"api/auth/#post-apiv1authmfareset","title":"POST /api/v1/auth/mfa/reset/","text":"<p>Emergency MFA reset. Only allowed from loopback addresses (127.0.0.1, ::1, localhost).</p> <p>Authentication: Bearer token required.</p> <p>Response (200):</p> <pre><code>{\n  \"mfa_enabled\": false\n}\n</code></pre> <p>Error (403): <code>\"MFA reset only allowed from localhost.\"</code></p>"},{"location":"api/chat/","title":"Chat","text":""},{"location":"api/chat/#chat","title":"Chat","text":"<p>Chat endpoints for sending messages to workflows with chat triggers and managing chat history. Messages are sent to a workflow's <code>trigger_chat</code> node, which starts a new execution.</p> <p>All endpoints are under <code>/api/v1/workflows/{slug}/chat/</code> and require Bearer token authentication.</p>"},{"location":"api/chat/#post-apiv1workflowsslugchat","title":"POST /api/v1/workflows/{slug}/chat/","text":"<p>Send a chat message to a workflow and start a new execution. The workflow must have at least one <code>trigger_chat</code> node.</p> <p>The execution runs asynchronously via a background job. Use the WebSocket to receive real-time status updates and the final response.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Request body:</p> Field Type Required Description <code>text</code> string yes Chat message text <code>trigger_node_id</code> string no Specific chat trigger node ID. If omitted, uses the first <code>trigger_chat</code> node. <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/chat/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"text\": \"Hello, I need help with my order\"}'\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"execution_id\": \"abc12345-def6-7890-abcd-ef1234567890\",\n  \"status\": \"pending\",\n  \"response\": \"\"\n}\n</code></pre> Field Type Description <code>execution_id</code> string UUID of the created execution <code>status</code> string Initial status (always <code>\"pending\"</code>) <code>response</code> string Empty initially; the actual response arrives via WebSocket <p>Error (404):</p> <ul> <li><code>\"Workflow not found.\"</code> -- workflow with the given slug does not exist.</li> <li><code>\"No chat trigger found.\"</code> -- workflow has no <code>trigger_chat</code> node (or the specified <code>trigger_node_id</code> does not match a chat trigger).</li> </ul>"},{"location":"api/chat/#get-apiv1workflowsslugchathistory","title":"GET /api/v1/workflows/{slug}/chat/history","text":"<p>Load chat history from LangGraph checkpoints for the authenticated user's conversation with this workflow.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 10 Max messages to return <code>before</code> string <code>null</code> ISO datetime string -- only return messages before this time <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/workflows/my-chatbot/chat/history?limit=20\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"messages\": [\n    {\n      \"role\": \"user\",\n      \"text\": \"Hello, I need help with my order\",\n      \"timestamp\": \"2025-01-15T10:30:00\"\n    },\n    {\n      \"role\": \"assistant\",\n      \"text\": \"I'd be happy to help! Could you provide your order number?\",\n      \"timestamp\": \"2025-01-15T10:30:05\"\n    }\n  ],\n  \"thread_id\": \"1:5\",\n  \"has_more\": false\n}\n</code></pre> Field Type Description <code>messages</code> array List of chat messages <code>thread_id</code> string Checkpoint thread ID (format: <code>{user_id}:{workflow_id}</code>) <code>has_more</code> boolean Whether older messages exist beyond the current page <p>Message fields:</p> Field Type Description <code>role</code> string <code>\"user\"</code> or <code>\"assistant\"</code> <code>text</code> string Message content <code>timestamp</code> string or null ISO datetime when the message was created"},{"location":"api/chat/#delete-apiv1workflowsslugchathistory","title":"DELETE /api/v1/workflows/{slug}/chat/history","text":"<p>Clear all chat history for the authenticated user's conversation with this workflow. This deletes the LangGraph checkpoint data.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/workflows/my-chatbot/chat/history \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Error (404): <code>\"Workflow not found.\"</code></p> <p>Warning</p> <p>This permanently deletes the conversation history stored in checkpoints. The agent will have no memory of previous conversations after this operation.</p>"},{"location":"api/credentials/","title":"Credentials","text":""},{"location":"api/credentials/#credentials","title":"Credentials","text":"<p>Endpoints for managing credentials (LLM providers, Telegram bots, Git repositories, tool configs). Credentials are global -- any authenticated user can access them. Sensitive fields (API keys, tokens) are masked in responses.</p> <p>All endpoints are under <code>/api/v1/credentials/</code> and require Bearer token authentication.</p>"},{"location":"api/credentials/#credential-types","title":"Credential Types","text":"Type Description Detail Fields <code>llm</code> LLM provider API key <code>provider_type</code>, <code>api_key</code>, <code>base_url</code>, <code>organization_id</code>, <code>custom_headers</code> <code>telegram</code> Telegram bot token <code>bot_token</code>, <code>allowed_user_ids</code> <code>git</code> Git repository credential <code>provider</code>, <code>credential_type</code>, <code>username</code>, <code>ssh_private_key</code>, <code>access_token</code> <code>tool</code> Tool-specific credential <code>tool_type</code>, <code>config</code>"},{"location":"api/credentials/#get-apiv1credentials","title":"GET /api/v1/credentials/","text":"<p>List all credentials. API keys and tokens are masked in responses.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/credentials/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"OpenAI Production\",\n      \"credential_type\": \"llm\",\n      \"detail\": {\n        \"provider_type\": \"openai_compatible\",\n        \"api_key\": \"sk-p****ab12\",\n        \"base_url\": \"https://api.openai.com/v1\",\n        \"organization_id\": \"\",\n        \"custom_headers\": {}\n      },\n      \"created_at\": \"2025-01-15T10:30:00\",\n      \"updated_at\": \"2025-01-15T10:30:00\"\n    },\n    {\n      \"id\": 2,\n      \"name\": \"My Telegram Bot\",\n      \"credential_type\": \"telegram\",\n      \"detail\": {\n        \"bot_token\": \"1234****6789\",\n        \"allowed_user_ids\": \"123456789\"\n      },\n      \"created_at\": \"2025-01-15T11:00:00\",\n      \"updated_at\": \"2025-01-15T11:00:00\"\n    }\n  ],\n  \"total\": 2\n}\n</code></pre>"},{"location":"api/credentials/#post-apiv1credentials","title":"POST /api/v1/credentials/","text":"<p>Create a new credential.</p> <p>Request body:</p> Field Type Required Description <code>name</code> string yes Display name <code>credential_type</code> string yes One of: <code>llm</code>, <code>telegram</code>, <code>git</code>, <code>tool</code> <code>detail</code> object no Type-specific configuration (see below)"},{"location":"api/credentials/#llm-detail-fields","title":"LLM Detail Fields","text":"Field Type Default Description <code>provider_type</code> string <code>\"openai_compatible\"</code> <code>\"openai_compatible\"</code> or <code>\"anthropic\"</code> <code>api_key</code> string <code>\"\"</code> API key <code>base_url</code> string <code>\"\"</code> API base URL (required for non-standard providers) <code>organization_id</code> string <code>\"\"</code> Organization ID (OpenAI) <code>custom_headers</code> object <code>{}</code> Custom HTTP headers"},{"location":"api/credentials/#telegram-detail-fields","title":"Telegram Detail Fields","text":"Field Type Default Description <code>bot_token</code> string <code>\"\"</code> Telegram bot token from BotFather <code>allowed_user_ids</code> string <code>\"\"</code> Comma-separated allowed Telegram user IDs"},{"location":"api/credentials/#git-detail-fields","title":"Git Detail Fields","text":"Field Type Default Description <code>provider</code> string <code>\"github\"</code> Git provider (<code>github</code>, <code>gitlab</code>, etc.) <code>credential_type</code> string <code>\"token\"</code> Auth method (<code>token</code>, <code>ssh</code>) <code>username</code> string <code>\"\"</code> Git username <code>ssh_private_key</code> string <code>\"\"</code> SSH private key (for SSH auth) <code>access_token</code> string <code>\"\"</code> Access token (for token auth) <code>webhook_secret</code> string <code>\"\"</code> Webhook secret for verifying payloads"},{"location":"api/credentials/#tool-detail-fields","title":"Tool Detail Fields","text":"Field Type Default Description <code>tool_type</code> string <code>\"api\"</code> Tool type identifier <code>config</code> object <code>{}</code> Tool-specific configuration <p>Example request -- LLM credential:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/credentials/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"OpenAI Production\",\n    \"credential_type\": \"llm\",\n    \"detail\": {\n      \"provider_type\": \"openai_compatible\",\n      \"api_key\": \"sk-proj-abc123...\",\n      \"base_url\": \"https://api.openai.com/v1\"\n    }\n  }'\n</code></pre> <p>Response (201): Credential object (API key masked in response).</p>"},{"location":"api/credentials/#get-apiv1credentialscredential_id","title":"GET /api/v1/credentials/{credential_id}/","text":"<p>Get a single credential by ID.</p> <p>Path parameters:</p> Parameter Type Description <code>credential_id</code> int Credential ID <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/credentials/1/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200): Credential object.</p> <p>Error (404): <code>\"Credential not found.\"</code></p>"},{"location":"api/credentials/#patch-apiv1credentialscredential_id","title":"PATCH /api/v1/credentials/{credential_id}/","text":"<p>Update a credential. Only include fields you want to change.</p> <p>Path parameters:</p> Parameter Type Description <code>credential_id</code> int Credential ID <p>Request body:</p> Field Type Required Description <code>name</code> string no New display name <code>detail</code> object no Updated type-specific fields <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/credentials/1/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"detail\": {\n      \"api_key\": \"sk-proj-new-key-abc123...\"\n    }\n  }'\n</code></pre> <p>Response (200): Updated credential object.</p> <p>Error (404): <code>\"Credential not found.\"</code></p>"},{"location":"api/credentials/#delete-apiv1credentialscredential_id","title":"DELETE /api/v1/credentials/{credential_id}/","text":"<p>Delete a credential.</p> <p>Path parameters:</p> Parameter Type Description <code>credential_id</code> int Credential ID <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/credentials/1/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Error (404): <code>\"Credential not found.\"</code></p>"},{"location":"api/credentials/#post-apiv1credentialsbatch-delete","title":"POST /api/v1/credentials/batch-delete/","text":"<p>Batch delete multiple credentials.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> int[] yes List of credential IDs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/credentials/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ids\": [1, 2, 3]}'\n</code></pre> <p>Response (204): No content.</p>"},{"location":"api/credentials/#post-apiv1credentialscredential_idtest","title":"POST /api/v1/credentials/{credential_id}/test/","text":"<p>Test an LLM credential by making a minimal API call to verify the key works.</p> <p>Path parameters:</p> Parameter Type Description <code>credential_id</code> int Credential ID (must be type <code>llm</code>) <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/credentials/1/test/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200) -- success:</p> <pre><code>{\n  \"ok\": true,\n  \"error\": \"\"\n}\n</code></pre> <p>Response (200) -- failure:</p> <pre><code>{\n  \"ok\": false,\n  \"error\": \"Authentication failed - invalid API key\"\n}\n</code></pre> <p>Error (404): <code>\"LLM credential not found.\"</code></p>"},{"location":"api/credentials/#get-apiv1credentialscredential_idmodels","title":"GET /api/v1/credentials/{credential_id}/models/","text":"<p>List available models for an LLM credential. For Anthropic credentials, returns a curated list. For OpenAI-compatible providers, queries the <code>/models</code> endpoint.</p> <p>Path parameters:</p> Parameter Type Description <code>credential_id</code> int Credential ID (must be type <code>llm</code>) <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/credentials/1/models/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>[\n  {\"id\": \"gpt-4o\", \"name\": \"gpt-4o\"},\n  {\"id\": \"gpt-4o-mini\", \"name\": \"gpt-4o-mini\"},\n  {\"id\": \"gpt-3.5-turbo\", \"name\": \"gpt-3.5-turbo\"}\n]\n</code></pre> <p>Error (404): <code>\"LLM credential not found.\"</code></p>"},{"location":"api/edges/","title":"Edges","text":""},{"location":"api/edges/#edges","title":"Edges","text":"<p>Edge (connection) CRUD endpoints for managing connections between workflow nodes. Edges are nested under their parent workflow.</p> <p>All endpoints are under <code>/api/v1/workflows/{slug}/edges/</code> and require Bearer token authentication.</p>"},{"location":"api/edges/#concepts","title":"Concepts","text":""},{"location":"api/edges/#edge-types","title":"Edge Types","text":"Type Description <code>direct</code> Standard data flow between nodes <code>conditional</code> Conditional routing from <code>switch</code> nodes. Each conditional edge carries a <code>condition_value</code> that is matched against the switch node's output route."},{"location":"api/edges/#edge-labels","title":"Edge Labels","text":"<p>Edge labels indicate the type of connection:</p> Label Description <code>\"\"</code> (empty) Standard data flow <code>llm</code> Model connection (ai_model to an AI node) <code>tool</code> Tool connection (tool node to agent) <code>memory</code> Memory connection <code>output_parser</code> Output parser connection <code>loop_body</code> Loop node to body node (flow control) <code>loop_return</code> Body node back to loop node (flow control)"},{"location":"api/edges/#validation","title":"Validation","text":"<p>When creating edges, the API validates type compatibility between source outputs and target inputs. Incompatible connections return a <code>422</code> error with validation details.</p> <p>Loop flow-control edges (<code>loop_body</code>, <code>loop_return</code>) bypass type-compatibility validation.</p> <p>Conditional edges can only originate from <code>switch</code> nodes.</p>"},{"location":"api/edges/#get-apiv1workflowsslugedges","title":"GET /api/v1/workflows/{slug}/edges/","text":"<p>List all edges in a workflow.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/workflows/my-chatbot/edges/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"source_node_id\": \"trigger_chat_a1b2c3\",\n    \"target_node_id\": \"agent_abc123\",\n    \"edge_type\": \"direct\",\n    \"edge_label\": \"\",\n    \"condition_mapping\": null,\n    \"condition_value\": \"\",\n    \"priority\": 0\n  },\n  {\n    \"id\": 2,\n    \"source_node_id\": \"ai_model_xyz789\",\n    \"target_node_id\": \"agent_abc123\",\n    \"edge_type\": \"direct\",\n    \"edge_label\": \"llm\",\n    \"condition_mapping\": null,\n    \"condition_value\": \"\",\n    \"priority\": 0\n  }\n]\n</code></pre> <p>Note</p> <p>Edge list endpoints return a flat array, not a paginated envelope.</p>"},{"location":"api/edges/#post-apiv1workflowsslugedges","title":"POST /api/v1/workflows/{slug}/edges/","text":"<p>Create a new edge connecting two nodes.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Request body:</p> Field Type Required Default Description <code>source_node_id</code> string yes Source node ID <code>target_node_id</code> string yes Target node ID <code>edge_type</code> string no <code>\"direct\"</code> <code>\"direct\"</code> or <code>\"conditional\"</code> <code>edge_label</code> string no <code>\"\"</code> Connection type label (see Edge Labels) <code>condition_mapping</code> object no <code>null</code> Legacy: mapping of route values to target node IDs <code>condition_value</code> string no <code>\"\"</code> Route value for conditional edges <code>priority</code> int no <code>0</code> Edge priority <p>Example -- data flow edge:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/edges/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source_node_id\": \"trigger_chat_a1b2c3\",\n    \"target_node_id\": \"agent_abc123\"\n  }'\n</code></pre> <p>Example -- model connection (LLM edge):</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/edges/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source_node_id\": \"ai_model_xyz789\",\n    \"target_node_id\": \"agent_abc123\",\n    \"edge_label\": \"llm\"\n  }'\n</code></pre> <p>Example -- conditional edge from a switch node:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/edges/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"source_node_id\": \"switch_def456\",\n    \"target_node_id\": \"agent_support\",\n    \"edge_type\": \"conditional\",\n    \"condition_value\": \"support\"\n  }'\n</code></pre> <p>Response (201):</p> <pre><code>{\n  \"id\": 3,\n  \"source_node_id\": \"trigger_chat_a1b2c3\",\n  \"target_node_id\": \"agent_abc123\",\n  \"edge_type\": \"direct\",\n  \"edge_label\": \"\",\n  \"condition_mapping\": null,\n  \"condition_value\": \"\",\n  \"priority\": 0\n}\n</code></pre> <p>Broadcasts an <code>edge_created</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (422) -- type mismatch:</p> <pre><code>{\n  \"detail\": {\n    \"validation_errors\": [\n      \"Source type 'calculator' output 'result' (number) is not compatible with target 'ai_model' input 'model' (llm)\"\n    ]\n  }\n}\n</code></pre> <p>Error (422) -- conditional edge rules:</p> <ul> <li><code>\"Conditional edges require a non-empty condition_value\"</code></li> <li><code>\"Conditional edges require a non-empty target_node_id\"</code></li> <li><code>\"Conditional edges can only originate from 'switch' nodes\"</code></li> </ul>"},{"location":"api/edges/#patch-apiv1workflowsslugedgesedge_id","title":"PATCH /api/v1/workflows/{slug}/edges/{edge_id}/","text":"<p>Update an existing edge.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <code>edge_id</code> int Edge database ID <p>Request body (all fields optional):</p> Field Type Description <code>source_node_id</code> string Source node ID <code>target_node_id</code> string Target node ID <code>edge_type</code> string <code>\"direct\"</code> or <code>\"conditional\"</code> <code>edge_label</code> string Connection type label <code>condition_mapping</code> object Route-to-target mapping <code>condition_value</code> string Route value for conditional edges <code>priority</code> int Edge priority <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/workflows/my-chatbot/edges/3/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"condition_value\": \"billing\"}'\n</code></pre> <p>Response (200): Updated edge object.</p> <p>Broadcasts an <code>edge_updated</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (404): <code>\"Edge not found.\"</code></p>"},{"location":"api/edges/#delete-apiv1workflowsslugedgesedge_id","title":"DELETE /api/v1/workflows/{slug}/edges/{edge_id}/","text":"<p>Delete an edge. If the edge has an <code>llm</code> label, the sub-component link on the target node is also cleared.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <code>edge_id</code> int Edge database ID <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/workflows/my-chatbot/edges/3/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Broadcasts an <code>edge_deleted</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (404): <code>\"Edge not found.\"</code></p>"},{"location":"api/epics/","title":"Epics","text":""},{"location":"api/epics/#epics","title":"Epics","text":"<p>Endpoints for managing epics -- high-level project containers that group related tasks. Epics track progress, budgets, and task completion.</p> <p>All endpoints are under <code>/api/v1/epics/</code> and require Bearer token authentication.</p>"},{"location":"api/epics/#epic-statuses","title":"Epic Statuses","text":"Status Description <code>planning</code> Initial state, epic is being defined <code>active</code> Epic is in progress <code>paused</code> Epic is temporarily paused <code>completed</code> All tasks completed successfully <code>failed</code> Epic failed <code>cancelled</code> Epic was cancelled (cascades to pending/blocked/running tasks)"},{"location":"api/epics/#get-apiv1epics","title":"GET /api/v1/epics/","text":"<p>List epics with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <code>status</code> string <code>null</code> Filter by status <code>tags</code> string <code>null</code> Comma-separated tags to filter by <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/epics/?status=active&amp;tags=backend\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"epic-uuid-1234\",\n      \"title\": \"Implement user dashboard\",\n      \"description\": \"Build the user-facing dashboard with analytics\",\n      \"tags\": [\"frontend\", \"dashboard\"],\n      \"created_by_node_id\": null,\n      \"workflow_id\": 1,\n      \"user_profile_id\": 1,\n      \"status\": \"active\",\n      \"priority\": 2,\n      \"budget_tokens\": 100000,\n      \"budget_usd\": 5.0,\n      \"spent_tokens\": 45000,\n      \"spent_usd\": 2.25,\n      \"agent_overhead_tokens\": 5000,\n      \"agent_overhead_usd\": 0.25,\n      \"total_tasks\": 8,\n      \"completed_tasks\": 3,\n      \"failed_tasks\": 0,\n      \"created_at\": \"2025-01-15T09:00:00\",\n      \"updated_at\": \"2025-01-15T12:00:00\",\n      \"completed_at\": null,\n      \"result_summary\": null\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/epics/#post-apiv1epics","title":"POST /api/v1/epics/","text":"<p>Create a new epic.</p> <p>Request body:</p> Field Type Required Default Description <code>title</code> string yes Epic title <code>description</code> string no <code>\"\"</code> Description <code>tags</code> string[] no <code>[]</code> Tags for categorization <code>priority</code> int no <code>2</code> Priority level <code>budget_tokens</code> int or null no <code>null</code> Token budget limit <code>budget_usd</code> float or null no <code>null</code> USD budget limit <code>workflow_id</code> int or null no <code>null</code> Associated workflow ID <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/epics/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"title\": \"Implement user dashboard\",\n    \"description\": \"Build the user-facing dashboard with analytics\",\n    \"tags\": [\"frontend\", \"dashboard\"],\n    \"budget_tokens\": 100000,\n    \"workflow_id\": 1\n  }'\n</code></pre> <p>Response (201): Epic object.</p> <p>Broadcasts an <code>epic_created</code> WebSocket event on the <code>epic:&lt;id&gt;</code> channel.</p>"},{"location":"api/epics/#get-apiv1epicsepic_id","title":"GET /api/v1/epics/{epic_id}/","text":"<p>Get an epic by ID.</p> <p>Path parameters:</p> Parameter Type Description <code>epic_id</code> string Epic UUID <p>Response (200): Epic object.</p> <p>Error (404): <code>\"Epic not found.\"</code></p>"},{"location":"api/epics/#patch-apiv1epicsepic_id","title":"PATCH /api/v1/epics/{epic_id}/","text":"<p>Update an epic. Only include fields you want to change. Setting <code>status</code> to <code>\"cancelled\"</code> automatically cancels all pending, blocked, and running tasks.</p> <p>Path parameters:</p> Parameter Type Description <code>epic_id</code> string Epic UUID <p>Request body (all fields optional):</p> Field Type Description <code>title</code> string Epic title <code>description</code> string Description <code>tags</code> string[] Tags <code>status</code> string New status (see Epic Statuses) <code>priority</code> int Priority level <code>budget_tokens</code> int or null Token budget <code>budget_usd</code> float or null USD budget <code>result_summary</code> string Summary of results <p>Response (200): Updated epic object.</p> <p>Broadcasts an <code>epic_updated</code> WebSocket event on the <code>epic:&lt;id&gt;</code> channel.</p> <p>Error (404): <code>\"Epic not found.\"</code></p>"},{"location":"api/epics/#delete-apiv1epicsepic_id","title":"DELETE /api/v1/epics/{epic_id}/","text":"<p>Delete an epic and all its tasks.</p> <p>Path parameters:</p> Parameter Type Description <code>epic_id</code> string Epic UUID <p>Response (204): No content.</p> <p>Broadcasts an <code>epic_deleted</code> WebSocket event on the <code>epic:&lt;id&gt;</code> channel.</p> <p>Error (404): <code>\"Epic not found.\"</code></p>"},{"location":"api/epics/#post-apiv1epicsbatch-delete","title":"POST /api/v1/epics/batch-delete/","text":"<p>Batch delete epics and their associated tasks.</p> <p>Request body:</p> Field Type Required Description <code>epic_ids</code> string[] yes List of epic UUIDs to delete <p>Response (204): No content.</p>"},{"location":"api/epics/#get-apiv1epicsepic_idtasks","title":"GET /api/v1/epics/{epic_id}/tasks/","text":"<p>List tasks belonging to a specific epic.</p> <p>Path parameters:</p> Parameter Type Description <code>epic_id</code> string Epic UUID <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Response (200):</p> <pre><code>{\n  \"items\": [ ... ],\n  \"total\": 8\n}\n</code></pre> <p>See Tasks for the task object format.</p> <p>Error (404): <code>\"Epic not found.\"</code></p>"},{"location":"api/executions/","title":"Executions","text":""},{"location":"api/executions/#executions","title":"Executions","text":"<p>Endpoints for listing, inspecting, cancelling, and batch-deleting workflow executions.</p> <p>All endpoints are under <code>/api/v1/executions/</code> and require Bearer token authentication.</p>"},{"location":"api/executions/#get-apiv1executions","title":"GET /api/v1/executions/","text":"<p>List executions for the authenticated user, with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>workflow_slug</code> string <code>null</code> Filter by workflow slug <code>status</code> string <code>null</code> Filter by status (<code>pending</code>, <code>running</code>, <code>completed</code>, <code>failed</code>, <code>cancelled</code>) <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/executions/?workflow_slug=my-chatbot&amp;status=completed&amp;limit=10\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"execution_id\": \"abc12345-def6-7890-abcd-ef1234567890\",\n      \"workflow_slug\": \"my-chatbot\",\n      \"status\": \"completed\",\n      \"error_message\": \"\",\n      \"started_at\": \"2025-01-15T10:30:00\",\n      \"completed_at\": \"2025-01-15T10:30:05\",\n      \"total_tokens\": 1500,\n      \"total_cost_usd\": 0.0045,\n      \"llm_calls\": 2\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/executions/#get-apiv1executionsexecution_id","title":"GET /api/v1/executions/{execution_id}/","text":"<p>Get detailed execution information including logs.</p> <p>Path parameters:</p> Parameter Type Description <code>execution_id</code> string Execution UUID <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/executions/abc12345-def6-7890-abcd-ef1234567890/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"execution_id\": \"abc12345-def6-7890-abcd-ef1234567890\",\n  \"workflow_slug\": \"my-chatbot\",\n  \"status\": \"completed\",\n  \"error_message\": \"\",\n  \"started_at\": \"2025-01-15T10:30:00\",\n  \"completed_at\": \"2025-01-15T10:30:05\",\n  \"total_tokens\": 1500,\n  \"total_cost_usd\": 0.0045,\n  \"llm_calls\": 2,\n  \"final_output\": {\"output\": \"Hello! How can I help you?\"},\n  \"trigger_payload\": {\"text\": \"Hi there\"},\n  \"logs\": [\n    {\n      \"id\": 1,\n      \"node_id\": \"trigger_chat_a1b2c3\",\n      \"status\": \"success\",\n      \"input\": null,\n      \"output\": {\"text\": \"Hi there\"},\n      \"error\": \"\",\n      \"error_code\": null,\n      \"metadata\": null,\n      \"duration_ms\": 5,\n      \"timestamp\": \"2025-01-15T10:30:00\"\n    },\n    {\n      \"id\": 2,\n      \"node_id\": \"agent_abc123\",\n      \"status\": \"success\",\n      \"input\": {\"text\": \"Hi there\"},\n      \"output\": {\"output\": \"Hello! How can I help you?\"},\n      \"error\": \"\",\n      \"error_code\": null,\n      \"metadata\": {\"model\": \"claude-3-5-sonnet\", \"tokens\": 1500},\n      \"duration_ms\": 4200,\n      \"timestamp\": \"2025-01-15T10:30:01\"\n    }\n  ]\n}\n</code></pre> <p>Error (404): <code>\"Execution not found.\"</code></p>"},{"location":"api/executions/#execution-log-fields","title":"Execution Log Fields","text":"<p>Each log entry represents one node's execution result:</p> Field Type Description <code>id</code> int Log entry ID <code>node_id</code> string Node that produced this log <code>status</code> string <code>success</code>, <code>failed</code>, or <code>skipped</code> <code>input</code> any or null Input data received by the node <code>output</code> any or null Output data produced by the node <code>error</code> string Error message (empty on success) <code>error_code</code> string or null Machine-readable error code <code>metadata</code> object or null Execution metadata (model, tokens, etc.) <code>duration_ms</code> int Execution time in milliseconds <code>timestamp</code> datetime When this log was recorded"},{"location":"api/executions/#post-apiv1executionsexecution_idcancel","title":"POST /api/v1/executions/{execution_id}/cancel/","text":"<p>Cancel a running, pending, or interrupted execution.</p> <p>Path parameters:</p> Parameter Type Description <code>execution_id</code> string Execution UUID <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/executions/abc12345-def6-7890-abcd-ef1234567890/cancel/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200): The execution object with updated status.</p> <pre><code>{\n  \"execution_id\": \"abc12345-def6-7890-abcd-ef1234567890\",\n  \"workflow_slug\": \"my-chatbot\",\n  \"status\": \"cancelled\",\n  \"error_message\": \"\",\n  \"started_at\": \"2025-01-15T10:30:00\",\n  \"completed_at\": \"2025-01-15T10:30:03\",\n  \"total_tokens\": 0,\n  \"total_cost_usd\": 0.0,\n  \"llm_calls\": 0\n}\n</code></pre> <p>Broadcasts an <code>execution_cancelled</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (404): <code>\"Execution not found.\"</code></p> <p>Note</p> <p>Cancellation only applies to executions with status <code>pending</code>, <code>running</code>, or <code>interrupted</code>. Already completed or failed executions are returned unchanged.</p>"},{"location":"api/executions/#post-apiv1executionsbatch-delete","title":"POST /api/v1/executions/batch-delete/","text":"<p>Permanently delete multiple executions and their associated logs.</p> <p>Request body:</p> Field Type Required Description <code>execution_ids</code> string[] yes List of execution UUIDs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/executions/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"execution_ids\": [\"abc12345-def6-7890-abcd-ef1234567890\"]}'\n</code></pre> <p>Response (204): No content.</p> <p>Warning</p> <p>This permanently deletes executions and their logs. This action cannot be undone.</p>"},{"location":"api/memory-api/","title":"Memory","text":""},{"location":"api/memory-api/#memory","title":"Memory","text":"<p>Endpoints for managing agent memory stores: facts, episodes, procedures, memory users, and checkpoints. Each resource type supports listing (with pagination and filtering) and batch deletion.</p> <p>All endpoints are under <code>/api/v1/memories/</code> and require Bearer token authentication.</p>"},{"location":"api/memory-api/#facts","title":"Facts","text":"<p>Facts are key-value knowledge entries stored by agents. They have a scope, type, and confidence level.</p>"},{"location":"api/memory-api/#get-apiv1memoriesfacts","title":"GET /api/v1/memories/facts/","text":"<p>List memory facts with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>scope</code> string <code>null</code> Filter by scope <code>fact_type</code> string <code>null</code> Filter by fact type <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/memories/facts/?scope=global&amp;limit=20\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"fact-uuid-1234\",\n      \"scope\": \"global\",\n      \"agent_id\": \"agent_abc123\",\n      \"user_id\": null,\n      \"key\": \"company_name\",\n      \"value\": \"Acme Corp\",\n      \"fact_type\": \"preference\",\n      \"confidence\": 0.95,\n      \"times_confirmed\": 3,\n      \"access_count\": 12,\n      \"created_at\": \"2025-01-15T10:30:00\",\n      \"updated_at\": \"2025-01-15T12:00:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/memory-api/#post-apiv1memoriesfactsbatch-delete","title":"POST /api/v1/memories/facts/batch-delete/","text":"<p>Batch delete facts by ID.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> string[] yes List of fact UUIDs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/memories/facts/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ids\": [\"fact-uuid-1234\", \"fact-uuid-5678\"]}'\n</code></pre> <p>Response (204): No content.</p>"},{"location":"api/memory-api/#episodes","title":"Episodes","text":"<p>Episodes represent interaction sessions between agents and users.</p>"},{"location":"api/memory-api/#get-apiv1memoriesepisodes","title":"GET /api/v1/memories/episodes/","text":"<p>List memory episodes with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>agent_id</code> string <code>null</code> Filter by agent ID <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/memories/episodes/?agent_id=agent_abc123\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"episode-uuid-1234\",\n      \"agent_id\": \"agent_abc123\",\n      \"user_id\": \"user-uuid-5678\",\n      \"trigger_type\": \"chat\",\n      \"success\": true,\n      \"error_code\": null,\n      \"summary\": \"Helped user with order tracking\",\n      \"started_at\": \"2025-01-15T10:30:00\",\n      \"ended_at\": \"2025-01-15T10:35:00\",\n      \"duration_ms\": 300000,\n      \"created_at\": \"2025-01-15T10:35:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/memory-api/#post-apiv1memoriesepisodesbatch-delete","title":"POST /api/v1/memories/episodes/batch-delete/","text":"<p>Batch delete episodes by ID.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> string[] yes List of episode UUIDs <p>Response (204): No content.</p>"},{"location":"api/memory-api/#procedures","title":"Procedures","text":"<p>Procedures are learned behavioral patterns that agents can reuse.</p>"},{"location":"api/memory-api/#get-apiv1memoriesprocedures","title":"GET /api/v1/memories/procedures/","text":"<p>List memory procedures with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>agent_id</code> string <code>null</code> Filter by agent ID <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/memories/procedures/\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"proc-uuid-1234\",\n      \"agent_id\": \"agent_abc123\",\n      \"name\": \"order_lookup\",\n      \"description\": \"Look up order status by order number\",\n      \"procedure_type\": \"tool_chain\",\n      \"times_used\": 15,\n      \"times_succeeded\": 14,\n      \"times_failed\": 1,\n      \"success_rate\": 0.933,\n      \"is_active\": true,\n      \"created_at\": \"2025-01-10T08:00:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/memory-api/#post-apiv1memoriesproceduresbatch-delete","title":"POST /api/v1/memories/procedures/batch-delete/","text":"<p>Batch delete procedures by ID.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> string[] yes List of procedure UUIDs <p>Response (204): No content.</p>"},{"location":"api/memory-api/#memory-users","title":"Memory Users","text":"<p>Memory users represent end-users that agents have interacted with and remembered.</p>"},{"location":"api/memory-api/#get-apiv1memoriesusers","title":"GET /api/v1/memories/users/","text":"<p>List memory users.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/memories/users/\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"user-uuid-1234\",\n      \"canonical_id\": \"telegram:123456789\",\n      \"display_name\": \"John Doe\",\n      \"telegram_id\": \"123456789\",\n      \"email\": null,\n      \"total_conversations\": 15,\n      \"last_seen_at\": \"2025-01-15T10:30:00\",\n      \"created_at\": \"2025-01-01T08:00:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/memory-api/#post-apiv1memoriesusersbatch-delete","title":"POST /api/v1/memories/users/batch-delete/","text":"<p>Batch delete memory users by ID.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> string[] yes List of memory user UUIDs <p>Response (204): No content.</p>"},{"location":"api/memory-api/#checkpoints","title":"Checkpoints","text":"<p>Checkpoints store LangGraph conversation state. They are used for agent conversation memory persistence.</p>"},{"location":"api/memory-api/#get-apiv1memoriescheckpoints","title":"GET /api/v1/memories/checkpoints/","text":"<p>List checkpoints with optional filtering by thread ID.</p> <p>Query parameters:</p> Parameter Type Default Description <code>thread_id</code> string <code>null</code> Filter by thread ID <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/memories/checkpoints/?thread_id=1:5\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"thread_id\": \"1:5\",\n      \"checkpoint_ns\": \"\",\n      \"checkpoint_id\": \"ckpt-uuid-1234\",\n      \"parent_checkpoint_id\": \"ckpt-uuid-0000\",\n      \"step\": 3,\n      \"source\": \"loop\",\n      \"blob_size\": 4096\n    }\n  ],\n  \"total\": 1\n}\n</code></pre> Field Type Description <code>thread_id</code> string Conversation thread identifier <code>checkpoint_ns</code> string Checkpoint namespace <code>checkpoint_id</code> string Unique checkpoint identifier <code>parent_checkpoint_id</code> string or null Parent checkpoint ID <code>step</code> int or null Step number in the graph execution <code>source</code> string or null Source of the checkpoint (<code>loop</code>, <code>input</code>, etc.) <code>blob_size</code> int Size of the serialized checkpoint in bytes"},{"location":"api/memory-api/#post-apiv1memoriescheckpointsbatch-delete","title":"POST /api/v1/memories/checkpoints/batch-delete/","text":"<p>Batch delete checkpoints by thread ID or checkpoint ID.</p> <p>Request body:</p> Field Type Required Description <code>thread_ids</code> string[] no Delete all checkpoints for these thread IDs <code>checkpoint_ids</code> string[] no Delete specific checkpoints by ID <p>At least one of <code>thread_ids</code> or <code>checkpoint_ids</code> should be provided.</p> <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/memories/checkpoints/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"thread_ids\": [\"1:5\", \"1:6\"]}'\n</code></pre> <p>Response (204): No content.</p> <p>Warning</p> <p>Deleting checkpoints removes the agent's conversation memory for the associated threads. This cannot be undone.</p>"},{"location":"api/nodes/","title":"Nodes","text":""},{"location":"api/nodes/#nodes","title":"Nodes","text":"<p>Node CRUD endpoints for managing workflow nodes. Nodes are nested under their parent workflow.</p> <p>All endpoints are under <code>/api/v1/workflows/{slug}/nodes/</code> and require Bearer token authentication.</p>"},{"location":"api/nodes/#get-apiv1workflowsslugnodes","title":"GET /api/v1/workflows/{slug}/nodes/","text":"<p>List all nodes in a workflow.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/workflows/my-chatbot/nodes/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>[\n  {\n    \"id\": 1,\n    \"node_id\": \"trigger_chat_a1b2c3\",\n    \"component_type\": \"trigger_chat\",\n    \"is_entry_point\": false,\n    \"interrupt_before\": false,\n    \"interrupt_after\": false,\n    \"position_x\": 100,\n    \"position_y\": 200,\n    \"config\": {\n      \"system_prompt\": \"\",\n      \"extra_config\": {},\n      \"llm_credential_id\": null,\n      \"model_name\": \"\",\n      \"temperature\": null,\n      \"max_tokens\": null,\n      \"frequency_penalty\": null,\n      \"presence_penalty\": null,\n      \"top_p\": null,\n      \"timeout\": null,\n      \"max_retries\": null,\n      \"response_format\": null,\n      \"llm_model_config_id\": null,\n      \"credential_id\": null,\n      \"is_active\": true,\n      \"priority\": 0,\n      \"trigger_config\": {}\n    },\n    \"subworkflow_id\": null,\n    \"code_block_id\": null,\n    \"updated_at\": \"2025-01-15T10:30:00\",\n    \"schedule_job\": null\n  }\n]\n</code></pre> <p>Note</p> <p>Node list endpoints return a flat array, not a paginated envelope.</p>"},{"location":"api/nodes/#post-apiv1workflowsslugnodes","title":"POST /api/v1/workflows/{slug}/nodes/","text":"<p>Create a new node in a workflow.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Request body:</p> Field Type Required Default Description <code>node_id</code> string yes Unique node identifier (e.g., <code>agent_abc123</code>) <code>component_type</code> string yes Node type (see Component Types) <code>is_entry_point</code> bool no <code>false</code> Whether this node is an entry point <code>interrupt_before</code> bool no <code>false</code> Pause execution before this node <code>interrupt_after</code> bool no <code>false</code> Pause execution after this node <code>position_x</code> int no <code>0</code> Canvas X position <code>position_y</code> int no <code>0</code> Canvas Y position <code>config</code> object no <code>{}</code> Component configuration (see below) <code>subworkflow_id</code> int no <code>null</code> ID of sub-workflow (for workflow nodes) <code>code_block_id</code> int no <code>null</code> ID of code block (for code nodes) <p>Config object fields:</p> Field Type Applies To Description <code>system_prompt</code> string AI nodes (agent, categorizer, router, extractor) System prompt for the LLM <code>extra_config</code> object All Type-specific configuration <code>llm_credential_id</code> int ai_model LLM credential to use <code>model_name</code> string ai_model Model identifier <code>temperature</code> float ai_model Sampling temperature <code>max_tokens</code> int ai_model Maximum output tokens <code>frequency_penalty</code> float ai_model Frequency penalty <code>presence_penalty</code> float ai_model Presence penalty <code>top_p</code> float ai_model Top-p sampling <code>timeout</code> int ai_model Request timeout in seconds <code>max_retries</code> int ai_model Max retry attempts <code>response_format</code> object ai_model Structured output format <code>credential_id</code> int Triggers Credential for trigger authentication <code>is_active</code> bool Triggers Whether the trigger is active <code>priority</code> int Triggers Trigger priority (0 = default) <code>trigger_config</code> object Triggers Trigger-specific settings <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/nodes/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"node_id\": \"agent_abc123\",\n    \"component_type\": \"agent\",\n    \"position_x\": 400,\n    \"position_y\": 200,\n    \"config\": {\n      \"system_prompt\": \"You are a helpful assistant.\"\n    }\n  }'\n</code></pre> <p>Response (201): Node object (same format as list response items).</p> <p>Broadcasts a <code>node_created</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p>"},{"location":"api/nodes/#patch-apiv1workflowsslugnodesnode_id","title":"PATCH /api/v1/workflows/{slug}/nodes/{node_id}/","text":"<p>Update an existing node's configuration or position.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <code>node_id</code> string Node identifier <p>Request body (all fields optional):</p> <p>Same fields as create, but all are optional. Only include the fields you want to update.</p> <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/workflows/my-chatbot/nodes/agent_abc123/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"position_x\": 500,\n    \"config\": {\n      \"system_prompt\": \"You are a customer support agent.\"\n    }\n  }'\n</code></pre> <p>Response (200): Updated node object.</p> <p>Broadcasts a <code>node_updated</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (404): <code>\"Node not found.\"</code></p>"},{"location":"api/nodes/#delete-apiv1workflowsslugnodesnode_id","title":"DELETE /api/v1/workflows/{slug}/nodes/{node_id}/","text":"<p>Delete a node and all its connected edges. If the node is a <code>trigger_schedule</code>, any associated scheduled job is also cleaned up.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <code>node_id</code> string Node identifier <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/workflows/my-chatbot/nodes/agent_abc123/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Broadcasts a <code>node_deleted</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p> <p>Error (404): <code>\"Node not found.\"</code></p>"},{"location":"api/nodes/#schedule-actions","title":"Schedule Actions","text":"<p>These endpoints manage the scheduled execution of <code>trigger_schedule</code> nodes.</p>"},{"location":"api/nodes/#post-apiv1workflowsslugnodesnode_idschedulestart","title":"POST /api/v1/workflows/{slug}/nodes/{node_id}/schedule/start","text":"<p>Start or restart a scheduled job for a <code>trigger_schedule</code> node. Configuration is read from the node's <code>extra_config</code>.</p> <p>Extra config fields:</p> Field Type Default Description <code>interval_seconds</code> int 300 Seconds between runs <code>total_repeats</code> int 0 Total runs (0 = unlimited) <code>max_retries</code> int 3 Max retries per run <code>timeout_seconds</code> int 600 Timeout per run <code>trigger_payload</code> object <code>{}</code> Payload passed to the trigger <p>Response (200): Updated node object.</p> <p>Error (400): <code>\"Node is not a trigger_schedule.\"</code></p>"},{"location":"api/nodes/#post-apiv1workflowsslugnodesnode_idschedulepause","title":"POST /api/v1/workflows/{slug}/nodes/{node_id}/schedule/pause","text":"<p>Pause an active scheduled job.</p> <p>Response (200): Updated node object.</p> <p>Error (400): <code>\"Cannot pause job with status 'paused'.\"</code></p>"},{"location":"api/nodes/#post-apiv1workflowsslugnodesnode_idschedulestop","title":"POST /api/v1/workflows/{slug}/nodes/{node_id}/schedule/stop","text":"<p>Stop and remove a scheduled job.</p> <p>Response (200): Updated node object.</p>"},{"location":"api/nodes/#component-types","title":"Component Types","text":"<p>The following component types are available:</p> Category Types AI <code>agent</code>, <code>categorizer</code>, <code>router</code>, <code>extractor</code> Models <code>ai_model</code> Routing <code>switch</code> Tools <code>run_command</code>, <code>http_request</code>, <code>web_search</code>, <code>calculator</code>, <code>datetime</code>, <code>create_agent_user</code>, <code>platform_api</code>, <code>whoami</code>, <code>epic_tools</code>, <code>task_tools</code>, <code>spawn_and_await</code>, <code>workflow_create</code>, <code>workflow_discover</code>, <code>scheduler_tools</code>, <code>system_health</code> Processing <code>aggregator</code>, <code>human_confirmation</code>, <code>workflow</code>, <code>code</code>, <code>code_execute</code>, <code>loop</code>, <code>wait</code>, <code>merge</code>, <code>filter</code>, <code>error_handler</code>, <code>output_parser</code> Memory <code>memory_read</code>, <code>memory_write</code>, <code>identify_user</code> Triggers <code>trigger_telegram</code>, <code>trigger_schedule</code>, <code>trigger_manual</code>, <code>trigger_workflow</code>, <code>trigger_error</code>, <code>trigger_chat</code>"},{"location":"api/schedules/","title":"Schedules","text":""},{"location":"api/schedules/#schedules","title":"Schedules","text":"<p>Endpoints for managing scheduled jobs. Scheduled jobs execute workflows on a recurring interval using a self-rescheduling mechanism via RQ (Redis Queue).</p> <p>All endpoints are under <code>/api/v1/schedules/</code> and require Bearer token authentication.</p>"},{"location":"api/schedules/#concepts","title":"Concepts","text":"<p>A <code>ScheduledJob</code> stores the interval, repeat count, retry configuration, and state machine status:</p> <ul> <li>Status flow: <code>active</code> -&gt; <code>paused</code> / <code>done</code> / <code>dead</code></li> <li>Repeat: Jobs run up to <code>total_repeats</code> times (0 = unlimited).</li> <li>Retry: On failure, exponential backoff up to 10x the interval. Max <code>max_retries</code> consecutive retries before marking as <code>dead</code>.</li> <li>Recovery: On server startup, any active jobs whose <code>next_run_at</code> is in the past are automatically re-enqueued.</li> </ul>"},{"location":"api/schedules/#get-apiv1schedules","title":"GET /api/v1/schedules/","text":"<p>List scheduled jobs with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <code>status</code> string <code>null</code> Filter by status (<code>active</code>, <code>paused</code>, <code>done</code>, <code>dead</code>) <code>workflow_id</code> int <code>null</code> Filter by workflow ID <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/schedules/?status=active&amp;limit=10\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"a1b2c3d4-e5f6-7890\",\n      \"name\": \"schedule:trigger_schedule_abc\",\n      \"description\": \"\",\n      \"workflow_id\": 1,\n      \"trigger_node_id\": \"trigger_schedule_abc\",\n      \"user_profile_id\": 1,\n      \"interval_seconds\": 300,\n      \"total_repeats\": 0,\n      \"max_retries\": 3,\n      \"timeout_seconds\": 600,\n      \"trigger_payload\": null,\n      \"status\": \"active\",\n      \"current_repeat\": 5,\n      \"current_retry\": 0,\n      \"last_run_at\": \"2025-01-15T10:30:00\",\n      \"next_run_at\": \"2025-01-15T10:35:00\",\n      \"run_count\": 5,\n      \"error_count\": 0,\n      \"last_error\": \"\",\n      \"created_at\": \"2025-01-15T09:00:00\",\n      \"updated_at\": \"2025-01-15T10:30:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/schedules/#post-apiv1schedules","title":"POST /api/v1/schedules/","text":"<p>Create and immediately start a new scheduled job.</p> <p>Request body:</p> Field Type Required Default Description <code>name</code> string yes Job name <code>description</code> string no <code>\"\"</code> Description <code>workflow_id</code> int yes Target workflow ID <code>trigger_node_id</code> string no <code>null</code> Specific trigger node to fire <code>interval_seconds</code> int yes Seconds between runs (must be &gt;= 1) <code>total_repeats</code> int no <code>0</code> Total runs (0 = unlimited, must be &gt;= 0) <code>max_retries</code> int no <code>3</code> Max consecutive retries (must be &gt;= 0) <code>timeout_seconds</code> int no <code>600</code> Timeout per run in seconds (must be &gt;= 1) <code>trigger_payload</code> object no <code>null</code> Payload passed to the trigger <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/schedules/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"Hourly health check\",\n    \"workflow_id\": 1,\n    \"trigger_node_id\": \"trigger_schedule_abc\",\n    \"interval_seconds\": 3600,\n    \"total_repeats\": 0,\n    \"max_retries\": 3\n  }'\n</code></pre> <p>Response (201): Scheduled job object.</p> <p>Error (404): <code>\"Workflow not found.\"</code></p> <p>Error (500): <code>\"Failed to start scheduled job.\"</code></p>"},{"location":"api/schedules/#get-apiv1schedulesjob_id","title":"GET /api/v1/schedules/{job_id}/","text":"<p>Get a scheduled job by ID.</p> <p>Path parameters:</p> Parameter Type Description <code>job_id</code> string Scheduled job UUID <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/schedules/a1b2c3d4-e5f6-7890/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200): Scheduled job object.</p> <p>Error (404): <code>\"Scheduled job not found.\"</code></p>"},{"location":"api/schedules/#patch-apiv1schedulesjob_id","title":"PATCH /api/v1/schedules/{job_id}/","text":"<p>Update a scheduled job's configuration. Only include fields you want to change.</p> <p>Path parameters:</p> Parameter Type Description <code>job_id</code> string Scheduled job UUID <p>Request body (all fields optional):</p> Field Type Description <code>name</code> string Job name <code>description</code> string Description <code>interval_seconds</code> int Seconds between runs (&gt;= 1) <code>total_repeats</code> int Total runs (&gt;= 0) <code>max_retries</code> int Max retries (&gt;= 0) <code>timeout_seconds</code> int Timeout per run (&gt;= 1) <code>trigger_payload</code> object Trigger payload <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/schedules/a1b2c3d4-e5f6-7890/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"interval_seconds\": 1800}'\n</code></pre> <p>Response (200): Updated scheduled job object.</p> <p>Error (404): <code>\"Scheduled job not found.\"</code></p>"},{"location":"api/schedules/#delete-apiv1schedulesjob_id","title":"DELETE /api/v1/schedules/{job_id}/","text":"<p>Delete a scheduled job.</p> <p>Path parameters:</p> Parameter Type Description <code>job_id</code> string Scheduled job UUID <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/schedules/a1b2c3d4-e5f6-7890/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Error (404): <code>\"Scheduled job not found.\"</code></p>"},{"location":"api/schedules/#post-apiv1schedulesjob_idpause","title":"POST /api/v1/schedules/{job_id}/pause/","text":"<p>Pause an active scheduled job. Only jobs with status <code>active</code> can be paused.</p> <p>Path parameters:</p> Parameter Type Description <code>job_id</code> string Scheduled job UUID <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/schedules/a1b2c3d4-e5f6-7890/pause/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200): Updated scheduled job object (status = <code>\"paused\"</code>).</p> <p>Error (400): <code>\"Cannot pause job with status 'paused'.\"</code></p> <p>Error (404): <code>\"Scheduled job not found.\"</code></p>"},{"location":"api/schedules/#post-apiv1schedulesjob_idresume","title":"POST /api/v1/schedules/{job_id}/resume/","text":"<p>Resume a paused scheduled job. Only jobs with status <code>paused</code> can be resumed.</p> <p>Path parameters:</p> Parameter Type Description <code>job_id</code> string Scheduled job UUID <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/schedules/a1b2c3d4-e5f6-7890/resume/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200): Updated scheduled job object (status = <code>\"active\"</code>).</p> <p>Error (400): <code>\"Cannot resume job with status 'active'.\"</code></p> <p>Error (404): <code>\"Scheduled job not found.\"</code></p>"},{"location":"api/schedules/#post-apiv1schedulesbatch-delete","title":"POST /api/v1/schedules/batch-delete/","text":"<p>Batch delete multiple scheduled jobs.</p> <p>Request body:</p> Field Type Required Description <code>schedule_ids</code> string[] yes List of scheduled job UUIDs <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/schedules/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"schedule_ids\": [\"a1b2c3d4-e5f6-7890\", \"b2c3d4e5-f6a7-8901\"]}'\n</code></pre> <p>Response (204): No content.</p>"},{"location":"api/tasks/","title":"Tasks","text":""},{"location":"api/tasks/#tasks","title":"Tasks","text":"<p>Endpoints for managing tasks within epics. Tasks represent individual units of work, support dependency chains, and track execution metrics.</p> <p>All endpoints are under <code>/api/v1/tasks/</code> and require Bearer token authentication.</p>"},{"location":"api/tasks/#task-statuses","title":"Task Statuses","text":"Status Description <code>pending</code> Ready to be worked on <code>blocked</code> Waiting for dependencies to complete <code>running</code> Currently being executed <code>completed</code> Successfully finished <code>failed</code> Execution failed <code>cancelled</code> Task was cancelled <p>Tasks with <code>depends_on</code> entries are automatically set to <code>blocked</code> on creation if their dependencies are not yet completed. When a dependency completes, blocked tasks are automatically unblocked.</p>"},{"location":"api/tasks/#get-apiv1tasks","title":"GET /api/v1/tasks/","text":"<p>List tasks with optional filtering.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <code>epic_id</code> string <code>null</code> Filter by epic ID <code>status</code> string <code>null</code> Filter by status <code>tags</code> string <code>null</code> Comma-separated tags to filter by <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/tasks/?epic_id=epic-uuid-1234&amp;status=pending\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": \"task-uuid-1234\",\n      \"epic_id\": \"epic-uuid-1234\",\n      \"title\": \"Create database schema\",\n      \"description\": \"Design and implement the user table schema\",\n      \"tags\": [\"backend\", \"database\"],\n      \"created_by_node_id\": null,\n      \"status\": \"completed\",\n      \"priority\": 1,\n      \"workflow_id\": null,\n      \"workflow_slug\": \"schema-generator\",\n      \"execution_id\": \"exec-uuid-5678\",\n      \"workflow_source\": \"inline\",\n      \"depends_on\": [],\n      \"requirements\": null,\n      \"estimated_tokens\": 5000,\n      \"actual_tokens\": 4200,\n      \"actual_usd\": 0.021,\n      \"llm_calls\": 3,\n      \"tool_invocations\": 1,\n      \"duration_ms\": 15000,\n      \"created_at\": \"2025-01-15T09:00:00\",\n      \"updated_at\": \"2025-01-15T09:15:00\",\n      \"started_at\": \"2025-01-15T09:00:05\",\n      \"completed_at\": \"2025-01-15T09:15:00\",\n      \"result_summary\": \"Created users table with 8 columns\",\n      \"error_message\": null,\n      \"retry_count\": 0,\n      \"max_retries\": 2,\n      \"notes\": []\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/tasks/#post-apiv1tasks","title":"POST /api/v1/tasks/","text":"<p>Create a new task within an epic.</p> <p>Request body:</p> Field Type Required Default Description <code>epic_id</code> string yes Parent epic ID <code>title</code> string yes Task title <code>description</code> string no <code>\"\"</code> Description <code>tags</code> string[] no <code>[]</code> Tags <code>depends_on</code> string[] no <code>[]</code> List of task IDs this task depends on <code>priority</code> int or null no <code>2</code> Priority level <code>workflow_slug</code> string no <code>null</code> Workflow to execute for this task <code>estimated_tokens</code> int or null no <code>null</code> Estimated token usage <code>max_retries</code> int no <code>2</code> Max retries on failure <code>requirements</code> object no <code>null</code> Task requirements specification <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/tasks/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"epic_id\": \"epic-uuid-1234\",\n    \"title\": \"Implement API endpoint\",\n    \"description\": \"Create the REST endpoint for user creation\",\n    \"depends_on\": [\"task-uuid-1234\"],\n    \"workflow_slug\": \"code-generator\",\n    \"estimated_tokens\": 8000\n  }'\n</code></pre> <p>Response (201): Task object. If <code>depends_on</code> contains uncompleted tasks, the initial status will be <code>\"blocked\"</code> instead of <code>\"pending\"</code>.</p> <p>Broadcasts a <code>task_created</code> WebSocket event on the <code>epic:&lt;epic_id&gt;</code> channel.</p> <p>Error (404): <code>\"Epic not found.\"</code></p>"},{"location":"api/tasks/#get-apiv1taskstask_id","title":"GET /api/v1/tasks/{task_id}/","text":"<p>Get a task by ID.</p> <p>Path parameters:</p> Parameter Type Description <code>task_id</code> string Task UUID <p>Response (200): Task object.</p> <p>Error (404): <code>\"Task not found.\"</code></p>"},{"location":"api/tasks/#patch-apiv1taskstask_id","title":"PATCH /api/v1/tasks/{task_id}/","text":"<p>Update a task. When a task is marked as <code>completed</code>, any dependent tasks that were <code>blocked</code> are automatically unblocked.</p> <p>Path parameters:</p> Parameter Type Description <code>task_id</code> string Task UUID <p>Request body (all fields optional):</p> Field Type Description <code>title</code> string Task title <code>description</code> string Description <code>tags</code> string[] Tags <code>status</code> string New status (see Task Statuses) <code>priority</code> int Priority level <code>workflow_slug</code> string Workflow slug <code>execution_id</code> string Associated execution ID <code>result_summary</code> string Summary of results <code>error_message</code> string Error message (on failure) <code>notes</code> array Task notes <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/tasks/task-uuid-5678/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"status\": \"completed\", \"result_summary\": \"Endpoint created successfully\"}'\n</code></pre> <p>Response (200): Updated task object.</p> <p>Broadcasts a <code>task_updated</code> WebSocket event on the <code>epic:&lt;epic_id&gt;</code> channel.</p> <p>Error (404): <code>\"Task not found.\"</code></p>"},{"location":"api/tasks/#delete-apiv1taskstask_id","title":"DELETE /api/v1/tasks/{task_id}/","text":"<p>Delete a task. Removes the task from any <code>depends_on</code> lists in sibling tasks and syncs the parent epic's progress counters.</p> <p>Path parameters:</p> Parameter Type Description <code>task_id</code> string Task UUID <p>Response (204): No content.</p> <p>Broadcasts a <code>task_deleted</code> WebSocket event on the <code>epic:&lt;epic_id&gt;</code> channel.</p> <p>Error (404): <code>\"Task not found.\"</code></p>"},{"location":"api/tasks/#post-apiv1tasksbatch-delete","title":"POST /api/v1/tasks/batch-delete/","text":"<p>Batch delete multiple tasks. Cleans up dependency references and syncs progress counters for all affected epics.</p> <p>Request body:</p> Field Type Required Description <code>task_ids</code> string[] yes List of task UUIDs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/tasks/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"task_ids\": [\"task-uuid-1234\", \"task-uuid-5678\"]}'\n</code></pre> <p>Response (204): No content.</p> <p>Broadcasts <code>tasks_deleted</code> WebSocket events on the <code>epic:&lt;epic_id&gt;</code> channel for each affected epic.</p>"},{"location":"api/users/","title":"Users","text":""},{"location":"api/users/#users","title":"Users","text":"<p>Endpoints for managing agent users. Agent users are programmatically created accounts (without passwords) used by workflows and agents to perform API operations.</p> <p>All endpoints are under <code>/api/v1/users/</code> and require Bearer token authentication.</p>"},{"location":"api/users/#get-apiv1usersagents","title":"GET /api/v1/users/agents/","text":"<p>List all agent users.</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl \"http://localhost:8000/api/v1/users/agents/\" \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 5,\n      \"username\": \"agent-workflow-chatbot\",\n      \"purpose\": \"Customer support chatbot agent\",\n      \"api_key_preview\": \"...abcd1234\",\n      \"created_at\": \"2025-01-15T10:30:00\",\n      \"created_by\": \"admin\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre> Field Type Description <code>id</code> int Agent user ID <code>username</code> string Agent username <code>purpose</code> string Purpose/description of the agent <code>api_key_preview</code> string Last 8 characters of the API key (masked) <code>created_at</code> datetime When the agent user was created <code>created_by</code> string or null Username of the creator"},{"location":"api/users/#delete-apiv1usersagentsuser_id","title":"DELETE /api/v1/users/agents/{user_id}/","text":"<p>Delete an agent user and revoke their API key.</p> <p>Path parameters:</p> Parameter Type Description <code>user_id</code> int Agent user ID <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/users/agents/5/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p> <p>Error (404): <code>\"Agent user not found\"</code></p>"},{"location":"api/users/#post-apiv1usersagentsbatch-delete","title":"POST /api/v1/users/agents/batch-delete/","text":"<p>Batch delete agent users and revoke their API keys.</p> <p>Request body:</p> Field Type Required Description <code>ids</code> int[] yes List of agent user IDs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/users/agents/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"ids\": [5, 6, 7]}'\n</code></pre> <p>Response (204): No content.</p> <p>Warning</p> <p>Deleting an agent user revokes their API key immediately. Any workflows or processes using that agent's key will lose access.</p>"},{"location":"api/websocket/","title":"WebSocket","text":""},{"location":"api/websocket/#websocket","title":"WebSocket","text":"<p>Pipelit uses a single global authenticated WebSocket connection for real-time event streaming. All workflow, node, edge, and execution events are delivered through this connection using Redis pub/sub fan-out.</p>"},{"location":"api/websocket/#connection","title":"Connection","text":""},{"location":"api/websocket/#endpoint","title":"Endpoint","text":"<pre><code>ws://localhost:8000/ws/?token=&lt;api_key&gt;\n</code></pre> <p>The <code>token</code> query parameter must be a valid API key (the same key used for Bearer token authentication).</p>"},{"location":"api/websocket/#authentication","title":"Authentication","text":"<p>Authentication happens on connection. If the token is missing or invalid, the server closes the WebSocket with code <code>1008</code> and reason <code>\"Invalid or missing token\"</code>.</p>"},{"location":"api/websocket/#connection-example-javascript","title":"Connection Example (JavaScript)","text":"<pre><code>const ws = new WebSocket(`ws://localhost:8000/ws/?token=${apiKey}`);\n\nws.onopen = () =&gt; {\n  console.log(\"Connected\");\n  // Subscribe to a workflow channel\n  ws.send(JSON.stringify({\n    type: \"subscribe\",\n    channel: \"workflow:my-chatbot\"\n  }));\n};\n\nws.onmessage = (event) =&gt; {\n  const data = JSON.parse(event.data);\n  console.log(\"Received:\", data);\n};\n</code></pre>"},{"location":"api/websocket/#heartbeat","title":"Heartbeat","text":"<p>The server sends a <code>ping</code> message every 30 seconds of inactivity. The client must respond with a <code>pong</code> within 10 seconds, or the connection will be closed.</p> <p>Server sends:</p> <pre><code>{\"type\": \"ping\"}\n</code></pre> <p>Client responds:</p> <pre><code>{\"type\": \"pong\"}\n</code></pre>"},{"location":"api/websocket/#subscription-protocol","title":"Subscription Protocol","text":"<p>Clients subscribe to channels to receive events. Only events from subscribed channels are forwarded.</p>"},{"location":"api/websocket/#subscribe","title":"Subscribe","text":"<p>Client sends:</p> <pre><code>{\n  \"type\": \"subscribe\",\n  \"channel\": \"workflow:my-chatbot\"\n}\n</code></pre> <p>Server responds:</p> <pre><code>{\n  \"type\": \"subscribed\",\n  \"channel\": \"workflow:my-chatbot\"\n}\n</code></pre>"},{"location":"api/websocket/#unsubscribe","title":"Unsubscribe","text":"<p>Client sends:</p> <pre><code>{\n  \"type\": \"unsubscribe\",\n  \"channel\": \"workflow:my-chatbot\"\n}\n</code></pre> <p>Server responds:</p> <pre><code>{\n  \"type\": \"unsubscribed\",\n  \"channel\": \"workflow:my-chatbot\"\n}\n</code></pre>"},{"location":"api/websocket/#channel-naming","title":"Channel Naming","text":"Pattern Description <code>workflow:&lt;slug&gt;</code> All events for a specific workflow (nodes, edges, executions) <code>execution:&lt;id&gt;</code> Events for a specific execution <code>epic:&lt;id&gt;</code> Events for a specific epic (epic and task updates)"},{"location":"api/websocket/#event-types","title":"Event Types","text":"<p>All events follow this envelope format:</p> <pre><code>{\n  \"type\": \"&lt;event_type&gt;\",\n  \"channel\": \"&lt;channel&gt;\",\n  \"timestamp\": 1705312200.123,\n  \"data\": { ... }\n}\n</code></pre> Field Type Description <code>type</code> string Event type identifier <code>channel</code> string Channel this event was published to <code>timestamp</code> float Unix timestamp when the event was published <code>data</code> object Event-specific payload"},{"location":"api/websocket/#workflow-events","title":"Workflow Events","text":"<p>Published on <code>workflow:&lt;slug&gt;</code> channels.</p>"},{"location":"api/websocket/#workflow_updated","title":"workflow_updated","text":"<p>Fired when a workflow's metadata is updated.</p> <pre><code>{\n  \"type\": \"workflow_updated\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"id\": 1,\n    \"name\": \"My Chatbot\",\n    \"slug\": \"my-chatbot\",\n    \"description\": \"Updated description\",\n    \"is_active\": true,\n    \"is_public\": false,\n    \"is_default\": false,\n    \"tags\": [],\n    \"node_count\": 3,\n    \"edge_count\": 2,\n    \"created_at\": \"2025-01-15T10:30:00\",\n    \"updated_at\": \"2025-01-15T12:00:00\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#node-events","title":"Node Events","text":"<p>Published on <code>workflow:&lt;slug&gt;</code> channels.</p>"},{"location":"api/websocket/#node_created","title":"node_created","text":"<pre><code>{\n  \"type\": \"node_created\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"id\": 1,\n    \"node_id\": \"agent_abc123\",\n    \"component_type\": \"agent\",\n    \"is_entry_point\": false,\n    \"interrupt_before\": false,\n    \"interrupt_after\": false,\n    \"position_x\": 400,\n    \"position_y\": 200,\n    \"config\": { ... },\n    \"updated_at\": \"2025-01-15T10:30:00\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#node_updated","title":"node_updated","text":"<p>Same payload as <code>node_created</code> but with updated fields.</p>"},{"location":"api/websocket/#node_deleted","title":"node_deleted","text":"<pre><code>{\n  \"type\": \"node_deleted\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"node_id\": \"agent_abc123\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#edge-events","title":"Edge Events","text":"<p>Published on <code>workflow:&lt;slug&gt;</code> channels.</p>"},{"location":"api/websocket/#edge_created","title":"edge_created","text":"<pre><code>{\n  \"type\": \"edge_created\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"id\": 1,\n    \"source_node_id\": \"trigger_chat_a1b2c3\",\n    \"target_node_id\": \"agent_abc123\",\n    \"edge_type\": \"direct\",\n    \"edge_label\": \"\",\n    \"condition_mapping\": null,\n    \"condition_value\": \"\",\n    \"priority\": 0\n  }\n}\n</code></pre>"},{"location":"api/websocket/#edge_updated","title":"edge_updated","text":"<p>Same payload as <code>edge_created</code> but with updated fields.</p>"},{"location":"api/websocket/#edge_deleted","title":"edge_deleted","text":"<pre><code>{\n  \"type\": \"edge_deleted\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"id\": 1\n  }\n}\n</code></pre>"},{"location":"api/websocket/#execution-events","title":"Execution Events","text":"<p>Published on <code>workflow:&lt;slug&gt;</code> channels by the orchestrator.</p>"},{"location":"api/websocket/#node_status","title":"node_status","text":"<p>Per-node execution status updates. Published as each node in the workflow starts and finishes.</p> <pre><code>{\n  \"type\": \"node_status\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312200.123,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\",\n    \"node_id\": \"agent_abc123\",\n    \"status\": \"running\"\n  }\n}\n</code></pre> <p>Status values: <code>pending</code>, <code>running</code>, <code>success</code>, <code>failed</code>, <code>skipped</code>.</p> <p>On <code>success</code>, the <code>data</code> object includes the node output:</p> <pre><code>{\n  \"type\": \"node_status\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312201.456,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\",\n    \"node_id\": \"agent_abc123\",\n    \"status\": \"success\",\n    \"output\": {\n      \"output\": \"Hello! How can I help you today?\"\n    }\n  }\n}\n</code></pre> <p>On <code>failed</code>, the <code>data</code> object includes error details:</p> <pre><code>{\n  \"type\": \"node_status\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312201.456,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\",\n    \"node_id\": \"agent_abc123\",\n    \"status\": \"failed\",\n    \"error\": \"LLM API returned 429: rate limit exceeded\",\n    \"error_code\": \"LLM_ERROR\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#execution_completed","title":"execution_completed","text":"<p>Fired when an entire execution finishes successfully.</p> <pre><code>{\n  \"type\": \"execution_completed\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312205.789,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#execution_failed","title":"execution_failed","text":"<p>Fired when an execution fails.</p> <pre><code>{\n  \"type\": \"execution_failed\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312205.789,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\",\n    \"error\": \"Node agent_abc123 failed: LLM API error\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#execution_interrupted","title":"execution_interrupted","text":"<p>Fired when an execution is interrupted (e.g., at a human confirmation node).</p> <pre><code>{\n  \"type\": \"execution_interrupted\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312205.789,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#execution_cancelled","title":"execution_cancelled","text":"<p>Fired when an execution is cancelled via the API.</p> <pre><code>{\n  \"type\": \"execution_cancelled\",\n  \"channel\": \"workflow:my-chatbot\",\n  \"timestamp\": 1705312205.789,\n  \"data\": {\n    \"execution_id\": \"abc12345-def6-7890\"\n  }\n}\n</code></pre>"},{"location":"api/websocket/#epic-events","title":"Epic Events","text":"<p>Published on <code>epic:&lt;id&gt;</code> channels.</p>"},{"location":"api/websocket/#epic_created-epic_updated-epic_deleted","title":"epic_created / epic_updated / epic_deleted","text":"<pre><code>{\n  \"type\": \"epic_updated\",\n  \"channel\": \"epic:epic-uuid-1234\",\n  \"timestamp\": 1705312200.123,\n  \"data\": { ... }\n}\n</code></pre>"},{"location":"api/websocket/#task_created-task_updated-task_deleted-tasks_deleted","title":"task_created / task_updated / task_deleted / tasks_deleted","text":"<pre><code>{\n  \"type\": \"task_updated\",\n  \"channel\": \"epic:epic-uuid-1234\",\n  \"timestamp\": 1705312200.123,\n  \"data\": { ... }\n}\n</code></pre>"},{"location":"api/websocket/#full-subscription-flow-example","title":"Full Subscription Flow Example","text":"<p>Here is a complete example showing connection, subscription, receiving events, and cleanup:</p> <pre><code>// 1. Connect with authentication\nconst ws = new WebSocket(`ws://localhost:8000/ws/?token=${apiKey}`);\n\n// 2. Handle connection open\nws.onopen = () =&gt; {\n  // Subscribe to workflow events\n  ws.send(JSON.stringify({\n    type: \"subscribe\",\n    channel: \"workflow:my-chatbot\"\n  }));\n};\n\n// 3. Handle incoming messages\nws.onmessage = (event) =&gt; {\n  const msg = JSON.parse(event.data);\n\n  switch (msg.type) {\n    case \"subscribed\":\n      console.log(`Subscribed to ${msg.channel}`);\n      break;\n\n    case \"ping\":\n      // Respond to heartbeat\n      ws.send(JSON.stringify({ type: \"pong\" }));\n      break;\n\n    case \"node_status\":\n      console.log(`Node ${msg.data.node_id}: ${msg.data.status}`);\n      break;\n\n    case \"execution_completed\":\n      console.log(`Execution ${msg.data.execution_id} completed`);\n      break;\n\n    case \"node_created\":\n    case \"node_updated\":\n    case \"node_deleted\":\n      // Update local node state\n      console.log(`Node event: ${msg.type}`, msg.data);\n      break;\n\n    case \"edge_created\":\n    case \"edge_updated\":\n    case \"edge_deleted\":\n      // Update local edge state\n      console.log(`Edge event: ${msg.type}`, msg.data);\n      break;\n  }\n};\n\n// 4. Cleanup on close\nws.onclose = (event) =&gt; {\n  console.log(`Disconnected: ${event.code} ${event.reason}`);\n};\n\n// 5. Unsubscribe when leaving a page\nfunction cleanup() {\n  ws.send(JSON.stringify({\n    type: \"unsubscribe\",\n    channel: \"workflow:my-chatbot\"\n  }));\n}\n</code></pre>"},{"location":"api/websocket/#reconnection","title":"Reconnection","text":"<p>The Pipelit frontend uses an exponential backoff strategy for reconnection:</p> <ol> <li>Initial reconnect delay: 1 second.</li> <li>Each failed attempt doubles the delay, up to a maximum of 30 seconds.</li> <li>On successful reconnection, all previous subscriptions are automatically re-established.</li> </ol> <p>Clients should implement similar reconnection logic to handle network interruptions.</p>"},{"location":"api/workflows/","title":"Workflows","text":""},{"location":"api/workflows/#workflows","title":"Workflows","text":"<p>Workflow CRUD, validation, and node type discovery endpoints.</p> <p>All endpoints are under <code>/api/v1/workflows/</code> and require Bearer token authentication.</p>"},{"location":"api/workflows/#get-apiv1workflows","title":"GET /api/v1/workflows/","text":"<p>List workflows accessible to the authenticated user (owned or collaborated).</p> <p>Query parameters:</p> Parameter Type Default Description <code>limit</code> int 50 Max items per page <code>offset</code> int 0 Items to skip <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/workflows/?limit=10&amp;offset=0 \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <pre><code>{\n  \"items\": [\n    {\n      \"id\": 1,\n      \"name\": \"My Chatbot\",\n      \"slug\": \"my-chatbot\",\n      \"description\": \"A customer support chatbot\",\n      \"is_active\": true,\n      \"is_public\": false,\n      \"is_default\": false,\n      \"tags\": [\"support\", \"chatbot\"],\n      \"error_handler_workflow_id\": null,\n      \"input_schema\": null,\n      \"output_schema\": null,\n      \"node_count\": 5,\n      \"edge_count\": 4,\n      \"created_at\": \"2025-01-15T10:30:00\",\n      \"updated_at\": \"2025-01-15T12:00:00\"\n    }\n  ],\n  \"total\": 1\n}\n</code></pre>"},{"location":"api/workflows/#post-apiv1workflows","title":"POST /api/v1/workflows/","text":"<p>Create a new workflow.</p> <p>Request body:</p> Field Type Required Default Description <code>name</code> string yes Display name <code>slug</code> string yes URL-friendly identifier (unique) <code>description</code> string no <code>\"\"</code> Description <code>is_active</code> boolean no <code>true</code> Whether the workflow is active <code>is_public</code> boolean no <code>false</code> Whether the workflow is publicly accessible <code>is_default</code> boolean no <code>false</code> Whether this is the default workflow <code>tags</code> string[] no <code>null</code> Tags for categorization <code>error_handler_workflow_id</code> int or null no <code>null</code> Workflow ID for error handling <code>input_schema</code> object no <code>null</code> JSON Schema for workflow input <code>output_schema</code> object no <code>null</code> JSON Schema for workflow output <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"name\": \"My Chatbot\",\n    \"slug\": \"my-chatbot\",\n    \"description\": \"A customer support chatbot\",\n    \"tags\": [\"support\"]\n  }'\n</code></pre> <p>Response (201):</p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"My Chatbot\",\n  \"slug\": \"my-chatbot\",\n  \"description\": \"A customer support chatbot\",\n  \"is_active\": true,\n  \"is_public\": false,\n  \"is_default\": false,\n  \"tags\": [\"support\"],\n  \"error_handler_workflow_id\": null,\n  \"input_schema\": null,\n  \"output_schema\": null,\n  \"node_count\": 0,\n  \"edge_count\": 0,\n  \"created_at\": \"2025-01-15T10:30:00\",\n  \"updated_at\": \"2025-01-15T10:30:00\"\n}\n</code></pre>"},{"location":"api/workflows/#get-apiv1workflowsslug","title":"GET /api/v1/workflows/{slug}/","text":"<p>Get full workflow detail including all nodes and edges.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/workflows/my-chatbot/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <p>Returns the workflow object with additional <code>nodes</code> and <code>edges</code> arrays:</p> <pre><code>{\n  \"id\": 1,\n  \"name\": \"My Chatbot\",\n  \"slug\": \"my-chatbot\",\n  \"description\": \"A customer support chatbot\",\n  \"is_active\": true,\n  \"is_public\": false,\n  \"is_default\": false,\n  \"tags\": [\"support\"],\n  \"error_handler_workflow_id\": null,\n  \"input_schema\": null,\n  \"output_schema\": null,\n  \"node_count\": 2,\n  \"edge_count\": 1,\n  \"created_at\": \"2025-01-15T10:30:00\",\n  \"updated_at\": \"2025-01-15T12:00:00\",\n  \"nodes\": [ ... ],\n  \"edges\": [ ... ]\n}\n</code></pre> <p>Error (404): <code>\"Workflow not found.\"</code></p>"},{"location":"api/workflows/#patch-apiv1workflowsslug","title":"PATCH /api/v1/workflows/{slug}/","text":"<p>Update a workflow. Only include fields you want to change.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Request body (all fields optional):</p> Field Type Description <code>name</code> string Display name <code>slug</code> string URL-friendly identifier <code>description</code> string Description <code>is_active</code> boolean Active state <code>is_public</code> boolean Public visibility <code>is_default</code> boolean Default workflow flag <code>tags</code> string[] Tags <code>error_handler_workflow_id</code> int or null Error handler workflow ID <code>input_schema</code> object Input JSON Schema <code>output_schema</code> object Output JSON Schema <p>Example request:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/workflows/my-chatbot/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"description\": \"Updated description\"}'\n</code></pre> <p>Response (200): Updated workflow object.</p> <p>Broadcasts a <code>workflow_updated</code> WebSocket event on the <code>workflow:&lt;slug&gt;</code> channel.</p>"},{"location":"api/workflows/#delete-apiv1workflowsslug","title":"DELETE /api/v1/workflows/{slug}/","text":"<p>Soft-delete a workflow.</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl -X DELETE http://localhost:8000/api/v1/workflows/my-chatbot/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (204): No content.</p>"},{"location":"api/workflows/#post-apiv1workflowsbatch-delete","title":"POST /api/v1/workflows/batch-delete/","text":"<p>Batch soft-delete multiple workflows.</p> <p>Request body:</p> Field Type Required Description <code>slugs</code> string[] yes List of workflow slugs to delete <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/batch-delete/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"slugs\": [\"workflow-1\", \"workflow-2\"]}'\n</code></pre> <p>Response (204): No content.</p>"},{"location":"api/workflows/#post-apiv1workflowsslugvalidate","title":"POST /api/v1/workflows/{slug}/validate/","text":"<p>Validate a workflow's structural integrity. Checks edge type compatibility and required sub-component connections (e.g., agent nodes require a model connection).</p> <p>Path parameters:</p> Parameter Type Description <code>slug</code> string Workflow slug <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/my-chatbot/validate/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200) -- valid:</p> <pre><code>{\n  \"valid\": true,\n  \"errors\": []\n}\n</code></pre> <p>Response (200) -- invalid:</p> <pre><code>{\n  \"valid\": false,\n  \"errors\": [\n    \"Node 'agent_abc123' is missing required 'model' connection\"\n  ]\n}\n</code></pre>"},{"location":"api/workflows/#get-apiv1workflowsnode-types","title":"GET /api/v1/workflows/node-types/","text":"<p>List all available component (node) types with their port definitions and configuration schemas.</p> <p>Example request:</p> <pre><code>curl http://localhost:8000/api/v1/workflows/node-types/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\"\n</code></pre> <p>Response (200):</p> <p>Returns a dictionary keyed by component type:</p> <pre><code>{\n  \"agent\": {\n    \"label\": \"Agent\",\n    \"category\": \"AI\",\n    \"description\": \"LLM-powered agent with tool calling\",\n    \"icon\": \"robot\",\n    \"color\": \"#8b5cf6\",\n    \"inputs\": [\n      {\"name\": \"input\", \"data_type\": \"text\", \"required\": true}\n    ],\n    \"outputs\": [\n      {\"name\": \"output\", \"data_type\": \"text\"}\n    ],\n    \"sub_inputs\": [\n      {\"name\": \"model\", \"data_type\": \"llm\", \"required\": true},\n      {\"name\": \"tools\", \"data_type\": \"tool\", \"required\": false},\n      {\"name\": \"memory\", \"data_type\": \"memory\", \"required\": false}\n    ],\n    \"executable\": true\n  },\n  \"trigger_chat\": {\n    \"label\": \"Chat Trigger\",\n    \"category\": \"Triggers\",\n    \"description\": \"Receives chat messages\",\n    \"icon\": \"comments\",\n    \"color\": \"#f97316\",\n    \"inputs\": [],\n    \"outputs\": [\n      {\"name\": \"text\", \"data_type\": \"text\"}\n    ],\n    \"sub_inputs\": [],\n    \"executable\": true\n  }\n}\n</code></pre>"},{"location":"api/workflows/#post-apiv1workflowsvalidate-dsl","title":"POST /api/v1/workflows/validate-dsl/","text":"<p>Validate a YAML DSL workflow definition.</p> <p>Request body:</p> Field Type Required Description <code>yaml_str</code> string yes YAML DSL string to validate <p>Example request:</p> <pre><code>curl -X POST http://localhost:8000/api/v1/workflows/validate-dsl/ \\\n  -H \"Authorization: Bearer &lt;api_key&gt;\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"yaml_str\": \"name: test\\nnodes:\\n  - id: trigger\\n    type: trigger_chat\"}'\n</code></pre> <p>Response (200): Validation result object.</p>"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#architecture","title":"Architecture","text":"<p>This section provides a deep dive into Pipelit's internal architecture, covering everything from the high-level system topology to the low-level execution mechanics.</p>"},{"location":"architecture/#section-overview","title":"Section Overview","text":"Page Description System Overview High-level diagram of how all system components connect: FastAPI, Redis, RQ, LangGraph, WebSocket, and the React frontend. Backend Backend architecture details -- FastAPI app structure, SQLAlchemy 2.0 models with polymorphic inheritance, Pydantic schemas, RQ background processing, Redis, and Alembic migrations. Execution Engine How workflows are compiled and executed: the orchestrator, builder, topology analyzer, executor, Jinja2 expression resolver, and LangGraph state management. Node I/O The standardized type system for node inputs and outputs: DataType enum, PortDefinition, NodeTypeSpec registry, edge validation, and component output conventions. WebSocket System The global authenticated WebSocket architecture: Redis pub/sub fan-out, subscription protocol, event types, and the frontend WebSocketManager singleton. Context Management How the platform manages LLM context windows: token counting, pre-call trimming, agent output isolation, conversation continuity, and sub-workflow context scoping. Multi-Agent Delegation Hierarchical multi-agent task delegation: the epic/task registry, spawn_and_await for child workflow execution, workflow discovery, and the YAML DSL for programmatic workflow creation. Workflow DSL The YAML-based declarative workflow definition language: step types, triggers, model resolution, implicit flow, fork-and-patch mode, and the DSL compiler pipeline. Self-Improving Agents The vision and roadmap for self-aware, self-evolving agents: self-inspection, self-modification with guardrails, guided learning, memory-driven emergence, and the protection layer."},{"location":"architecture/#key-design-principles","title":"Key Design Principles","text":"<p>Pipelit's architecture follows several guiding principles:</p> <ul> <li>Triggers are nodes. There is no separate trigger subsystem. Triggers (chat, Telegram, webhook, scheduler) are first-class workflow nodes with the same lifecycle as any other node.</li> <li>Workflows over agents. The unit of delegation is workflows, not individual agents. Workflows are composable graphs that subsume agent capabilities.</li> <li>Trigger-scoped execution. When a trigger fires, only the nodes reachable downstream from that trigger are compiled and executed. Unconnected nodes on the same canvas are ignored.</li> <li>Component output convention. Components return flat dicts. The orchestrator handles wrapping, state management, and side effects via underscore-prefixed keys.</li> <li>Real-time by default. All mutations and execution events are broadcast via WebSocket. The frontend never polls.</li> </ul>"},{"location":"architecture/backend/","title":"Backend","text":""},{"location":"architecture/backend/#backend-architecture","title":"Backend Architecture","text":"<p>The Pipelit backend is a FastAPI application with SQLAlchemy ORM, Alembic migrations, RQ background processing, and Redis for pub/sub, caching, and execution state.</p>"},{"location":"architecture/backend/#directory-structure","title":"Directory Structure","text":"<pre><code>platform/\n\u251c\u2500\u2500 main.py              # FastAPI app entry point (routers, CORS, static files)\n\u251c\u2500\u2500 config.py            # Pydantic Settings (DATABASE_URL, REDIS_URL, etc.)\n\u251c\u2500\u2500 database.py          # SQLAlchemy engine + SessionLocal + get_db()\n\u251c\u2500\u2500 auth.py              # Bearer token auth dependency (HTTPBearer -&gt; UserProfile)\n\u251c\u2500\u2500 api/                 # REST endpoint routers\n\u2502   \u251c\u2500\u2500 auth.py          # POST /token/, GET /me/, POST /setup/\n\u2502   \u251c\u2500\u2500 workflows.py     # Workflow CRUD + GET /node-types/ + POST /validate/\n\u2502   \u251c\u2500\u2500 nodes.py         # Node + Edge CRUD (nested under workflow)\n\u2502   \u251c\u2500\u2500 executions.py    # Execution list/detail/cancel + chat\n\u2502   \u251c\u2500\u2500 credentials.py   # Credential CRUD + test + LLM models\n\u2502   \u251c\u2500\u2500 schedules.py     # ScheduledJob CRUD + pause/resume/batch-delete\n\u2502   \u2514\u2500\u2500 _helpers.py      # Response serialization helpers\n\u251c\u2500\u2500 models/              # SQLAlchemy ORM models\n\u2502   \u251c\u2500\u2500 user.py          # UserProfile, APIKey\n\u2502   \u251c\u2500\u2500 credential.py    # BaseCredential, LLMProviderCredential, TelegramCredential\n\u2502   \u251c\u2500\u2500 workflow.py      # Workflow, WorkflowCollaborator\n\u2502   \u251c\u2500\u2500 node.py          # WorkflowNode, WorkflowEdge, ComponentConfig hierarchy\n\u2502   \u251c\u2500\u2500 execution.py     # WorkflowExecution, ExecutionLog, PendingTask\n\u2502   \u251c\u2500\u2500 scheduled_job.py # ScheduledJob (self-rescheduling recurring jobs)\n\u2502   \u251c\u2500\u2500 conversation.py  # Conversation\n\u2502   \u251c\u2500\u2500 tool.py          # ToolDefinition, WorkflowTool\n\u2502   \u251c\u2500\u2500 code.py          # CodeBlock, CodeBlockVersion, CodeBlockTest\n\u2502   \u2514\u2500\u2500 git.py           # GitRepository, GitCommit, GitSyncTask\n\u251c\u2500\u2500 schemas/             # Pydantic schemas\n\u2502   \u251c\u2500\u2500 node_io.py       # NodeStatus, NodeResult, NodeInput\n\u2502   \u251c\u2500\u2500 node_types.py    # DataType, PortDefinition, NodeTypeSpec, NODE_TYPE_REGISTRY\n\u2502   \u251c\u2500\u2500 node_type_defs.py# Registers all 23+ built-in node types\n\u2502   \u2514\u2500\u2500 schedule.py      # ScheduledJobCreate/Update/Out, BatchDeleteSchedulesIn\n\u251c\u2500\u2500 services/            # Business logic\n\u2502   \u251c\u2500\u2500 orchestrator.py  # Node execution, state management, WebSocket events\n\u2502   \u251c\u2500\u2500 topology.py      # Workflow DAG analysis (BFS reachability)\n\u2502   \u251c\u2500\u2500 builder.py       # Compiles Workflow -&gt; LangGraph CompiledGraph\n\u2502   \u251c\u2500\u2500 executor.py      # WorkflowExecutor + RQ job wrappers\n\u2502   \u251c\u2500\u2500 expressions.py   # Jinja2 template resolver for node config\n\u2502   \u251c\u2500\u2500 cache.py         # Redis-backed graph caching\n\u2502   \u251c\u2500\u2500 delivery.py      # Routes results to Telegram, webhooks, etc.\n\u2502   \u251c\u2500\u2500 llm.py           # create_llm_from_db(), resolve_llm_for_node()\n\u2502   \u251c\u2500\u2500 scheduler.py     # Self-rescheduling scheduler (execute, backoff, recovery)\n\u2502   \u2514\u2500\u2500 state.py         # WorkflowState (LangGraph MessagesState)\n\u251c\u2500\u2500 handlers/            # Event/trigger handlers\n\u2502   \u251c\u2500\u2500 __init__.py      # dispatch_event() - unified trigger dispatch\n\u2502   \u251c\u2500\u2500 telegram.py      # TelegramTriggerHandler\n\u2502   \u251c\u2500\u2500 webhook.py       # Incoming webhook endpoint\n\u2502   \u2514\u2500\u2500 manual.py        # Manual execution endpoint\n\u251c\u2500\u2500 components/          # LangGraph node component implementations (20+ files)\n\u251c\u2500\u2500 tasks/               # RQ job wrappers\n\u251c\u2500\u2500 triggers/            # Trigger resolver\n\u251c\u2500\u2500 validation/          # EdgeValidator (type compatibility checks)\n\u251c\u2500\u2500 ws/                  # WebSocket endpoints + broadcast helper\n\u251c\u2500\u2500 alembic/             # Database migrations\n\u2514\u2500\u2500 frontend/            # React SPA (built and served as static files)\n</code></pre>"},{"location":"architecture/backend/#fastapi-application-structure","title":"FastAPI Application Structure","text":""},{"location":"architecture/backend/#entry-point-mainpy","title":"Entry Point (<code>main.py</code>)","text":"<p>The FastAPI app is created in <code>main.py</code>, which:</p> <ol> <li>Creates the <code>FastAPI</code> instance with CORS middleware</li> <li>Registers all API routers under <code>/api/v1/</code></li> <li>Mounts the WebSocket endpoint at <code>/ws/</code></li> <li>Serves the built frontend from <code>frontend/dist/</code> as a static file mount</li> <li>Includes startup/shutdown lifecycle hooks for Redis connections and scheduler recovery</li> </ol>"},{"location":"architecture/backend/#configuration-configpy","title":"Configuration (<code>config.py</code>)","text":"<p>Application settings use Pydantic <code>BaseSettings</code>, loading from environment variables:</p> <ul> <li><code>DATABASE_URL</code> -- SQLAlchemy connection string (default: SQLite)</li> <li><code>REDIS_URL</code> -- Redis connection for RQ, pub/sub, and caching</li> <li><code>FIELD_ENCRYPTION_KEY</code> -- Fernet key for encrypting credential secrets</li> <li><code>SECRET_KEY</code> -- Application secret for token generation</li> </ul>"},{"location":"architecture/backend/#authentication-authpy","title":"Authentication (<code>auth.py</code>)","text":"<p>All API endpoints use Bearer token authentication via FastAPI's <code>HTTPBearer</code> dependency:</p> <pre><code># Every protected endpoint receives the current user via dependency injection\nasync def get_current_user(\n    credentials: HTTPAuthorizationCredentials = Security(security),\n    db: Session = Depends(get_db),\n) -&gt; UserProfile:\n    token = credentials.credentials\n    api_key = db.query(APIKey).filter_by(key_hash=hash_key(token)).first()\n    if not api_key:\n        raise HTTPException(status_code=401)\n    return api_key.user_profile\n</code></pre> <p>There is no session auth, OAuth, or basic auth anywhere in the system. Agent users are created without passwords via <code>create_agent_user</code> and authenticated solely through API keys.</p>"},{"location":"architecture/backend/#sqlalchemy-models","title":"SQLAlchemy Models","text":""},{"location":"architecture/backend/#polymorphic-node-configuration","title":"Polymorphic Node Configuration","text":"<p>The node system uses SQLAlchemy's single-table polymorphic inheritance for component configurations. This allows each component type to have its own configuration class while sharing a single database table.</p> <pre><code>classDiagram\n    class WorkflowNode {\n        +int id\n        +int workflow_id\n        +str node_id\n        +str component_type\n        +int position_x\n        +int position_y\n        +bool is_entry_point\n    }\n\n    class ComponentConfig {\n        +int id\n        +int node_id\n        +str component_type\n        +str system_prompt\n        +int llm_credential_id\n        +str model_name\n        +JSON extra_config\n    }\n\n    class AgentConfig {\n        polymorphic_identity: \"agent\"\n    }\n\n    class CategorizerConfig {\n        polymorphic_identity: \"categorizer\"\n    }\n\n    class TriggerChatConfig {\n        polymorphic_identity: \"trigger_chat\"\n    }\n\n    class CodeConfig {\n        polymorphic_identity: \"code\"\n    }\n\n    WorkflowNode \"1\" --&gt; \"1\" ComponentConfig\n    ComponentConfig &lt;|-- AgentConfig\n    ComponentConfig &lt;|-- CategorizerConfig\n    ComponentConfig &lt;|-- TriggerChatConfig\n    ComponentConfig &lt;|-- CodeConfig</code></pre> <p>Every new component type requires registration in four places:</p> <ol> <li>SQLAlchemy -- A <code>_*Config</code> class with <code>polymorphic_identity</code></li> <li>Pydantic -- A <code>Literal</code> type in the schema for validation</li> <li>Node Type Registry -- A <code>register_node_type()</code> call with port definitions</li> <li>Frontend -- TypeScript type definition in <code>types/models.ts</code></li> </ol>"},{"location":"architecture/backend/#credential-model","title":"Credential Model","text":"<p>Credentials are global -- any user on the machine can use any credential. The <code>user_profile_id</code> FK tracks who created a credential, not ownership.</p> <p>Sensitive fields (API keys, tokens) use <code>EncryptedString</code>, a custom SQLAlchemy type that encrypts/decrypts with Fernet via <code>FIELD_ENCRYPTION_KEY</code>:</p> <pre><code>class LLMProviderCredential(BaseCredential):\n    api_key = Column(EncryptedString)  # Encrypted at rest\n    provider = Column(String)          # \"openai\", \"anthropic\", etc.\n</code></pre>"},{"location":"architecture/backend/#edge-model","title":"Edge Model","text":"<p>Edges connect nodes with typed connections:</p> Edge Label Purpose Example <code>\"\"</code> (empty) Data flow between nodes trigger -&gt; agent <code>\"llm\"</code> Model connection ai_model -&gt; agent <code>\"tool\"</code> Tool connection run_command -&gt; agent <code>\"memory\"</code> Memory connection memory_read -&gt; agent <code>\"output_parser\"</code> Parser connection output_parser -&gt; categorizer <code>\"loop_body\"</code> Loop body flow loop -&gt; body_node <code>\"loop_return\"</code> Loop return flow body_node -&gt; loop <p>Conditional edges carry a <code>condition_value</code> string on each <code>WorkflowEdge</code> row. Only <code>switch</code> nodes can originate conditional edges.</p>"},{"location":"architecture/backend/#pydantic-schemas","title":"Pydantic Schemas","text":""},{"location":"architecture/backend/#requestresponse-validation","title":"Request/Response Validation","text":"<p>All API endpoints use Pydantic models for input validation and output serialization. Component types, trigger types, and edge types use <code>Literal</code> types:</p> <pre><code>class NodeCreate(BaseModel):\n    node_id: str\n    component_type: Literal[\n        \"agent\", \"categorizer\", \"router\", \"extractor\",\n        \"trigger_chat\", \"trigger_telegram\", \"trigger_webhook\",\n        \"code\", \"switch\", \"loop\", ...\n    ]\n    config: ComponentConfigData | None = None\n</code></pre>"},{"location":"architecture/backend/#pagination","title":"Pagination","text":"<p>All list endpoints return paginated responses:</p> <pre><code>{\n    \"items\": [...],\n    \"total\": 42\n}\n</code></pre> <p>Endpoints accept <code>limit</code> and <code>offset</code> query parameters. The default frontend page size is 50.</p>"},{"location":"architecture/backend/#background-processing-with-rq","title":"Background Processing with RQ","text":"<p>RQ (Redis Queue) handles all background job processing. Workflow executions, scheduled jobs, and trigger dispatches run as RQ jobs to keep the API server responsive.</p> <pre><code>graph LR\n    API[FastAPI] --&gt;|enqueue| Redis[(Redis Queue)]\n    Redis --&gt;|dequeue| W1[RQ Worker 1]\n    Redis --&gt;|dequeue| W2[RQ Worker 2]\n    Redis --&gt;|dequeue| W3[RQ Worker N]\n\n    W1 --&gt;|execute_workflow_job| Orchestrator\n    W2 --&gt;|execute_scheduled_job| Scheduler\n    W3 --&gt;|dispatch_event| Handlers</code></pre> <p>Key RQ job types:</p> <ul> <li><code>execute_workflow_job</code> -- Runs a complete workflow execution</li> <li><code>execute_node_job</code> -- Runs a single node (used for re-invocations after subworkflow completion)</li> <li><code>execute_scheduled_job</code> -- Runs a scheduled job, then self-reschedules via <code>Queue.enqueue_in()</code></li> <li><code>dispatch_event</code> -- Routes incoming events (Telegram messages, webhooks) to the appropriate trigger handler</li> </ul>"},{"location":"architecture/backend/#self-rescheduling-scheduler","title":"Self-Rescheduling Scheduler","text":"<p>The scheduler implements recurring workflow execution without external cron. Each <code>ScheduledJob</code> stores its interval, repeat count, retry config, and status (<code>active</code> / <code>paused</code> / <code>done</code> / <code>dead</code>).</p> <p>The <code>execute_scheduled_job()</code> function runs as an RQ job: it dispatches the workflow trigger, handles success/failure with exponential backoff (capped at 10x interval), and calls <code>_enqueue_next()</code> to schedule itself again. Deterministic RQ job IDs (<code>sched-{id}-n{repeat}-rc{retry}</code>) prevent duplicate enqueues.</p> <p>On startup, <code>recover_scheduled_jobs()</code> re-enqueues any active jobs whose <code>next_run_at</code> is in the past.</p>"},{"location":"architecture/backend/#redis-usage","title":"Redis Usage","text":"<p>Redis serves four distinct roles:</p>"},{"location":"architecture/backend/#1-pubsub-websocket-broadcasting","title":"1. Pub/Sub (WebSocket Broadcasting)","text":"<p>The <code>broadcast()</code> helper publishes events to Redis channels. The WebSocket endpoint subscribes to channels on behalf of connected clients and forwards messages. This allows events from RQ workers (running in separate processes) to reach frontend clients.</p>"},{"location":"architecture/backend/#2-job-queue-rq","title":"2. Job Queue (RQ)","text":"<p>Standard RQ job queue for background processing. Workers dequeue and execute jobs.</p>"},{"location":"architecture/backend/#3-graph-cache","title":"3. Graph Cache","text":"<p>Compiled LangGraph graphs are cached in Redis keyed by workflow ID and a hash of the workflow's structure. Cache is invalidated when nodes or edges change.</p>"},{"location":"architecture/backend/#4-execution-state","title":"4. Execution State","text":"<p>During execution, per-node state (outputs, results, route values) is stored in Redis. This allows the orchestrator to resume execution after interruptions and enables multi-step workflows where later nodes reference earlier outputs. State is cleaned up after execution completes.</p>"},{"location":"architecture/backend/#alembic-migrations","title":"Alembic Migrations","text":"<p>Schema changes use Alembic with SQLAlchemy autogeneration:</p> <pre><code>cd platform\nalembic revision --autogenerate -m \"description\"\nalembic upgrade head\n</code></pre> <p>SQLite Caution</p> <p><code>batch_alter_table</code> operations in SQLite can cascade and delete data. Always test migrations against existing data, not just empty databases. Check for conflicting migration heads before creating new migrations.</p>"},{"location":"architecture/backend/#llm-resolution","title":"LLM Resolution","text":"<p>LLM configuration lives entirely on <code>ComponentConfig</code> (per-node). Each agent-type node must have both <code>llm_model</code> and <code>llm_credential</code> set on its config. There are no workflow-level LLM defaults.</p> <p>Resolution is handled by <code>services/llm.py</code>:</p> <pre><code>def resolve_llm_for_node(node: WorkflowNode, db: Session) -&gt; BaseChatModel:\n    \"\"\"Load the LLM for a node from its ComponentConfig.\"\"\"\n    config = node.component_config\n    credential = db.query(LLMProviderCredential).get(config.llm_credential_id)\n    return create_llm_from_db(\n        credential=credential,\n        model_name=config.model_name,\n        extra_config=config.extra_config or {},\n    )\n</code></pre>"},{"location":"architecture/context-management/","title":"Context Management","text":""},{"location":"architecture/context-management/#context-management","title":"Context Management","text":"<p>Managing LLM context windows is one of the most critical challenges in a multi-node workflow platform. This page describes Pipelit's three-layer architecture for context management: intra-workflow trimming, cross-execution conversation continuity, and sub-workflow context isolation.</p>"},{"location":"architecture/context-management/#the-problem","title":"The Problem","text":""},{"location":"architecture/context-management/#unbounded-messages-within-a-single-execution","title":"Unbounded Messages Within a Single Execution","text":"<p>All nodes in a workflow share <code>state[\"messages\"]</code>. Each node appends to it. Agent components dump all intermediate ReAct messages (tool calls, tool results, reasoning steps) into shared state. A 5-node workflow with 2 agents can accumulate 50+ messages before hitting the final node, easily exceeding context windows.</p>"},{"location":"architecture/context-management/#no-conversation-continuity-across-executions","title":"No Conversation Continuity Across Executions","text":"<p>Each chat message creates a new <code>WorkflowExecution</code> with a random thread ID. The initial state contains only the current message -- no history. Redis state is deleted after execution completes.</p>"},{"location":"architecture/context-management/#sub-workflows-have-no-context-isolation","title":"Sub-Workflows Have No Context Isolation","text":"<p>When a parent workflow invokes a child, the child should not inherit the parent's raw message history. It needs a scoped context with only the relevant input.</p>"},{"location":"architecture/context-management/#three-layer-architecture","title":"Three-Layer Architecture","text":"<pre><code>graph TB\n    subgraph L3[\"Layer 3: Sub-Workflow Context Isolation\"]\n        L3a[Parent scopes context]\n        L3b[Child has own state]\n        L3c[Result flows back as structured data]\n        L3a --&gt; L3b --&gt; L3c\n    end\n\n    subgraph L2[\"Layer 2: Conversation Continuity\"]\n        L2a[Thread grouping]\n        L2b[History loading]\n        L2c[Sliding window + compression]\n        L2a --&gt; L2b --&gt; L2c\n    end\n\n    subgraph L1[\"Layer 1: Intra-Workflow Context Management\"]\n        L1a[Token counting]\n        L1b[Pre-call trimming]\n        L1c[Agent output isolation]\n        L1a --&gt; L1b --&gt; L1c\n    end\n\n    L1 --&gt; L2\n    L2 --&gt; L3\n\n    classDef layer1 fill:#dbeafe,stroke:#2563eb\n    classDef layer2 fill:#fef3c7,stroke:#d97706\n    classDef layer3 fill:#d1fae5,stroke:#059669\n\n    class L1a,L1b,L1c layer1\n    class L2a,L2b,L2c layer2\n    class L3a,L3b,L3c layer3</code></pre>"},{"location":"architecture/context-management/#layer-1-intra-workflow-context-management","title":"Layer 1: Intra-Workflow Context Management","text":"<p>Goal: Prevent context overflow within a single execution. Zero schema changes required.</p>"},{"location":"architecture/context-management/#token-counting-service","title":"Token Counting Service","text":"<p>The <code>platform/services/context.py</code> module provides:</p> <pre><code>def count_message_tokens(msg: AnyMessage) -&gt; int:\n    \"\"\"Count tokens in a single message using tiktoken cl100k_base.\n    Handles str/list content and tool_calls.\"\"\"\n\ndef count_messages_tokens(messages: list) -&gt; int:\n    \"\"\"Sum token counts across all messages.\"\"\"\n\ndef get_context_window(model_name: str, extra_config: dict) -&gt; int:\n    \"\"\"Look up context window size for a model.\n    Uses extra_config[\"context_window\"] override if set,\n    otherwise a lookup table, defaulting to 128K.\"\"\"\n\ndef trim_messages(\n    messages: list,\n    model_name: str,\n    max_tokens: int,\n    extra_config: dict,\n    system_messages: list,\n) -&gt; list:\n    \"\"\"Keep the most recent messages that fit within\n    context_window - response_reserve - system_tokens.\"\"\"\n</code></pre>"},{"location":"architecture/context-management/#pre-call-trimming","title":"Pre-Call Trimming","text":"<p>Before every LLM call, agent and AI model components trim the message list:</p> <pre><code># Inside agent.py, ai_model.py, react_agent.py:\nmessages = trim_messages(\n    messages,\n    model_name=config.model_name,\n    max_tokens=get_context_window(config.model_name, extra_config),\n    extra_config=extra_config,\n    system_messages=[system_prompt_message],\n)\n</code></pre> <p>The context window can be overridden per-node via <code>extra_config[\"context_window\"]</code> without any schema migration.</p>"},{"location":"architecture/context-management/#agent-output-isolation","title":"Agent Output Isolation","text":"<p>Agent nodes return only their final AI response to shared state, not the full ReAct loop:</p> <pre><code># BEFORE: Pollutes shared state with 10-20 intermediate messages\nreturn {\"_messages\": out_messages, ...}\n\n# AFTER: Only the final answer enters shared state\nreturn {\"_messages\": [final_ai_message], ...}\n</code></pre> <p>This prevents intermediate tool_call/tool_result messages from consuming context budget for downstream nodes. The full ReAct trace is still logged in <code>ExecutionLog</code> for debugging.</p> <p>Token Usage Tracking</p> <p>Pipelit also tracks actual token usage from LLM providers via <code>platform/services/token_usage.py</code>. This uses LangChain <code>usage_metadata</code> (provider-reported actuals, not tiktoken estimates) for cost tracking and budget enforcement. This is complementary to -- but separate from -- the pre-call context trimming described here.</p>"},{"location":"architecture/context-management/#layer-2-conversation-continuity","title":"Layer 2: Conversation Continuity","text":"<p>Goal: Multi-turn chat where each execution has access to conversation history. Requires schema changes.</p>"},{"location":"architecture/context-management/#thread-based-execution-grouping","title":"Thread-Based Execution Grouping","text":"<p>The existing <code>Conversation</code> model is activated to group executions into threads:</p> <pre><code>sequenceDiagram\n    participant User\n    participant API\n    participant DB as Database\n    participant Orch as Orchestrator\n\n    User-&gt;&gt;API: \"Hello\" (chat message)\n    API-&gt;&gt;DB: Find Conversation for (user, workflow)\n    Note over DB: None found - create new\n    DB--&gt;&gt;API: conversation_id, thread_id\n    API-&gt;&gt;Orch: Execute with thread_id\n\n    User-&gt;&gt;API: \"Tell me more\" (follow-up)\n    API-&gt;&gt;DB: Find Conversation for (user, workflow)\n    Note over DB: Found existing conversation\n    DB--&gt;&gt;API: same thread_id\n    API-&gt;&gt;Orch: Execute with same thread_id\n    Orch-&gt;&gt;DB: Load history from thread</code></pre> <p>When a chat message arrives, the system finds or creates a conversation thread for the <code>(user_profile_id, workflow_id)</code> pair. All executions within that thread share the same <code>thread_id</code>.</p>"},{"location":"architecture/context-management/#history-loading","title":"History Loading","text":"<p>The orchestrator loads conversation history when building initial state:</p> <pre><code>def _build_initial_state(execution) -&gt; dict:\n    history_messages = _load_thread_history(\n        thread_id=execution.thread_id,\n        limit=20,            # Last 20 messages\n        max_tokens=16000,    # Or token-budgeted\n    )\n    messages = history_messages + [HumanMessage(content=trigger_text)]\n    return {\"messages\": messages, ...}\n</code></pre>"},{"location":"architecture/context-management/#history-persistence","title":"History Persistence","text":"<p>After execution completes, the conversation turn is persisted:</p> <pre><code>class ConversationMessage(Base):\n    id: int                  # Primary key\n    conversation_id: int     # FK -&gt; Conversation\n    execution_id: str        # FK -&gt; WorkflowExecution\n    role: str                # \"human\" | \"ai\"\n    content: str\n    token_count: int\n    created_at: datetime\n</code></pre>"},{"location":"architecture/context-management/#sliding-window-and-compression","title":"Sliding Window and Compression","text":"<p>For long conversations, a context budget is applied:</p> <ul> <li>Phase 1 (Simple): Keep the last N messages that fit the token budget (reuses <code>trim_messages</code> from Layer 1)</li> <li>Phase 2 (Advanced): LLM-based compression -- summarize old messages, keep recent ones verbatim</li> </ul>"},{"location":"architecture/context-management/#agent-conversation-memory-current-implementation","title":"Agent Conversation Memory (Current Implementation)","text":"<p>Agent nodes already support optional <code>conversation_memory</code> via <code>extra_config</code>. When enabled, a <code>SqliteSaver</code> checkpointer (<code>platform/checkpoints.db</code>) persists conversation history across executions.</p> <p>The thread ID is constructed from <code>user_profile_id</code>, <code>telegram_chat_id</code>, and <code>workflow_id</code> so the same user talking to the same workflow gets continuity. The system prompt uses both a <code>SystemMessage</code> and a <code>HumanMessage</code> fallback (for providers like Venice.ai that ignore the system role), with a stable ID to prevent duplication via LangGraph's <code>add_messages</code> reducer.</p>"},{"location":"architecture/context-management/#layer-3-sub-workflow-context-isolation","title":"Layer 3: Sub-Workflow Context Isolation","text":"<p>Goal: Parent workflows can invoke child workflows with scoped context. Each child has its own state. Results flow back as structured data.</p>"},{"location":"architecture/context-management/#context-scoping-parent-to-child","title":"Context Scoping (Parent to Child)","text":"<p>The parent decides what context to pass to the child:</p> <pre><code>def _scope_context(parent_state: dict, node: WorkflowNode) -&gt; dict:\n    \"\"\"Build trigger payload for child workflow.\"\"\"\n    extra = node.component_config.extra_config or {}\n    input_source = extra.get(\"input_source\", \"last_message\")\n\n    if input_source == \"last_message\":\n        messages = parent_state.get(\"messages\", [])\n        text = messages[-1].content if messages else \"\"\n    elif input_source == \"node_output\":\n        source_node = extra.get(\"source_node_id\")\n        text = str(parent_state.get(\"node_outputs\", {}).get(source_node, \"\"))\n    else:\n        text = \"\"\n\n    return {\n        \"text\": text,\n        \"parent_execution_id\": parent_state[\"execution_id\"],\n        \"user_context\": parent_state.get(\"user_context\", {}),\n    }\n</code></pre> <p>What the child receives:</p> <ul> <li>Trigger payload -- The parent's current output or a user-configured subset</li> <li>User context -- Inherited from parent's state</li> <li>Not messages -- The child starts with a fresh message list</li> </ul>"},{"location":"architecture/context-management/#result-aggregation-child-to-parent","title":"Result Aggregation (Child to Parent)","text":"<p>The child execution produces a <code>final_output</code>. The parent receives it as:</p> <ul> <li>A structured dict in <code>node_outputs</code> (for downstream nodes to reference via Jinja2)</li> <li>An <code>AIMessage</code> summary in <code>messages</code> (for conversational continuity)</li> </ul>"},{"location":"architecture/context-management/#execution-relationship","title":"Execution Relationship","text":"<p>A <code>parent_execution_id</code> FK on <code>WorkflowExecution</code> enables:</p> <ul> <li>Tracing execution trees</li> <li>Cancellation cascading (cancel parent cancels children)</li> <li>Debugging nested workflows in the execution detail view</li> </ul>"},{"location":"architecture/context-management/#implementation-phases","title":"Implementation Phases","text":"Phase Layer Scope Dependencies Phase A Layer 1 Token counting, pre-call trimming, agent output filtering None Phase B Layer 2a-2b Thread grouping + history loading Phase A (for <code>trim_messages</code>) Phase C Layer 2c-2d History persistence + compression Phase B Phase D Layer 3 Sub-workflow implementation Phase A <p>Phase A is self-contained and delivers immediate value. Phases B through D can proceed in any order after A.</p>"},{"location":"architecture/context-management/#key-design-decisions","title":"Key Design Decisions","text":"<ol> <li> <p>Trimming over compression (Layer 1). No LLM calls for compression. Fast, deterministic, predictable. Compression is deferred to Layer 2.</p> </li> <li> <p>Agent output isolation is always-on. No downstream node needs intermediate tool_call messages. The full trace remains in execution logs.</p> </li> <li> <p>Context window via <code>extra_config</code>. No schema migration needed. Users optionally set <code>{\"context_window\": 32000}</code> on an ai_model node. Otherwise, auto-detected from model name.</p> </li> <li> <p>Thread grouping via existing Conversation model. Activating the unused model avoids creating a new one. <code>ConversationMessage</code> is added for per-turn storage.</p> </li> <li> <p>Child workflows get scoped context, not raw messages. Clean boundary. Parent decides what to pass via <code>extra_config</code>. Child starts fresh.</p> </li> <li> <p>Memory system stays orthogonal. The memory system (facts, episodes, procedures) provides long-term knowledge. Context management provides short-term conversation flow. They complement but do not replace each other.</p> </li> </ol>"},{"location":"architecture/execution-engine/","title":"Execution Engine","text":""},{"location":"architecture/execution-engine/#execution-engine","title":"Execution Engine","text":"<p>The execution engine is the core of Pipelit's runtime. It compiles workflow graphs, resolves execution order, manages state, executes node components, and broadcasts real-time status events. This page covers each service in detail.</p>"},{"location":"architecture/execution-engine/#execution-pipeline-overview","title":"Execution Pipeline Overview","text":"<pre><code>sequenceDiagram\n    participant Trigger as Trigger Handler\n    participant RQ as RQ Worker\n    participant Builder as Builder\n    participant Topo as Topology\n    participant Orch as Orchestrator\n    participant Expr as Expression Resolver\n    participant Comp as Component\n    participant State as Redis State\n    participant WS as WebSocket Broadcast\n\n    Trigger-&gt;&gt;RQ: dispatch_event() -&gt; enqueue job\n    RQ-&gt;&gt;Builder: build_graph(workflow, trigger_node)\n    Builder-&gt;&gt;Topo: get_reachable_nodes(trigger_node)\n    Topo--&gt;&gt;Builder: reachable node set\n    Builder--&gt;&gt;RQ: CompiledGraph\n\n    RQ-&gt;&gt;Orch: execute(execution, compiled_graph)\n    Orch-&gt;&gt;State: Initialize execution state\n\n    loop For each node in topological order\n        Orch-&gt;&gt;WS: node_status: \"running\"\n        Orch-&gt;&gt;Expr: resolve_expressions(node.config, state)\n        Expr--&gt;&gt;Orch: resolved config\n        Orch-&gt;&gt;Comp: execute_component(node, state)\n        Comp--&gt;&gt;Orch: component output (flat dict)\n        Orch-&gt;&gt;Orch: process output (wrap, side effects)\n        Orch-&gt;&gt;State: store node_outputs[node_id]\n        Orch-&gt;&gt;WS: node_status: \"success\" + output\n    end\n\n    Orch-&gt;&gt;State: Cleanup execution state\n    Orch-&gt;&gt;WS: execution_completed</code></pre>"},{"location":"architecture/execution-engine/#builder-servicesbuilderpy","title":"Builder (<code>services/builder.py</code>)","text":"<p>The builder compiles a <code>Workflow</code> database model into a LangGraph <code>CompiledGraph</code>. This is the bridge between Pipelit's database representation and LangGraph's execution model.</p>"},{"location":"architecture/execution-engine/#trigger-scoped-compilation","title":"Trigger-Scoped Compilation","text":"<p>When a trigger fires, the builder only compiles nodes reachable downstream from that specific trigger. This is a critical design decision:</p> <ul> <li>A single workflow can have multiple trigger branches (e.g., a chat trigger and a Telegram trigger feeding different agent chains)</li> <li>Unused nodes on the canvas do not cause build errors</li> <li>Each trigger activation produces a minimal, focused execution graph</li> </ul> <pre><code>graph LR\n    subgraph \"Full Workflow Canvas\"\n        TC[trigger_chat] --&gt; A1[agent_1]\n        TT[trigger_telegram] --&gt; A2[agent_2]\n        A2 --&gt; Code[code_1]\n        Unused[unused_node]\n    end\n\n    subgraph \"Compiled Graph (chat trigger fires)\"\n        TC2[trigger_chat] --&gt; A1b[agent_1]\n    end</code></pre> <p>In this example, when the chat trigger fires, only <code>trigger_chat</code> and <code>agent_1</code> are compiled. <code>trigger_telegram</code>, <code>agent_2</code>, <code>code_1</code>, and <code>unused_node</code> are all excluded.</p>"},{"location":"architecture/execution-engine/#compilation-steps","title":"Compilation Steps","text":"<ol> <li>Load workflow nodes and edges from the database</li> <li>BFS reachability from the trigger node (via <code>topology.py</code>)</li> <li>Filter nodes and edges to the reachable set</li> <li>Resolve LLM configurations for AI-type nodes</li> <li>Load tool factories for connected tool nodes</li> <li>Build LangGraph state graph with node functions and edge routing</li> <li>Compile and optionally cache the result in Redis</li> </ol>"},{"location":"architecture/execution-engine/#graph-caching","title":"Graph Caching","text":"<p>Compiled graphs are cached in Redis keyed by workflow ID and a structural hash. The cache is invalidated whenever nodes or edges are modified (detected via WebSocket-broadcast mutations).</p>"},{"location":"architecture/execution-engine/#topology-analyzer-servicestopologypy","title":"Topology Analyzer (<code>services/topology.py</code>)","text":"<p>The topology service provides BFS-based graph analysis:</p> <pre><code>def get_reachable_nodes(\n    trigger_node_id: str,\n    edges: list[WorkflowEdge],\n) -&gt; set[str]:\n    \"\"\"BFS from trigger node following direct edges.\n    Returns the set of node_ids reachable downstream.\"\"\"\n</code></pre> <p>This is used by the builder for trigger-scoped compilation and by the orchestrator to determine execution order.</p>"},{"location":"architecture/execution-engine/#orchestrator-servicesorchestratorpy","title":"Orchestrator (<code>services/orchestrator.py</code>)","text":"<p>The orchestrator is the execution engine's core. It walks through nodes in topological order, resolves template expressions, executes components, manages state, and broadcasts events.</p>"},{"location":"architecture/execution-engine/#execution-lifecycle","title":"Execution Lifecycle","text":"<p>For each node in the execution:</p> <ol> <li>Status broadcast -- Publish <code>node_status: \"pending\"</code> then <code>\"running\"</code> via WebSocket</li> <li>Expression resolution -- Resolve <code>{{ nodeId.portName }}</code> Jinja2 templates in <code>system_prompt</code> and <code>extra_config</code></li> <li>Component execution -- Call the component factory to get the node function, then execute it</li> <li>Output processing -- Process the component's return dict:<ul> <li>Non-underscore keys are wrapped into <code>node_outputs[node_id]</code></li> <li><code>_route</code> sets <code>state[\"route\"]</code> for conditional routing</li> <li><code>_messages</code> are appended to <code>state[\"messages\"]</code></li> <li><code>_state_patch</code> is merged into global state</li> </ul> </li> <li>Result recording -- Wrap output in a <code>NodeResult</code> with status, data, error code, and metadata</li> <li>State storage -- Store <code>node_outputs</code> and <code>node_results</code> in Redis</li> <li>Status broadcast -- Publish <code>node_status: \"success\"</code> (with output) or <code>\"failed\"</code> (with error)</li> </ol>"},{"location":"architecture/execution-engine/#state-management","title":"State Management","text":"<p>Execution state is stored in Redis during execution:</p> <pre><code>state = {\n    \"messages\": [...],              # LangGraph message list\n    \"node_outputs\": {               # Per-node output data\n        \"trigger_chat_abc\": {\"text\": \"hello\", \"payload\": {...}},\n        \"agent_def\": {\"output\": \"response text\"},\n    },\n    \"node_results\": {               # Per-node execution results\n        \"trigger_chat_abc\": NodeResult(status=\"success\", ...),\n    },\n    \"route\": \"category_a\",          # Current route for conditional edges\n    \"execution_id\": \"exec_xyz\",\n    \"user_context\": {...},          # User info from trigger\n}\n</code></pre>"},{"location":"architecture/execution-engine/#subworkflow-handling","title":"Subworkflow Handling","text":"<p>When a node returns <code>{\"_subworkflow\": {...}}</code>, the orchestrator:</p> <ol> <li>Creates a child <code>WorkflowExecution</code></li> <li>Enqueues the child execution as an RQ job</li> <li>Sets the parent node status to <code>\"waiting\"</code></li> <li>Releases the RQ worker (non-blocking)</li> <li>When the child completes, injects the result into <code>state[\"_subworkflow_results\"]</code></li> <li>Re-enqueues the parent node for continuation</li> </ol>"},{"location":"architecture/execution-engine/#error-handling","title":"Error Handling","text":"<p>Failed nodes are wrapped in <code>NodeResult.failed()</code> with:</p> <ul> <li><code>error</code> -- Human-readable error message</li> <li><code>error_code</code> -- Machine-readable error classification</li> <li><code>metadata</code> -- Additional context (stack trace, timing)</li> </ul> <p>The orchestrator decides whether to skip downstream nodes or halt the entire execution based on the error severity and the node's position in the graph.</p>"},{"location":"architecture/execution-engine/#expression-resolver-servicesexpressionspy","title":"Expression Resolver (<code>services/expressions.py</code>)","text":"<p>Before executing a component, the orchestrator resolves Jinja2 template expressions in <code>system_prompt</code> and <code>extra_config</code> values.</p>"},{"location":"architecture/execution-engine/#template-syntax","title":"Template Syntax","text":"<pre><code>{{ nodeId.portName }}     -- Reference a specific node's output port\n{{ trigger.text }}        -- The trigger's text input\n{{ trigger.payload }}     -- The trigger's full payload\n{{ trigger.payload.key }} -- A specific key from the trigger payload\n</code></pre>"},{"location":"architecture/execution-engine/#context-variables","title":"Context Variables","text":"<p>The expression context includes:</p> Variable Source Example <code>&lt;node_id&gt;</code> <code>node_outputs[node_id]</code> <code>{{ agent_abc.output }}</code> <code>trigger</code> The trigger that fired this execution <code>{{ trigger.text }}</code> <p>The <code>trigger</code> shorthand always refers to whichever trigger fired the current execution, which is useful in multi-trigger workflows where chat and Telegram triggers feed the same downstream nodes.</p>"},{"location":"architecture/execution-engine/#jinja2-features","title":"Jinja2 Features","text":"<ul> <li>Standard filters are supported: <code>{{ trigger.text | upper }}</code></li> <li>Undefined variables gracefully fall back to the original template string (no errors)</li> <li>Nested access works: <code>{{ node.output.nested.key }}</code></li> </ul>"},{"location":"architecture/execution-engine/#frontend-integration","title":"Frontend Integration","text":"<p>The frontend provides an <code>ExpressionTextarea</code> component with a <code>{ }</code> button that opens a <code>VariablePicker</code> popover. The picker performs BFS over upstream nodes and presents clickable <code>{{ nodeId.port }}</code> items for insertion.</p>"},{"location":"architecture/execution-engine/#executor-servicesexecutorpy","title":"Executor (<code>services/executor.py</code>)","text":"<p>The executor is the top-level wrapper around the orchestrator, responsible for:</p> <ol> <li>Job setup -- Loading the workflow, execution, and related data from the database</li> <li>Graph building -- Calling the builder to compile the LangGraph graph</li> <li>Execution dispatch -- Calling the orchestrator to execute the graph</li> <li>Finalization -- Updating the execution status, persisting costs, and broadcasting completion events</li> <li>Cleanup -- Removing execution state from Redis</li> </ol>"},{"location":"architecture/execution-engine/#rq-job-wrappers","title":"RQ Job Wrappers","text":"<pre><code>def execute_workflow_job(execution_id: str):\n    \"\"\"RQ job entry point for full workflow execution.\"\"\"\n\ndef execute_node_job(execution_id: str, node_id: str):\n    \"\"\"RQ job entry point for single-node re-invocation\n    (used after subworkflow completion).\"\"\"\n</code></pre>"},{"location":"architecture/execution-engine/#state-model-servicesstatepy","title":"State Model (<code>services/state.py</code>)","text":"<p>The workflow state extends LangGraph's <code>MessagesState</code>:</p> <pre><code>class WorkflowState(MessagesState):\n    \"\"\"Global state passed through the LangGraph execution.\"\"\"\n    messages: Annotated[list[AnyMessage], add_messages]\n    node_outputs: dict[str, dict]\n    node_results: dict[str, NodeResult]\n    route: str\n    execution_id: str\n    user_context: dict\n</code></pre> <p>The <code>messages</code> field uses LangGraph's <code>add_messages</code> reducer, which handles deduplication via stable message IDs. This is critical for conversation memory where the system prompt is re-injected on each invocation.</p>"},{"location":"architecture/execution-engine/#component-output-convention","title":"Component Output Convention","text":"<p>Components return flat dicts with their port values:</p> <pre><code># Simple component\nreturn {\"output\": \"processed text\"}\n\n# Multi-port component\nreturn {\"category\": \"spam\", \"raw\": \"original text\", \"confidence\": 0.95}\n</code></pre> <p>The orchestrator automatically wraps all non-underscore keys into <code>node_outputs[node_id]</code>.</p>"},{"location":"architecture/execution-engine/#reserved-underscore-keys","title":"Reserved Underscore Keys","text":"Key Effect <code>_route</code> Sets <code>state[\"route\"]</code> for conditional edge routing <code>_messages</code> Appended to <code>state[\"messages\"]</code> (LangGraph message list) <code>_state_patch</code> Dict merged into global state (excluding protected keys) <code>_subworkflow</code> Signals subworkflow delegation to orchestrator <code>_token_usage</code> Token usage data accumulated by orchestrator for cost tracking <p>Components no longer receive or use their own <code>node_id</code>. Legacy format (returning <code>node_outputs</code> directly) is still supported for backwards compatibility.</p>"},{"location":"architecture/execution-engine/#conditional-routing","title":"Conditional Routing","text":""},{"location":"architecture/execution-engine/#switch-node","title":"Switch Node","text":"<p>The <code>switch</code> node evaluates rules against input data and emits a <code>_route</code> value:</p> <pre><code>rules = [\n    {\"field\": \"trigger.payload.type\", \"operator\": \"equals\", \"value\": \"urgent\", \"route\": \"fast_path\"},\n    {\"field\": \"trigger.payload.type\", \"operator\": \"equals\", \"value\": \"normal\", \"route\": \"standard\"},\n]\n# Falls back to \"default\" route if no rules match\n</code></pre>"},{"location":"architecture/execution-engine/#per-edge-condition-values","title":"Per-Edge Condition Values","text":"<p>Each conditional edge carries a <code>condition_value</code> string. The orchestrator matches <code>state[\"route\"]</code> against each outgoing edge's <code>condition_value</code> to determine the next node:</p> <pre><code>graph LR\n    Switch[switch] --&gt;|condition_value=\"fast_path\"| Agent1[urgent_agent]\n    Switch --&gt;|condition_value=\"standard\"| Agent2[normal_agent]\n    Switch --&gt;|condition_value=\"default\"| Log[logger]</code></pre> <p>Only <code>switch</code> nodes can originate conditional edges. This is enforced by the edge creation API.</p>"},{"location":"architecture/multi-agent/","title":"Multi-Agent","text":""},{"location":"architecture/multi-agent/#multi-agent-delegation","title":"Multi-Agent Delegation","text":"<p>Pipelit supports hierarchical multi-agent task delegation. An agent can receive a complex goal, decompose it into tasks, create or discover workflows to execute those tasks, track progress through a persistent registry, and learn from outcomes.</p> <p>This architecture builds entirely on Pipelit's existing primitives (workflow CRUD, agent nodes, tool sub-components, subworkflow execution) with the addition of a task registry and specialized agent tools.</p>"},{"location":"architecture/multi-agent/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph Trigger[\"Trigger Layer\"]\n        Chat[Chat Trigger]\n        TG[Telegram Trigger]\n        WH[Webhook Trigger]\n    end\n\n    subgraph MainAgent[\"Main Agent\"]\n        Agent[Agent Node + Tools]\n        Decision{Decision}\n        Agent --&gt; Decision\n        Decision --&gt;|Simple| Direct[Respond Directly]\n        Decision --&gt;|Multi-step| Epic[Create Epic]\n        Decision --&gt;|Familiar| Search[Search Registry]\n    end\n\n    subgraph Registry[\"Task Registry\"]\n        EpicModel[Epic&lt;br/&gt;Top-level goal]\n        Tasks[Tasks&lt;br/&gt;Discrete units of work]\n        EpicModel --&gt; Tasks\n    end\n\n    subgraph Execution[\"Workflow Execution\"]\n        Inline[Inline Tool Calls]\n        Spawn[spawn_and_await&lt;br/&gt;Subworkflow]\n        Create[workflow_create&lt;br/&gt;+ spawn_and_await]\n    end\n\n    Chat --&gt; Agent\n    TG --&gt; Agent\n    WH --&gt; Agent\n\n    Epic --&gt; Tasks\n    Search --&gt; Tasks\n    Tasks --&gt;|Simple task| Inline\n    Tasks --&gt;|Complex task| Spawn\n    Tasks --&gt;|Novel task| Create\n    Spawn --&gt;|Results| Registry\n    Create --&gt;|Results| Registry\n\n    classDef trigger fill:#fed7aa,stroke:#ea580c\n    classDef agent fill:#dbeafe,stroke:#2563eb\n    classDef registry fill:#d1fae5,stroke:#059669\n    classDef exec fill:#fce7f3,stroke:#db2777\n\n    class Chat,TG,WH trigger\n    class Agent,Decision,Direct,Epic,Search agent\n    class EpicModel,Tasks registry\n    class Inline,Spawn,Create exec</code></pre>"},{"location":"architecture/multi-agent/#key-architectural-decisions","title":"Key Architectural Decisions","text":""},{"location":"architecture/multi-agent/#workflows-over-agents","title":"Workflows Over Agents","text":"<p>The unit of delegation is workflows, not individual agents. Agents are single nodes. Workflows are composable graphs with triggers, tools, routing, and memory -- strictly more expressive. An agent delegating to a workflow subsumes delegating to an agent.</p>"},{"location":"architecture/multi-agent/#dynamic-subworkflows-over-json-plans","title":"Dynamic Subworkflows Over JSON Plans","text":"<p>Agents create executable workflow graphs, not static JSON task plans. A dynamically created subworkflow IS the plan AND is immediately executable:</p> <ul> <li>Nodes = subtasks</li> <li>Edges = dependencies</li> <li>Fan-out topology = parallel groups</li> </ul> <p>This eliminates the \"plan then interpret then execute\" pipeline.</p>"},{"location":"architecture/multi-agent/#two-level-task-hierarchy","title":"Two-Level Task Hierarchy","text":"<p>The registry uses two levels only -- Epics and Tasks:</p> <ul> <li>Epic = Top-level goal (e.g., \"Write comprehensive tests for platform auth\"). Spans multiple tasks, tracks budget, aggregates cost.</li> <li>Task = Discrete unit of work (e.g., \"Analyze coverage gaps in auth module\"). Maps to one workflow execution or one inline tool call sequence.</li> <li>Subtask = Nodes within a workflow. Already exist as workflow internals. Not modeled in the registry.</li> </ul>"},{"location":"architecture/multi-agent/#task-registry","title":"Task Registry","text":""},{"location":"architecture/multi-agent/#epic-model","title":"Epic Model","text":"<pre><code>class Epic(Base):\n    __tablename__ = \"epics\"\n\n    id: str                     # ULID primary key (ep_xxxxxxxxxxxx)\n    title: str                  # Short goal name\n    description: str            # Detailed goal, constraints, criteria\n    tags: list                  # For discovery (JSON column)\n    status: str                 # planning | active | paused | completed | failed | cancelled\n    priority: int               # 1=critical, 2=high, 3=medium, 4=low\n\n    # Budget tracking\n    budget_tokens: int | None   # Token ceiling\n    budget_usd: float | None    # USD ceiling\n    spent_tokens: int           # Running total from child tasks\n    spent_usd: float            # Running total from child tasks\n    agent_overhead_tokens: int  # Main agent's reasoning cost\n\n    # Progress\n    total_tasks: int\n    completed_tasks: int\n    failed_tasks: int\n</code></pre>"},{"location":"architecture/multi-agent/#task-model","title":"Task Model","text":"<pre><code>class Task(Base):\n    __tablename__ = \"tasks\"\n\n    id: str                     # ULID primary key (tk_xxxxxxxxxxxx)\n    epic_id: str                # FK -&gt; epics\n    title: str\n    status: str                 # pending | blocked | running | completed | failed | cancelled\n\n    # Workflow linkage\n    workflow_slug: str | None   # Assigned workflow\n    execution_id: str | None    # Current execution (soft reference)\n    workflow_source: str        # inline | existing | created | template\n\n    # Dependencies\n    depends_on: list            # List of task IDs (JSON column)\n\n    # Requirements for workflow matching\n    requirements: dict          # {\"model\": \"gpt-4\", \"tools\": [\"code\"], ...}\n\n    # Cost tracking\n    actual_tokens: int\n    actual_usd: float\n    retry_count: int\n    max_retries: int\n</code></pre>"},{"location":"architecture/multi-agent/#status-lifecycles","title":"Status Lifecycles","text":"<pre><code>stateDiagram-v2\n    state \"Epic Lifecycle\" as EpicLC {\n        [*] --&gt; planning\n        planning --&gt; active\n        active --&gt; completed\n        active --&gt; paused\n        paused --&gt; active\n        active --&gt; failed\n        active --&gt; cancelled\n        paused --&gt; cancelled\n    }\n\n    state \"Task Lifecycle\" as TaskLC {\n        [*] --&gt; pending\n        pending --&gt; blocked\n        blocked --&gt; pending : dependencies met\n        pending --&gt; running\n        running --&gt; completed\n        running --&gt; failed\n        failed --&gt; pending : retry\n        pending --&gt; cancelled\n        blocked --&gt; cancelled\n    }</code></pre>"},{"location":"architecture/multi-agent/#cost-aggregation","title":"Cost Aggregation","text":"<p>Costs roll up automatically from Task to Epic:</p> <pre><code>def sync_epic_costs(epic: Epic):\n    tasks = epic.tasks\n    epic.spent_tokens = sum(t.actual_tokens for t in tasks)\n    epic.spent_usd = sum(t.actual_usd for t in tasks)\n    epic.total_tasks = len(tasks)\n    epic.completed_tasks = sum(1 for t in tasks if t.status == \"completed\")\n    epic.failed_tasks = sum(1 for t in tasks if t.status == \"failed\")\n</code></pre> <p>Budget is checked before spawning new tasks:</p> <pre><code>def check_budget(epic: Epic, estimated_tokens: int) -&gt; tuple[bool, str]:\n    if epic.budget_tokens and (epic.spent_tokens + estimated_tokens &gt; epic.budget_tokens):\n        return False, \"Would exceed token budget\"\n    return True, \"ok\"\n</code></pre>"},{"location":"architecture/multi-agent/#agent-tools","title":"Agent Tools","text":""},{"location":"architecture/multi-agent/#registry-tools","title":"Registry Tools","text":"<p>These are registered as tool sub-components and connected to agent nodes via tool edges:</p> Tool Function Name Description <code>epic_create</code> <code>create_epic</code> Create a tracked epic with budget and tags <code>epic_status</code> <code>epic_status</code> Get progress, cost, and task breakdown <code>epic_update</code> <code>update_epic</code> Transition status, adjust budget, record outcome <code>epic_search</code> <code>search_epics</code> Search past epics by description and tags <code>task_create</code> <code>create_task</code> Create a task with dependencies and requirements <code>task_list</code> <code>list_tasks</code> List tasks filtered by epic, status, or tags <code>task_update</code> <code>update_task</code> Update status, add notes, record results <code>task_cancel</code> <code>cancel_task</code> Cancel task and its running execution"},{"location":"architecture/multi-agent/#spawn_and_await","title":"<code>spawn_and_await</code>","text":"<p>The critical delegation tool. Spawns a subworkflow execution and returns results using LangGraph's <code>interrupt()</code> primitive -- no RQ workers are blocked.</p> <pre><code>sequenceDiagram\n    participant RQ1 as RQ Worker 1\n    participant Agent as Agent (LangGraph)\n    participant Check as Checkpointer\n    participant Orch as Orchestrator\n    participant RQ2 as RQ Worker 2\n    participant Child as Child Workflow\n\n    RQ1-&gt;&gt;Agent: invoke(messages)\n    Agent-&gt;&gt;Agent: LLM reasons: \"delegate this task\"\n    Agent-&gt;&gt;Agent: Call spawn_and_await tool\n    Agent-&gt;&gt;Check: interrupt() - save full state\n    Note over Check: Conversation + pending&lt;br/&gt;tool call saved\n    Agent--&gt;&gt;RQ1: Return _subworkflow signal\n    RQ1-&gt;&gt;Orch: Handle _subworkflow\n    Orch-&gt;&gt;RQ2: Enqueue child execution\n    Note over RQ1: Worker released\n\n    RQ2-&gt;&gt;Child: Execute child workflow\n    Child--&gt;&gt;RQ2: Child result\n\n    RQ2-&gt;&gt;Orch: Child completed\n    Orch-&gt;&gt;Orch: Inject result into state\n    Orch-&gt;&gt;RQ1: Re-enqueue agent node\n\n    RQ1-&gt;&gt;Check: Load saved state\n    RQ1-&gt;&gt;Agent: Command(resume=child_result)\n    Agent-&gt;&gt;Agent: interrupt() returns child result\n    Agent-&gt;&gt;Agent: LLM continues: \"The subworkflow returned...\"\n    Agent--&gt;&gt;RQ1: Normal completion</code></pre>"},{"location":"architecture/multi-agent/#dual-checkpointer-strategy","title":"Dual Checkpointer Strategy","text":"<p><code>spawn_and_await</code> requires a checkpointer to save/restore agent state during interrupt/resume. Two backends are used depending on configuration:</p> Scenario Checkpointer Storage Thread ID Lifecycle <code>conversation_memory</code> ON <code>SqliteSaver</code> SQLite (<code>checkpoints.db</code>) <code>{user_id}:{chat_id}:{workflow_id}</code> Permanent -- conversation history persists <code>conversation_memory</code> OFF + has <code>spawn_and_await</code> Redis checkpointer Redis <code>exec:{execution_id}:{node_id}</code> Ephemeral -- auto-expires with 1h TTL Neither None -- -- One-shot, no checkpointing"},{"location":"architecture/multi-agent/#workflow_create","title":"<code>workflow_create</code>","text":"<p>Creates workflows programmatically from a YAML DSL specification. Supports two modes:</p> <ol> <li>Create from scratch -- Full DSL with trigger, steps, tools, and model declarations</li> <li>Fork and patch -- Start from an existing workflow, apply incremental modifications</li> </ol> <p>See the Workflow DSL page for the full specification.</p>"},{"location":"architecture/multi-agent/#workflow_discover","title":"<code>workflow_discover</code>","text":"<p>Searches existing workflows with gap-analysis scoring against declared requirements:</p> <pre><code># Agent calls workflow_discover with requirements\ndiscover_workflows(\n    query=\"webhook verification\",\n    requirements='{\"trigger\": \"webhook\", \"tools\": [\"code\"]}'\n)\n\n# Returns ranked results with gap analysis\n[{\n    \"slug\": \"moltbook-verify\",\n    \"match_score\": 0.95,\n    \"has\": [\"code\", \"webhook\"],\n    \"missing\": [],\n    \"extra\": [\"http_request\"],\n    \"success_rate\": 0.92,\n}]\n</code></pre> <p>Three-tier reuse decision:</p> Match Score Action &gt;= 0.95 Reuse as-is -- <code>spawn_and_await</code> directly &gt;= 0.50 Fork and patch -- <code>workflow_create</code> with <code>based_on</code> + <code>patches</code> &lt; 0.50 Create from scratch -- <code>workflow_create</code> with full DSL"},{"location":"architecture/multi-agent/#execution-walkthrough","title":"Execution Walkthrough","text":"<p>A concrete trace showing the full architecture handling: \"Read moltbook.com/skill.md and follow the instructions to join Moltbook.\"</p>"},{"location":"architecture/multi-agent/#step-1-agent-creates-epic","title":"Step 1: Agent Creates Epic","text":"<pre><code>Tool: epic_create({\n    title: \"Join Moltbook\",\n    description: \"Read moltbook.com/skill.md and follow join instructions\",\n    tags: [\"moltbook\", \"onboarding\"]\n})\n-&gt; { epic_id: \"ep_01JKXYZ\" }\n</code></pre>"},{"location":"architecture/multi-agent/#step-2-research-task-inline","title":"Step 2: Research Task (Inline)","text":"<pre><code>Tool: task_create({ epic_id: \"ep_01JKXYZ\", title: \"Fetch and analyze skill.md\" })\nTool: http_request({ url: \"https://moltbook.com/skill.md\" })\nTool: task_update({ task_id: \"tk_01JKABC\", status: \"completed\",\n    result_summary: \"Join requires: register, submit profile, verify webhook\" })\n</code></pre>"},{"location":"architecture/multi-agent/#step-3-registration-task-inline","title":"Step 3: Registration Task (Inline)","text":"<pre><code>Tool: task_create({ epic_id: \"ep_01JKXYZ\", title: \"Register with Moltbook API\" })\nTool: http_request({ url: \"https://moltbook.com/api/register\", method: \"POST\", ... })\nTool: task_update({ task_id: \"tk_01JKDEF\", status: \"completed\" })\n</code></pre>"},{"location":"architecture/multi-agent/#step-4-webhook-task-dynamic-workflow-creation","title":"Step 4: Webhook Task (Dynamic Workflow Creation)","text":"<pre><code>Tool: task_create({\n    epic_id: \"ep_01JKXYZ\",\n    title: \"Set up webhook for verification\",\n    depends_on: [\"tk_01JKDEF\"]\n})\nTool: workflow_create({\n    dsl: \"name: Moltbook Webhook\\ntrigger:\\n  type: webhook\\nsteps:\\n  ...\"\n})\nTool: task_update({ task_id: \"tk_01JKGHI\", status: \"completed\",\n    workflow_slug: \"moltbook-verify\" })\n</code></pre>"},{"location":"architecture/multi-agent/#step-5-epic-completed","title":"Step 5: Epic Completed","text":"<pre><code>Tool: epic_update({\n    epic_id: \"ep_01JKXYZ\",\n    status: \"completed\",\n    result_summary: \"Registered with Moltbook. Webhook endpoint live.\"\n})\n</code></pre>"},{"location":"architecture/multi-agent/#next-time-reuse","title":"Next Time: Reuse","text":"<p>When a similar request arrives (\"Set up a webhook for ServiceX\"):</p> <pre><code>Tool: epic_search({ query: \"webhook verification\" })\n-&gt; Returns ep_01JKXYZ with workflow \"moltbook-verify\"\n\nTool: workflow_discover({ requirements: {\"trigger\": \"webhook\", \"tools\": [\"code\"]} })\n-&gt; [{\"slug\": \"moltbook-verify\", \"match_score\": 0.95}]\n\nTool: workflow_create({\n    dsl: \"based_on: moltbook-verify\\npatches:\\n  - action: update_prompt\\n    ...\"\n})\n</code></pre> <p>Fork instead of reinvent. The proven structure is preserved.</p>"},{"location":"architecture/multi-agent/#integration-points","title":"Integration Points","text":""},{"location":"architecture/multi-agent/#orchestrator-cost-sync","title":"Orchestrator Cost Sync","text":"<p>After a child execution completes, token usage and USD costs are synced from the execution to the task, then rolled up to the epic:</p> <pre><code>Child execution completes\n  -&gt; _persist_execution_costs() writes to WorkflowExecution\n  -&gt; _sync_task_costs() writes to Task\n  -&gt; sync_epic_costs() rolls up to Epic\n  -&gt; _check_budget() gates next task\n</code></pre>"},{"location":"architecture/multi-agent/#websocket-events","title":"WebSocket Events","text":"<p>New channels and event types for real-time task tracking:</p> <ul> <li>Channel <code>epic:&lt;epic_id&gt;</code> carries <code>task_created</code>, <code>task_updated</code>, <code>epic_updated</code> events</li> <li>Agents subscribed to epic channels receive real-time status updates</li> </ul>"},{"location":"architecture/multi-agent/#feedback-loop","title":"Feedback Loop","text":"<p>After an epic completes successfully, it is persisted as procedural memory:</p> <pre><code>memory_write(\n    key=f\"procedure:{epic.id}\",\n    value={\n        \"goal\": epic.title,\n        \"tags\": epic.tags,\n        \"workflow_ids\": [t.workflow_id for t in epic.tasks],\n        \"success_rate\": epic.completed_tasks / epic.total_tasks,\n    },\n    fact_type=\"procedure\"\n)\n</code></pre> <p>Future agents discover successful patterns via both the registry (structured query through <code>epic_search</code>) and memory (semantic search through <code>memory_read</code>).</p>"},{"location":"architecture/node-io/","title":"Node I/O","text":""},{"location":"architecture/node-io/#node-io-standardization","title":"Node I/O Standardization","text":"<p>Pipelit uses a standardized type system for node inputs and outputs. This enables compile-time edge validation, a node type registry with port definitions, and consistent error handling across all component types.</p>"},{"location":"architecture/node-io/#core-schemas","title":"Core Schemas","text":"<p>All I/O schemas are defined in <code>platform/schemas/</code>:</p> <ul> <li><code>node_io.py</code> -- <code>NodeStatus</code>, <code>NodeError</code>, <code>NodeResult</code>, <code>NodeInput</code></li> <li><code>node_types.py</code> -- <code>DataType</code>, <code>PortDefinition</code>, <code>NodeTypeSpec</code>, <code>NODE_TYPE_REGISTRY</code></li> <li><code>node_type_defs.py</code> -- Registers all 23+ built-in node types with their port definitions</li> </ul>"},{"location":"architecture/node-io/#datatype-enum","title":"DataType Enum","text":"<p>Every port has a data type that determines what kind of data it produces or accepts:</p> DataType Description Example <code>STRING</code> Text content Agent output, code snippet result <code>NUMBER</code> Numeric value Calculator result, confidence score <code>BOOLEAN</code> True/false Filter pass/fail <code>OBJECT</code> JSON object Trigger payload, structured extraction <code>ARRAY</code> JSON array Loop items, search results <code>MESSAGES</code> LangGraph message list Conversation history <code>ANY</code> Accepts any type Generic pass-through"},{"location":"architecture/node-io/#portdefinition","title":"PortDefinition","text":"<p>Each port on a node is defined with:</p> <pre><code>class PortDefinition(BaseModel):\n    name: str           # Port name (e.g., \"output\", \"category\")\n    data_type: DataType # Type of data on this port\n    required: bool      # Whether this input must be connected\n    description: str    # Human-readable description\n</code></pre> <p>Example -- an agent node has one output port:</p> <pre><code>outputs=[\n    PortDefinition(\n        name=\"output\",\n        data_type=DataType.STRING,\n        required=False,\n        description=\"The agent's response text\",\n    )\n]\n</code></pre> <p>A categorizer node has two output ports:</p> <pre><code>outputs=[\n    PortDefinition(name=\"category\", data_type=DataType.STRING, ...),\n    PortDefinition(name=\"raw\", data_type=DataType.STRING, ...),\n]\n</code></pre>"},{"location":"architecture/node-io/#nodetypespec-and-the-registry","title":"NodeTypeSpec and the Registry","text":"<p>Each component type is registered as a <code>NodeTypeSpec</code>:</p> <pre><code>class NodeTypeSpec(BaseModel):\n    component_type: str        # \"agent\", \"trigger_chat\", \"code\", etc.\n    display_name: str          # \"Agent\", \"Chat Trigger\", \"Code\"\n    description: str           # Human-readable description\n    category: str              # \"ai\", \"trigger\", \"logic\", \"tool\", \"sub_component\"\n    inputs: list[PortDefinition]\n    outputs: list[PortDefinition]\n    executable: bool           # Whether this node runs during execution\n    config_schema: dict | None # JSON Schema for extra_config\n</code></pre> <p>All specs are collected in <code>NODE_TYPE_REGISTRY</code>, a dict keyed by <code>component_type</code>. This registry is:</p> <ul> <li>Served via <code>GET /workflows/node-types/</code> for the frontend</li> <li>Used by <code>EdgeValidator</code> for type compatibility checks</li> <li>Used by the orchestrator to determine which nodes are executable</li> </ul>"},{"location":"architecture/node-io/#registration-example","title":"Registration Example","text":"<pre><code>register_node_type(NodeTypeSpec(\n    component_type=\"agent\",\n    display_name=\"Agent\",\n    description=\"LLM-powered agent with tool calling\",\n    category=\"ai\",\n    inputs=[\n        PortDefinition(name=\"input\", data_type=DataType.STRING, required=True),\n    ],\n    outputs=[\n        PortDefinition(name=\"output\", data_type=DataType.STRING),\n    ],\n    executable=True,\n))\n</code></pre>"},{"location":"architecture/node-io/#edge-validation","title":"Edge Validation","text":"<p>The <code>EdgeValidator</code> class in <code>platform/validation/edges.py</code> enforces type safety at edge creation time.</p>"},{"location":"architecture/node-io/#type-compatibility-matrix","title":"Type Compatibility Matrix","text":"<pre><code>graph TD\n    subgraph \"Type Compatibility\"\n        ANY[\"ANY (accepts all)\"]\n        STRING[\"STRING\"]\n        NUMBER[\"NUMBER\"]\n        BOOLEAN[\"BOOLEAN\"]\n        OBJECT[\"OBJECT\"]\n        ARRAY[\"ARRAY\"]\n        MESSAGES[\"MESSAGES\"]\n    end\n\n    STRING --&gt;|compatible| ANY\n    NUMBER --&gt;|compatible| ANY\n    BOOLEAN --&gt;|compatible| ANY\n    OBJECT --&gt;|compatible| ANY\n    ARRAY --&gt;|compatible| ANY\n    MESSAGES --&gt;|compatible| ANY\n    STRING --&gt;|compatible| STRING\n    NUMBER --&gt;|compatible| NUMBER\n    BOOLEAN --&gt;|compatible| BOOLEAN\n    OBJECT --&gt;|compatible| OBJECT\n    ARRAY --&gt;|compatible| ARRAY\n    MESSAGES --&gt;|compatible| MESSAGES</code></pre> <p>A source output port is compatible with a target input port if:</p> <ul> <li>The target input accepts <code>ANY</code>, or</li> <li>The source output type matches the target input type exactly</li> </ul>"},{"location":"architecture/node-io/#validation-methods","title":"Validation Methods","text":"<pre><code>class EdgeValidator:\n    @staticmethod\n    def validate_edge(\n        source_node: WorkflowNode,\n        target_node: WorkflowNode,\n        edge_label: str,\n    ) -&gt; tuple[bool, str]:\n        \"\"\"Check type compatibility for a single edge.\"\"\"\n\n    @staticmethod\n    def validate_workflow_edges(\n        workflow_id: int, db: Session,\n    ) -&gt; list[str]:\n        \"\"\"Validate all edges in a workflow. Returns list of errors.\"\"\"\n\n    @staticmethod\n    def validate_required_inputs(\n        workflow_id: int, db: Session,\n    ) -&gt; list[str]:\n        \"\"\"Check that nodes have required sub-component connections\n        (e.g., agent must have a model connected).\"\"\"\n</code></pre>"},{"location":"architecture/node-io/#api-integration","title":"API Integration","text":"<ul> <li>Edge creation (<code>POST /workflows/{slug}/edges/</code>) -- Returns <code>422 Unprocessable Entity</code> if the edge would create a type mismatch</li> <li>Workflow validation (<code>POST /workflows/{slug}/validate/</code>) -- Runs full validation including all edges and required inputs</li> </ul>"},{"location":"architecture/node-io/#bypass-rules","title":"Bypass Rules","text":"<p>Certain edge labels bypass type-compatibility validation:</p> <ul> <li><code>loop_body</code> -- Loop to body node (flow control)</li> <li><code>loop_return</code> -- Body node back to loop (flow control)</li> <li><code>llm</code> -- Model connection (sub-component)</li> <li><code>tool</code> -- Tool connection (sub-component)</li> <li><code>memory</code> -- Memory connection (sub-component)</li> <li><code>output_parser</code> -- Parser connection (sub-component)</li> </ul>"},{"location":"architecture/node-io/#noderesult","title":"NodeResult","text":"<p>Every node execution produces a <code>NodeResult</code>:</p> <pre><code>class NodeResult(BaseModel):\n    status: NodeStatus        # success | failed | skipped\n    data: dict | None         # Output data (on success)\n    error: str | None         # Error message (on failure)\n    error_code: str | None    # Machine-readable error code\n    metadata: dict | None     # Timing, token usage, etc.\n\n    @classmethod\n    def success(cls, data: dict, **metadata) -&gt; \"NodeResult\": ...\n\n    @classmethod\n    def failed(cls, error: str, error_code: str, **metadata) -&gt; \"NodeResult\": ...\n\n    @classmethod\n    def skipped(cls, reason: str) -&gt; \"NodeResult\": ...\n</code></pre>"},{"location":"architecture/node-io/#nodestatus-enum","title":"NodeStatus Enum","text":"Status Description <code>pending</code> Node is queued for execution <code>running</code> Node is currently executing <code>success</code> Node completed successfully <code>failed</code> Node encountered an error <code>skipped</code> Node was skipped (upstream failure or route mismatch) <p>These statuses are broadcast via WebSocket <code>node_status</code> events and displayed as color-coded badges on the canvas:</p> <ul> <li>Running -- Spinning circle animation</li> <li>Success -- Green checkmark</li> <li>Failed -- Red X</li> <li>Skipped -- Gray dash</li> </ul> <p>Badges are only shown on executable nodes (driven by the <code>executable</code> flag from the node type registry).</p>"},{"location":"architecture/node-io/#component-output-convention","title":"Component Output Convention","text":"<p>Components return flat dicts. The orchestrator handles all wrapping and side effects:</p> <pre><code># Simple output\nreturn {\"output\": \"Hello, world!\"}\n\n# Multi-port output\nreturn {\n    \"category\": \"technical\",\n    \"raw\": \"Original question about Python decorators\",\n    \"confidence\": 0.92,\n}\n\n# Output with side effects\nreturn {\n    \"output\": \"Routed to fast path\",\n    \"_route\": \"fast_path\",                    # Sets state[\"route\"]\n    \"_messages\": [AIMessage(content=\"...\")],   # Appends to messages\n    \"_state_patch\": {\"user_context\": {...}},   # Merges into state\n}\n</code></pre>"},{"location":"architecture/node-io/#processing-rules","title":"Processing Rules","text":"<ol> <li>All keys without an underscore prefix become <code>node_outputs[node_id][key]</code></li> <li><code>_route</code> sets <code>state[\"route\"]</code> for downstream conditional edges</li> <li><code>_messages</code> entries are appended to <code>state[\"messages\"]</code></li> <li><code>_state_patch</code> dict is merged into state, excluding protected keys (<code>messages</code>, <code>node_outputs</code>, <code>node_results</code>)</li> <li><code>_subworkflow</code> triggers the orchestrator's subworkflow delegation flow</li> <li><code>_token_usage</code> is accumulated into <code>state[\"_execution_token_usage\"]</code> for cost tracking</li> </ol>"},{"location":"architecture/node-io/#frontend-integration","title":"Frontend Integration","text":""},{"location":"architecture/node-io/#typescript-interfaces","title":"TypeScript Interfaces","text":"<p>The frontend mirrors the Python schemas in <code>types/nodeIO.ts</code>:</p> <pre><code>interface PortDefinition {\n    name: string;\n    data_type: DataType;\n    required: boolean;\n    description: string;\n}\n\ninterface NodeTypeSpec {\n    component_type: string;\n    display_name: string;\n    description: string;\n    category: string;\n    inputs: PortDefinition[];\n    outputs: PortDefinition[];\n    executable: boolean;\n    config_schema?: Record&lt;string, unknown&gt;;\n}\n</code></pre>"},{"location":"architecture/node-io/#canvas-status-display","title":"Canvas Status Display","text":"<p>The <code>WorkflowCanvas</code> component tracks node execution status via WebSocket <code>node_status</code> events and applies:</p> <ul> <li>Color-coded borders matching the node's status</li> <li>Status badges (spinning circle, checkmark, X, dash)</li> <li>Clickable \"output\" links (emerald green) that open a popover with pretty-printed JSON output</li> <li>Clickable \"error\" links (red) that show error details and error codes</li> </ul>"},{"location":"architecture/self-improving/","title":"Self-Improving","text":""},{"location":"architecture/self-improving/#self-improving-agents","title":"Self-Improving Agents","text":"<p>Pipelit's long-term vision is a \"Self-Evolving Lego\" system where agents assemble workflows from nodes at runtime, learn from outcomes, modify themselves with guardrails, ask humans when uncertain, and crystallize successful patterns into reusable blocks.</p> <p>This page describes the roadmap, architecture, and design principles for self-aware, self-evolving agent capabilities.</p>"},{"location":"architecture/self-improving/#vision","title":"Vision","text":"<pre><code>Agent assembles workflows from nodes at runtime\nHuman watches construction on visual canvas\nAgent learns from outcomes, remembers patterns\nAgent can modify itself (with guardrails)\nAgent asks human when uncertain\nSuccessful patterns crystallize into reusable blocks\nComplexity emerges organically over time\n</code></pre>"},{"location":"architecture/self-improving/#core-capabilities","title":"Core Capabilities","text":"Capability Description Self-Awareness Agent knows its own config, structure, capabilities, and history Self-Evaluation Agent can assess what is working and what is not Self-Modification Agent can change its own workflows and configuration Guided Learning Agent asks human when uncertain, learns from answers Memory Agent remembers episodes, facts, and procedures Protection Guardrails prevent agent from breaking itself"},{"location":"architecture/self-improving/#architecture-layers","title":"Architecture Layers","text":"<pre><code>graph TB\n    subgraph Protection[\"Protection Layer\"]\n        Inv[Invariants]\n        Perm[Permissions]\n        CB[Circuit Breakers]\n        Audit[Audit Log]\n    end\n\n    subgraph SelfModel[\"Agent Self-Model\"]\n        Config[Config&lt;br/&gt;model, temperature, limits]\n        Structure[Structure&lt;br/&gt;nodes, edges, sub-agents]\n        Caps[Capabilities&lt;br/&gt;tools available]\n        Mem[Memory&lt;br/&gt;facts, procedures, episodes]\n        Hist[History&lt;br/&gt;successes, failures, corrections]\n    end\n\n    subgraph Tools[\"Evolution Tools\"]\n        WI[workflow_inspect]\n        WM[workflow_modify]\n        MR[memory_read / write]\n        CE[code_execute]\n        RG[request_guidance]\n        SE[self_evaluate]\n    end\n\n    subgraph Engine[\"Execution Engine\"]\n        Safe[Safe executor&lt;br/&gt;all checks applied]\n        Stream[Live streaming&lt;br/&gt;to canvas]\n        Approval[Approval workflows]\n    end\n\n    subgraph MemoryLayer[\"Memory Layer\"]\n        Episodes[Episodes&lt;br/&gt;raw logs]\n        Facts[Facts&lt;br/&gt;knowledge]\n        Procedures[Procedures&lt;br/&gt;skills]\n    end\n\n    Protection --&gt; SelfModel\n    SelfModel --&gt; Tools\n    Tools --&gt; Engine\n    Engine --&gt; MemoryLayer\n\n    classDef protect fill:#fee2e2,stroke:#dc2626\n    classDef self fill:#dbeafe,stroke:#2563eb\n    classDef tool fill:#d1fae5,stroke:#059669\n    classDef engine fill:#fef3c7,stroke:#d97706\n    classDef memory fill:#f3e8ff,stroke:#7c3aed\n\n    class Inv,Perm,CB,Audit protect\n    class Config,Structure,Caps,Mem,Hist self\n    class WI,WM,MR,CE,RG,SE tool\n    class Safe,Stream,Approval engine\n    class Episodes,Facts,Procedures memory</code></pre>"},{"location":"architecture/self-improving/#what-already-exists","title":"What Already Exists","text":"<p>The foundation for self-improving agents is largely in place:</p> Capability Status Implementation Trigger receiving (Telegram/Chat/Webhook) Complete <code>trigger_telegram</code>, <code>trigger_chat</code>, <code>trigger_webhook</code> Agent with tool calling Complete <code>agent</code> node + 12+ tool sub-component types Memory read/write Complete <code>memory_read</code>, <code>memory_write</code> tools Workflow inspect / self-modify Partial <code>whoami</code> + <code>platform_api</code> tools Human confirmation Complete <code>human_confirmation</code> node Subworkflow execution Complete <code>workflow</code> node + <code>spawn_and_await</code> Conditional routing Complete <code>switch</code> node + per-edge <code>condition_value</code> Sequential and DAG execution Complete Topology-based ordering, RQ job queue Loop iteration Complete <code>loop</code> node with body subgraph State flow between nodes Complete <code>node_outputs</code> + Jinja2 expression resolution Agent API credentials Complete <code>create_agent_user</code> tool Platform API access Complete <code>platform_api</code> tool Workflow CRUD via REST Complete Full API for workflows, nodes, edges Visual canvas with live updates Complete React Flow + WebSocket Cost tracking Complete <code>token_usage</code> service, budget enforcement via Epic budgets"},{"location":"architecture/self-improving/#development-phases","title":"Development Phases","text":""},{"location":"architecture/self-improving/#phase-1-foundation-memory","title":"Phase 1: Foundation (Memory)","text":"<p>Goal: Agent can remember and persist knowledge across executions.</p> <ul> <li>Memory tables (Episodes, Facts, Procedures)</li> <li><code>memory_read</code> and <code>memory_write</code> tool nodes</li> <li>Auto-logging of episodes after each execution</li> </ul> <p>Outcome: Agent remembers things across conversations. Status: Complete.</p>"},{"location":"architecture/self-improving/#phase-2-self-awareness","title":"Phase 2: Self-Awareness","text":"<p>Goal: Agent can see itself -- its own structure, capabilities, and history.</p> <ul> <li><code>workflow_inspect</code> tool (see own structure)</li> <li><code>AgentSelfModel</code> (structured self-knowledge)</li> <li>Execution logging and success/failure tracking</li> </ul> <p>Outcome: Agent can answer \"What am I? What can I do? What is my history?\" Status: Partial -- <code>whoami</code> and <code>platform_api</code> tools provide base capability.</p>"},{"location":"architecture/self-improving/#phase-3-protection","title":"Phase 3: Protection","text":"<p>Goal: Agent cannot break itself.</p> Component Purpose Status Invariants Hardcoded limits agent cannot see or change Planned Permission matrix What agent can and cannot modify Planned Circuit breakers Auto-stop on repeated failures Planned Rate limits Prevent runaway execution Planned Cost tracking Budget enforcement Complete Audit log Immutable record of all actions Planned <p>Outcome: Agent operates safely within defined boundaries.</p>"},{"location":"architecture/self-improving/#phase-4-self-modification","title":"Phase 4: Self-Modification","text":"<p>Goal: Agent can change itself, safely.</p> <ul> <li><code>workflow_modify</code> tool (add/remove/rewire nodes)</li> <li>Approval system (human approves risky changes)</li> <li>Config adjustment (agent tunes own temperature, etc.)</li> <li>Pattern saving (save successful workflows as templates)</li> </ul> <p>Outcome: Agent can propose and apply changes to itself.</p>"},{"location":"architecture/self-improving/#phase-5-guided-learning","title":"Phase 5: Guided Learning","text":"<p>Goal: Agent asks when stuck, learns from answers.</p> <ul> <li>Confidence scoring (know when uncertain)</li> <li>Human guidance request (ask questions with options)</li> <li>Learning persistence (save human teachings)</li> <li>Preference extraction (learn from corrections)</li> </ul> <p>Outcome: Agent improves through human interaction.</p>"},{"location":"architecture/self-improving/#phase-6-live-visibility","title":"Phase 6: Live Visibility","text":"<p>Goal: Human sees everything in real-time.</p> <ul> <li>Execution streaming (watch nodes execute live) -- Complete</li> <li>Canvas status colors (see running/success/failed) -- Complete</li> <li>Pause/resume (intervene mid-execution) -- Planned</li> <li>Edit mid-flight (change nodes during execution) -- Planned</li> <li>Agent proposals UI (see what agent wants to change) -- Planned</li> </ul> <p>Outcome: Full transparency into agent behavior.</p>"},{"location":"architecture/self-improving/#phase-7-emergence","title":"Phase 7: Emergence","text":"<p>Goal: Complexity grows organically.</p> <ul> <li>Self-reflection workflow (periodic self-evaluation)</li> <li>Pattern composition (combine patterns into larger ones)</li> <li>Habit formation (frequently-used patterns become automatic)</li> <li>Priority emergence (learn task importance from usage)</li> <li>Memory consolidation (extract facts from episodes)</li> </ul> <p>Outcome: Agent evolves toward emergent executive function.</p>"},{"location":"architecture/self-improving/#the-bootstrap-moment","title":"The Bootstrap Moment","text":"<p>After Phase 4, the agent reaches bootstrap capability -- the point where it can request and grow its own capabilities:</p> <pre><code>graph TD\n    A[\"Agent: 'I need to fetch weather data&lt;br/&gt;but I don't have HTTP capability'\"]\n    B[\"workflow_inspect() -&gt; sees no http_request node\"]\n    C[\"workflow_modify('add_node', {type: 'http_request'})\"]\n    D[\"System: 'Requires approval'\"]\n    E[\"Human: 'Approved'\"]\n    F[\"Agent now has http_request capability\"]\n    G[\"memory_write('I can now make HTTP requests')\"]\n\n    A --&gt; B --&gt; C --&gt; D --&gt; E --&gt; F --&gt; G\n\n    classDef agent fill:#dbeafe,stroke:#2563eb\n    classDef system fill:#fef3c7,stroke:#d97706\n    classDef human fill:#d1fae5,stroke:#059669\n\n    class A,B,C,F,G agent\n    class D system\n    class E human</code></pre> <p>From this point, the agent can request and grow its own capabilities. The human approves, or the agent writes code to compensate.</p>"},{"location":"architecture/self-improving/#self-iteration-loop","title":"Self-Iteration Loop","text":"<p>The minimum viable self-evolution loop:</p> <pre><code>graph LR\n    Observe[\"1. OBSERVE&lt;br/&gt;Log execution\"] --&gt; Evaluate[\"2. EVALUATE&lt;br/&gt;Score outcomes\"]\n    Evaluate --&gt; Modify[\"3. MODIFY&lt;br/&gt;Save pattern /&lt;br/&gt;request change\"]\n    Modify --&gt; Observe\n\n    classDef step fill:#e0e7ff,stroke:#4f46e5\n    class Observe,Evaluate,Modify step</code></pre> <ol> <li>Observe -- Automatically log every execution (episodes, inputs, outputs, success/failure)</li> <li>Evaluate -- Score outcomes using a multi-signal formula:<ul> <li>Success rate (0.3 weight)</li> <li>1 - intervention rate (0.2 weight)</li> <li>Human rating (0.3 weight)</li> <li>Reuse count (0.2 weight)</li> </ul> </li> <li>Modify -- Save successful patterns as procedures, or request changes via the approval system</li> </ol>"},{"location":"architecture/self-improving/#evaluation-signals","title":"Evaluation Signals","text":"<p>No single signal is sufficient. The platform combines multiple evaluation layers:</p> Layer Signal When Immediate Success/failure, errors During execution Session Human rating, corrections End of interaction Implicit Reuse count, intervention rate Over time Outcome External success signals Days later"},{"location":"architecture/self-improving/#memory-driven-learning","title":"Memory-Driven Learning","text":"<p>The three memory types each serve a different role in the learning cycle:</p> Memory Type Purpose Growth Rate Example Episodes Raw execution logs Fast (every run) \"Executed Moltbook join workflow, 3 tasks, 2340ms\" Facts Extracted knowledge Slow (consolidated) \"Moltbook requires webhook verification\" Procedures Reusable patterns/skills Slowest (learned) \"Webhook verification: create code node + webhook trigger\" <p>The learning progression:</p> <ol> <li>Episodes accumulate from raw execution</li> <li>Facts are extracted from episodes (e.g., \"This API requires auth header\")</li> <li>Procedures crystallize from repeated successful patterns (e.g., \"To verify webhooks, fork the moltbook-verify workflow\")</li> </ol>"},{"location":"architecture/self-improving/#integration-with-multi-agent-delegation","title":"Integration with Multi-Agent Delegation","text":"<p>The self-improving architecture connects directly to the multi-agent delegation system:</p> <ul> <li>Epic/Task Registry -- Provides the structured tracking layer for self-assessment (\"What have I worked on? What succeeded?\")</li> <li>workflow_discover -- Enables pattern reuse (\"Has anyone solved this before?\")</li> <li>workflow_create -- Enables self-modification (\"I need a new workflow for this task\")</li> <li>spawn_and_await -- Enables delegation (\"This task needs its own workflow\")</li> <li>Cost tracking -- Provides budget guardrails (\"Am I within my resource limits?\")</li> </ul>"},{"location":"architecture/self-improving/#success-criteria","title":"Success Criteria","text":"Milestone Criteria Memory works Agent recalls facts from previous sessions Self-aware Agent accurately describes its own structure Protected Agent cannot delete its own protection layer Self-modifying Agent successfully adds a new node (with approval) Learning Agent asks question, human answers, agent remembers Visible Human watches execution in real-time on canvas Evolving Agent proposes improvement based on failure pattern"},{"location":"architecture/self-improving/#roadmap-summary","title":"Roadmap Summary","text":"Week Phase Deliverable 1-3 Foundation Memory tables + read/write nodes + code execution 4-5 Self-Awareness workflow_inspect + AgentSelfModel 6-7 Protection Invariants + permissions + circuit breakers 8-10 Self-Modification workflow_modify + approval flow + pattern saving 11-13 Guided Learning Confidence scoring + human guidance + persistence 14-16 Live Visibility Execution streaming + pause/resume + edit mid-flight 17+ Emergence Self-reflection + pattern composition + habit formation <p>The foundation (Phase 1) comes first because without memory there is no learning. Everything else builds on that base.</p>"},{"location":"architecture/system-overview/","title":"System Overview","text":""},{"location":"architecture/system-overview/#system-overview","title":"System Overview","text":"<p>Pipelit is a visual workflow automation platform for building LLM-powered agents. This page describes how all major system components connect and interact.</p>"},{"location":"architecture/system-overview/#architecture-diagram","title":"Architecture Diagram","text":"<pre><code>graph TB\n    subgraph Frontend[\"React Frontend (Vite + TypeScript)\"]\n        RC[React Flow Canvas]\n        TQ[TanStack Query]\n        WM[WebSocketManager]\n    end\n\n    subgraph API[\"FastAPI Application\"]\n        Routes[API Routers&lt;br/&gt;/api/v1/*]\n        Auth[Bearer Token Auth]\n        Pydantic[Pydantic Schemas]\n        StaticMount[Static File Mount&lt;br/&gt;frontend/dist/]\n    end\n\n    subgraph DB[\"Database Layer\"]\n        SA[SQLAlchemy 2.0 ORM]\n        Alembic[Alembic Migrations]\n        SQLite[(SQLite / PostgreSQL)]\n        Checkpoints[(checkpoints.db&lt;br/&gt;SqliteSaver)]\n    end\n\n    subgraph RedisLayer[\"Redis\"]\n        PubSub[Pub/Sub Channels]\n        JobQueue[RQ Job Queue]\n        Cache[Graph Cache]\n        ExecState[Execution State]\n    end\n\n    subgraph Workers[\"RQ Workers\"]\n        Executor[WorkflowExecutor]\n        Orchestrator[Orchestrator]\n        Scheduler[Scheduler Jobs]\n    end\n\n    subgraph Execution[\"Execution Engine\"]\n        Builder[Builder&lt;br/&gt;Workflow \u2192 LangGraph]\n        LangGraph[LangGraph&lt;br/&gt;CompiledGraph]\n        Components[Component Library&lt;br/&gt;20+ node types]\n        Topology[Topology Analyzer&lt;br/&gt;BFS reachability]\n    end\n\n    subgraph External[\"External Services\"]\n        LLM[LLM Providers&lt;br/&gt;OpenAI / Anthropic / etc.]\n        Telegram[Telegram Bot API]\n        Webhooks[Incoming Webhooks]\n    end\n\n    %% Frontend \u2192 API\n    RC --&gt;|HTTP REST| Routes\n    TQ --&gt;|fetch + Bearer token| Routes\n    WM &lt;--&gt;|WebSocket + token| PubSub\n\n    %% API \u2192 DB\n    Routes --&gt; Auth\n    Routes --&gt; Pydantic\n    Routes --&gt; SA\n    SA --&gt; SQLite\n    Alembic --&gt; SQLite\n\n    %% API \u2192 Redis\n    Routes --&gt;|broadcast events| PubSub\n    Routes --&gt;|enqueue jobs| JobQueue\n\n    %% Workers\n    JobQueue --&gt;|dequeue| Executor\n    Executor --&gt; Orchestrator\n    Orchestrator --&gt; Builder\n    Builder --&gt; Topology\n    Builder --&gt; LangGraph\n    Orchestrator --&gt; Components\n    Orchestrator --&gt;|node_status events| PubSub\n    Orchestrator --&gt;|state read/write| ExecState\n    Scheduler --&gt;|self-rescheduling| JobQueue\n\n    %% Execution\n    Components --&gt;|LLM calls| LLM\n    Components --&gt;|checkpointer| Checkpoints\n    Builder --&gt;|cache compiled graph| Cache\n\n    %% External triggers\n    Telegram --&gt;|incoming messages| Routes\n    Webhooks --&gt;|incoming payloads| Routes\n\n    %% Styling\n    classDef frontend fill:#e0e7ff,stroke:#4f46e5,color:#1e1b4b\n    classDef api fill:#fef3c7,stroke:#d97706,color:#78350f\n    classDef db fill:#d1fae5,stroke:#059669,color:#064e3b\n    classDef redis fill:#fee2e2,stroke:#dc2626,color:#7f1d1d\n    classDef worker fill:#fce7f3,stroke:#db2777,color:#831843\n    classDef exec fill:#e0f2fe,stroke:#0284c7,color:#0c4a6e\n    classDef external fill:#f3e8ff,stroke:#7c3aed,color:#3b0764\n\n    class RC,TQ,WM frontend\n    class Routes,Auth,Pydantic,StaticMount api\n    class SA,Alembic,SQLite,Checkpoints db\n    class PubSub,JobQueue,Cache,ExecState redis\n    class Executor,Orchestrator,Scheduler worker\n    class Builder,LangGraph,Components,Topology exec\n    class LLM,Telegram,Webhooks external</code></pre>"},{"location":"architecture/system-overview/#component-descriptions","title":"Component Descriptions","text":""},{"location":"architecture/system-overview/#react-frontend","title":"React Frontend","text":"<p>The frontend is a React SPA built with Vite and TypeScript. It uses React Flow (v12) for the visual workflow canvas, TanStack Query for server state management, and Shadcn/ui for the component library.</p> <ul> <li>React Flow Canvas -- Users design workflows by placing nodes and connecting them with edges on a drag-and-drop canvas.</li> <li>TanStack Query -- All API calls use TanStack Query hooks. Mutations no longer invalidate queries on success; instead, updates arrive via WebSocket and are applied directly to the query cache.</li> <li>WebSocketManager -- A singleton that maintains a persistent WebSocket connection with exponential backoff reconnection and automatic resubscription after disconnect.</li> </ul>"},{"location":"architecture/system-overview/#fastapi-application","title":"FastAPI Application","text":"<p>The backend is a FastAPI application serving both the REST API and the built frontend.</p> <ul> <li>API Routers -- All endpoints live under <code>/api/v1/</code> and handle workflow CRUD, node/edge management, executions, credentials, chat, schedules, memory, and epics/tasks.</li> <li>Bearer Token Auth -- Every request is authenticated via <code>Authorization: Bearer &lt;api_key&gt;</code>. There is no session auth, OAuth, or basic auth.</li> <li>Pydantic Schemas -- Request/response validation uses Pydantic models with <code>Literal</code> types for component types, trigger types, and edge types.</li> <li>Static File Mount -- In production, the built frontend (<code>frontend/dist/</code>) is served directly by FastAPI.</li> </ul>"},{"location":"architecture/system-overview/#database-layer","title":"Database Layer","text":"<ul> <li>SQLAlchemy 2.0 ORM -- All models use SQLAlchemy 2.0 with declarative mapping. The node system uses polymorphic inheritance for component configurations.</li> <li>Alembic Migrations -- Schema changes are managed via Alembic. SQLite <code>batch_alter_table</code> operations require extra care to avoid data loss.</li> <li>SQLite / PostgreSQL -- SQLite is the default for development; PostgreSQL is supported for production.</li> <li>Checkpoints DB -- A separate SQLite database (<code>checkpoints.db</code>) stores LangGraph conversation checkpoints for agent memory continuity.</li> </ul>"},{"location":"architecture/system-overview/#redis","title":"Redis","text":"<p>Redis serves four distinct roles in the platform:</p> <ul> <li>Pub/Sub -- The WebSocket broadcast system uses Redis pub/sub to fan out events across multiple API server instances and RQ workers.</li> <li>Job Queue -- RQ (Redis Queue) manages background job processing for workflow executions and scheduled jobs.</li> <li>Graph Cache -- Compiled LangGraph graphs are cached in Redis to avoid recompilation on repeated executions.</li> <li>Execution State -- Per-execution state (node outputs, node results, route values) is stored in Redis during execution and cleaned up after completion.</li> </ul>"},{"location":"architecture/system-overview/#rq-workers","title":"RQ Workers","text":"<p>Background processing is handled by RQ workers that dequeue jobs from Redis.</p> <ul> <li>WorkflowExecutor -- The top-level wrapper that sets up the execution environment and delegates to the orchestrator.</li> <li>Orchestrator -- The core execution engine that walks through nodes in topological order, resolves expressions, executes components, and broadcasts status events.</li> <li>Scheduler Jobs -- Self-rescheduling jobs that implement recurring workflow execution without external cron. Each job dispatches its trigger, handles success/failure with exponential backoff, and enqueues its next run.</li> </ul>"},{"location":"architecture/system-overview/#execution-engine","title":"Execution Engine","text":"<ul> <li>Builder -- Compiles a <code>Workflow</code> database model into a LangGraph <code>CompiledGraph</code>. Only nodes reachable from the firing trigger are included (trigger-scoped execution via BFS).</li> <li>LangGraph -- The compiled graph is executed by LangGraph, which handles state transitions, message passing, and checkpointing.</li> <li>Component Library -- Over 20 component types implement the actual node logic: agents, tools, triggers, routing, code execution, memory, and more.</li> <li>Topology Analyzer -- BFS-based reachability analysis that determines which nodes are downstream from a given trigger.</li> </ul>"},{"location":"architecture/system-overview/#external-services","title":"External Services","text":"<ul> <li>LLM Providers -- Agent and AI nodes call external LLM APIs (OpenAI, Anthropic, and others) via LangChain. Credentials are stored encrypted with Fernet.</li> <li>Telegram Bot API -- The Telegram trigger handler receives incoming messages and dispatches them to workflows.</li> <li>Incoming Webhooks -- External services can trigger workflow execution via webhook endpoints.</li> </ul>"},{"location":"architecture/system-overview/#request-flow","title":"Request Flow","text":"<p>A typical user interaction flows through the system as follows:</p> <pre><code>sequenceDiagram\n    participant User as Browser\n    participant API as FastAPI\n    participant DB as SQLite\n    participant Redis\n    participant RQ as RQ Worker\n    participant LG as LangGraph\n    participant LLM as LLM Provider\n    participant WS as WebSocket\n\n    User-&gt;&gt;API: POST /workflows/{slug}/chat/\n    API-&gt;&gt;DB: Create WorkflowExecution\n    API-&gt;&gt;Redis: Enqueue RQ job\n    API--&gt;&gt;User: 202 Accepted (execution_id)\n\n    RQ-&gt;&gt;Redis: Dequeue job\n    RQ-&gt;&gt;DB: Load workflow + nodes + edges\n    RQ-&gt;&gt;RQ: Build LangGraph (trigger-scoped BFS)\n    RQ-&gt;&gt;Redis: Set initial execution state\n\n    loop For each node in topological order\n        RQ-&gt;&gt;WS: Broadcast node_status: running\n        RQ-&gt;&gt;RQ: Resolve Jinja2 expressions\n        RQ-&gt;&gt;LG: Execute component\n        LG-&gt;&gt;LLM: API call (if AI node)\n        LLM--&gt;&gt;LG: Response\n        LG--&gt;&gt;RQ: Component output\n        RQ-&gt;&gt;Redis: Store node_outputs\n        RQ-&gt;&gt;WS: Broadcast node_status: success\n    end\n\n    RQ-&gt;&gt;DB: Update execution status\n    RQ-&gt;&gt;WS: Broadcast execution_completed\n    RQ-&gt;&gt;Redis: Cleanup execution state\n\n    WS--&gt;&gt;User: Real-time status updates</code></pre>"},{"location":"architecture/system-overview/#technology-stack-summary","title":"Technology Stack Summary","text":"Layer Technology Frontend React, TypeScript, Vite, React Flow v12, TanStack Query, Shadcn/ui API FastAPI, Pydantic, Uvicorn ORM SQLAlchemy 2.0 Database SQLite (dev) / PostgreSQL (prod) Migrations Alembic Background Jobs RQ (Redis Queue) Execution Engine LangGraph LLM Integration LangChain Cache / Pub/Sub / State Redis Auth Bearer token (API keys), Fernet encryption for secrets"},{"location":"architecture/websocket-system/","title":"WebSocket System","text":""},{"location":"architecture/websocket-system/#websocket-system","title":"WebSocket System","text":"<p>Pipelit uses a single global authenticated WebSocket connection to deliver real-time updates to the frontend. This replaces per-execution WebSocket connections and eliminates the need for polling.</p>"},{"location":"architecture/websocket-system/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph Clients[\"Frontend Clients\"]\n        C1[Browser 1]\n        C2[Browser 2]\n    end\n\n    subgraph API[\"FastAPI Server\"]\n        WSEndpoint[WebSocket Endpoint&lt;br/&gt;/ws/?token=API_KEY]\n        Router1[API Router&lt;br/&gt;node/edge mutations]\n    end\n\n    subgraph Redis[\"Redis\"]\n        PS[Pub/Sub Channels]\n    end\n\n    subgraph Workers[\"RQ Workers\"]\n        Orch[Orchestrator&lt;br/&gt;node_status events]\n        Sched[Scheduler&lt;br/&gt;execution events]\n    end\n\n    C1 &lt;--&gt;|WebSocket| WSEndpoint\n    C2 &lt;--&gt;|WebSocket| WSEndpoint\n    WSEndpoint &lt;--&gt;|subscribe/publish| PS\n    Router1 --&gt;|broadcast()| PS\n    Orch --&gt;|broadcast()| PS\n    Sched --&gt;|broadcast()| PS\n\n    classDef client fill:#e0e7ff,stroke:#4f46e5\n    classDef api fill:#fef3c7,stroke:#d97706\n    classDef redis fill:#fee2e2,stroke:#dc2626\n    classDef worker fill:#fce7f3,stroke:#db2777\n\n    class C1,C2 client\n    class WSEndpoint,Router1 api\n    class PS redis\n    class Orch,Sched worker</code></pre>"},{"location":"architecture/websocket-system/#backend-implementation","title":"Backend Implementation","text":""},{"location":"architecture/websocket-system/#websocket-endpoint-wsglobal_wspy","title":"WebSocket Endpoint (<code>ws/global_ws.py</code>)","text":"<p>A single persistent WebSocket at <code>GET /ws/?token=&lt;api_key&gt;</code>:</p> <ul> <li>Authentication -- Token is validated on connect. Invalid tokens get an immediate close.</li> <li>Heartbeat -- Server sends <code>{\"type\": \"ping\"}</code> every 30 seconds. Client must respond with <code>{\"type\": \"pong\"}</code>. Missing pongs trigger disconnect.</li> <li>Redis pub/sub fan-out -- Each WebSocket connection subscribes to Redis channels on behalf of the client. Messages from Redis are forwarded to the WebSocket.</li> </ul>"},{"location":"architecture/websocket-system/#broadcast-helper-wsbroadcastpy","title":"Broadcast Helper (<code>ws/broadcast.py</code>)","text":"<p>A synchronous function usable from both API endpoints and RQ workers:</p> <pre><code>def broadcast(channel: str, event_type: str, data: dict):\n    \"\"\"Publish an event to all subscribers of a channel.\n\n    Args:\n        channel: \"workflow:&lt;slug&gt;\" or \"execution:&lt;id&gt;\"\n        event_type: \"node_status\", \"node_created\", etc.\n        data: Event payload\n    \"\"\"\n</code></pre> <p>This function publishes to Redis pub/sub. The WebSocket endpoint picks up the message and forwards it to all connected clients subscribed to that channel.</p>"},{"location":"architecture/websocket-system/#subscription-protocol","title":"Subscription Protocol","text":"<p>The client and server communicate via JSON messages over the WebSocket:</p>"},{"location":"architecture/websocket-system/#client-to-server","title":"Client to Server","text":"<pre><code>{\"type\": \"subscribe\", \"channel\": \"workflow:my-workflow\"}\n</code></pre> <pre><code>{\"type\": \"unsubscribe\", \"channel\": \"workflow:my-workflow\"}\n</code></pre> <pre><code>{\"type\": \"pong\"}\n</code></pre>"},{"location":"architecture/websocket-system/#server-to-client","title":"Server to Client","text":"<pre><code>{\"type\": \"subscribed\", \"channel\": \"workflow:my-workflow\"}\n</code></pre> <pre><code>{\"type\": \"unsubscribed\", \"channel\": \"workflow:my-workflow\"}\n</code></pre> <pre><code>{\"type\": \"ping\"}\n</code></pre> <pre><code>{\n    \"type\": \"node_status\",\n    \"channel\": \"workflow:my-workflow\",\n    \"data\": {\n        \"node_id\": \"agent_abc123\",\n        \"status\": \"success\",\n        \"output\": {\"output\": \"Hello!\"}\n    }\n}\n</code></pre>"},{"location":"architecture/websocket-system/#subscription-flow","title":"Subscription Flow","text":"<pre><code>sequenceDiagram\n    participant Client as Browser\n    participant WS as WebSocket Endpoint\n    participant Redis as Redis Pub/Sub\n\n    Client-&gt;&gt;WS: Connect /ws/?token=KEY\n    WS-&gt;&gt;WS: Validate token\n    WS--&gt;&gt;Client: Connection established\n\n    Client-&gt;&gt;WS: {\"type\":\"subscribe\",\"channel\":\"workflow:my-wf\"}\n    WS-&gt;&gt;Redis: SUBSCRIBE workflow:my-wf\n    WS--&gt;&gt;Client: {\"type\":\"subscribed\",\"channel\":\"workflow:my-wf\"}\n\n    Note over Redis: API mutation or orchestrator&lt;br/&gt;calls broadcast()\n    Redis--&gt;&gt;WS: Event message\n    WS--&gt;&gt;Client: {\"type\":\"node_created\",\"channel\":\"workflow:my-wf\",\"data\":{...}}\n\n    loop Every 30 seconds\n        WS--&gt;&gt;Client: {\"type\":\"ping\"}\n        Client-&gt;&gt;WS: {\"type\":\"pong\"}\n    end\n\n    Client-&gt;&gt;WS: {\"type\":\"unsubscribe\",\"channel\":\"workflow:my-wf\"}\n    WS-&gt;&gt;Redis: UNSUBSCRIBE workflow:my-wf\n    WS--&gt;&gt;Client: {\"type\":\"unsubscribed\",\"channel\":\"workflow:my-wf\"}</code></pre>"},{"location":"architecture/websocket-system/#event-types","title":"Event Types","text":""},{"location":"architecture/websocket-system/#canvas-mutation-events","title":"Canvas Mutation Events","text":"<p>Published by API routers when nodes or edges are created, updated, or deleted:</p> Event Type Channel Payload <code>node_created</code> <code>workflow:&lt;slug&gt;</code> Full node data <code>node_updated</code> <code>workflow:&lt;slug&gt;</code> Updated node fields <code>node_deleted</code> <code>workflow:&lt;slug&gt;</code> <code>{node_id}</code> <code>edge_created</code> <code>workflow:&lt;slug&gt;</code> Full edge data <code>edge_updated</code> <code>workflow:&lt;slug&gt;</code> Updated edge fields <code>edge_deleted</code> <code>workflow:&lt;slug&gt;</code> <code>{edge_id}</code> <code>workflow_updated</code> <code>workflow:&lt;slug&gt;</code> Updated workflow fields"},{"location":"architecture/websocket-system/#execution-events","title":"Execution Events","text":"<p>Published by the orchestrator during workflow execution:</p> Event Type Channel Payload <code>node_status</code> <code>workflow:&lt;slug&gt;</code> <code>{node_id, status, output?, error?, error_code?}</code> <code>execution_completed</code> <code>workflow:&lt;slug&gt;</code> <code>{execution_id, status, duration_ms}</code> <code>execution_failed</code> <code>workflow:&lt;slug&gt;</code> <code>{execution_id, error}</code> <code>execution_interrupted</code> <code>workflow:&lt;slug&gt;</code> <code>{execution_id, reason}</code>"},{"location":"architecture/websocket-system/#task-registry-events","title":"Task Registry Events","text":"<p>Published when epics or tasks are modified:</p> Event Type Channel Payload <code>task_created</code> <code>epic:&lt;epic_id&gt;</code> <code>{task_id, epic_id, title, status}</code> <code>task_updated</code> <code>epic:&lt;epic_id&gt;</code> <code>{task_id, status, cost?}</code> <code>epic_updated</code> <code>epic:&lt;epic_id&gt;</code> <code>{epic_id, status, progress}</code>"},{"location":"architecture/websocket-system/#node-status-values","title":"Node Status Values","text":"<p>The <code>node_status</code> event carries a <code>status</code> field with one of:</p> Status Meaning Canvas Badge <code>pending</code> Queued for execution -- <code>running</code> Currently executing Spinning circle <code>success</code> Completed successfully Green checkmark <code>failed</code> Encountered an error Red X <code>skipped</code> Skipped (route mismatch or upstream failure) Gray dash"},{"location":"architecture/websocket-system/#frontend-implementation","title":"Frontend Implementation","text":""},{"location":"architecture/websocket-system/#websocketmanager-libwsmanagerts","title":"WebSocketManager (<code>lib/wsManager.ts</code>)","text":"<p>A singleton that manages the WebSocket connection lifecycle:</p> <pre><code>class WebSocketManager {\n    connect(token: string): void;\n    disconnect(): void;\n    subscribe(channel: string): void;\n    unsubscribe(channel: string): void;\n    registerHandler(eventType: string, handler: Function): void;\n    unregisterHandler(eventType: string, handler: Function): void;\n}\n</code></pre> <p>Key behaviors:</p> <ul> <li>Exponential backoff reconnection -- On disconnect, the manager retries with increasing delays (1s, 2s, 4s, 8s, up to 30s)</li> <li>Auto-resubscribe -- After reconnecting, all previously active subscriptions are automatically restored</li> <li>TanStack Query cache updates -- The manager directly updates TanStack Query's cache when receiving mutation events:<ul> <li><code>node_created/updated/deleted</code> -- <code>setQueryData</code> on the nodes query</li> <li><code>edge_created/updated/deleted</code> -- <code>setQueryData</code> on the edges query</li> <li><code>execution_completed/failed</code> -- <code>invalidateQueries</code> on the executions query</li> </ul> </li> <li>Handler registration -- Components can register callbacks for specific event types (e.g., ChatPanel registers for <code>execution_completed</code>)</li> </ul>"},{"location":"architecture/websocket-system/#react-hooks-hooksusewebsocketts","title":"React Hooks (<code>hooks/useWebSocket.ts</code>)","text":"<pre><code>function useWebSocket(): void;\n// Connects on mount, disconnects on unmount\n\nfunction useSubscription(channel: string): void;\n// Subscribes on mount, unsubscribes on unmount\n// Channel changes trigger resubscription\n</code></pre>"},{"location":"architecture/websocket-system/#no-more-polling","title":"No More Polling","text":"<p>The WebSocket system eliminates all polling patterns:</p> <ul> <li>Node/edge mutation hooks no longer use <code>onSuccess</code> query invalidation -- updates arrive via WebSocket</li> <li><code>useExecution()</code> no longer uses <code>refetchInterval</code> polling -- status updates arrive via WebSocket</li> <li>ChatPanel uses <code>wsManager.registerHandler()</code> for execution completion instead of per-execution WebSocket connections</li> </ul>"},{"location":"architecture/websocket-system/#multi-worker-broadcasting","title":"Multi-Worker Broadcasting","text":"<p>The Redis pub/sub layer ensures events reach all connected clients regardless of which process generated them:</p> <pre><code>graph LR\n    subgraph \"Process 1: FastAPI\"\n        API[API Handler] --&gt;|broadcast()| R1[Redis Publish]\n        WS1[WS Connection 1] --&gt;|subscribe| R2[Redis Subscribe]\n        WS2[WS Connection 2] --&gt;|subscribe| R2\n    end\n\n    subgraph \"Process 2: RQ Worker\"\n        Orch[Orchestrator] --&gt;|broadcast()| R3[Redis Publish]\n    end\n\n    R1 --&gt;|pub/sub| Redis[(Redis)]\n    R3 --&gt;|pub/sub| Redis\n    Redis --&gt;|fan-out| R2</code></pre> <p>This means:</p> <ul> <li>An API mutation (node update) broadcasts from the FastAPI process</li> <li>An execution status event broadcasts from the RQ worker process</li> <li>Both reach the same connected clients via Redis pub/sub</li> <li>Scaling to multiple API server instances works automatically</li> </ul>"},{"location":"architecture/workflow-dsl/","title":"Workflow DSL","text":""},{"location":"architecture/workflow-dsl/#workflow-dsl","title":"Workflow DSL","text":"<p>Pipelit provides a YAML-based declarative workflow definition language that agents use to create workflows programmatically via the <code>workflow_create</code> tool. The DSL compiles to the standard node/edge representation at creation time -- it is not a persistent format.</p>"},{"location":"architecture/workflow-dsl/#overview","title":"Overview","text":"<p>The DSL provides two modes:</p> <ol> <li>Create from scratch -- Full workflow definition with steps, triggers, tools, and model declarations</li> <li>Fork and patch (<code>based_on</code> + <code>patches</code>) -- Start from an existing workflow and apply incremental modifications</li> </ol>"},{"location":"architecture/workflow-dsl/#why-yaml","title":"Why YAML?","text":"<ul> <li>More readable for LLMs generating workflow specs</li> <li>Multi-line strings (<code>|</code>) are natural for code snippets and prompts</li> <li>Comments are supported (agents can annotate their reasoning)</li> <li>JSON is a valid YAML subset -- agents can emit either</li> </ul>"},{"location":"architecture/workflow-dsl/#relationship-to-the-visual-canvas","title":"Relationship to the Visual Canvas","text":"<p>The DSL is for programmatic workflow creation by agents. Human users continue using the visual canvas. Both produce the same underlying representation (nodes + edges in the database).</p>"},{"location":"architecture/workflow-dsl/#basic-structure","title":"Basic Structure","text":"<pre><code>name: \"Moltbook Webhook Verification\"\ndescription: \"Receives Moltbook verification ping and responds with token\"\ntags: [\"webhook\", \"verification\", \"moltbook\"]\n\ntrigger:\n  type: webhook\n\nmodel:\n  capability: \"gpt-4\"       # Resolved to concrete credential at compile time\n\nsteps:\n  - id: validate\n    type: code\n    snippet: |\n      import json\n      payload = json.loads(input_data)\n      if payload.get(\"type\") != \"verification\":\n          raise ValueError(\"Not a verification request\")\n      return {\"token\": payload[\"verify_token\"], \"status\": \"ok\"}\n\n  - id: respond\n    type: code\n    snippet: |\n      return {\"verified\": True, \"token\": trigger.payload.token}\n</code></pre>"},{"location":"architecture/workflow-dsl/#step-types","title":"Step Types","text":"<p>Each step maps to a Pipelit component type:</p> Step Type Component Type Required Fields Optional Fields <code>agent</code> <code>agent</code> <code>prompt</code> <code>model</code>, <code>tools</code>, <code>memory</code> <code>code</code> <code>code</code> <code>snippet</code> -- <code>http</code> <code>http_request</code> <code>url</code> <code>method</code>, <code>headers</code>, <code>body</code>, <code>timeout</code> <code>switch</code> <code>switch</code> <code>rules</code> <code>default</code> <code>loop</code> <code>loop</code> <code>over</code>, <code>body</code> <code>max_iterations</code> <code>workflow</code> <code>workflow</code> <code>slug</code> <code>payload</code> <code>transform</code> <code>text_template</code> <code>template</code> -- <code>human</code> <code>human_confirmation</code> <code>message</code> <code>timeout</code>"},{"location":"architecture/workflow-dsl/#triggers","title":"Triggers","text":"<pre><code># Webhook trigger\ntrigger:\n  type: webhook\n\n# Telegram trigger\ntrigger:\n  type: telegram\n  credential: inherit     # Use parent's telegram credential\n\n# Chat trigger (for testing / manual invocation)\ntrigger:\n  type: chat\n\n# No trigger (subworkflow -- invoked by parent)\ntrigger: none\n</code></pre>"},{"location":"architecture/workflow-dsl/#model-declaration","title":"Model Declaration","text":"<p>Models are declared by capability, not by credential ID. The compiler resolves capabilities to concrete credentials at creation time.</p>"},{"location":"architecture/workflow-dsl/#strategy-1-capability-matching-recommended","title":"Strategy 1: Capability Matching (Recommended)","text":"<pre><code>model:\n  capability: \"gpt-4\"\n  temperature: 0.7\n</code></pre> <p>The compiler queries <code>GET /credentials/?type=llm_provider</code> and finds a credential providing the requested model.</p>"},{"location":"architecture/workflow-dsl/#strategy-2-inherit-from-parent","title":"Strategy 2: Inherit from Parent","text":"<pre><code>model:\n  inherit: true\n</code></pre> <p>Copies the parent agent's <code>llm_credential_id</code> and <code>model_name</code> into the new workflow's agent nodes. This is the simplest and most common case for subworkflows.</p>"},{"location":"architecture/workflow-dsl/#strategy-3-discovery","title":"Strategy 3: Discovery","text":"<pre><code>model:\n  discover: true\n  preference: \"cheapest\"    # or \"fastest\", \"most_capable\"\n</code></pre> <p>Lists available credentials and models, applies the preference filter, and selects automatically.</p>"},{"location":"architecture/workflow-dsl/#strategy-4-explicit-escape-hatch","title":"Strategy 4: Explicit (Escape Hatch)","text":"<pre><code>model:\n  credential_id: 5\n  model_name: \"gpt-4o\"\n  temperature: 0.7\n</code></pre> <p>Direct reference -- fragile, avoid in agent-created workflows.</p> <p>Resolution order: <code>inherit</code> &gt; <code>capability</code> &gt; <code>discover</code> &gt; <code>credential_id</code>.</p>"},{"location":"architecture/workflow-dsl/#implicit-vs-explicit-flow","title":"Implicit vs. Explicit Flow","text":""},{"location":"architecture/workflow-dsl/#implicit-linear-flow","title":"Implicit Linear Flow","text":"<p>Steps execute in declaration order. No explicit edges needed:</p> <pre><code>steps:\n  - id: fetch\n    type: http\n    url: \"https://api.example.com/data\"\n\n  - id: process\n    type: code\n    snippet: |\n      data = json.loads(input_data)\n      return {\"count\": len(data[\"items\"])}\n\n  - id: respond\n    type: agent\n    prompt: \"Summarize the data\"\n</code></pre> <p>Compiles to: <code>trigger -&gt; fetch -&gt; process -&gt; respond</code> (3 direct edges).</p>"},{"location":"architecture/workflow-dsl/#explicit-branching","title":"Explicit Branching","text":"<p>Use <code>switch</code> for conditional routing:</p> <pre><code>steps:\n  - id: classify\n    type: switch\n    rules:\n      - field: \"trigger.payload.type\"\n        operator: \"equals\"\n        value: \"verification\"\n        route: \"verify\"\n      - field: \"trigger.payload.type\"\n        operator: \"equals\"\n        value: \"message\"\n        route: \"handle_msg\"\n    default: \"log_unknown\"\n\n  - id: verify\n    type: code\n    snippet: \"return {'verified': True}\"\n\n  - id: handle_msg\n    type: agent\n    prompt: \"Process the incoming message\"\n\n  - id: log_unknown\n    type: code\n    snippet: \"return {'error': 'unknown type'}\"\n</code></pre> <p>Compiles to a <code>switch</code> node with conditional edges (<code>condition_value</code> on each edge).</p>"},{"location":"architecture/workflow-dsl/#tools-for-agent-steps","title":"Tools for Agent Steps","text":"<p>Agent steps can declare inline tools:</p> <pre><code>steps:\n  - id: worker\n    type: agent\n    prompt: \"You are a data analysis agent.\"\n    model:\n      capability: \"gpt-4\"\n    tools:\n      - type: code\n      - type: http_request\n      - type: calculator\n      - type: web_search\n        config:\n          searxng_url: \"http://localhost:8080\"\n    memory: true    # Enable memory_read + memory_write\n</code></pre> <p>Each tool entry creates a tool node and a <code>tool</code> edge connecting it to the agent. Tool configs support <code>inherit</code> to copy from the parent agent's matching tool.</p>"},{"location":"architecture/workflow-dsl/#loops","title":"Loops","text":"<pre><code>steps:\n  - id: process_items\n    type: loop\n    over: \"{{ fetch.output }}\"       # Jinja2 expression for the iterable\n    max_iterations: 100\n    body:\n      - id: transform_item\n        type: code\n        snippet: |\n          item = json.loads(input_data)\n          return {\"processed\": item[\"name\"].upper()}\n\n      - id: store_item\n        type: http\n        url: \"https://api.example.com/items\"\n        method: POST\n        body: \"{{ transform_item.output }}\"\n</code></pre>"},{"location":"architecture/workflow-dsl/#subworkflow-steps","title":"Subworkflow Steps","text":"<p>Reference existing workflows:</p> <pre><code>steps:\n  - id: verify\n    type: workflow\n    slug: \"moltbook-verify\"\n    payload:\n      token: \"{{ trigger.payload.verify_token }}\"\n</code></pre>"},{"location":"architecture/workflow-dsl/#fork-and-patch-mode","title":"Fork and Patch Mode","text":"<p>For partial matches -- start from an existing workflow and apply modifications.</p>"},{"location":"architecture/workflow-dsl/#structure","title":"Structure","text":"<pre><code>based_on: \"moltbook-verify\"\nname: \"ServiceX Webhook Verification\"\ndescription: \"Adapted from moltbook-verify for ServiceX\"\ntags: [\"webhook\", \"verification\", \"servicex\"]\n\npatches:\n  - action: update_prompt\n    step_id: \"code_1\"\n    snippet: |\n      return {\"token\": payload[\"sx_token\"], \"status\": \"ok\"}\n\n  - action: add_step\n    after: \"code_1\"\n    step:\n      id: notify\n      type: http\n      url: \"https://servicex.com/api/confirm\"\n      method: POST\n      body: '{\"verified\": true}'\n\n  - action: add_tool\n    agent_id: \"agent_1\"\n    tool:\n      type: web_search\n      config:\n        searxng_url: \"http://localhost:8080\"\n\n  - action: remove_step\n    step_id: \"old_logger\"\n</code></pre>"},{"location":"architecture/workflow-dsl/#patch-actions","title":"Patch Actions","text":"Action Description Parameters <code>add_step</code> Insert a new step <code>after</code> (step_id), <code>step</code> (full spec) <code>remove_step</code> Remove a step, reconnect edges <code>step_id</code> <code>update_prompt</code> Update code snippet or system prompt <code>step_id</code>, <code>snippet</code> or <code>prompt</code> <code>update_config</code> Modify step configuration <code>step_id</code>, <code>config</code> (merged) <code>add_tool</code> Connect a new tool to an agent <code>agent_id</code>, <code>tool</code> (tool spec) <code>remove_tool</code> Disconnect a tool from an agent <code>agent_id</code>, <code>tool_type</code> <code>update_trigger</code> Change trigger type or config <code>trigger</code> (trigger spec) <code>update_model</code> Change model for an agent step <code>step_id</code>, <code>model</code> (model spec)"},{"location":"architecture/workflow-dsl/#fork-semantics","title":"Fork Semantics","text":"<p>When <code>based_on</code> is specified:</p> <ol> <li>Clone -- Copy all nodes, edges, and configurations from the source workflow</li> <li>Rename -- Apply <code>name</code>, <code>description</code>, <code>tags</code> from the DSL</li> <li>Patch -- Apply each patch action in order</li> <li>Validate -- Run the standard workflow validation pipeline</li> <li>Return -- New workflow slug; the original is never modified</li> </ol>"},{"location":"architecture/workflow-dsl/#dsl-compiler-pipeline","title":"DSL Compiler Pipeline","text":"<pre><code>graph TD\n    YAML[\"YAML String&lt;br/&gt;(from agent tool call)\"] --&gt; Parser\n    Parser[\"DSL Parser&lt;br/&gt;Validate structure, resolve inherit\"] --&gt; Resolver\n    Resolver[\"Resource Resolver&lt;br/&gt;Capabilities -&gt; credential IDs\"] --&gt; GraphBuilder\n    GraphBuilder[\"Graph Builder&lt;br/&gt;Steps -&gt; nodes[] + edges[]\"] --&gt; APICaller\n    APICaller[\"API Caller&lt;br/&gt;POST /workflows/, /nodes/, /edges/\"] --&gt; Validate\n    Validate[\"POST /validate/\"] --&gt; Result\n    Result[\"{ workflow_id, slug,&lt;br/&gt;node_count, edge_count }\"]\n\n    Error[\"On error: delete workflow&lt;br/&gt;(rollback)\"]\n    Validate -.-&gt;|validation fails| Error\n\n    classDef step fill:#dbeafe,stroke:#2563eb\n    classDef error fill:#fee2e2,stroke:#dc2626\n\n    class YAML,Parser,Resolver,GraphBuilder,APICaller,Validate,Result step\n    class Error error</code></pre>"},{"location":"architecture/workflow-dsl/#compilation-example","title":"Compilation Example","text":"<p>For a simple linear workflow:</p> <pre><code>trigger:\n  type: webhook\nsteps:\n  - id: code_1\n    type: code\n    snippet: \"return {'ok': True}\"\n  - id: agent_1\n    type: agent\n    prompt: \"Summarize\"\n</code></pre> <p>Compiles to:</p> <pre><code>{\n  \"nodes\": [\n    {\"node_id\": \"trigger_webhook_1\", \"component_type\": \"trigger_webhook\"},\n    {\"node_id\": \"code_1\", \"component_type\": \"code\",\n     \"config\": {\"extra_config\": {\"snippet\": \"return {'ok': True}\"}}},\n    {\"node_id\": \"agent_1\", \"component_type\": \"agent\",\n     \"config\": {\"system_prompt\": \"Summarize\",\n                \"llm_credential_id\": 5, \"model_name\": \"gpt-4o\"}}\n  ],\n  \"edges\": [\n    {\"source_node_id\": \"trigger_webhook_1\", \"target_node_id\": \"code_1\"},\n    {\"source_node_id\": \"code_1\", \"target_node_id\": \"agent_1\"}\n  ]\n}\n</code></pre>"},{"location":"architecture/workflow-dsl/#error-handling","title":"Error Handling","text":"<p>The compiler validates at each stage:</p> <ol> <li>Parse errors -- Invalid YAML structure</li> <li>Unknown step types -- Unrecognized step type in a step definition</li> <li>Resource resolution failures -- No credential found providing the requested model</li> <li>API validation failures -- Edge type mismatches or missing required connections; partially-created workflow is rolled back (deleted)</li> </ol>"},{"location":"architecture/workflow-dsl/#integration-with-task-registry","title":"Integration with Task Registry","text":"<p>Tasks in the registry declare requirements -- capabilities needed for the workflow that executes them. This connects task planning to workflow creation:</p> <pre><code>create_task(\n    epic_id=\"ep_01JKXYZ\",\n    title=\"Analyze coverage gaps\",\n    requirements='{\"model\": \"gpt-4\", \"tools\": [\"code\", \"web_search\"], \"memory\": true}',\n)\n</code></pre> <p>The discovery-create-execute pipeline:</p> <pre><code>graph LR\n    TC[task_create&lt;br/&gt;with requirements] --&gt; WD[workflow_discover&lt;br/&gt;gap analysis]\n    WD --&gt;|\"score &gt;= 0.95\"| Reuse[Reuse as-is&lt;br/&gt;spawn_and_await]\n    WD --&gt;|\"score &gt;= 0.50\"| Fork[Fork + patch&lt;br/&gt;workflow_create based_on]\n    WD --&gt;|\"score &lt; 0.50\"| Create[Create from scratch&lt;br/&gt;workflow_create full DSL]\n    Fork --&gt; SA[spawn_and_await]\n    Create --&gt; SA</code></pre>"},{"location":"architecture/workflow-dsl/#examples","title":"Examples","text":""},{"location":"architecture/workflow-dsl/#simple-webhook-handler","title":"Simple Webhook Handler","text":"<pre><code>name: \"Health Check Endpoint\"\ndescription: \"Returns 200 OK for monitoring\"\ntags: [\"health\", \"monitoring\"]\n\ntrigger:\n  type: webhook\n\nsteps:\n  - id: respond\n    type: code\n    snippet: |\n      return {\"status\": \"healthy\"}\n</code></pre>"},{"location":"architecture/workflow-dsl/#agent-with-tools-subworkflow","title":"Agent with Tools (Subworkflow)","text":"<pre><code>name: \"Research Assistant\"\ndescription: \"Agent that can search the web and execute code\"\ntags: [\"research\", \"agent\"]\n\ntrigger: none    # Subworkflow -- invoked by parent\n\nmodel:\n  inherit: true\n\nsteps:\n  - id: researcher\n    type: agent\n    prompt: |\n      You are a research assistant. Use web search to find information\n      and code execution to process data.\n    tools:\n      - type: web_search\n        config:\n          searxng_url: inherit\n      - type: code\n      - type: calculator\n    memory: true\n</code></pre>"},{"location":"architecture/workflow-dsl/#multi-step-pipeline-with-branching","title":"Multi-Step Pipeline with Branching","text":"<pre><code>name: \"Content Moderator\"\ntags: [\"moderation\", \"content\"]\n\ntrigger:\n  type: webhook\n\nmodel:\n  capability: \"gpt-4\"\n\nsteps:\n  - id: classify\n    type: agent\n    prompt: \"Classify the content as 'safe', 'review', or 'block'.\"\n\n  - id: route\n    type: switch\n    rules:\n      - field: \"classify.output\"\n        operator: equals\n        value: \"safe\"\n        route: approve\n      - field: \"classify.output\"\n        operator: equals\n        value: \"block\"\n        route: reject\n    default: manual_review\n\n  - id: approve\n    type: code\n    snippet: \"return {'action': 'approve'}\"\n\n  - id: reject\n    type: code\n    snippet: \"return {'action': 'reject'}\"\n\n  - id: manual_review\n    type: human\n    message: \"Content needs manual review.\"\n</code></pre>"},{"location":"architecture/workflow-dsl/#design-notes","title":"Design Notes","text":""},{"location":"architecture/workflow-dsl/#dsl-is-not-stored","title":"DSL Is Not Stored","text":"<p>The YAML DSL is ephemeral -- it is compiled to nodes and edges at creation time. The workflow stores the standard node/edge representation. To reconstruct the DSL from a workflow, a decompiler would be needed (future enhancement).</p>"},{"location":"architecture/workflow-dsl/#relationship-to-platform_api-tool","title":"Relationship to <code>platform_api</code> Tool","text":"<p>The <code>workflow_create</code> tool with DSL is a higher-level interface than the raw <code>platform_api</code> tool. Agents could still use <code>platform_api</code> directly for fine-grained control, but the DSL handles resource resolution, validation, and rollback automatically.</p>"},{"location":"components/","title":"Components","text":""},{"location":"components/#components","title":"Components","text":"<p>Pipelit provides approximately 42 component types that serve as the building blocks for workflows. Each component type represents a distinct piece of functionality -- from receiving events to reasoning with LLMs to routing data through conditional logic.</p> <p>Components are organized into seven categories, each with a distinct role in the workflow pipeline.</p>"},{"location":"components/#triggers-6-types","title":"Triggers 6 types","text":"<p>Entry points that initiate workflow execution. Triggers are first-class nodes on the canvas -- they receive events from external sources (Telegram, chat, schedules) and pass data downstream.</p> <p>Chat | Telegram | Manual | Schedule | Workflow | Error</p>"},{"location":"components/#ai-4-types","title":"AI 4 types","text":"<p>LLM-powered nodes that reason, classify, route, and extract structured data. AI nodes connect to an AI Model sub-component and optionally to tools and memory.</p> <p>Agent | Categorizer | Router | Extractor</p>"},{"location":"components/#tools-5-types","title":"Tools 5 types","text":"<p>Sub-component nodes that provide capabilities to agents via LangChain tool calling. When an agent invokes a tool, the tool node executes and returns results to the agent's reasoning loop.</p> <p>Run Command | HTTP Request | Web Search | Calculator | Date &amp; Time</p>"},{"location":"components/#self-awareness-11-types","title":"Self-Awareness 11 types","text":"<p>Components that give agents awareness of the platform itself -- creating API credentials, inspecting their own identity, managing epics and tasks, spawning child workflows, and monitoring system health.</p> <p>Create Agent User | Platform API | WhoAmI | Get TOTP Code | Epic Tools | Task Tools | Spawn &amp; Await | Workflow Create | Workflow Discover | Scheduler Tools | System Health</p>"},{"location":"components/#memory-3-types","title":"Memory 3 types","text":"<p>Persistent knowledge storage that agents can read from and write to across executions. Includes user identification for personalized interactions.</p> <p>Memory Read | Memory Write | Identify User</p>"},{"location":"components/#logic-9-types","title":"Logic 9 types","text":"<p>Flow-control nodes for branching, looping, filtering, merging, and orchestrating execution order. These nodes shape how data flows through the workflow graph.</p> <p>Switch | Code | Merge | Filter | Loop | Wait | Human Confirmation | Aggregator | Subworkflow</p>"},{"location":"components/#sub-components-3-types","title":"Sub-Components 3 types","text":"<p>Configuration nodes that attach to AI nodes via special handles. They provide model selection, output parsing, and code execution capabilities.</p> <p>AI Model | Output Parser | Code Execute</p>"},{"location":"components/#how-components-work","title":"How Components Work","text":"<p>Every component on the canvas is a node in the workflow graph. Nodes connect to each other via edges that carry typed data between output ports and input ports.</p>"},{"location":"components/#port-system","title":"Port System","text":"<p>Each component type defines its input ports and output ports with specific data types:</p> Data Type Description <code>STRING</code> Plain text <code>NUMBER</code> Numeric value <code>BOOLEAN</code> True/false <code>OBJECT</code> JSON object <code>ARRAY</code> JSON array <code>MESSAGES</code> LangGraph message list <code>ANY</code> Accepts any type <p>When you draw an edge between two nodes, Pipelit validates that the source output port type is compatible with the target input port type. Incompatible connections are rejected with a 422 error.</p>"},{"location":"components/#execution-model","title":"Execution Model","text":"<p>Components follow a consistent execution pattern:</p> <ol> <li>The orchestrator resolves Jinja2 expressions in the component's configuration (system prompt, extra config).</li> <li>The component's <code>run()</code> function executes with the current workflow state.</li> <li>The component returns a flat dict with port values (e.g., <code>{\"output\": \"result text\"}</code>).</li> <li>The orchestrator wraps non-underscore keys into <code>node_outputs[node_id]</code> for downstream access.</li> <li>A <code>node_status</code> WebSocket event is published with the result status.</li> </ol>"},{"location":"components/#sub-component-connections","title":"Sub-Component Connections","text":"<p>AI nodes connect to sub-components via special diamond-shaped handles at the bottom of the node:</p> Handle Color Purpose model Blue (#3b82f6) AI Model connection (required) tools Green (#10b981) Tool connections memory Amber (#f59e0b) Memory connections output_parser Slate (#94a3b8) Output parser connection"},{"location":"components/#accessing-upstream-data","title":"Accessing Upstream Data","text":"<p>Use Jinja2 template expressions to reference data from upstream nodes:</p> <pre><code>{{ trigger.text }}\n{{ nodeId.portName }}\n{{ agent_abc123.output | upper }}\n</code></pre> <p>The <code>trigger</code> shorthand always refers to whichever trigger fired the current execution.</p>"},{"location":"components/ai/","title":"AI Components","text":""},{"location":"components/ai/#ai-components","title":"AI Components","text":"<p>AI components are the LLM-powered nodes in Pipelit. They send messages to a language model, interpret the response, and produce structured outputs that drive the rest of your workflow.</p>"},{"location":"components/ai/#overview","title":"Overview","text":"<p>There are four AI component types:</p> Component Purpose Key Output Agent Autonomous reasoning with tool calling <code>output</code> (final text), <code>messages</code> (full conversation) Categorizer Classify input into predefined categories <code>category</code> (matched label), <code>raw</code> (LLM response) Router Route execution to different branches based on input content <code>route</code> (branch identifier) Extractor Extract structured data from unstructured text <code>extracted</code> (JSON object) <p>All four share a common trait: they require an AI Model sub-component connection to function. Without a model, the node cannot resolve which LLM to use and will fail at build time.</p>"},{"location":"components/ai/#canvas-appearance","title":"Canvas Appearance","text":"<p>AI nodes have a distinctive visual treatment on the workflow canvas:</p> <ul> <li>Fixed 250px width with a separator line dividing the node header from the sub-component pills below.</li> <li>Bottom diamond handles for connecting sub-components (model, tools, memory, output parser).</li> <li>Left circle handle for the input connection (messages).</li> <li>Right circle handle for the output connection.</li> </ul>"},{"location":"components/ai/#sub-component-support","title":"Sub-Component Support","text":"<p>Each AI node type supports a different set of sub-components. Connect these via the colored diamond handles at the bottom of the node.</p> Node Model Tools Memory Output Parser Agent :material-check: :material-check: :material-check: :material-close: Categorizer :material-check: :material-close: :material-check: :material-check: Router :material-check: :material-close: :material-check: :material-check: Extractor :material-check: :material-close: :material-check: :material-check: <p>Handle colors:</p> Sub-Component Handle Color Edge Label Model Blue (<code>#3b82f6</code>) <code>llm</code> Tools Green (<code>#10b981</code>) <code>tool</code> Memory Amber (<code>#f59e0b</code>) <code>memory</code> Output Parser Slate (<code>#94a3b8</code>) <code>output_parser</code> <p>Agent is the only node with tool support</p> <p>Only the Agent node supports connecting tool sub-components. Categorizer, Router, and Extractor rely solely on the LLM's text generation without tool calling.</p>"},{"location":"components/ai/#common-input","title":"Common Input","text":"<p>All four AI nodes accept the same input:</p> Port Type Required <code>messages</code> <code>MESSAGES</code> Yes <p>The <code>messages</code> input typically comes from a trigger node (Chat, Telegram, etc.) or from an upstream node that produces LangChain messages. The messages list carries the full conversation context that the LLM uses to generate its response.</p>"},{"location":"components/ai/#system-prompt-and-jinja2","title":"System Prompt and Jinja2","text":"<p>All AI nodes support a system prompt that instructs the LLM on its behavior. System prompts support Jinja2 template expressions, resolved by the orchestrator before execution:</p> <pre><code>You are a {{ trigger.payload.role }} assistant.\nThe user said: {{ trigger.text }}\nPrevious output: {{ code_abc123.output }}\n</code></pre> <p>See Expressions for the full template syntax.</p>"},{"location":"components/ai/#whats-next","title":"What's Next?","text":"<ul> <li>Agent -- autonomous reasoning with tool calling</li> <li>Categorizer -- classify input into categories</li> <li>Router -- route execution based on input content</li> <li>Extractor -- extract structured data from text</li> </ul>"},{"location":"components/ai/agent/","title":"Agent","text":""},{"location":"components/ai/agent/#agent","title":"Agent","text":"<p>The Agent node is a LangGraph ReAct agent -- an LLM that can reason about a task, decide which tools to call, observe the results, and iterate until it produces a final answer. It is the primary AI node in Pipelit.</p> <p>Component type: <code>agent</code></p>"},{"location":"components/ai/agent/#ports","title":"Ports","text":""},{"location":"components/ai/agent/#inputs","title":"Inputs","text":"Port Type Required Description <code>messages</code> <code>MESSAGES</code> Yes Conversation messages from a trigger or upstream node"},{"location":"components/ai/agent/#outputs","title":"Outputs","text":"Port Type Description <code>messages</code> <code>MESSAGES</code> Full conversation including tool calls and responses <code>output</code> <code>STRING</code> Final text content from the last AI message"},{"location":"components/ai/agent/#sub-components","title":"Sub-Components","text":"<p>The Agent supports three sub-component connections via the diamond handles at the bottom of the node:</p> Sub-Component Handle Color Required Edge Label Purpose Model Blue (<code>#3b82f6</code>) Yes <code>llm</code> The LLM provider and model (e.g., GPT-4o, Claude) Tools Green (<code>#10b981</code>) No <code>tool</code> LangChain tools the agent can invoke during reasoning Memory Amber (<code>#f59e0b</code>) No <code>memory</code> Global memory read/write access (Memory Read, Memory Write) <p>Model is required</p> <p>Every Agent node must have an AI Model sub-component connected. Without it, the agent cannot resolve which LLM to use and will fail at build time.</p>"},{"location":"components/ai/agent/#configuration","title":"Configuration","text":"Setting Type Default Description System Prompt <code>string</code> <code>\"\"</code> Instructions and persona for the agent. Supports Jinja2 expressions. Conversation Memory <code>boolean</code> <code>false</code> When enabled, persists conversation history across executions using a SqliteSaver checkpointer."},{"location":"components/ai/agent/#system-prompt","title":"System Prompt","text":"<p>The system prompt defines the agent's personality, instructions, and constraints. It is delivered to the LLM in two ways:</p> <ol> <li>SystemMessage -- passed via LangGraph's <code>create_react_agent(prompt=SystemMessage(...))</code> for the standard system role.</li> <li>HumanMessage fallback -- a <code>HumanMessage</code> with a stable ID is prepended to the conversation to support LLM providers that ignore the system role (e.g., Venice.ai).</li> </ol> <p>The system prompt supports Jinja2 template expressions resolved against upstream node outputs and trigger data:</p> <pre><code>You are a helpful assistant for {{ trigger.payload.company_name }}.\nUse the context from: {{ identify_user_abc123.user_context }}\n</code></pre>"},{"location":"components/ai/agent/#conversation-memory","title":"Conversation Memory","text":"<p>By default, agents are stateless -- each execution starts fresh. Enabling conversation memory changes this:</p> <ul> <li>A SqliteSaver checkpointer stores the full conversation state in <code>platform/checkpoints.db</code>.</li> <li>The thread ID is constructed from <code>{user_profile_id}:{telegram_chat_id}:{workflow_id}</code>, so the same user talking to the same workflow always resumes the same conversation.</li> <li>If there is no Telegram chat ID, the thread simplifies to <code>{user_profile_id}:{workflow_id}</code>.</li> </ul> <p>Ephemeral checkpoints for Spawn &amp; Await</p> <p>If an agent has a <code>spawn_and_await</code> tool connected but conversation memory is disabled, a RedisSaver checkpointer is used instead. This ephemeral checkpointer only persists state long enough for the child workflow to complete and the agent to resume.</p>"},{"location":"components/ai/agent/#usage","title":"Usage","text":""},{"location":"components/ai/agent/#execution-loop","title":"Execution Loop","text":"<p>The Agent follows the ReAct (Reason + Act) pattern:</p> <ol> <li>Receive -- the agent receives input messages from the trigger or upstream node.</li> <li>Reason -- the LLM reads the conversation and system prompt, then decides what to do.</li> <li>Act -- if the LLM needs more information, it calls one of its connected tools.</li> <li>Observe -- the tool result is appended to the conversation as a <code>ToolMessage</code>.</li> <li>Repeat -- the LLM reasons again with the new information. This loop continues until the LLM produces a text response without any tool calls.</li> </ol> <pre><code>sequenceDiagram\n    participant Trigger\n    participant Agent\n    participant LLM\n    participant Tool\n\n    Trigger-&gt;&gt;Agent: Input messages\n    Agent-&gt;&gt;LLM: Messages + system prompt\n    LLM--&gt;&gt;Agent: Tool call: web_search(\"query\")\n    Agent-&gt;&gt;Tool: Invoke tool\n    Tool--&gt;&gt;Agent: Tool result\n    Agent-&gt;&gt;LLM: Messages + tool result\n    LLM--&gt;&gt;Agent: Final text response\n    Agent--&gt;&gt;Trigger: {output, messages}</code></pre>"},{"location":"components/ai/agent/#tool-resolution","title":"Tool Resolution","text":"<p>At build time, the agent queries all edges with <code>edge_label=\"tool\"</code> or <code>edge_label=\"memory\"</code> pointing to it. For each connected tool node, it loads the tool's factory and registers the resulting LangChain <code>@tool</code> function. When the LLM invokes a tool during reasoning:</p> <ol> <li>A <code>node_status</code> WebSocket event with <code>status: \"running\"</code> is published for the tool node.</li> <li>The tool function executes.</li> <li>A <code>node_status</code> event with <code>status: \"success\"</code> or <code>status: \"failed\"</code> is published.</li> <li>The result is returned to the LLM as a <code>ToolMessage</code>.</li> </ol> <p>Tool nodes on the canvas show real-time status badges as the agent uses them.</p>"},{"location":"components/ai/agent/#output-convention","title":"Output Convention","text":"<p>The Agent returns:</p> Key Type Description <code>output</code> <code>string</code> The final text content extracted from the last AI message <code>_messages</code> <code>list</code> All messages from the agent's execution (appended to workflow state) <code>_token_usage</code> <code>dict</code> Token counts, cost in USD, and tool invocation count <p>Downstream nodes access the agent's text via <code>{{ agent_abc123.output }}</code>.</p> <p>Tool message cleanup</p> <p>If an agent has no tools connected, it automatically strips <code>ToolMessage</code> and tool-call AI messages from upstream agents. This prevents the LLM from being confused by foreign tool calls it cannot handle.</p>"},{"location":"components/ai/agent/#example","title":"Example","text":"<p>A simple chat agent with web search and command execution:</p> <pre><code>flowchart LR\n    Chat[Chat Trigger] --&gt; Agent\n    Model[AI Model&lt;br/&gt;GPT-4o] -.-&gt;|llm| Agent\n    Search[Web Search] -.-&gt;|tool| Agent\n    Command[Run Command] -.-&gt;|tool| Agent\n    MemRead[Memory Read] -.-&gt;|memory| Agent\n    Agent --&gt; Output[Code: Format Response]</code></pre> <p>System prompt: </p><pre><code>You are a helpful research assistant. When the user asks a question:\n1. Search the web for current information.\n2. Verify facts by running commands if needed.\n3. Check memory for any relevant prior context.\n4. Provide a comprehensive, well-sourced answer.\n</code></pre><p></p> <p>Configuration:</p> <ul> <li>Conversation Memory: <code>true</code> (remembers prior interactions)</li> <li>AI Model: GPT-4o via OpenAI credential</li> <li>Tools: Web Search (SearXNG), Run Command</li> <li>Memory: Memory Read</li> </ul>"},{"location":"components/ai/categorizer/","title":"Categorizer","text":""},{"location":"components/ai/categorizer/#categorizer","title":"Categorizer","text":"<p>The Categorizer node classifies input messages into one of a set of predefined categories using an LLM. It outputs the matched category label and the raw LLM response, and sets the <code>_route</code> state for downstream conditional routing.</p> <p>Component type: <code>categorizer</code></p>"},{"location":"components/ai/categorizer/#ports","title":"Ports","text":""},{"location":"components/ai/categorizer/#inputs","title":"Inputs","text":"Port Type Required Description <code>messages</code> <code>MESSAGES</code> Yes Conversation messages to classify"},{"location":"components/ai/categorizer/#outputs","title":"Outputs","text":"Port Type Description <code>category</code> <code>STRING</code> The matched category name <code>raw</code> <code>STRING</code> The raw LLM response text before parsing"},{"location":"components/ai/categorizer/#sub-components","title":"Sub-Components","text":"Sub-Component Handle Color Required Edge Label Purpose Model Blue (<code>#3b82f6</code>) Yes <code>llm</code> The LLM provider and model to use for classification Memory Amber (<code>#f59e0b</code>) No <code>memory</code> Global memory access for context-aware classification Output Parser Slate (<code>#94a3b8</code>) No <code>output_parser</code> Custom parsing logic for the LLM response <p>Model is required</p> <p>Every Categorizer node must have an AI Model sub-component connected. Without it, the node cannot resolve which LLM to use and will fail at build time.</p>"},{"location":"components/ai/categorizer/#configuration","title":"Configuration","text":"Setting Type Default Description System Prompt <code>string</code> <code>\"\"</code> Optional custom instructions prepended to the classification prompt Categories <code>array</code> <code>[]</code> List of category objects, each with a <code>name</code> and optional <code>description</code>"},{"location":"components/ai/categorizer/#categories","title":"Categories","text":"<p>Categories are defined in the <code>extra_config</code> field as a list of objects:</p> <pre><code>{\n  \"categories\": [\n    {\"name\": \"billing\", \"description\": \"Questions about invoices, payments, or pricing\"},\n    {\"name\": \"technical\", \"description\": \"Bug reports, feature requests, or technical help\"},\n    {\"name\": \"general\", \"description\": \"General inquiries and small talk\"}\n  ]\n}\n</code></pre> <p>The Categorizer automatically constructs a classification prompt that lists all category names and descriptions, then instructs the LLM to respond with a JSON object containing the matched category.</p>"},{"location":"components/ai/categorizer/#system-prompt","title":"System Prompt","text":"<p>An optional custom system prompt is prepended to the auto-generated classification instructions. This lets you add domain-specific context without replacing the core classification logic:</p> <pre><code>You are classifying messages for Acme Corp's support team.\nConsider the customer's account tier when classifying.\n</code></pre> <p>The system prompt supports Jinja2 template expressions (e.g., <code>{{ trigger.text }}</code>).</p>"},{"location":"components/ai/categorizer/#usage","title":"Usage","text":""},{"location":"components/ai/categorizer/#classification-flow","title":"Classification Flow","text":"<ol> <li>The Categorizer receives input messages (typically the last user message).</li> <li>It constructs a prompt listing all defined categories with their descriptions.</li> <li>The LLM is invoked with the classification prompt and the user's message.</li> <li>The response is parsed to extract the category name.</li> <li>The matched category is returned as <code>category</code> and also set as <code>_route</code> for conditional edge routing.</li> </ol>"},{"location":"components/ai/categorizer/#response-parsing","title":"Response Parsing","text":"<p>The Categorizer uses a multi-strategy parser to extract the category from the LLM response:</p> <ol> <li>JSON parse -- attempts to parse the full response as <code>{\"category\": \"name\"}</code>.</li> <li>Regex extraction -- looks for <code>\"category\": \"name\"</code> patterns in the text.</li> <li>Fuzzy match -- checks if any category name appears in the response text (case-insensitive).</li> <li>Fallback -- if nothing matches, returns the first category in the list.</li> </ol>"},{"location":"components/ai/categorizer/#route-output","title":"Route Output","text":"<p>The Categorizer sets <code>_route</code> to the matched category name. This integrates with downstream Switch nodes or any conditional routing logic that reads the workflow route state. You can connect a Switch node downstream and create conditional edges matching each category value.</p>"},{"location":"components/ai/categorizer/#token-usage","title":"Token Usage","text":"<p>The Categorizer tracks token usage from the LLM call and returns it as <code>_token_usage</code> with input tokens, output tokens, total tokens, and estimated cost in USD.</p>"},{"location":"components/ai/categorizer/#example","title":"Example","text":"<p>A customer support message classifier that routes to specialized agents:</p> <pre><code>flowchart LR\n    Chat[Chat Trigger] --&gt; Cat[Categorizer]\n    Model[AI Model&lt;br/&gt;GPT-4o-mini] -.-&gt;|llm| Cat\n    Cat --&gt; Switch\n    Switch --&gt;|billing| BillingAgent[Agent: Billing]\n    Switch --&gt;|technical| TechAgent[Agent: Technical]\n    Switch --&gt;|general| GenAgent[Agent: General]</code></pre> <p>Categories configuration: </p><pre><code>{\n  \"categories\": [\n    {\"name\": \"billing\", \"description\": \"Invoices, payments, refunds, pricing\"},\n    {\"name\": \"technical\", \"description\": \"Bug reports, errors, feature requests\"},\n    {\"name\": \"general\", \"description\": \"Greetings, general questions, feedback\"}\n  ]\n}\n</code></pre><p></p> <p>System prompt: </p><pre><code>You are classifying customer support messages for a SaaS platform.\nBe precise -- billing questions about feature limits should go to \"technical\",\nnot \"billing\".\n</code></pre><p></p> <p>When a user sends \"I can't log into my account\", the Categorizer outputs:</p> <ul> <li><code>category</code>: <code>\"technical\"</code></li> <li><code>raw</code>: <code>'{\"category\": \"technical\"}'</code></li> <li><code>_route</code>: <code>\"technical\"</code></li> </ul> <p>The Switch node then follows the conditional edge labeled <code>technical</code> to the Technical Support Agent.</p>"},{"location":"components/ai/extractor/","title":"Extractor","text":""},{"location":"components/ai/extractor/#extractor","title":"Extractor","text":"<p>The Extractor node uses an LLM to extract structured data from unstructured text input. It parses the LLM response into a JSON object according to a schema defined by the connected Output Parser.</p> <p>Component type: <code>extractor</code></p>"},{"location":"components/ai/extractor/#ports","title":"Ports","text":""},{"location":"components/ai/extractor/#inputs","title":"Inputs","text":"Port Type Required Description <code>messages</code> <code>MESSAGES</code> Yes Conversation messages containing the text to extract from"},{"location":"components/ai/extractor/#outputs","title":"Outputs","text":"Port Type Description <code>extracted</code> <code>OBJECT</code> A JSON object containing the extracted structured data"},{"location":"components/ai/extractor/#sub-components","title":"Sub-Components","text":"Sub-Component Handle Color Required Edge Label Purpose Model Blue (<code>#3b82f6</code>) Yes <code>llm</code> The LLM provider and model to use for extraction Memory Amber (<code>#f59e0b</code>) No <code>memory</code> Global memory access for context-aware extraction Output Parser Slate (<code>#94a3b8</code>) Yes <code>output_parser</code> Defines the extraction schema and parses the LLM response into structured data <p>Model and Output Parser are required</p> <p>The Extractor needs both an AI Model (to generate the extraction) and an Output Parser (to define the target schema and parse the result). Without either, the node will fail at build time.</p>"},{"location":"components/ai/extractor/#configuration","title":"Configuration","text":"Setting Type Default Description System Prompt <code>string</code> <code>\"\"</code> Instructions for the LLM on how to extract data. Supports Jinja2 expressions."},{"location":"components/ai/extractor/#system-prompt","title":"System Prompt","text":"<p>The system prompt should instruct the LLM on what information to extract and in what format. The Output Parser defines the target schema, but the system prompt provides the LLM with context about the extraction task:</p> <pre><code>Extract the following information from the user's message:\n- Full name\n- Email address\n- Phone number (if mentioned)\n- Company name (if mentioned)\n\nReturn the data as a JSON object. Use null for fields not found in the text.\n</code></pre> <p>The system prompt supports Jinja2 template expressions for dynamic context:</p> <pre><code>Extract order details from the message.\nCustomer tier: {{ identify_user_abc123.user_context.tier }}\n</code></pre>"},{"location":"components/ai/extractor/#output-parser","title":"Output Parser","text":"<p>The Output Parser sub-component defines the schema for the extracted data. It controls how the raw LLM response is parsed into the structured <code>extracted</code> output. Connect an Output Parser node to the Extractor via the slate-colored diamond handle.</p> <p>The parser's configuration specifies the expected fields, their types, and any validation rules. The Extractor sends the LLM response through the parser, which returns a validated JSON object.</p>"},{"location":"components/ai/extractor/#usage","title":"Usage","text":""},{"location":"components/ai/extractor/#extraction-flow","title":"Extraction Flow","text":"<ol> <li>The Extractor receives input messages containing unstructured text.</li> <li>The system prompt and Output Parser schema are combined into instructions for the LLM.</li> <li>The LLM analyzes the text and produces a response conforming to the schema.</li> <li>The Output Parser validates and structures the LLM response into a JSON object.</li> <li>The structured object is returned as the <code>extracted</code> output port.</li> </ol>"},{"location":"components/ai/extractor/#accessing-extracted-data","title":"Accessing Extracted Data","text":"<p>Downstream nodes can access individual fields from the extracted object using Jinja2 expressions:</p> <pre><code>{{ extractor_abc123.extracted.name }}\n{{ extractor_abc123.extracted.email }}\n{{ extractor_abc123.extracted.order_total }}\n</code></pre> <p>Or access the entire extracted object:</p> <pre><code>{{ extractor_abc123.extracted }}\n</code></pre>"},{"location":"components/ai/extractor/#example","title":"Example","text":""},{"location":"components/ai/extractor/#contact-information-extraction","title":"Contact information extraction","text":"<p>Extract contact details from a free-text customer message:</p> <pre><code>flowchart LR\n    Chat[Chat Trigger] --&gt; Extractor\n    Model[AI Model&lt;br/&gt;GPT-4o-mini] -.-&gt;|llm| Extractor\n    Parser[Output Parser] -.-&gt;|output_parser| Extractor\n    Extractor --&gt; Code[Code: Save to CRM]</code></pre> <p>System prompt: </p><pre><code>Extract contact information from the user's message.\nBe precise with email addresses and phone numbers.\nIf a field is not mentioned, set it to null.\n</code></pre><p></p> <p>Output Parser schema: </p><pre><code>{\n  \"name\": \"string\",\n  \"email\": \"string\",\n  \"phone\": \"string | null\",\n  \"company\": \"string | null\",\n  \"role\": \"string | null\"\n}\n</code></pre><p></p> <p>Input message: </p><pre><code>Hi, I'm Jane Smith from Acme Corp. You can reach me at jane@acme.com\nor call 555-0123. I'm the VP of Engineering.\n</code></pre><p></p> <p>Extracted output: </p><pre><code>{\n  \"name\": \"Jane Smith\",\n  \"email\": \"jane@acme.com\",\n  \"phone\": \"555-0123\",\n  \"company\": \"Acme Corp\",\n  \"role\": \"VP of Engineering\"\n}\n</code></pre><p></p>"},{"location":"components/ai/extractor/#order-detail-extraction","title":"Order detail extraction","text":"<p>Extract structured order data from conversational input for downstream processing:</p> <pre><code>flowchart LR\n    Telegram[Telegram Trigger] --&gt; Extractor\n    Model[AI Model&lt;br/&gt;Claude Sonnet] -.-&gt;|llm| Extractor\n    Parser[Output Parser] -.-&gt;|output_parser| Extractor\n    Extractor --&gt; Switch\n    Switch --&gt;|above_threshold| Approval[Agent: Manager Approval]\n    Switch --&gt;|below_threshold| Auto[Code: Auto-Process]</code></pre> <p>System prompt: </p><pre><code>Extract order information from the customer's message.\nAmounts should be numeric (no currency symbols).\nDates should be in ISO 8601 format (YYYY-MM-DD).\n</code></pre><p></p> <p>Extracted output: </p><pre><code>{\n  \"product\": \"Enterprise License\",\n  \"quantity\": 50,\n  \"unit_price\": 99.00,\n  \"total\": 4950.00,\n  \"requested_delivery\": \"2026-03-15\"\n}\n</code></pre><p></p> <p>The extracted <code>total</code> field can then be evaluated by a downstream Switch node to route high-value orders through a manager approval flow.</p>"},{"location":"components/ai/router/","title":"Router","text":""},{"location":"components/ai/router/#router","title":"Router","text":"<p>The Router node evaluates state fields or expressions and directs execution to different downstream branches. Unlike the Categorizer (which uses an LLM to classify messages), the Router operates on rule-based logic against the current workflow state.</p> <p>Component type: <code>router</code></p>"},{"location":"components/ai/router/#ports","title":"Ports","text":""},{"location":"components/ai/router/#inputs","title":"Inputs","text":"Port Type Required Description <code>messages</code> <code>MESSAGES</code> Yes Conversation messages (provides state context)"},{"location":"components/ai/router/#outputs","title":"Outputs","text":"Port Type Description <code>route</code> <code>STRING</code> The resolved route value used for conditional edge matching"},{"location":"components/ai/router/#sub-components","title":"Sub-Components","text":"Sub-Component Handle Color Required Edge Label Purpose Model Blue (<code>#3b82f6</code>) Yes <code>llm</code> The LLM provider and model (required by the type registry, though routing itself is rule-based) Memory Amber (<code>#f59e0b</code>) No <code>memory</code> Global memory access for context-aware routing decisions Output Parser Slate (<code>#94a3b8</code>) No <code>output_parser</code> Custom parsing logic for route resolution"},{"location":"components/ai/router/#configuration","title":"Configuration","text":"Setting Type Default Description <code>condition_field</code> <code>string</code> <code>\"route\"</code> The state field to read the route value from <code>condition_expression</code> <code>string</code> <code>null</code> A condition expression to evaluate against state (overrides <code>condition_field</code> if set)"},{"location":"components/ai/router/#condition-field","title":"Condition Field","text":"<p>The simplest routing mode. The Router reads the value of a state field and emits it as the route. The default field is <code>\"route\"</code>, which is set by upstream nodes that produce <code>_route</code> output (like the Categorizer).</p>"},{"location":"components/ai/router/#condition-expression","title":"Condition Expression","text":"<p>For more control, you can provide an expression that evaluates against the workflow state. Supported syntax:</p> <p>Field access -- dotted paths into the state dictionary: </p><pre><code>state.route\nstate.node_outputs.categorizer_abc123.category\nstate.user_context.tier\n</code></pre><p></p> <p>Equality checks -- returns the matched value or an empty string: </p><pre><code>state.route == 'premium'\nstate.node_outputs.categorizer_abc123.category == 'billing'\n</code></pre><p></p> <p>When a condition expression is provided, it takes precedence over <code>condition_field</code>.</p>"},{"location":"components/ai/router/#usage","title":"Usage","text":""},{"location":"components/ai/router/#routing-flow","title":"Routing Flow","text":"<ol> <li>The Router receives the current workflow state.</li> <li>If a <code>condition_expression</code> is configured, it evaluates the expression against the state.</li> <li>Otherwise, it reads the value of <code>condition_field</code> from the state.</li> <li>The resolved value is returned as both <code>route</code> (output port) and <code>_route</code> (sets the workflow route state for conditional edge matching).</li> </ol>"},{"location":"components/ai/router/#conditional-edge-integration","title":"Conditional Edge Integration","text":"<p>The Router's <code>_route</code> output integrates with Switch nodes and conditional edges downstream. You can connect a Switch node after the Router and create conditional edges that match specific route values:</p> <pre><code>flowchart LR\n    Trigger[Chat Trigger] --&gt; Cat[Categorizer]\n    Cat --&gt; Router\n    Router --&gt; Switch\n    Switch --&gt;|premium| PremiumAgent[Agent: Premium Support]\n    Switch --&gt;|standard| StandardAgent[Agent: Standard Support]\n    Switch --&gt;|default| Fallback[Agent: Fallback]</code></pre>"},{"location":"components/ai/router/#difference-from-categorizer","title":"Difference from Categorizer","text":"<p>The Router and Categorizer both produce route values, but they work differently:</p> Aspect Router Categorizer Decision method Rule-based state evaluation LLM classification LLM cost None (reads existing state) One LLM call per execution Speed Instant Depends on LLM latency Use case Route on values already in state Classify raw text input <p>Use the Router when an upstream node has already determined the route value (e.g., a Categorizer or Code node). Use the Categorizer when you need the LLM to interpret and classify the input.</p>"},{"location":"components/ai/router/#example","title":"Example","text":""},{"location":"components/ai/router/#route-on-upstream-categorizer-output","title":"Route on upstream categorizer output","text":"<p>A Router that reads the category set by a previous Categorizer and forwards it for conditional branching:</p> <p>Configuration: </p><pre><code>{\n  \"condition_field\": \"route\"\n}\n</code></pre><p></p> <p>Since the Categorizer sets <code>_route</code> to the category name, the Router simply reads the <code>route</code> field from state and re-emits it. This is useful when you need a routing decision point after additional processing between the Categorizer and the branching Switch.</p>"},{"location":"components/ai/router/#route-on-user-tier-with-expression","title":"Route on user tier with expression","text":"<p>A Router that checks a user's account tier from state context:</p> <p>Configuration: </p><pre><code>{\n  \"condition_expression\": \"state.user_context.tier\"\n}\n</code></pre><p></p> <p>If <code>state[\"user_context\"][\"tier\"]</code> is <code>\"premium\"</code>, the Router emits <code>route: \"premium\"</code>. A downstream Switch with conditional edges for <code>\"premium\"</code>, <code>\"standard\"</code>, and <code>\"default\"</code> then directs execution accordingly.</p>"},{"location":"components/ai/router/#equality-check","title":"Equality check","text":"<p>A Router that only matches a specific value:</p> <p>Configuration: </p><pre><code>{\n  \"condition_expression\": \"state.node_outputs.categorizer_abc123.category == 'urgent'\"\n}\n</code></pre><p></p> <p>If the categorizer's output category equals <code>\"urgent\"</code>, the route value is <code>\"urgent\"</code>. Otherwise, it is an empty string, which a downstream Switch can match as the <code>\"default\"</code> route.</p>"},{"location":"components/logic/","title":"Logic","text":""},{"location":"components/logic/#logic","title":"Logic","text":"<p>Logic components control how data flows through a workflow. They handle branching, iteration, filtering, merging, delays, and orchestration -- everything between receiving input and producing output that is not LLM reasoning.</p>"},{"location":"components/logic/#overview","title":"Overview","text":"<p>There are nine logic component types:</p> Component Purpose Key Feature Switch Route to branches based on rules Conditional edges with <code>condition_value</code> Code Execute custom Python code Access to workflow state and node outputs Merge Combine outputs from multiple branches Append or combine modes Filter Filter array items using rules Same operator set as Switch Loop Iterate over arrays Special <code>loop_body</code> / <code>loop_return</code> edges Wait Delay execution Configurable duration and unit Human Confirmation Pause for user approval Interrupt/resume execution flow Aggregator Collect and combine array items Flexible aggregation Subworkflow Execute another workflow as a child Implicit or explicit trigger mode"},{"location":"components/logic/#how-logic-components-work","title":"How logic components work","text":"<p>Logic components are executable nodes -- they run during workflow execution and produce outputs that downstream nodes can consume. Unlike AI nodes, they do not require an LLM connection. Unlike tools, they are not invoked by an agent's reasoning loop. They simply process data according to their configuration.</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; S{Switch}\n    S --&gt;|greeting| A1[Greeting Agent]\n    S --&gt;|question| A2[Q&amp;A Agent]\n    S --&gt;|default| A3[General Agent]</code></pre>"},{"location":"components/logic/#flow-control-patterns","title":"Flow control patterns","text":""},{"location":"components/logic/#branching","title":"Branching","text":"<p>Use Switch to route execution to different branches based on rules. Each branch is connected via a conditional edge with a <code>condition_value</code> that matches the switch's output route.</p>"},{"location":"components/logic/#parallel-branches-and-merging","title":"Parallel branches and merging","text":"<p>Multiple nodes can receive the same input (fan-out). Use Merge to bring parallel branches back together (fan-in), combining their outputs into a single value.</p>"},{"location":"components/logic/#iteration","title":"Iteration","text":"<p>Use Loop to process each item in an array individually. The loop body runs once per item, and results are collected into an output array.</p>"},{"location":"components/logic/#filtering","title":"Filtering","text":"<p>Use Filter to remove items from an array that do not match specified rules, reducing the dataset before further processing.</p>"},{"location":"components/logic/#human-in-the-loop","title":"Human-in-the-loop","text":"<p>Use Human Confirmation to pause execution and wait for user approval before proceeding with sensitive or irreversible operations.</p>"},{"location":"components/logic/#composition","title":"Composition","text":"<p>Use Subworkflow to delegate work to another workflow, keeping complex logic modular and reusable.</p>"},{"location":"components/logic/aggregator/","title":"Aggregator","text":""},{"location":"components/logic/aggregator/#aggregator","title":"Aggregator","text":"<p>The Aggregator component collects items from an array input and combines them into a single aggregated output. It is useful for gathering results from parallel branches, loop iterations, or multi-step processing pipelines.</p> Property Value Component Type <code>aggregator</code> Category Flow Display Name Aggregator"},{"location":"components/logic/aggregator/#ports","title":"Ports","text":""},{"location":"components/logic/aggregator/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>items</code> ARRAY No Array of items to aggregate"},{"location":"components/logic/aggregator/#outputs","title":"Outputs","text":"Port Data Type Description <code>aggregated</code> ANY Combined result"},{"location":"components/logic/aggregator/#configuration","title":"Configuration","text":"<p>The Aggregator component uses <code>extra_config</code> for any aggregation-specific settings. Configuration depends on the aggregation strategy being applied.</p>"},{"location":"components/logic/aggregator/#usage","title":"Usage","text":"<ol> <li>Add an Aggregator node from the Node Palette (Logic category)</li> <li>Connect upstream nodes that produce array outputs</li> <li>Connect the Aggregator's output to downstream nodes</li> </ol> <p>The Aggregator takes an array of items and produces a single aggregated value. This is particularly useful as the final step after a Loop or after multiple parallel branches have produced individual results.</p>"},{"location":"components/logic/aggregator/#example","title":"Example","text":"<p>A loop processes multiple documents, and the aggregator combines all results:</p> <pre><code>flowchart LR\n    T[Manual Trigger] --&gt; L[Loop]\n    L --&gt;|loop_body| P[Process Agent]\n    P -.-&gt;|loop_return| L\n    L --&gt; AG[Aggregator]\n    AG --&gt; S[Summary Agent]</code></pre> <p>The Loop iterates over a list of documents, the Process Agent analyzes each one, and the Aggregator combines all analysis results into a single structure that the Summary Agent can use to produce a final report.</p> <p>Aggregator vs. Merge</p> <p>The Aggregator collects items from a single array input (typically the output of a Loop). The Merge component combines outputs from multiple parallel branches. Use Aggregator when working with array data; use Merge when combining separate node outputs.</p>"},{"location":"components/logic/code/","title":"Code","text":""},{"location":"components/logic/code/#code","title":"Code","text":"<p>The Code component executes custom Python code as a step in the workflow graph. It provides direct access to the workflow state and upstream node outputs, making it suitable for data transformation, computation, and custom logic that does not require an LLM.</p> Property Value Component Type <code>code</code> Category Logic Display Name Code"},{"location":"components/logic/code/#ports","title":"Ports","text":""},{"location":"components/logic/code/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>input</code> ANY No Data from upstream nodes"},{"location":"components/logic/code/#outputs","title":"Outputs","text":"Port Data Type Description <code>output</code> ANY Result of the code execution"},{"location":"components/logic/code/#configuration","title":"Configuration","text":"<p>The Code component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>code</code> string -- Python code snippet to execute (required) <code>language</code> string <code>python</code> Programming language (currently only Python is supported)"},{"location":"components/logic/code/#usage","title":"Usage","text":"<ol> <li>Add a Code node from the Node Palette (Logic category)</li> <li>Connect upstream nodes to provide input data</li> <li>Write your Python code in the Code Snippet field in the node details panel</li> <li>Connect the Code node's output to downstream nodes</li> </ol>"},{"location":"components/logic/code/#available-variables","title":"Available variables","text":"<p>Your code has access to the following local variables:</p> Variable Description <code>state</code> The full workflow state dict (read-only by convention) <code>node_outputs</code> Shortcut for <code>state[\"node_outputs\"]</code> -- dict of all upstream node outputs keyed by node ID <code>result</code> Set this variable to produce the component's output"},{"location":"components/logic/code/#output-resolution","title":"Output resolution","text":"<p>The Code component determines its output using this priority:</p> <ol> <li>If you set the <code>result</code> variable, its string value becomes the output</li> <li>If <code>result</code> is not set, anything written to stdout via <code>print()</code> becomes the output</li> <li>If neither produces content, the output is empty</li> </ol>"},{"location":"components/logic/code/#using-return","title":"Using <code>return</code>","text":"<p>If your code contains a <code>return</code> statement, it is automatically wrapped in a function. The return value is assigned to <code>result</code>:</p> <pre><code>data = node_outputs.get(\"agent_abc123\", {})\ntext = data.get(\"output\", \"\")\nreturn text.upper()\n</code></pre>"},{"location":"components/logic/code/#jinja2-in-code","title":"Jinja2 in code","text":"<p>The Code Snippet field supports Jinja2 syntax highlighting. You can use <code>{{ }}</code> template expressions that are resolved before execution:</p> <pre><code>name = \"{{ trigger.text }}\"\nresult = f\"Hello, {name}!\"\n</code></pre>"},{"location":"components/logic/code/#example","title":"Example","text":"<p>A code node that transforms an agent's output into a structured summary:</p> <pre><code>import json\n\nagent_output = node_outputs.get(\"agent_abc123\", {})\ntext = agent_output.get(\"output\", \"\")\n\nlines = text.strip().split(\"\\n\")\nresult = json.dumps({\n    \"line_count\": len(lines),\n    \"first_line\": lines[0] if lines else \"\",\n    \"last_line\": lines[-1] if lines else \"\",\n    \"total_chars\": len(text),\n})\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    A --&gt; C[Code]\n    C --&gt; D[Downstream Node]\n    M[AI Model] -.-&gt;|model| A</code></pre> <p>No sandboxing</p> <p>The Code component executes Python code directly in the Pipelit process using <code>exec()</code>. It has access to all built-in Python functions. Unlike the Code Execute sub-component tool, it does not run in a subprocess and does not enforce security restrictions. Use the Code Execute tool for agent-invoked code execution with sandboxing.</p> <p>Error handling</p> <p>If the code raises an exception, the node fails with a <code>RuntimeError</code> containing the error message. The error is visible in the execution logs and on the canvas as a failed node status.</p>"},{"location":"components/logic/filter/","title":"Filter","text":""},{"location":"components/logic/filter/#filter","title":"Filter","text":"<p>The Filter component removes items from an array that do not match specified rules. It uses the same operator set as the Switch component, applied to each item in the input array.</p> Property Value Component Type <code>filter</code> Category Logic Display Name Filter"},{"location":"components/logic/filter/#ports","title":"Ports","text":""},{"location":"components/logic/filter/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>input</code> ARRAY Yes Array of items to filter"},{"location":"components/logic/filter/#outputs","title":"Outputs","text":"Port Data Type Description <code>filtered</code> ARRAY Items that matched all rules"},{"location":"components/logic/filter/#configuration","title":"Configuration","text":"<p>The Filter component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>rules</code> array <code>[]</code> List of filter rule objects <code>source_node</code> string -- Node ID to read input from (optional) <code>field</code> string -- Field name to extract from the source node's output (optional)"},{"location":"components/logic/filter/#rule-structure","title":"Rule structure","text":"<p>Each rule has the same structure as Switch rules:</p> Field Description <code>field</code> Key to read from each item (for dict items) <code>operator</code> Comparison operator (same set as Switch -- see Switch operators) <code>value</code> Value to compare against"},{"location":"components/logic/filter/#matching-behavior","title":"Matching behavior","text":"<p>An item passes the filter only if all rules match (AND logic). If no rules are configured, all items pass through unchanged.</p>"},{"location":"components/logic/filter/#usage","title":"Usage","text":"<ol> <li>Add a Filter node from the Node Palette (Logic category)</li> <li>Connect an upstream node that produces an array output</li> <li>Configure filter rules in Extra Config</li> <li>Connect the Filter node's output to downstream nodes</li> </ol>"},{"location":"components/logic/filter/#source-data-resolution","title":"Source data resolution","text":"<p>The Filter component resolves its input data in this order:</p> <ol> <li>If <code>source_node</code> is set, reads that node's output from <code>state.node_outputs</code></li> <li>If <code>field</code> is also set, extracts that specific field from the source node's dict output</li> <li>If neither is set, reads from the generic <code>state.output</code></li> </ol>"},{"location":"components/logic/filter/#example","title":"Example","text":"<p>An agent produces a list of search results, and the filter keeps only high-relevance items:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Search Agent]\n    A --&gt; F[Filter]\n    F --&gt; R[Response Agent]\n    M[AI Model] -.-&gt;|model| A\n    M2[AI Model] -.-&gt;|model| R</code></pre> <p>Filter Extra Config:</p> <pre><code>{\n  \"source_node\": \"agent_search\",\n  \"field\": \"results\",\n  \"rules\": [\n    {\"field\": \"relevance\", \"operator\": \"gte\", \"value\": \"0.7\"},\n    {\"field\": \"status\", \"operator\": \"equals\", \"value\": \"active\"}\n  ]\n}\n</code></pre> <p>Input array:</p> <pre><code>[\n  {\"title\": \"Result A\", \"relevance\": 0.9, \"status\": \"active\"},\n  {\"title\": \"Result B\", \"relevance\": 0.4, \"status\": \"active\"},\n  {\"title\": \"Result C\", \"relevance\": 0.8, \"status\": \"archived\"}\n]\n</code></pre> <p>Filtered output:</p> <pre><code>[\n  {\"title\": \"Result A\", \"relevance\": 0.9, \"status\": \"active\"}\n]\n</code></pre> <p>Only Result A passes both rules (relevance &gt;= 0.7 AND status equals \"active\").</p> <p>Combining with Loop</p> <p>Filter pairs well with Loop -- filter an array down to relevant items, then iterate over them with a Loop node for individual processing.</p>"},{"location":"components/logic/human-confirmation/","title":"Human Confirmation","text":""},{"location":"components/logic/human-confirmation/#human-confirmation","title":"Human Confirmation","text":"<p>The Human Confirmation component pauses workflow execution and waits for a user to approve or reject before continuing. It enables human-in-the-loop workflows where sensitive or irreversible actions require explicit consent.</p> Property Value Component Type <code>human_confirmation</code> Category Flow Display Name Human Confirmation"},{"location":"components/logic/human-confirmation/#ports","title":"Ports","text":""},{"location":"components/logic/human-confirmation/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>prompt</code> STRING No Context or question shown to the user"},{"location":"components/logic/human-confirmation/#outputs","title":"Outputs","text":"Port Data Type Description <code>confirmed</code> BOOLEAN Whether the user confirmed (<code>true</code>) or rejected (<code>false</code>) <code>user_response</code> STRING The raw text response from the user"},{"location":"components/logic/human-confirmation/#configuration","title":"Configuration","text":"<p>The Human Confirmation component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>prompt</code> string <code>Please confirm to proceed.</code> Message displayed to the user when the workflow pauses"},{"location":"components/logic/human-confirmation/#usage","title":"Usage","text":"<ol> <li>Add a Human Confirmation node from the Node Palette (Logic category)</li> <li>Configure the prompt message in Extra Config</li> <li>Place it before any nodes that perform sensitive operations</li> <li>Optionally connect a Switch node downstream to branch on the confirmation result</li> </ol>"},{"location":"components/logic/human-confirmation/#interruptresume-flow","title":"Interrupt/resume flow","text":"<p>The Human Confirmation component works with the orchestrator's interrupt mechanism:</p> <ol> <li>First invocation -- the orchestrator interrupts execution before or after this node. The workflow enters an interrupted state and waits for user input.</li> <li>Resume -- when the user provides a response, the orchestrator resumes execution with <code>_resume_input</code> set in the state.</li> <li>Second invocation -- the component reads <code>_resume_input</code> and determines whether the user confirmed.</li> </ol>"},{"location":"components/logic/human-confirmation/#confirmation-parsing","title":"Confirmation parsing","text":"<p>The following responses are treated as confirmation (case-insensitive):</p> <ul> <li><code>yes</code>, <code>confirm</code>, <code>true</code>, <code>y</code>, <code>1</code></li> </ul> <p>Any other response is treated as rejection.</p>"},{"location":"components/logic/human-confirmation/#routing","title":"Routing","text":"<p>The component also emits a <code>_route</code> value (<code>confirmed</code> or <code>cancelled</code>), which can be used with a downstream Switch node for conditional branching:</p> <pre><code>flowchart LR\n    A[Agent] --&gt; HC[Human Confirmation]\n    HC --&gt; S{Switch}\n    S --&gt;|confirmed| E[Execute Action]\n    S --&gt;|cancelled| C[Cancel Message]</code></pre>"},{"location":"components/logic/human-confirmation/#example","title":"Example","text":"<p>A workflow that asks for approval before executing a shell command:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Planning Agent]\n    A --&gt; HC[Human Confirmation]\n    HC --&gt; S{Switch}\n    S --&gt;|confirmed| E[Execution Agent]\n    S --&gt;|cancelled| C[Cancel Agent]</code></pre> <p>Human Confirmation Extra Config:</p> <pre><code>{\n  \"prompt\": \"The agent wants to run: rm -rf /tmp/old_builds. Approve? (yes/no)\"\n}\n</code></pre> <p>When the Planning Agent finishes and the workflow reaches the Human Confirmation node, execution pauses. The user sees the prompt and responds. If the user replies \"yes\", the Execution Agent runs. If the user replies \"no\" or anything else, the Cancel Agent handles the rejection.</p> <p>Execution state</p> <p>While waiting for user input, the execution remains in an interrupted state. The execution detail page shows the current status and the pending confirmation prompt.</p> <p>Dynamic prompts</p> <p>The prompt field supports Jinja2 expressions. You can include upstream node outputs in the prompt to give the user context about what they are approving:</p> <pre><code>The agent wants to execute: {{ agent_abc123.output }}\nApprove this action? (yes/no)\n</code></pre>"},{"location":"components/logic/loop/","title":"Loop","text":""},{"location":"components/logic/loop/#loop","title":"Loop","text":"<p>The Loop component iterates over an array, executing a body of nodes once for each item. Results from each iteration are collected into an output array.</p> Property Value Component Type <code>loop</code> Category Logic Display Name Loop"},{"location":"components/logic/loop/#ports","title":"Ports","text":""},{"location":"components/logic/loop/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>items</code> ARRAY Yes Array of items to iterate over"},{"location":"components/logic/loop/#outputs","title":"Outputs","text":"Port Data Type Description <code>results</code> ARRAY Collected results from each iteration"},{"location":"components/logic/loop/#configuration","title":"Configuration","text":"<p>The Loop component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>source_node</code> string -- Node ID to read the items array from <code>field</code> string -- Field name to extract from the source node's output"},{"location":"components/logic/loop/#usage","title":"Usage","text":"<ol> <li>Add a Loop node from the Node Palette (Logic category)</li> <li>Connect an upstream node that produces an array</li> <li>Add body nodes that should execute for each item</li> <li>Connect the Loop to the first body node via a <code>loop_body</code> edge</li> <li>Connect the last body node back to the Loop via a <code>loop_return</code> edge</li> <li>Connect the Loop's output to downstream nodes</li> </ol>"},{"location":"components/logic/loop/#special-edge-labels","title":"Special edge labels","text":"<p>Loop nodes use two special edge labels that bypass standard type-compatibility validation:</p> Edge Label Direction Purpose <code>loop_body</code> Loop to body node Sends the current item to the body for processing <code>loop_return</code> Body node to Loop Returns the processed result back to the loop"},{"location":"components/logic/loop/#canvas-rendering","title":"Canvas rendering","text":"<p>On the canvas, <code>loop_return</code> edges render with a distinctive visual style:</p> <ul> <li>Path: Routes below the nodes (right from source, down, left, up to target) with rounded 90-degree corners</li> <li>Stroke: Dashed line</li> <li>Label: \"return\"</li> </ul> <p>This visual treatment makes loop structures easy to identify at a glance.</p>"},{"location":"components/logic/loop/#data-flow","title":"Data flow","text":"<p>For each item in the input array:</p> <ol> <li>The Loop emits the current item to the body node via the <code>loop_body</code> edge</li> <li>The body node(s) process the item</li> <li>The last body node returns its result via the <code>loop_return</code> edge</li> <li>The result is appended to the Loop's <code>results</code> array</li> </ol> <p>The Loop also sets a <code>_loop</code> key in the state containing <code>{\"items\": [...]}</code> for internal orchestrator use.</p>"},{"location":"components/logic/loop/#example","title":"Example","text":"<p>Process each search result individually with an agent:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; S[Search Agent]\n    S --&gt; L[Loop]\n    L --&gt;|loop_body| P[Process Agent]\n    P -.-&gt;|loop_return| L\n    L --&gt; R[Summary Agent]</code></pre> <p>Loop Extra Config:</p> <pre><code>{\n  \"source_node\": \"agent_search\",\n  \"field\": \"results\"\n}\n</code></pre> <p>If the search agent returns <code>{\"results\": [\"item1\", \"item2\", \"item3\"]}</code>, the Process Agent runs three times -- once for each item. The Loop collects all three results into its <code>results</code> array, which the Summary Agent then receives.</p> <p>Body complexity</p> <p>The loop body can contain multiple nodes connected in sequence, but keep loop bodies simple. Each iteration runs the full body chain, so complex bodies with many nodes or LLM calls can significantly increase execution time.</p> <p>Non-array input</p> <p>If the input data is not a list, the Loop wraps it in a single-element array. If the input is <code>None</code>, the Loop runs with an empty array and produces an empty results array.</p>"},{"location":"components/logic/merge/","title":"Merge","text":""},{"location":"components/logic/merge/#merge","title":"Merge","text":"<p>The Merge component combines outputs from multiple upstream branches into a single value. It is the fan-in counterpart to branching patterns -- use it after parallel paths to bring results back together.</p> Property Value Component Type <code>merge</code> Category Logic Display Name Merge"},{"location":"components/logic/merge/#ports","title":"Ports","text":""},{"location":"components/logic/merge/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>branches</code> ARRAY Yes Outputs from multiple upstream nodes"},{"location":"components/logic/merge/#outputs","title":"Outputs","text":"Port Data Type Description <code>merged</code> ANY Combined result from all branches"},{"location":"components/logic/merge/#configuration","title":"Configuration","text":"<p>The Merge component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>mode</code> string <code>append</code> Merge strategy: <code>append</code> or <code>combine</code> <code>source_nodes</code> array -- Explicit list of node IDs to merge (optional)"},{"location":"components/logic/merge/#merge-modes","title":"Merge modes","text":"Mode Behavior Output Type <code>append</code> Collects all source outputs into a flat array. Lists are flattened, scalar values are appended as individual items. Array <code>combine</code> Merges all source outputs into a single object. Each dict source is merged via <code>update()</code>. Non-dict sources are keyed by an auto-generated ID. Object"},{"location":"components/logic/merge/#usage","title":"Usage","text":"<ol> <li>Add a Merge node from the Node Palette (Logic category)</li> <li>Connect multiple upstream nodes to the Merge node's input</li> <li>Optionally set the <code>mode</code> and <code>source_nodes</code> in Extra Config</li> <li>Connect the Merge node's output to downstream nodes</li> </ol>"},{"location":"components/logic/merge/#source-resolution","title":"Source resolution","text":"<p>If <code>source_nodes</code> is specified, only outputs from those node IDs are merged. If not specified, all available node outputs in the workflow state are included.</p>"},{"location":"components/logic/merge/#example","title":"Example","text":"<p>Two agents process input in parallel, and their outputs are merged before being sent to a final summarizer:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A1[Research Agent]\n    T --&gt; A2[Analysis Agent]\n    A1 --&gt; MG[Merge]\n    A2 --&gt; MG\n    MG --&gt; S[Summary Agent]</code></pre> <p>Merge Extra Config (append mode):</p> <pre><code>{\n  \"mode\": \"append\",\n  \"source_nodes\": [\"agent_research\", \"agent_analysis\"]\n}\n</code></pre> <p>Output:</p> <pre><code>{\n  \"merged\": [\n    \"Research findings: The market grew 15% in Q4...\",\n    \"Analysis conclusion: Growth is driven by...\"\n  ]\n}\n</code></pre> <p>Merge Extra Config (combine mode):</p> <pre><code>{\n  \"mode\": \"combine\",\n  \"source_nodes\": [\"agent_research\", \"agent_analysis\"]\n}\n</code></pre> <p>Output:</p> <pre><code>{\n  \"merged\": {\n    \"output\": \"Analysis conclusion: Growth is driven by...\",\n    \"research_data\": \"...\"\n  }\n}\n</code></pre> <p>Combine mode key collisions</p> <p>In <code>combine</code> mode, if multiple source nodes produce dicts with the same keys, later sources overwrite earlier ones. Use <code>append</code> mode if you need to preserve all values, or ensure source nodes use distinct output keys.</p>"},{"location":"components/logic/subworkflow/","title":"Subworkflow","text":""},{"location":"components/logic/subworkflow/#subworkflow","title":"Subworkflow","text":"<p>The Subworkflow component executes another workflow as a child and returns its output. It enables composition -- breaking complex automation into modular, reusable workflows that can be invoked from a parent workflow.</p> Property Value Component Type <code>workflow</code> Category Logic Display Name Subworkflow"},{"location":"components/logic/subworkflow/#ports","title":"Ports","text":""},{"location":"components/logic/subworkflow/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>payload</code> ANY No Data passed to the child workflow's trigger"},{"location":"components/logic/subworkflow/#outputs","title":"Outputs","text":"Port Data Type Description <code>output</code> ANY Final output from the child workflow"},{"location":"components/logic/subworkflow/#configuration","title":"Configuration","text":"<p>The Subworkflow component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Required Description <code>target_workflow</code> string -- Yes Slug of the workflow to invoke <code>trigger_mode</code> string <code>implicit</code> No How to invoke the child: <code>implicit</code> or <code>explicit</code> <code>input_mapping</code> object <code>{}</code> No Map parent state fields to child trigger payload"},{"location":"components/logic/subworkflow/#trigger-modes","title":"Trigger modes","text":"Mode Description <code>implicit</code> Looks up the target workflow by slug and creates a child execution directly. Does not go through trigger resolution. This is the default and recommended mode. <code>explicit</code> Dispatches a <code>workflow</code> event through the trigger resolver, which matches the event to a <code>trigger_workflow</code> node in the target workflow. Use this when the target workflow has specific trigger-based preprocessing."},{"location":"components/logic/subworkflow/#input-mapping","title":"Input mapping","text":"<p>By default (when <code>input_mapping</code> is empty), the child workflow receives:</p> <pre><code>{\n  \"text\": \"&lt;trigger text from parent&gt;\",\n  \"payload\": {\n    \"trigger\": \"&lt;parent trigger data&gt;\",\n    \"node_outputs\": \"&lt;all parent node outputs&gt;\"\n  }\n}\n</code></pre> <p>When <code>input_mapping</code> is specified, each key-value pair maps a target payload field to a dotted path in the parent state:</p> <pre><code>{\n  \"query\": \"node_outputs.agent_abc.output\",\n  \"context\": \"trigger.payload\"\n}\n</code></pre> <p>This produces a child trigger payload of:</p> <pre><code>{\n  \"query\": \"&lt;resolved value from parent&gt;\",\n  \"context\": \"&lt;resolved value from parent&gt;\"\n}\n</code></pre>"},{"location":"components/logic/subworkflow/#usage","title":"Usage","text":"<ol> <li>Add a Subworkflow node from the Node Palette (Logic category)</li> <li>Set the <code>target_workflow</code> slug in Extra Config (required)</li> <li>Optionally configure <code>trigger_mode</code> and <code>input_mapping</code></li> <li>Connect upstream nodes to provide input data</li> <li>Connect the Subworkflow's output to downstream nodes</li> </ol>"},{"location":"components/logic/subworkflow/#execution-flow","title":"Execution flow","text":"<p>The Subworkflow component uses a two-phase execution model:</p> <ol> <li>First invocation -- creates a child <code>WorkflowExecution</code> record, enqueues it on the RQ <code>workflows</code> queue, and returns a <code>_subworkflow</code> signal to the orchestrator with the child execution ID. The parent execution waits.</li> <li>Second invocation -- when the child execution completes, its result is injected into the parent state under <code>_subworkflow_results[node_id]</code>. The Subworkflow component reads this result and returns it as its <code>output</code>.</li> </ol>"},{"location":"components/logic/subworkflow/#parent-child-linkage","title":"Parent-child linkage","text":"<p>The child execution records its <code>parent_execution_id</code> and <code>parent_node_id</code>, creating a traceable lineage. This is visible in the execution detail page.</p>"},{"location":"components/logic/subworkflow/#example","title":"Example","text":"<p>A research workflow delegates summarization to a dedicated summary workflow:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; R[Research Agent]\n    R --&gt; SW[Subworkflow]\n    SW --&gt; F[Format Agent]</code></pre> <p>Subworkflow Extra Config:</p> <pre><code>{\n  \"target_workflow\": \"summarizer-v2\",\n  \"trigger_mode\": \"implicit\",\n  \"input_mapping\": {\n    \"text\": \"node_outputs.agent_research.output\"\n  }\n}\n</code></pre> <p>The Research Agent gathers information, the Subworkflow sends the research output to the <code>summarizer-v2</code> workflow for processing, and the Format Agent receives the summary as the Subworkflow's output.</p> <p>Circular references</p> <p>Avoid creating circular subworkflow references (workflow A invokes workflow B which invokes workflow A). This will cause infinite execution loops. Pipelit does not currently detect circular subworkflow references at build time.</p> <p>Child workflow errors</p> <p>If the child workflow fails, the Subworkflow node in the parent workflow also fails. The error from the child execution is propagated to the parent's execution logs.</p> <p>Reusable building blocks</p> <p>Design child workflows as self-contained units with clear trigger inputs and outputs. This makes them reusable across multiple parent workflows, similar to functions in programming.</p>"},{"location":"components/logic/switch/","title":"Switch","text":""},{"location":"components/logic/switch/#switch","title":"Switch","text":"<p>The Switch component routes execution to different downstream branches based on configurable rules. It evaluates the current workflow state against a list of rules and emits a <code>_route</code> value that determines which conditional edge to follow.</p> Property Value Component Type <code>switch</code> Category Logic Display Name Switch"},{"location":"components/logic/switch/#ports","title":"Ports","text":""},{"location":"components/logic/switch/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>input</code> ANY Yes Data to evaluate against rules"},{"location":"components/logic/switch/#outputs","title":"Outputs","text":"Port Data Type Description <code>route</code> STRING The matched route identifier"},{"location":"components/logic/switch/#configuration","title":"Configuration","text":"<p>Switch rules are configured in the <code>extra_config</code> field:</p> Field Type Default Description <code>rules</code> array -- List of rule objects (see below) <code>enable_fallback</code> boolean <code>false</code> Emit <code>__other__</code> route when no rules match"},{"location":"components/logic/switch/#rule-structure","title":"Rule structure","text":"<p>Each rule in the <code>rules</code> array has the following fields:</p> Field Description <code>id</code> Route identifier emitted when this rule matches (used as <code>condition_value</code> on edges) <code>field</code> Dotted path to the state field to evaluate (e.g., <code>node_outputs.categorizer.category</code>) <code>operator</code> Comparison operator (see table below) <code>value</code> Value to compare against"},{"location":"components/logic/switch/#available-operators","title":"Available operators","text":"<p>The Switch component supports the full set of shared operators:</p> Category Operators Universal <code>exists</code>, <code>does_not_exist</code>, <code>is_empty</code>, <code>is_not_empty</code> String / Equality <code>equals</code>, <code>not_equals</code>, <code>contains</code>, <code>not_contains</code>, <code>starts_with</code>, <code>not_starts_with</code>, <code>ends_with</code>, <code>not_ends_with</code>, <code>matches_regex</code>, <code>not_matches_regex</code> Number <code>gt</code>, <code>lt</code>, <code>gte</code>, <code>lte</code> Datetime <code>after</code>, <code>before</code>, <code>after_or_equal</code>, <code>before_or_equal</code> Boolean <code>is_true</code>, <code>is_false</code> Array Length <code>length_eq</code>, <code>length_neq</code>, <code>length_gt</code>, <code>length_lt</code>, <code>length_gte</code>, <code>length_lte</code>"},{"location":"components/logic/switch/#usage","title":"Usage","text":"<ol> <li>Add a Switch node from the Node Palette (Logic category)</li> <li>Connect the upstream node to the Switch's input</li> <li>Configure rules in the node's Extra Config field</li> <li>Draw edges from the Switch to each target branch node</li> <li>Set each edge's <code>condition_value</code> to match the corresponding rule's <code>id</code></li> </ol>"},{"location":"components/logic/switch/#rule-evaluation","title":"Rule evaluation","text":"<p>Rules are evaluated in order -- the first matching rule wins. If no rules match and <code>enable_fallback</code> is enabled, the route is set to <code>__other__</code>. If no rules match and fallback is disabled, the route is an empty string.</p>"},{"location":"components/logic/switch/#conditional-edges","title":"Conditional edges","text":"<p>Only Switch nodes can originate conditional edges. Each downstream edge carries a <code>condition_value</code> string that the orchestrator matches against the emitted <code>_route</code>. This is a per-edge model -- each edge has its own <code>condition_value</code> rather than a single mapping dict.</p>"},{"location":"components/logic/switch/#legacy-mode","title":"Legacy mode","text":"<p>The Switch component also supports a legacy configuration using <code>condition_field</code> or <code>condition_expression</code> in <code>extra_config</code>. This mode reads a field directly from state or evaluates a simple expression. The rule-based mode is recommended for new workflows.</p>"},{"location":"components/logic/switch/#example","title":"Example","text":"<p>A categorizer classifies user input, then a switch routes to the appropriate handler:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; C[Categorizer]\n    C --&gt; S{Switch}\n    S --&gt;|greeting| A1[Greeting Agent]\n    S --&gt;|question| A2[Q&amp;A Agent]\n    S --&gt;|complaint| A3[Support Agent]\n    S --&gt;|__other__| A4[General Agent]</code></pre> <p>Switch Extra Config:</p> <pre><code>{\n  \"rules\": [\n    {\"id\": \"greeting\", \"field\": \"node_outputs.categorizer_abc.category\", \"operator\": \"equals\", \"value\": \"greeting\"},\n    {\"id\": \"question\", \"field\": \"node_outputs.categorizer_abc.category\", \"operator\": \"equals\", \"value\": \"question\"},\n    {\"id\": \"complaint\", \"field\": \"node_outputs.categorizer_abc.category\", \"operator\": \"equals\", \"value\": \"complaint\"}\n  ],\n  \"enable_fallback\": true\n}\n</code></pre> <p>Each edge from the Switch to a downstream agent has its <code>condition_value</code> set to the corresponding route ID (<code>greeting</code>, <code>question</code>, <code>complaint</code>, or <code>__other__</code>).</p> <p>Switch vs. Router</p> <p>The Switch node evaluates rules against state data -- it does not use an LLM. The Router (AI category) uses an LLM to determine which branch to take based on natural language understanding. Use Switch for deterministic, rule-based routing; use Router when the decision requires language comprehension.</p>"},{"location":"components/logic/wait/","title":"Wait","text":""},{"location":"components/logic/wait/#wait","title":"Wait","text":"<p>The Wait component delays downstream execution by a specified duration. It passes through data unchanged after the delay period, useful for rate limiting, scheduling gaps, or creating timed workflows.</p> Property Value Component Type <code>wait</code> Category Logic Display Name Wait"},{"location":"components/logic/wait/#ports","title":"Ports","text":""},{"location":"components/logic/wait/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>input</code> ANY No Data to pass through after the delay"},{"location":"components/logic/wait/#outputs","title":"Outputs","text":"Port Data Type Description <code>output</code> STRING Confirmation message (e.g., \"Waited 30 seconds\")"},{"location":"components/logic/wait/#configuration","title":"Configuration","text":"<p>The Wait component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>duration</code> number <code>0</code> Length of the delay <code>unit</code> string <code>seconds</code> Time unit: <code>seconds</code>, <code>minutes</code>, or <code>hours</code> <p>The actual delay is calculated as <code>duration * multiplier</code>, where the multiplier is:</p> Unit Multiplier <code>seconds</code> 1 <code>minutes</code> 60 <code>hours</code> 3600"},{"location":"components/logic/wait/#usage","title":"Usage","text":"<ol> <li>Add a Wait node from the Node Palette (Logic category)</li> <li>Configure the duration and unit in Extra Config</li> <li>Place the Wait node between the steps where you need a delay</li> </ol> <p>The Wait component emits a <code>_delay_seconds</code> key in its output, which the orchestrator uses to pause execution for the specified duration before continuing to downstream nodes.</p>"},{"location":"components/logic/wait/#example","title":"Example","text":"<p>A workflow that sends a follow-up message 5 minutes after the initial response:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A1[Response Agent]\n    A1 --&gt; W[Wait]\n    W --&gt; A2[Follow-up Agent]\n    M[AI Model] -.-&gt;|model| A1\n    M2[AI Model] -.-&gt;|model| A2</code></pre> <p>Wait Extra Config:</p> <pre><code>{\n  \"duration\": 5,\n  \"unit\": \"minutes\"\n}\n</code></pre> <p>The Response Agent answers immediately. After a 5-minute delay, the Follow-up Agent runs and can send additional information or ask for feedback.</p> <p>Rate limiting</p> <p>Place a Wait node before API calls or tool-heavy agents to avoid hitting rate limits on external services. A short delay (e.g., 1-2 seconds) between iterations in a loop can prevent throttling.</p> <p>Execution time</p> <p>The wait duration counts toward the total execution time. Long delays keep the execution in a running state. For delays longer than a few minutes, consider using the Scheduler system instead.</p>"},{"location":"components/memory/","title":"Memory","text":""},{"location":"components/memory/#memory","title":"Memory","text":"<p>Memory components give agents persistent knowledge that survives across executions. They connect to agents as sub-component tools via the amber diamond memory handle, allowing an agent to read from, write to, and personalize interactions using a global memory system.</p>"},{"location":"components/memory/#overview","title":"Overview","text":"<p>There are three memory component types:</p> Component Purpose Connection Memory Read Recall stored facts, episodes, and procedures Sub-component tool (memory handle) Memory Write Store new facts and knowledge Sub-component tool (memory handle) Identify User Identify who is talking and load their context Direct node (standard edges)"},{"location":"components/memory/#how-memory-components-work","title":"How memory components work","text":"<p>Memory Read and Memory Write are sub-component tools -- they connect to agent nodes via the amber diamond memory handle and become available as LangChain tools inside the agent's reasoning loop. The agent decides when to recall or remember information based on the conversation.</p> <p>Identify User is different -- it is a direct node in the workflow graph that runs before the agent, extracting user identity from trigger payloads and loading personalized context into the workflow state.</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; IU[Identify User]\n    IU --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    MR[Memory Read] -.-&gt;|memory| A\n    MW[Memory Write] -.-&gt;|memory| A</code></pre>"},{"location":"components/memory/#memory-types","title":"Memory types","text":"<p>The global memory system stores three types of knowledge:</p> Type Description Example Facts Key-value pairs with confidence scores <code>user_name = Alice (0.95)</code> Episodes Time-stamped event summaries <code>User asked about pricing on 2024-03-15</code> Procedures Named workflows with steps and context <code>deploy_app: Build, test, push to production</code> <p>Memory Read can search across one type or all types simultaneously. Memory Write stores facts with configurable type classification.</p>"},{"location":"components/memory/#memory-scope","title":"Memory scope","text":"<p>All memory operations use a global scope by default. Facts written by one workflow are readable by any other workflow on the same platform instance. This enables shared knowledge across agents -- for example, one agent can learn a user's preferences while another agent uses that knowledge to personalize responses.</p>"},{"location":"components/memory/#connecting-memory-to-agents","title":"Connecting memory to agents","text":"<ol> <li>Add a Memory Read and/or Memory Write node from the Node Palette</li> <li>Connect them to an agent node via the amber diamond memory handle at the bottom</li> <li>Optionally add an Identify User node before the agent to load user-specific context</li> </ol> <p>The agent's LLM will then have <code>recall</code> and <code>remember</code> tools available for reading and writing memory during its reasoning loop.</p> <p>Memory is optional</p> <p>An agent does not require any memory components. Without memory, the agent has no persistent knowledge between executions (though it can still use conversation memory via the <code>conversation_memory</code> toggle for within-session continuity).</p>"},{"location":"components/memory/identify-user/","title":"Identify User","text":""},{"location":"components/memory/identify-user/#identify-user","title":"Identify User","text":"<p>The Identify User component identifies who is interacting with the workflow and loads their stored context. Unlike Memory Read and Memory Write, this is a direct workflow node -- it runs as a step in the graph rather than as an agent tool.</p> Property Value Component Type <code>identify_user</code> Category Memory Display Name Identify User"},{"location":"components/memory/identify-user/#ports","title":"Ports","text":""},{"location":"components/memory/identify-user/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>trigger_input</code> OBJECT Yes Raw trigger payload containing user-identifying information <code>channel</code> STRING Yes Channel type (telegram, webhook, chat, manual)"},{"location":"components/memory/identify-user/#outputs","title":"Outputs","text":"Port Data Type Description <code>user_id</code> STRING Canonical user ID (unique across channels) <code>user_context</code> OBJECT User facts, preferences, and conversation history <code>is_new_user</code> BOOLEAN Whether this is a first-time user"},{"location":"components/memory/identify-user/#configuration","title":"Configuration","text":"<p>The Identify User component has no additional configuration. It infers the channel and extracts user identity from the trigger payload automatically.</p>"},{"location":"components/memory/identify-user/#usage","title":"Usage","text":"<ol> <li>Add an Identify User node from the Node Palette (Memory category)</li> <li>Place it between the trigger node and the agent node</li> <li>Connect the trigger's output to Identify User's input</li> <li>Connect Identify User's output to the agent's input</li> </ol> <p>The component examines the trigger payload and automatically detects the channel type. It then extracts channel-specific identifiers:</p> Channel Identifier Source Display Name Source <code>telegram</code> <code>message.from.id</code> <code>message.from.first_name</code> + <code>last_name</code> <code>webhook</code> <code>user_id</code> or <code>email</code> field <code>user_name</code> or <code>name</code> field <code>chat</code> <code>user_id</code> field <code>user_name</code> field <code>manual</code> <code>user_id</code> field <code>user_name</code> field"},{"location":"components/memory/identify-user/#channel-auto-detection","title":"Channel auto-detection","text":"<p>If the <code>channel</code> input is not explicitly provided, the component infers it from the trigger payload structure:</p> <ul> <li>Contains <code>message.from</code> -- detected as <code>telegram</code></li> <li>Contains <code>webhook_id</code> -- detected as <code>webhook</code></li> <li>Contains <code>source: \"manual\"</code> -- detected as <code>manual</code></li> <li>Contains <code>source: \"chat\"</code> -- detected as <code>chat</code></li> </ul>"},{"location":"components/memory/identify-user/#state-patch","title":"State patch","text":"<p>In addition to its output ports, the Identify User component writes a <code>_state_patch</code> that merges user context into the global workflow state under the <code>user_context</code> key. This makes user information available to all downstream nodes via Jinja2 expressions without needing explicit edges.</p>"},{"location":"components/memory/identify-user/#example","title":"Example","text":"<p>A workflow that personalizes responses based on user identity:</p> <pre><code>flowchart LR\n    T[Telegram Trigger] --&gt; IU[Identify User]\n    IU --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    MR[Memory Read] -.-&gt;|memory| A</code></pre> <p>On first interaction from a Telegram user:</p> <pre><code>Identify User output:\n{\n  \"user_id\": \"tg_12345678\",\n  \"user_context\": {\"is_new\": true, \"facts\": [], \"history\": []},\n  \"is_new_user\": true\n}\n</code></pre> <p>On subsequent interactions:</p> <pre><code>Identify User output:\n{\n  \"user_id\": \"tg_12345678\",\n  \"user_context\": {\n    \"is_new\": false,\n    \"facts\": [\n      {\"key\": \"user_name\", \"value\": \"Alice\"},\n      {\"key\": \"preferred_language\", \"value\": \"English\"}\n    ],\n    \"history\": [...]\n  },\n  \"is_new_user\": false\n}\n</code></pre> <p>The agent can then reference user context in its system prompt:</p> <pre><code>{% if user_context.is_new %}\nWelcome! This is your first time here.\n{% else %}\nWelcome back, {{ user_context.facts | selectattr(\"key\", \"equalto\", \"user_name\") | map(attribute=\"value\") | first }}!\n{% endif %}\n</code></pre> <p>Combine with Memory Write</p> <p>Identify User loads existing context, but it does not store new facts. Pair it with a Memory Write tool on the agent so the agent can learn and remember new information about the user over time.</p> <p>Conversation counting</p> <p>Each time Identify User runs for a known user, it increments their <code>total_conversations</code> counter. This can be used to distinguish between first-time and returning users via the <code>is_new_user</code> output.</p>"},{"location":"components/memory/memory-read/","title":"Memory Read","text":""},{"location":"components/memory/memory-read/#memory-read","title":"Memory Read","text":"<p>The Memory Read component provides a <code>recall</code> tool that retrieves information from the global memory system. When connected to an agent, the agent can look up facts by key, search by query, or list all stored memories.</p> Property Value Component Type <code>memory_read</code> Category Sub-component (Memory) Display Name Memory Read"},{"location":"components/memory/memory-read/#ports","title":"Ports","text":""},{"location":"components/memory/memory-read/#inputs","title":"Inputs","text":"<p>This component has no wired inputs. It operates as a LangChain tool that the agent invokes with arguments during its reasoning loop.</p>"},{"location":"components/memory/memory-read/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Retrieved memory content (JSON or plain text)"},{"location":"components/memory/memory-read/#configuration","title":"Configuration","text":"<p>The Memory Read component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Options Description <code>memory_type</code> string <code>facts</code> <code>facts</code>, <code>episodes</code>, <code>procedures</code>, <code>all</code> Type of memory to search <code>limit</code> integer <code>10</code> 1--100 Maximum number of results to return <code>min_confidence</code> number <code>0.5</code> 0--1 Minimum confidence threshold for fact results"},{"location":"components/memory/memory-read/#usage","title":"Usage","text":"<ol> <li>Add a Memory Read node from the Node Palette (Memory category)</li> <li>Connect it to an agent node via the amber diamond memory handle</li> <li>Optionally configure the memory type, result limit, and confidence threshold in the node's Extra Config</li> </ol> <p>The agent's LLM will then have a <code>recall</code> tool available. The tool accepts two optional parameters:</p> Parameter Description <code>key</code> Exact key lookup. Falls back to search if no exact match is found. <code>query</code> Search query for fuzzy matching across memory. <p>If called with no arguments, the tool lists all stored memories up to the configured limit.</p>"},{"location":"components/memory/memory-read/#search-behavior","title":"Search behavior","text":"<p>The <code>recall</code> tool follows this resolution order:</p> <ol> <li>No arguments -- lists all facts from global memory</li> <li>Key provided -- attempts exact key lookup first, then falls back to fuzzy search using the key as a query</li> <li>Query provided -- searches across the configured memory type(s):<ul> <li>Facts -- fuzzy search with confidence filtering</li> <li>Procedures -- finds procedures matching the goal</li> <li>Episodes -- searches recent episode summaries</li> <li>All -- searches across all three types</li> </ul> </li> </ol>"},{"location":"components/memory/memory-read/#return-format","title":"Return format","text":"<p>Results are returned as JSON arrays with the following structure:</p> <pre><code>[\n  {\"key\": \"user_name\", \"value\": \"Alice\", \"confidence\": 0.95},\n  {\"key\": \"favorite_color\", \"value\": \"blue\", \"confidence\": 0.8}\n]\n</code></pre> <p>For exact key lookups, the format is a simple string: <code>user_name = Alice</code>.</p> <p>If no results are found, a descriptive message is returned (e.g., <code>No memory found for key: unknown_key</code>).</p>"},{"location":"components/memory/memory-read/#example","title":"Example","text":"<p>An agent with Memory Read connected can answer questions about previously stored knowledge:</p> <pre><code>User: What do you know about me?\nAgent: [calls recall(query=\"user\")]\n       \u2192 [{\"key\": \"user_name\", \"value\": \"Alice\", \"confidence\": 0.95},\n          {\"key\": \"user_role\", \"value\": \"developer\", \"confidence\": 0.8}]\nAgent: I know your name is Alice and you're a developer.\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    MR[Memory Read] -.-&gt;|memory| A\n\n    style MR fill:#f59e0b,color:white</code></pre> <p>Global scope</p> <p>Memory Read always searches the global memory scope. Facts stored by any workflow on the platform are accessible. Use the <code>min_confidence</code> setting to filter out low-confidence facts.</p>"},{"location":"components/memory/memory-write/","title":"Memory Write","text":""},{"location":"components/memory/memory-write/#memory-write","title":"Memory Write","text":"<p>The Memory Write component provides a <code>remember</code> tool that stores facts in the global memory system. When connected to an agent, the agent can persist key-value pairs that survive across executions and are accessible to any workflow on the platform.</p> Property Value Component Type <code>memory_write</code> Category Sub-component (Memory) Display Name Memory Write"},{"location":"components/memory/memory-write/#ports","title":"Ports","text":""},{"location":"components/memory/memory-write/#inputs","title":"Inputs","text":"<p>This component has no wired inputs. It operates as a LangChain tool that the agent invokes with arguments during its reasoning loop.</p>"},{"location":"components/memory/memory-write/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Confirmation of what was stored"},{"location":"components/memory/memory-write/#configuration","title":"Configuration","text":"<p>The Memory Write component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Options Description <code>fact_type</code> string <code>world_knowledge</code> <code>user_preference</code>, <code>world_knowledge</code>, <code>self_knowledge</code>, <code>correction</code>, <code>relationship</code> Type classification for the stored fact <code>overwrite</code> boolean <code>true</code> -- Whether to overwrite an existing fact with the same key"},{"location":"components/memory/memory-write/#fact-types","title":"Fact types","text":"Fact Type Description Example <code>user_preference</code> User-specific preferences and settings Preferred language, notification settings <code>world_knowledge</code> General facts about the world API endpoints, project names <code>self_knowledge</code> Facts the agent knows about itself Its own capabilities, assigned roles <code>correction</code> Corrections to previously stored facts Updated values after user feedback <code>relationship</code> Relationships between entities \"Alice manages the backend team\""},{"location":"components/memory/memory-write/#usage","title":"Usage","text":"<ol> <li>Add a Memory Write node from the Node Palette (Memory category)</li> <li>Connect it to an agent node via the amber diamond memory handle</li> <li>Optionally configure the default fact type and overwrite behavior in the node's Extra Config</li> </ol> <p>The agent's LLM will then have a <code>remember</code> tool available. The tool accepts three parameters:</p> Parameter Required Description <code>key</code> Yes The identifier for the fact <code>value</code> Yes The content to store <code>fact_type</code> No Override the configured default fact type"},{"location":"components/memory/memory-write/#write-behavior","title":"Write behavior","text":"<p>When the <code>remember</code> tool is called:</p> <ol> <li>If a fact with the same key already exists and <code>overwrite</code> is <code>true</code>, the value is updated and the confirmation count is incremented</li> <li>If a fact with the same key exists and <code>overwrite</code> is <code>false</code>, the write is skipped</li> <li>If no fact with that key exists, a new fact is created</li> </ol>"},{"location":"components/memory/memory-write/#return-format","title":"Return format","text":"<p>The tool returns a confirmation string:</p> <pre><code>Remembered: user_name = Alice (created)\nRemembered: user_name = Alice Smith (updated)\nRemembered: user_name = Alice (skipped)\n</code></pre>"},{"location":"components/memory/memory-write/#example","title":"Example","text":"<p>An agent with Memory Write connected can store information for later retrieval:</p> <pre><code>User: My name is Alice and I prefer dark mode.\nAgent: [calls remember(key=\"user_name\", value=\"Alice\", fact_type=\"user_preference\")]\n       \u2192 Remembered: user_name = Alice (created)\n       [calls remember(key=\"ui_preference\", value=\"dark mode\", fact_type=\"user_preference\")]\n       \u2192 Remembered: ui_preference = dark mode (created)\nAgent: Got it! I've noted your name and preference.\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    MW[Memory Write] -.-&gt;|memory| A\n\n    style MW fill:#f59e0b,color:white</code></pre> <p>Pair with Memory Read</p> <p>Memory Write is most useful when paired with Memory Read on the same agent. The agent can then both store and recall information, building persistent knowledge over time.</p> <p>Global scope</p> <p>All facts are stored in the global memory scope. Any workflow on the platform can read facts written by this component. Be mindful of key naming to avoid unintended collisions across workflows.</p>"},{"location":"components/self-awareness/","title":"Self-Awareness","text":""},{"location":"components/self-awareness/#self-awareness","title":"Self-Awareness","text":"<p>Self-awareness tools give agents the ability to interact with the Pipelit platform itself -- creating users, making API calls, managing workflows, scheduling jobs, and understanding their own identity. This is what enables self-improving agents: agents that can inspect their own configuration, modify their system prompts, create new workflows, delegate tasks, and monitor the health of the infrastructure they run on.</p> <p>All self-awareness components are tool nodes. They connect to agent nodes via the green diamond \"tool\" handle and are invoked by the LLM during its reasoning loop, just like any other tool.</p>"},{"location":"components/self-awareness/#available-components","title":"Available Components","text":"Component Type Description Create Agent User <code>create_agent_user</code> Provision API credentials so the agent can authenticate against the platform Platform API <code>platform_api</code> Make authenticated HTTP requests to any platform REST endpoint WhoAmI <code>whoami</code> Retrieve the agent's own identity: workflow slug, node ID, current config, and self-modification instructions Get TOTP Code <code>get_totp_code</code> Retrieve the current TOTP code for agent identity verification Epic Tools <code>epic_tools</code> Create, query, update, and search epics for organizing multi-step work Task Tools <code>task_tools</code> Create, list, update, and cancel tasks within epics Spawn &amp; Await <code>spawn_and_await</code> Spawn a child workflow and wait for its result inside the agent's reasoning loop Workflow Create <code>workflow_create</code> Create workflows programmatically from a YAML DSL specification Workflow Discover <code>workflow_discover</code> Search existing workflows by requirements and get scored reuse recommendations Scheduler Tools <code>scheduler_tools</code> Create, pause, resume, stop, and list scheduled recurring jobs System Health <code>system_health</code> Check platform infrastructure health: Redis, RQ workers, queues, and executions"},{"location":"components/self-awareness/#self-improvement-pattern","title":"Self-Improvement Pattern","text":"<p>The typical self-improvement cycle uses three tools together:</p> <pre><code>sequenceDiagram\n    participant Agent\n    participant WhoAmI as whoami\n    participant CreateUser as create_agent_user\n    participant API as platform_api\n\n    Agent-&gt;&gt;WhoAmI: Who am I?\n    WhoAmI--&gt;&gt;Agent: workflow_slug, node_id, current system_prompt\n    Agent-&gt;&gt;CreateUser: Get API credentials\n    CreateUser--&gt;&gt;Agent: username, api_key, api_base_url\n    Agent-&gt;&gt;API: PATCH /api/v1/workflows/{slug}/nodes/{node_id}/\n    API--&gt;&gt;Agent: Updated config\n    Note over Agent: Changes take effect on next execution</code></pre> <ol> <li>WhoAmI tells the agent its workflow slug, node ID, and current system prompt.</li> <li>Create Agent User provisions API credentials (or returns existing ones).</li> <li>Platform API sends a <code>PATCH</code> request to update the agent's own configuration.</li> </ol>"},{"location":"components/self-awareness/#multi-agent-delegation-pattern","title":"Multi-Agent Delegation Pattern","text":"<p>For complex tasks, agents can decompose work into epics and tasks, then spawn child workflows to execute them:</p> <pre><code>flowchart LR\n    Orchestrator[Orchestrator Agent] --&gt;|create_epic| Epic[Epic Tools]\n    Orchestrator --&gt;|create_task| Task[Task Tools]\n    Orchestrator --&gt;|spawn_and_await| Child[Spawn &amp; Await]\n    Child --&gt;|executes| Worker[Worker Workflow]\n    Worker --&gt;|result| Child\n    Child --&gt;|result| Orchestrator\n    Orchestrator --&gt;|update_task: completed| Task</code></pre>"},{"location":"components/self-awareness/#connection","title":"Connection","text":"<p>All self-awareness tools connect to agent nodes via the green diamond tool handle, the same way standard tools (Run Command, HTTP Request, etc.) connect. An agent can have any number of self-awareness tools attached simultaneously.</p>"},{"location":"components/self-awareness/#whats-next","title":"What's Next?","text":"<ul> <li>Learn how agents work: Agents</li> <li>Build a self-improving agent: Self-Improving Agent Tutorial</li> <li>Understand the YAML DSL: YAML DSL Tutorial</li> <li>See the multi-agent architecture: Multi-Agent Architecture</li> </ul>"},{"location":"components/self-awareness/create-agent-user/","title":"Create Agent User","text":""},{"location":"components/self-awareness/create-agent-user/#create-agent-user","title":"Create Agent User","text":"<p>The Create Agent User tool provisions API credentials that an agent can use to authenticate against the Pipelit platform. This is the first step in enabling self-modification -- without credentials, an agent cannot call the platform API.</p> <p>Component type: <code>create_agent_user</code></p>"},{"location":"components/self-awareness/create-agent-user/#how-it-works","title":"How It Works","text":"<p>When invoked, the tool creates (or retrieves existing) API credentials scoped to the agent. The username is deterministic, constructed from the workflow slug and the parent agent's node ID:</p> <pre><code>agent_{workflow_slug}_{agent_node_id}\n</code></pre> <p>This means calling the tool multiple times is safe -- it returns the same credentials if they already exist. Agent users are created without passwords and with MFA enabled (a TOTP secret is generated automatically).</p>"},{"location":"components/self-awareness/create-agent-user/#ports","title":"Ports","text":""},{"location":"components/self-awareness/create-agent-user/#outputs","title":"Outputs","text":"Port Type Description <code>credentials</code> <code>STRING</code> JSON object with <code>username</code>, <code>api_key</code>, <code>api_base_url</code>, <code>purpose</code>, and <code>already_existed</code>"},{"location":"components/self-awareness/create-agent-user/#output-format","title":"Output Format","text":"<pre><code>{\n  \"success\": true,\n  \"username\": \"agent_my-workflow_agent_abc123\",\n  \"api_key\": \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\",\n  \"api_base_url\": \"http://localhost:8000\",\n  \"purpose\": \"Self-modification agent\",\n  \"already_existed\": false\n}\n</code></pre>"},{"location":"components/self-awareness/create-agent-user/#configuration","title":"Configuration","text":"Setting Type Default Description <code>api_base_url</code> string <code>http://localhost:8000</code> Base URL for the platform API. Set this to your production URL if deploying remotely. <p>Set <code>api_base_url</code> in the node's Extra Config panel.</p>"},{"location":"components/self-awareness/create-agent-user/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. The agent calls it when it needs API access:</p> <pre><code>flowchart LR\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre> <p>The agent typically calls <code>create_agent_user</code> first to obtain credentials, then passes the <code>api_key</code> to subsequent <code>platform_api</code> calls.</p>"},{"location":"components/self-awareness/create-agent-user/#tool-signature","title":"Tool Signature","text":"<pre><code>create_agent_user(purpose: str = \"\") -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>purpose</code> string <code>\"\"</code> Optional description of what the credentials are for. Stored in the user's <code>first_name</code> field."},{"location":"components/self-awareness/create-agent-user/#example","title":"Example","text":"<p>An agent with a system prompt like:</p> <pre><code>You are a self-improving agent. When asked to improve yourself:\n1. Call create_agent_user to get your API credentials.\n2. Call whoami to learn your identity and current configuration.\n3. Use platform_api to update your system prompt via PATCH.\n</code></pre> <p>When the user says \"improve your greeting,\" the agent:</p> <ol> <li>Calls <code>create_agent_user(purpose=\"Self-improvement\")</code> and receives credentials.</li> <li>Uses the <code>api_key</code> in subsequent <code>platform_api</code> calls to modify its own configuration.</li> </ol> <p>Idempotent</p> <p>Calling <code>create_agent_user</code> multiple times is safe. If credentials already exist for this agent, the tool returns them without creating duplicates. The <code>already_existed</code> field in the response indicates whether credentials were freshly created or retrieved.</p> <p>Agent Users Are Not Human Users</p> <p>Agent users are created without passwords and cannot log in through the web UI. They exist solely for API access via Bearer token authentication. Each agent user also has a TOTP secret for identity verification -- see Get TOTP Code.</p>"},{"location":"components/self-awareness/epic-tools/","title":"Epic Tools","text":""},{"location":"components/self-awareness/epic-tools/#epic-tools","title":"Epic Tools","text":"<p>The Epic Tools component provides a set of LangChain tools for creating, querying, updating, and searching epics. Epics are high-level work packages that organize multiple tasks for multi-agent delegation and tracking.</p> <p>Component type: <code>epic_tools</code></p>"},{"location":"components/self-awareness/epic-tools/#how-it-works","title":"How It Works","text":"<p>This component registers four tools with the parent agent. Epics serve as containers for tasks -- each epic has a title, description, priority, optional budget limits, and a status that tracks progress from planning through completion.</p> <p>All epics are scoped to the workflow owner. The component resolves the owner from the workflow at build time.</p>"},{"location":"components/self-awareness/epic-tools/#ports","title":"Ports","text":""},{"location":"components/self-awareness/epic-tools/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON result from epic operations"},{"location":"components/self-awareness/epic-tools/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/epic-tools/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It is typically paired with Task Tools for full work decomposition:</p> <pre><code>flowchart LR\n    Epic[Epic Tools] -.-&gt;|tool| Agent\n    Task[Task Tools] -.-&gt;|tool| Agent\n    SA[Spawn &amp; Await] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/epic-tools/#tools-provided","title":"Tools Provided","text":"<p>This component registers four tools with the agent:</p>"},{"location":"components/self-awareness/epic-tools/#create_epic","title":"<code>create_epic</code>","text":"<p>Create a new epic for organizing tasks.</p> <pre><code>create_epic(\n    title: str,\n    description: str = \"\",\n    tags: str = \"\",\n    priority: int = 2,\n    budget_tokens: int | None = None,\n    budget_usd: float | None = None,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>title</code> string (required) Epic title <code>description</code> string <code>\"\"</code> Detailed description <code>tags</code> string <code>\"\"</code> Comma-separated tags (e.g., <code>\"backend,urgent\"</code>) <code>priority</code> int <code>2</code> Priority level 1-5 (1 = highest) <code>budget_tokens</code> int <code>None</code> Optional token budget limit <code>budget_usd</code> float <code>None</code> Optional USD budget limit <p>Returns: <code>{\"success\": true, \"epic_id\": \"ep-abc123\", \"title\": \"...\", \"status\": \"planning\"}</code></p>"},{"location":"components/self-awareness/epic-tools/#epic_status","title":"<code>epic_status</code>","text":"<p>Get detailed status of an epic including its task breakdown.</p> <pre><code>epic_status(epic_id: str) -&gt; str\n</code></pre> Parameter Type Description <code>epic_id</code> string The epic ID (e.g., <code>\"ep-abc123\"</code>) <p>Returns: JSON with epic details, task counts, budget usage, and full task list.</p>"},{"location":"components/self-awareness/epic-tools/#update_epic","title":"<code>update_epic</code>","text":"<p>Update an epic's fields. Only provided fields are changed.</p> <pre><code>update_epic(\n    epic_id: str,\n    status: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    priority: int | None = None,\n    budget_tokens: int | None = None,\n    budget_usd: float | None = None,\n    result_summary: str | None = None,\n) -&gt; str\n</code></pre> Parameter Type Description <code>epic_id</code> string The epic ID <code>status</code> string New status: <code>planning</code>, <code>active</code>, <code>paused</code>, <code>completed</code>, <code>cancelled</code>, <code>failed</code> <code>title</code> string New title <code>description</code> string New description <code>priority</code> int New priority 1-5 <code>budget_tokens</code> int New token budget <code>budget_usd</code> float New USD budget <code>result_summary</code> string Summary of results when completing <p>Returns: <code>{\"success\": true, \"epic_id\": \"ep-abc123\", \"status\": \"completed\"}</code></p> <p>Cancellation Cascades</p> <p>Setting an epic's status to <code>cancelled</code> automatically cancels all its pending, blocked, and running tasks.</p>"},{"location":"components/self-awareness/epic-tools/#search_epics","title":"<code>search_epics</code>","text":"<p>Search epics by text, tags, or status.</p> <pre><code>search_epics(\n    query: str = \"\",\n    tags: str = \"\",\n    status: str | None = None,\n    limit: int = 10,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>query</code> string <code>\"\"</code> Search text (matches title and description, case-insensitive) <code>tags</code> string <code>\"\"</code> Comma-separated tags to filter by (OR semantics) <code>status</code> string <code>None</code> Filter by status <code>limit</code> int <code>10</code> Max results (1-100) <p>Returns: JSON with <code>results</code> list, <code>success_rate</code> (ratio of completed to finished epics), and <code>avg_cost</code>.</p>"},{"location":"components/self-awareness/epic-tools/#example","title":"Example","text":"<p>An orchestrator agent decomposing a complex request:</p> <pre><code>User: Build me a data pipeline that fetches weather data hourly.\n\nAgent thinking: I need to create an epic and break this into tasks.\n\nTool call: create_epic(\n    title=\"Weather Data Pipeline\",\n    description=\"Build an hourly weather data fetching pipeline\",\n    tags=\"data,automation\",\n    priority=2\n)\nResult: {\"success\": true, \"epic_id\": \"ep-w3ath3r\", \"status\": \"planning\"}\n\nTool call: update_epic(epic_id=\"ep-w3ath3r\", status=\"active\")\nResult: {\"success\": true, \"epic_id\": \"ep-w3ath3r\", \"status\": \"active\"}\n</code></pre> <p>The agent then uses Task Tools to create individual tasks within the epic, and Spawn &amp; Await to delegate each task to a worker workflow.</p> <p>WebSocket Events</p> <p>Epic creation and updates broadcast WebSocket events (<code>epic_created</code>, <code>epic_updated</code>) on the <code>epic:{epic_id}</code> channel, enabling real-time UI updates.</p>"},{"location":"components/self-awareness/get-totp-code/","title":"Get TOTP Code","text":""},{"location":"components/self-awareness/get-totp-code/#get-totp-code","title":"Get TOTP Code","text":"<p>The Get TOTP Code tool retrieves the current time-based one-time password (TOTP) for an agent user. This enables agent identity verification when interacting with systems that require MFA.</p> <p>Component type: <code>get_totp_code</code></p>"},{"location":"components/self-awareness/get-totp-code/#how-it-works","title":"How It Works","text":"<p>Every agent user created by Create Agent User is provisioned with a TOTP secret and MFA enabled. This tool reads the secret from the database and generates the current 6-digit TOTP code using the standard RFC 6238 algorithm (via <code>pyotp</code>).</p> <p>If no username is provided, the tool automatically resolves the agent user associated with the current workflow and node by following the <code>tool</code> edge to the parent agent and constructing the deterministic username (<code>agent_{workflow_slug}_{agent_node_id}</code>).</p>"},{"location":"components/self-awareness/get-totp-code/#ports","title":"Ports","text":""},{"location":"components/self-awareness/get-totp-code/#outputs","title":"Outputs","text":"Port Type Description <code>totp_code</code> <code>STRING</code> JSON object with <code>username</code> and current <code>totp_code</code>"},{"location":"components/self-awareness/get-totp-code/#output-format","title":"Output Format","text":"<pre><code>{\n  \"success\": true,\n  \"username\": \"agent_my-workflow_agent_abc123\",\n  \"totp_code\": \"483291\"\n}\n</code></pre>"},{"location":"components/self-awareness/get-totp-code/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/get-totp-code/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It pairs with <code>create_agent_user</code> for scenarios where the agent needs to prove its identity:</p> <pre><code>flowchart LR\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    TOTP[Get TOTP Code] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/get-totp-code/#tool-signature","title":"Tool Signature","text":"<pre><code>get_totp_code(username: str = \"\") -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>username</code> string <code>\"\"</code> The agent username to get the TOTP code for. If omitted, the tool automatically resolves the agent user for the current workflow/node."},{"location":"components/self-awareness/get-totp-code/#example","title":"Example","text":"<p>An agent that needs to authenticate with an external system requiring MFA:</p> <ol> <li>Calls <code>create_agent_user()</code> to ensure credentials exist.</li> <li>Calls <code>get_totp_code()</code> to retrieve the current TOTP code.</li> <li>Submits both the API key and TOTP code to the external system.</li> </ol> <pre><code>Agent: I need to verify my identity with the external service.\n       Let me get my credentials and TOTP code.\n\nTool call: create_agent_user(purpose=\"External auth\")\nResult: {\"success\": true, \"username\": \"agent_my-workflow_agent_abc123\", ...}\n\nTool call: get_totp_code()\nResult: {\"success\": true, \"username\": \"agent_my-workflow_agent_abc123\", \"totp_code\": \"483291\"}\n</code></pre> <p>Code Rotation</p> <p>TOTP codes rotate every 30 seconds. The tool returns the code that is valid at the moment of the call. If the agent needs to use the code in a subsequent API call, it should do so promptly.</p> <p>Agent User Must Exist</p> <p>The tool returns an error if the agent user has not been created yet or if the user has no TOTP secret configured. Always call <code>create_agent_user</code> first to ensure the agent user exists.</p>"},{"location":"components/self-awareness/platform-api/","title":"Platform API","text":""},{"location":"components/self-awareness/platform-api/#platform-api","title":"Platform API","text":"<p>The Platform API tool allows agents to make authenticated HTTP requests to any endpoint on the Pipelit REST API. Combined with Create Agent User, this gives agents full programmatic access to the platform -- reading workflows, modifying node configurations, managing credentials, and more.</p> <p>Component type: <code>platform_api</code></p>"},{"location":"components/self-awareness/platform-api/#how-it-works","title":"How It Works","text":"<p>The tool wraps an HTTP client (<code>httpx</code>) that sends requests to the platform API with Bearer token authentication. The agent provides the HTTP method, path, optional JSON body, and the API key obtained from <code>create_agent_user</code>.</p> <p>A recommended first call is <code>path=\"/openapi.json\"</code> to retrieve the full OpenAPI schema, which the agent can then use to discover all available endpoints and their expected request/response formats.</p>"},{"location":"components/self-awareness/platform-api/#ports","title":"Ports","text":""},{"location":"components/self-awareness/platform-api/#outputs","title":"Outputs","text":"Port Type Description <code>response</code> <code>STRING</code> JSON object with <code>status_code</code>, <code>success</code>, <code>data</code>, and optionally <code>error</code>"},{"location":"components/self-awareness/platform-api/#output-format","title":"Output Format","text":"<pre><code>{\n  \"status_code\": 200,\n  \"success\": true,\n  \"data\": { ... }\n}\n</code></pre> <p>On error (HTTP 4xx/5xx):</p> <pre><code>{\n  \"status_code\": 404,\n  \"success\": false,\n  \"data\": { \"detail\": \"Not found\" },\n  \"error\": \"HTTP 404\"\n}\n</code></pre>"},{"location":"components/self-awareness/platform-api/#configuration","title":"Configuration","text":"Setting Type Default Description <code>api_base_url</code> string <code>http://localhost:8000</code> Base URL for the platform API. Override for remote deployments. <p>Set <code>api_base_url</code> in the node's Extra Config panel.</p>"},{"location":"components/self-awareness/platform-api/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle, alongside <code>create_agent_user</code> for credential provisioning:</p> <pre><code>flowchart LR\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    WhoAmI[WhoAmI] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/platform-api/#tool-signature","title":"Tool Signature","text":"<pre><code>platform_api(\n    method: str = \"GET\",\n    path: str = \"/openapi.json\",\n    body: str = \"\",\n    api_key: str = \"\",\n    base_url: str = \"\",\n) -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>method</code> string <code>\"GET\"</code> HTTP method: <code>GET</code>, <code>POST</code>, <code>PATCH</code>, <code>DELETE</code> <code>path</code> string <code>\"/openapi.json\"</code> API path (e.g., <code>/api/v1/workflows/</code>, <code>/api/v1/auth/me/</code>) <code>body</code> string <code>\"\"</code> JSON body for <code>POST</code>/<code>PATCH</code> requests (as a string) <code>api_key</code> string <code>\"\"</code> Bearer token from <code>create_agent_user</code> <code>base_url</code> string <code>\"\"</code> Override base URL (defaults to node config <code>api_base_url</code>)"},{"location":"components/self-awareness/platform-api/#example","title":"Example","text":"<p>A typical self-modification workflow:</p> <ol> <li> <p>Discover the API: </p><pre><code>platform_api(path=\"/openapi.json\", api_key=\"...\")\n</code></pre><p></p> </li> <li> <p>List workflows: </p><pre><code>platform_api(method=\"GET\", path=\"/api/v1/workflows/\", api_key=\"...\")\n</code></pre><p></p> </li> <li> <p>Read current node config: </p><pre><code>platform_api(method=\"GET\", path=\"/api/v1/workflows/my-workflow/nodes/\", api_key=\"...\")\n</code></pre><p></p> </li> <li> <p>Update the agent's system prompt: </p><pre><code>platform_api(\n    method=\"PATCH\",\n    path=\"/api/v1/workflows/my-workflow/nodes/agent_abc123/\",\n    body='{\"config\": {\"system_prompt\": \"You are an improved agent...\"}}',\n    api_key=\"...\"\n)\n</code></pre><p></p> </li> </ol> <p>Discover Endpoints First</p> <p>The default path (<code>/openapi.json</code>) returns the full OpenAPI specification. Encourage your agent to call this first so it understands what endpoints are available before making targeted requests. This is especially useful when the agent needs to interact with APIs it has not been explicitly told about.</p> <p>Timeout</p> <p>Requests have a 30-second timeout. Long-running operations (like triggering a workflow execution) should be handled through other mechanisms such as Spawn &amp; Await.</p>"},{"location":"components/self-awareness/scheduler-tools/","title":"Scheduler Tools","text":""},{"location":"components/self-awareness/scheduler-tools/#scheduler-tools","title":"Scheduler Tools","text":"<p>The Scheduler Tools component provides LangChain tools for creating, pausing, resuming, stopping, and listing scheduled recurring jobs. This allows agents to set up automated workflow executions on intervals without human intervention.</p> <p>Component type: <code>scheduler_tools</code></p>"},{"location":"components/self-awareness/scheduler-tools/#how-it-works","title":"How It Works","text":"<p>This component registers five tools with the parent agent. Scheduled jobs use Pipelit's self-rescheduling architecture -- each job runs as an RQ task that, on completion, enqueues itself for the next run via <code>Queue.enqueue_in()</code>. This approach avoids external cron dependencies and supports exponential backoff on failure.</p> <p>Each scheduled job tracks:</p> <ul> <li>Run count -- how many times it has executed.</li> <li>Error count -- how many failures have occurred.</li> <li>Status -- <code>active</code>, <code>paused</code>, <code>done</code>, <code>dead</code>.</li> <li>Interval -- seconds between successful runs.</li> </ul>"},{"location":"components/self-awareness/scheduler-tools/#ports","title":"Ports","text":""},{"location":"components/self-awareness/scheduler-tools/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON result from schedule operations"},{"location":"components/self-awareness/scheduler-tools/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/scheduler-tools/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle:</p> <pre><code>flowchart LR\n    Sched[Scheduler Tools] -.-&gt;|tool| Agent\n    SH[System Health] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/scheduler-tools/#tools-provided","title":"Tools Provided","text":"<p>This component registers five tools with the agent:</p>"},{"location":"components/self-awareness/scheduler-tools/#create_schedule","title":"<code>create_schedule</code>","text":"<p>Create a scheduled job that runs a workflow on a recurring interval.</p> <pre><code>create_schedule(\n    name: str,\n    workflow_id: int,\n    interval_seconds: int,\n    description: str = \"\",\n    trigger_node_id: str | None = None,\n    total_repeats: int = 0,\n    max_retries: int = 3,\n    timeout_seconds: int = 600,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>name</code> string (required) Human-readable schedule name <code>workflow_id</code> int (required) ID of the workflow to execute <code>interval_seconds</code> int (required) Seconds between successful runs (must be &gt;= 1) <code>description</code> string <code>\"\"</code> Optional description <code>trigger_node_id</code> string <code>None</code> Specific trigger node to target (uses first trigger if omitted) <code>total_repeats</code> int <code>0</code> Total runs before stopping (0 = infinite) <code>max_retries</code> int <code>3</code> Max retries per run on failure <code>timeout_seconds</code> int <code>600</code> Per-execution timeout in seconds <p>Returns: <code>{\"success\": true, \"schedule_id\": \"...\", \"name\": \"...\", \"status\": \"active\"}</code></p>"},{"location":"components/self-awareness/scheduler-tools/#pause_schedule","title":"<code>pause_schedule</code>","text":"<p>Pause a running scheduled job. It stops rescheduling until resumed.</p> <pre><code>pause_schedule(schedule_id: str) -&gt; str\n</code></pre> Parameter Type Description <code>schedule_id</code> string The schedule UUID <p>Returns: <code>{\"success\": true, \"schedule_id\": \"...\", \"status\": \"paused\"}</code></p>"},{"location":"components/self-awareness/scheduler-tools/#resume_schedule","title":"<code>resume_schedule</code>","text":"<p>Resume a paused scheduled job.</p> <pre><code>resume_schedule(schedule_id: str) -&gt; str\n</code></pre> Parameter Type Description <code>schedule_id</code> string The schedule UUID <p>Returns: <code>{\"success\": true, \"schedule_id\": \"...\", \"status\": \"active\"}</code></p>"},{"location":"components/self-awareness/scheduler-tools/#stop_schedule","title":"<code>stop_schedule</code>","text":"<p>Permanently delete a scheduled job.</p> <pre><code>stop_schedule(schedule_id: str) -&gt; str\n</code></pre> Parameter Type Description <code>schedule_id</code> string The schedule UUID <p>Returns: <code>{\"success\": true, \"schedule_id\": \"...\", \"deleted\": true}</code></p> <p>Permanent Deletion</p> <p><code>stop_schedule</code> permanently deletes the scheduled job from the database. This action cannot be undone. Use <code>pause_schedule</code> if you want to temporarily suspend a job.</p>"},{"location":"components/self-awareness/scheduler-tools/#list_schedules","title":"<code>list_schedules</code>","text":"<p>List scheduled jobs with optional filters.</p> <pre><code>list_schedules(\n    status: str | None = None,\n    workflow_id: int | None = None,\n    limit: int = 10,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>status</code> string <code>None</code> Filter by status: <code>active</code>, <code>paused</code>, <code>stopped</code>, <code>dead</code>, <code>done</code> <code>workflow_id</code> int <code>None</code> Filter by workflow ID <code>limit</code> int <code>10</code> Max results (1-100) <p>Returns: JSON with <code>results</code> list, each containing <code>schedule_id</code>, <code>name</code>, <code>status</code>, <code>workflow_id</code>, <code>interval_seconds</code>, <code>run_count</code>, and <code>error_count</code>.</p>"},{"location":"components/self-awareness/scheduler-tools/#example","title":"Example","text":"<p>An agent setting up hourly monitoring:</p> <pre><code>User: Run the site-monitor workflow every hour.\n\nAgent thinking: I need to find the workflow ID and create a schedule.\n\nTool call: list_schedules(workflow_id=12)\nResult: {\"success\": true, \"results\": []}\n\nTool call: create_schedule(\n    name=\"Hourly Site Monitor\",\n    workflow_id=12,\n    interval_seconds=3600,\n    description=\"Check site health every hour\",\n    max_retries=3\n)\nResult: {\"success\": true, \"schedule_id\": \"sched-abc123\", \"name\": \"Hourly Site Monitor\", \"status\": \"active\"}\n\nAgent: Done! The site-monitor workflow will run every hour.\n       Schedule ID: sched-abc123\n</code></pre> <p>Later, pausing the schedule:</p> <pre><code>User: Pause the monitoring, we're doing maintenance.\n\nTool call: pause_schedule(schedule_id=\"sched-abc123\")\nResult: {\"success\": true, \"schedule_id\": \"sched-abc123\", \"status\": \"paused\"}\n</code></pre> <p>Failure Backoff</p> <p>When a scheduled execution fails, the scheduler uses exponential backoff (capped at 10x the interval) before retrying. After exhausting <code>max_retries</code>, the job transitions to <code>dead</code> status. Use System Health to monitor for dead scheduled jobs.</p> <p>Finite Schedules</p> <p>Set <code>total_repeats</code> to a non-zero value for jobs that should run a fixed number of times. For example, <code>total_repeats=24</code> with <code>interval_seconds=3600</code> runs once per hour for exactly one day, then transitions to <code>done</code> status.</p>"},{"location":"components/self-awareness/spawn-and-await/","title":"Spawn & Await","text":""},{"location":"components/self-awareness/spawn-and-await/#spawn-await","title":"Spawn &amp; Await","text":"<p>The Spawn &amp; Await tool is the key mechanism for multi-agent delegation. It allows an agent to spawn a child workflow, pause its own execution, and resume when the child completes -- all within the agent's reasoning loop.</p> <p>Component type: <code>spawn_and_await</code></p>"},{"location":"components/self-awareness/spawn-and-await/#how-it-works","title":"How It Works","text":"<p>When an agent calls this tool, it triggers LangGraph's <code>interrupt()</code> mechanism to checkpoint the agent mid-tool-call. The orchestrator then:</p> <ol> <li>Spawns a new execution of the specified child workflow.</li> <li>Passes the <code>input_text</code> and <code>input_data</code> as the child's trigger payload.</li> <li>Optionally links the child execution to a task (via <code>task_id</code>).</li> <li>Waits for the child to complete.</li> <li>Resumes the parent agent with the child's output as the tool return value.</li> </ol> <p>This means the parent agent's full reasoning state -- including prior tool calls, messages, and context -- is preserved across the interrupt.</p> <pre><code>sequenceDiagram\n    participant Parent as Parent Agent\n    participant SA as spawn_and_await\n    participant Child as Child Workflow\n\n    Parent-&gt;&gt;SA: spawn_and_await(\"worker-workflow\", \"Process this data\")\n    SA-&gt;&gt;SA: interrupt() \u2014 checkpoint parent\n    SA-&gt;&gt;Child: Spawn child execution\n    Note over Parent: Parent is suspended\n    Child--&gt;&gt;SA: Child completes with result\n    SA--&gt;&gt;Parent: Resume with child output\n    Parent-&gt;&gt;Parent: Continue reasoning with result</code></pre>"},{"location":"components/self-awareness/spawn-and-await/#ports","title":"Ports","text":""},{"location":"components/self-awareness/spawn-and-await/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON result from the child workflow's execution"},{"location":"components/self-awareness/spawn-and-await/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/spawn-and-await/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It is the primary tool for orchestrator agents that delegate work:</p> <pre><code>flowchart LR\n    SA[Spawn &amp; Await] -.-&gt;|tool| Agent\n    Epic[Epic Tools] -.-&gt;|tool| Agent\n    Task[Task Tools] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/spawn-and-await/#tool-signature","title":"Tool Signature","text":"<pre><code>spawn_and_await(\n    workflow_slug: str,\n    input_text: str = \"\",\n    task_id: str | None = None,\n    input_data: dict | None = None,\n) -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>workflow_slug</code> string (required) Slug of the child workflow to spawn <code>input_text</code> string <code>\"\"</code> Text input passed as the child's trigger text <code>task_id</code> string <code>None</code> Optional task ID to link the child execution to <code>input_data</code> dict <code>None</code> Optional dict of additional data for the child trigger payload"},{"location":"components/self-awareness/spawn-and-await/#example","title":"Example","text":"<p>An orchestrator agent delegating a code review task:</p> <pre><code>User: Review the authentication module for security issues.\n\nAgent thinking: I'll delegate this to the security-review workflow.\n\nTool call: spawn_and_await(\n    workflow_slug=\"security-review\",\n    input_text=\"Review the authentication module for security vulnerabilities\",\n    task_id=\"tsk-review01\",\n    input_data={\"module\": \"auth\", \"priority\": \"high\"}\n)\n\n[Parent agent suspends while child executes]\n\nResult: {\"findings\": [\"SQL injection risk in login handler\", ...], \"severity\": \"high\"}\n\nAgent: The security review found the following issues:\n1. SQL injection risk in the login handler...\n</code></pre>"},{"location":"components/self-awareness/spawn-and-await/#task-integration","title":"Task Integration","text":"<p>When <code>task_id</code> is provided, the child execution is linked to the task record. This enables the orchestrator to track which execution handled which task, and allows Task Tools to cancel the execution if the task is cancelled.</p>"},{"location":"components/self-awareness/spawn-and-await/#error-handling","title":"Error Handling","text":"<p>If the child workflow fails, the tool raises a <code>ToolException</code> with the error message. This triggers the agent's error handling rather than having the LLM retry the tool call:</p> <pre><code>{\"_error\": \"Child workflow failed: Connection timeout\"}\n</code></pre> <p>The parent agent can then decide how to proceed -- retry with different parameters, try a different workflow, or report the failure.</p> <p>Checkpointing</p> <p>If the parent agent does not have conversation memory enabled, Pipelit uses a RedisSaver ephemeral checkpointer (instead of SqliteSaver) to persist state only long enough for the child to complete. The thread ID format is <code>exec:{execution_id}:{node_id}</code>.</p> <p>Child Must Complete</p> <p>The parent agent remains suspended until the child workflow finishes (successfully or with an error). Ensure child workflows are designed to complete in a reasonable time. Use the <code>timeout_seconds</code> setting on scheduled jobs if you need to bound execution time.</p>"},{"location":"components/self-awareness/system-health/","title":"System Health","text":""},{"location":"components/self-awareness/system-health/#system-health","title":"System Health","text":"<p>The System Health tool checks the health of the Pipelit platform infrastructure. It inspects Redis connectivity, RQ worker status, queue depths, stuck executions, recent failures, and problematic scheduled jobs -- returning a comprehensive health report with a summary status and actionable issues.</p> <p>Component type: <code>system_health</code></p>"},{"location":"components/self-awareness/system-health/#how-it-works","title":"How It Works","text":"<p>When invoked, the tool runs six health checks in sequence:</p> <ol> <li>Redis -- Pings Redis and reports memory usage and connected clients.</li> <li>RQ Workers -- Lists all active workers, their state, and queues.</li> <li>Queue Depths -- Reports the number of pending jobs in the <code>workflows</code> and <code>default</code> queues.</li> <li>Stuck Executions -- Finds executions that have been <code>running</code> for more than 15 minutes.</li> <li>Failed Executions -- Counts failures in the last 24 hours, grouped by error message.</li> <li>Scheduled Jobs -- Identifies dead or erroring scheduled jobs.</li> </ol> <p>The results are combined into a summary status:</p> Summary Condition <code>healthy</code> All checks pass, no critical issues <code>degraded</code> More than 5 failed executions in 24h, or dead scheduled jobs <code>critical</code> Redis unreachable, no RQ workers, or stuck executions"},{"location":"components/self-awareness/system-health/#ports","title":"Ports","text":""},{"location":"components/self-awareness/system-health/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON health report with <code>timestamp</code>, <code>summary</code>, <code>checks</code>, and <code>issues</code>"},{"location":"components/self-awareness/system-health/#output-format","title":"Output Format","text":"<pre><code>{\n  \"timestamp\": \"2026-02-16T10:30:00+00:00\",\n  \"summary\": \"healthy\",\n  \"checks\": {\n    \"redis\": {\n      \"status\": \"ok\",\n      \"used_memory_human\": \"2.50M\",\n      \"used_memory_peak_human\": \"4.12M\",\n      \"connected_clients\": 5\n    },\n    \"workers\": {\n      \"status\": \"ok\",\n      \"count\": 2,\n      \"workers\": [\n        {\"name\": \"worker-1\", \"state\": \"idle\", \"queues\": [\"workflows\", \"default\"]},\n        {\"name\": \"worker-2\", \"state\": \"busy\", \"queues\": [\"workflows\"]}\n      ]\n    },\n    \"queues\": {\n      \"status\": \"ok\",\n      \"workflows\": 3,\n      \"default\": 0\n    },\n    \"stuck_executions\": {\n      \"status\": \"ok\",\n      \"count\": 0,\n      \"executions\": []\n    },\n    \"failed_executions\": {\n      \"status\": \"ok\",\n      \"total_24h\": 2,\n      \"by_error\": [\n        {\"error\": \"LLM timeout\", \"count\": 2}\n      ]\n    },\n    \"scheduled_jobs\": {\n      \"status\": \"ok\",\n      \"dead_count\": 0,\n      \"erroring_count\": 0,\n      \"jobs\": []\n    }\n  },\n  \"issues\": []\n}\n</code></pre>"},{"location":"components/self-awareness/system-health/#issues-format","title":"Issues Format","text":"<p>When problems are found, the <code>issues</code> array contains actionable items:</p> <pre><code>{\n  \"issues\": [\n    {\n      \"severity\": \"critical\",\n      \"check\": \"workers\",\n      \"detail\": \"No RQ workers running\"\n    },\n    {\n      \"severity\": \"warn\",\n      \"check\": \"failed_executions\",\n      \"detail\": \"12 failed execution(s) in the last 24 hours\"\n    }\n  ]\n}\n</code></pre> <p>Issue severity levels:</p> Severity Meaning <code>critical</code> System cannot function properly -- immediate action required <code>warn</code> Degraded performance or accumulating problems -- should be investigated"},{"location":"components/self-awareness/system-health/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/system-health/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It is useful for operational monitoring and self-healing agents:</p> <pre><code>flowchart LR\n    SH[System Health] -.-&gt;|tool| Agent\n    Sched[Scheduler Tools] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Schedule Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/system-health/#tool-signature","title":"Tool Signature","text":"<pre><code>check_system_health() -&gt; str\n</code></pre> <p>This tool takes no parameters.</p>"},{"location":"components/self-awareness/system-health/#example","title":"Example","text":"<p>A monitoring agent that runs on a schedule and reports issues:</p> <pre><code>Agent: Let me check the system health.\n\nTool call: check_system_health()\n\nResult: {\n    \"summary\": \"degraded\",\n    \"checks\": { ... },\n    \"issues\": [\n        {\n            \"severity\": \"warn\",\n            \"check\": \"scheduled_jobs\",\n            \"detail\": \"2 dead scheduled job(s)\"\n        },\n        {\n            \"severity\": \"warn\",\n            \"check\": \"failed_executions\",\n            \"detail\": \"8 failed execution(s) in the last 24 hours\"\n        }\n    ]\n}\n\nAgent: System status is DEGRADED. Two issues found:\n1. 2 dead scheduled jobs need attention -- they have exceeded retry limits.\n2. 8 failed executions in the last 24 hours, indicating a recurring problem.\n\nRecommended actions:\n- Review the dead scheduled jobs and either restart or delete them.\n- Check the error messages on failed executions to identify the root cause.\n</code></pre>"},{"location":"components/self-awareness/system-health/#self-healing-pattern","title":"Self-Healing Pattern","text":"<p>Combine System Health with Scheduler Tools and Platform API for a self-healing agent:</p> <pre><code>flowchart TD\n    Schedule[Schedule Trigger&lt;br/&gt;Every 5 minutes] --&gt; Agent\n    SH[System Health] -.-&gt;|tool| Agent\n    Sched[Scheduler Tools] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent</code></pre> <p>The agent:</p> <ol> <li>Runs <code>check_system_health()</code> on a schedule.</li> <li>If it finds dead scheduled jobs, uses <code>scheduler_tools</code> to restart or delete them.</li> <li>If it finds stuck executions, uses <code>platform_api</code> to cancel them.</li> <li>Reports its actions via a delivery channel (Telegram, webhook, etc.).</li> </ol> <p>Check Thresholds</p> <ul> <li>Stuck executions: Running longer than 15 minutes.</li> <li>Failed executions warning: More than 5 failures in 24 hours.</li> <li>Scheduled jobs: Any job with <code>dead</code> status or non-zero <code>error_count</code>.</li> </ul> <p>Combine with Scheduling</p> <p>For continuous monitoring, create a scheduled job that runs the health-check workflow every few minutes using Scheduler Tools. The agent can then escalate issues by sending alerts via Telegram or webhook delivery.</p>"},{"location":"components/self-awareness/task-tools/","title":"Task Tools","text":""},{"location":"components/self-awareness/task-tools/#task-tools","title":"Task Tools","text":"<p>The Task Tools component provides LangChain tools for creating, listing, updating, and cancelling tasks within epics. Tasks are the individual units of work that agents execute, each trackable with status, dependencies, and budget.</p> <p>Component type: <code>task_tools</code></p>"},{"location":"components/self-awareness/task-tools/#how-it-works","title":"How It Works","text":"<p>This component registers four tools with the parent agent. Tasks belong to epics and support dependency chains -- a task can depend on other tasks within the same epic, and will be automatically set to <code>blocked</code> status until its dependencies complete. When a task is marked <code>completed</code>, any downstream tasks that depended on it are automatically unblocked.</p>"},{"location":"components/self-awareness/task-tools/#ports","title":"Ports","text":""},{"location":"components/self-awareness/task-tools/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON result from task operations"},{"location":"components/self-awareness/task-tools/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/task-tools/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It is typically paired with Epic Tools and Spawn &amp; Await:</p> <pre><code>flowchart LR\n    Epic[Epic Tools] -.-&gt;|tool| Agent\n    Task[Task Tools] -.-&gt;|tool| Agent\n    SA[Spawn &amp; Await] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/task-tools/#tools-provided","title":"Tools Provided","text":"<p>This component registers four tools with the agent:</p>"},{"location":"components/self-awareness/task-tools/#create_task","title":"<code>create_task</code>","text":"<p>Create a new task within an epic.</p> <pre><code>create_task(\n    epic_id: str,\n    title: str,\n    description: str = \"\",\n    tags: str = \"\",\n    depends_on: str = \"\",\n    priority: int = 2,\n    estimated_tokens: int | None = None,\n    max_retries: int = 2,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>epic_id</code> string (required) Parent epic ID <code>title</code> string (required) Task title <code>description</code> string <code>\"\"</code> Detailed description <code>tags</code> string <code>\"\"</code> Comma-separated tags <code>depends_on</code> string <code>\"\"</code> Comma-separated task IDs this task depends on <code>priority</code> int <code>2</code> Priority 1-5 (1 = highest) <code>estimated_tokens</code> int <code>None</code> Estimated token cost <code>max_retries</code> int <code>2</code> Max retry attempts on failure <p>Returns: <code>{\"success\": true, \"task_id\": \"tsk-abc123\", \"status\": \"pending\"}</code></p> <p>Automatic Blocking</p> <p>If <code>depends_on</code> is specified and not all dependencies are completed, the task is created with status <code>blocked</code> instead of <code>pending</code>. It will be automatically unblocked when all dependencies complete.</p>"},{"location":"components/self-awareness/task-tools/#list_tasks","title":"<code>list_tasks</code>","text":"<p>List tasks within an epic, optionally filtered by status or tags.</p> <pre><code>list_tasks(\n    epic_id: str,\n    status: str | None = None,\n    tags: str | None = None,\n    limit: int = 20,\n) -&gt; str\n</code></pre> Parameter Type Default Description <code>epic_id</code> string (required) The epic ID <code>status</code> string <code>None</code> Filter: <code>pending</code>, <code>blocked</code>, <code>running</code>, <code>completed</code>, <code>failed</code>, <code>cancelled</code> <code>tags</code> string <code>None</code> Comma-separated tags to filter by <code>limit</code> int <code>20</code> Max results (1-100) <p>Returns: JSON with <code>tasks</code> list (each with <code>id</code>, <code>title</code>, <code>status</code>, <code>priority</code>, <code>depends_on</code>, <code>execution_id</code>) and <code>total</code> count.</p>"},{"location":"components/self-awareness/task-tools/#update_task","title":"<code>update_task</code>","text":"<p>Update a task's fields. Only provided fields are changed.</p> <pre><code>update_task(\n    task_id: str,\n    status: str | None = None,\n    title: str | None = None,\n    description: str | None = None,\n    priority: int | None = None,\n    result_summary: str | None = None,\n    error_message: str | None = None,\n    notes: str | None = None,\n) -&gt; str\n</code></pre> Parameter Type Description <code>task_id</code> string The task ID <code>status</code> string New status: <code>pending</code>, <code>blocked</code>, <code>running</code>, <code>completed</code>, <code>failed</code>, <code>cancelled</code> <code>title</code> string New title <code>description</code> string New description <code>priority</code> int New priority 1-5 <code>result_summary</code> string Summary of results when completing <code>error_message</code> string Error message if failed <code>notes</code> string A note to append to the task's notes list <p>Returns: <code>{\"success\": true, \"task_id\": \"tsk-abc123\", \"status\": \"completed\"}</code></p> <p>Dependency Resolution</p> <p>When a task is marked <code>completed</code>, the tool automatically checks for downstream tasks that depend on it and unblocks them if all their dependencies are now satisfied.</p>"},{"location":"components/self-awareness/task-tools/#cancel_task","title":"<code>cancel_task</code>","text":"<p>Cancel a task and optionally its linked execution.</p> <pre><code>cancel_task(task_id: str, reason: str = \"\") -&gt; str\n</code></pre> Parameter Type Default Description <code>task_id</code> string (required) The task ID to cancel <code>reason</code> string <code>\"\"</code> Optional cancellation reason (appended to notes) <p>Returns: <code>{\"success\": true, \"task_id\": \"tsk-abc123\", \"execution_cancelled\": true}</code></p> <p>If the task has a linked workflow execution that is still <code>pending</code> or <code>running</code>, it is cancelled as well.</p>"},{"location":"components/self-awareness/task-tools/#example","title":"Example","text":"<p>An orchestrator agent managing a multi-step project:</p> <pre><code>Tool call: create_task(\n    epic_id=\"ep-w3ath3r\",\n    title=\"Create weather API integration workflow\",\n    description=\"Build a workflow that calls the OpenWeatherMap API\",\n    tags=\"api,integration\",\n    priority=1\n)\nResult: {\"success\": true, \"task_id\": \"tsk-api001\", \"status\": \"pending\"}\n\nTool call: create_task(\n    epic_id=\"ep-w3ath3r\",\n    title=\"Create data storage workflow\",\n    description=\"Build a workflow that stores weather data\",\n    depends_on=\"tsk-api001\",\n    priority=2\n)\nResult: {\"success\": true, \"task_id\": \"tsk-store01\", \"status\": \"blocked\"}\n</code></pre> <p>The second task is automatically <code>blocked</code> because it depends on the first. When the agent marks <code>tsk-api001</code> as <code>completed</code>, <code>tsk-store01</code> is automatically unblocked and moves to <code>pending</code>.</p> <p>WebSocket Events</p> <p>Task creation and updates broadcast WebSocket events (<code>task_created</code>, <code>task_updated</code>) on the <code>epic:{epic_id}</code> channel. The epic's progress counters (<code>total_tasks</code>, <code>completed_tasks</code>, <code>failed_tasks</code>) are automatically synced after each task mutation.</p>"},{"location":"components/self-awareness/whoami/","title":"WhoAmI","text":""},{"location":"components/self-awareness/whoami/#whoami","title":"WhoAmI","text":"<p>The WhoAmI tool gives an agent self-awareness about its own identity within the platform. It returns the agent's workflow slug, node ID, current system prompt, extra configuration, and step-by-step instructions for self-modification.</p> <p>Component type: <code>whoami</code></p>"},{"location":"components/self-awareness/whoami/#how-it-works","title":"How It Works","text":"<p>When invoked, the tool follows the <code>tool</code> edge from itself back to the parent agent node, then queries the database for the agent's current configuration and the workflow it belongs to. The response includes everything the agent needs to modify itself via the Platform API.</p>"},{"location":"components/self-awareness/whoami/#ports","title":"Ports","text":""},{"location":"components/self-awareness/whoami/#outputs","title":"Outputs","text":"Port Type Description <code>identity</code> <code>STRING</code> JSON object with <code>identity</code>, <code>current_config</code>, and <code>self_modification</code> sections"},{"location":"components/self-awareness/whoami/#output-format","title":"Output Format","text":"<pre><code>{\n  \"identity\": {\n    \"workflow_slug\": \"my-workflow\",\n    \"workflow_id\": 42,\n    \"node_id\": \"agent_abc123\",\n    \"component_type\": \"agent\"\n  },\n  \"current_config\": {\n    \"system_prompt\": \"You are a helpful assistant...\",\n    \"system_prompt_length\": 45,\n    \"extra_config\": {\n      \"conversation_memory\": true\n    }\n  },\n  \"self_modification\": {\n    \"endpoint\": \"/api/v1/workflows/my-workflow/nodes/agent_abc123/\",\n    \"method\": \"PATCH\",\n    \"example_body\": {\n      \"config\": {\n        \"system_prompt\": \"Your new system prompt here\",\n        \"extra_config\": { \"conversation_memory\": true }\n      }\n    },\n    \"instructions\": [\n      \"1. Use create_agent_user to get API credentials if you don't have them\",\n      \"2. Use platform_api with method='PATCH' to update your configuration\",\n      \"3. Changes take effect on the next execution/conversation\"\n    ]\n  }\n}\n</code></pre>"},{"location":"components/self-awareness/whoami/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings. It automatically resolves its parent agent from the tool edge connection.</p>"},{"location":"components/self-awareness/whoami/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It is most useful alongside <code>create_agent_user</code> and <code>platform_api</code>:</p> <pre><code>flowchart LR\n    WhoAmI[WhoAmI] -.-&gt;|tool| Agent\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/whoami/#tool-signature","title":"Tool Signature","text":"<pre><code>whoami() -&gt; str\n</code></pre> <p>This tool takes no parameters. It automatically discovers the parent agent node through the edge graph.</p>"},{"location":"components/self-awareness/whoami/#example","title":"Example","text":"<p>A self-improving agent's system prompt might include:</p> <pre><code>You are a self-improving assistant. When asked to change your behavior:\n1. Call whoami() to learn your current configuration.\n2. Call create_agent_user() to get API credentials.\n3. Use platform_api() to PATCH your system prompt at the endpoint from whoami.\n4. Confirm to the user that the change will take effect on the next conversation.\n</code></pre> <p>When a user says \"Be more concise in your responses,\" the agent:</p> <ol> <li>Calls <code>whoami()</code> to get its current system prompt and the PATCH endpoint.</li> <li>Calls <code>create_agent_user()</code> to get an API key.</li> <li>Calls <code>platform_api(method=\"PATCH\", path=\"/api/v1/workflows/my-workflow/nodes/agent_abc123/\", body='{\"config\": {\"system_prompt\": \"You are a concise assistant...\"}}', api_key=\"...\")</code>.</li> </ol> <p>System Prompt Truncation</p> <p>If the current system prompt exceeds 1,000 characters, it is truncated in the <code>whoami</code> response with a <code>\"...\"</code> suffix. The full length is always available in the <code>system_prompt_length</code> field.</p> <p>Connection Required</p> <p>The WhoAmI tool must be connected to an agent node via a <code>tool</code> edge. If the tool is not connected, it returns an error with a hint to connect it.</p>"},{"location":"components/self-awareness/workflow-create/","title":"Workflow Create","text":""},{"location":"components/self-awareness/workflow-create/#workflow-create","title":"Workflow Create","text":"<p>The Workflow Create tool allows agents to create entire workflows programmatically from a YAML DSL specification. This is a core capability for self-improving agents -- they can design and deploy new workflows without human intervention.</p> <p>Component type: <code>workflow_create</code></p>"},{"location":"components/self-awareness/workflow-create/#how-it-works","title":"How It Works","text":"<p>The tool accepts a YAML string defining a workflow and compiles it into persisted database objects (workflow, nodes, edges, configurations) in a single transaction. It supports two modes:</p> <ul> <li>Create mode -- define <code>name</code>, <code>trigger</code>, and <code>steps</code> for a new workflow from scratch.</li> <li>Fork mode -- specify <code>based_on: &lt;slug&gt;</code> to clone an existing workflow and apply <code>patches</code> (add/remove steps, update prompts, add/remove tools, update config).</li> </ul>"},{"location":"components/self-awareness/workflow-create/#model-resolution","title":"Model Resolution","text":"<p>The DSL compiler supports several strategies for resolving which LLM model to use for agent steps:</p> Strategy DSL Syntax Description <code>inherit</code> <code>model: inherit</code> Copy the model from the parent agent that owns this tool <code>capability</code> <code>model: \"gpt-4\"</code> Find the first LLM credential matching a substring <code>credential_id</code> <code>model: { credential_id: 5 }</code> Direct credential ID pass-through <code>discover</code> <code>model: discover</code> Auto-discover the best model from available credentials"},{"location":"components/self-awareness/workflow-create/#ports","title":"Ports","text":""},{"location":"components/self-awareness/workflow-create/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON with <code>workflow_id</code>, <code>slug</code>, <code>node_count</code>, <code>edge_count</code>, or <code>error</code>"},{"location":"components/self-awareness/workflow-create/#output-format","title":"Output Format","text":"<pre><code>{\n  \"success\": true,\n  \"workflow_id\": 15,\n  \"slug\": \"weather-pipeline\",\n  \"node_count\": 4,\n  \"edge_count\": 3\n}\n</code></pre>"},{"location":"components/self-awareness/workflow-create/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings. Model resolution is handled through the DSL syntax.</p>"},{"location":"components/self-awareness/workflow-create/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle:</p> <pre><code>flowchart LR\n    WC[Workflow Create] -.-&gt;|tool| Agent\n    WD[Workflow Discover] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/workflow-create/#tool-signature","title":"Tool Signature","text":"<pre><code>workflow_create(dsl: str, tags: str = \"\") -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>dsl</code> string (required) YAML string defining the workflow <code>tags</code> string <code>\"\"</code> Optional comma-separated tags to add to the created workflow"},{"location":"components/self-awareness/workflow-create/#example","title":"Example","text":""},{"location":"components/self-awareness/workflow-create/#create-mode","title":"Create Mode","text":"<p>An agent creating a simple chat workflow:</p> <pre><code>name: \"Customer Support Bot\"\ntrigger: chat\nsteps:\n  - name: support_agent\n    type: agent\n    prompt: |\n      You are a customer support agent. Be helpful and professional.\n      Answer questions about our products and services.\n    model: inherit\n    tools:\n      - web_search\n      - http\n</code></pre> <p>The agent invokes:</p> <pre><code>Tool call: workflow_create(\n    dsl=\"name: 'Customer Support Bot'\\ntrigger: chat\\nsteps:\\n  - name: support_agent\\n    type: agent\\n    prompt: 'You are a customer support agent...'\\n    model: inherit\\n    tools:\\n      - web_search\",\n    tags=\"support,customer\"\n)\nResult: {\"success\": true, \"workflow_id\": 15, \"slug\": \"customer-support-bot\", \"node_count\": 4, \"edge_count\": 3}\n</code></pre>"},{"location":"components/self-awareness/workflow-create/#fork-mode","title":"Fork Mode","text":"<p>Cloning and modifying an existing workflow:</p> <pre><code>based_on: \"customer-support-bot\"\npatches:\n  - type: update_prompt\n    step: support_agent\n    prompt: |\n      You are a technical support agent specializing in API issues.\n  - type: add_tool\n    step: support_agent\n    tool: run_command\n</code></pre>"},{"location":"components/self-awareness/workflow-create/#dsl-step-types","title":"DSL Step Types","text":"DSL Type Component Type Description <code>agent</code> <code>agent</code> LLM agent with tools <code>code</code> <code>code</code> Python/Jinja2 code execution <code>http</code> <code>http_request</code> HTTP request <code>switch</code> <code>switch</code> Conditional routing <code>loop</code> <code>loop</code> Array iteration <code>workflow</code> <code>workflow</code> Subworkflow invocation <code>human</code> <code>human_confirmation</code> Human confirmation gate <code>transform</code> <code>code</code> Data transformation (alias for code)"},{"location":"components/self-awareness/workflow-create/#dsl-trigger-types","title":"DSL Trigger Types","text":"DSL Trigger Component Type <code>chat</code> <code>trigger_chat</code> <code>telegram</code> <code>trigger_telegram</code> <code>manual</code> <code>trigger_manual</code> <code>none</code> <code>trigger_workflow</code> <p>Discover Before Creating</p> <p>Use Workflow Discover first to check if a similar workflow already exists. If a close match is found (score &gt;= 0.50), fork mode is more efficient than creating from scratch.</p> <p>Model Inheritance</p> <p>When using <code>model: inherit</code>, the created workflow's agent steps automatically inherit the LLM model and credential from the parent agent that owns the <code>workflow_create</code> tool. This is the simplest approach and avoids hardcoding credential IDs.</p>"},{"location":"components/self-awareness/workflow-discover/","title":"Workflow Discover","text":""},{"location":"components/self-awareness/workflow-discover/#workflow-discover","title":"Workflow Discover","text":"<p>The Workflow Discover tool searches existing workflows by requirements and returns scored matches with gap analysis and reuse recommendations. This helps agents avoid creating duplicate workflows and instead reuse or fork existing ones.</p> <p>Component type: <code>workflow_discover</code></p>"},{"location":"components/self-awareness/workflow-discover/#how-it-works","title":"How It Works","text":"<p>The tool queries all active, non-deleted workflows on the platform (excluding the caller's own workflow), scores each one against the provided requirements, and returns the top matches sorted by score. The scoring considers trigger types, node types, tools, tags, and description similarity.</p> <p>Each match includes a recommendation based on its score:</p> Score Recommendation Meaning &gt;= 0.95 <code>reuse</code> The workflow already meets your requirements -- use it as-is &gt;= 0.50 <code>fork_and_patch</code> Close enough to fork and modify via Workflow Create fork mode &lt; 0.50 <code>create_new</code> No good match -- create a new workflow from scratch <p>Each match also includes a gap analysis listing what the existing workflow is missing compared to your requirements (missing triggers, node types, or tools).</p>"},{"location":"components/self-awareness/workflow-discover/#ports","title":"Ports","text":""},{"location":"components/self-awareness/workflow-discover/#outputs","title":"Outputs","text":"Port Type Description <code>result</code> <code>STRING</code> JSON with <code>matches</code> (scored results), and <code>total_searched</code>"},{"location":"components/self-awareness/workflow-discover/#output-format","title":"Output Format","text":"<pre><code>{\n  \"success\": true,\n  \"matches\": [\n    {\n      \"workflow_id\": 12,\n      \"slug\": \"data-pipeline\",\n      \"name\": \"Data Pipeline\",\n      \"description\": \"Fetches and processes data hourly\",\n      \"score\": 0.82,\n      \"recommendation\": \"fork_and_patch\",\n      \"capabilities\": {\n        \"triggers\": [\"trigger_schedule\"],\n        \"node_types\": [\"agent\", \"code\"],\n        \"tools\": [\"http_request\", \"run_command\"]\n      },\n      \"gaps\": {\n        \"triggers\": [],\n        \"node_types\": [\"switch\"],\n        \"tools\": [\"web_search\"]\n      },\n      \"success_rate\": 0.95,\n      \"execution_count\": 47\n    }\n  ],\n  \"total_searched\": 15\n}\n</code></pre>"},{"location":"components/self-awareness/workflow-discover/#configuration","title":"Configuration","text":"<p>This tool has no configurable settings.</p>"},{"location":"components/self-awareness/workflow-discover/#usage","title":"Usage","text":"<p>Connect this tool to an agent via the green diamond tool handle. It pairs naturally with Workflow Create:</p> <pre><code>flowchart LR\n    WD[Workflow Discover] -.-&gt;|tool| Agent\n    WC[Workflow Create] -.-&gt;|tool| Agent\n    Model[AI Model] -.-&gt;|llm| Agent\n    Trigger[Chat Trigger] --&gt; Agent</code></pre>"},{"location":"components/self-awareness/workflow-discover/#tool-signature","title":"Tool Signature","text":"<pre><code>workflow_discover(requirements: str, limit: int = 5) -&gt; str\n</code></pre> <p>Parameters:</p> Parameter Type Default Description <code>requirements</code> string (required) JSON string with search criteria <code>limit</code> int <code>5</code> Maximum number of results"},{"location":"components/self-awareness/workflow-discover/#requirements-format","title":"Requirements Format","text":"<p>The <code>requirements</code> parameter is a JSON string with optional keys:</p> <pre><code>{\n  \"triggers\": [\"trigger_chat\", \"trigger_telegram\"],\n  \"node_types\": [\"agent\", \"code\", \"switch\"],\n  \"tools\": [\"web_search\", \"run_command\"],\n  \"tags\": [\"support\", \"automation\"],\n  \"description\": \"A workflow that handles customer support queries\",\n  \"model_capability\": \"gpt-4\"\n}\n</code></pre> Key Type Description <code>triggers</code> array Required trigger types <code>node_types</code> array Required node component types <code>tools</code> array Required tool component types <code>tags</code> array Tags to match against <code>description</code> string Natural language description for similarity matching <code>model_capability</code> string Required model capability substring <p>All keys are optional. Omitted keys are not factored into the score.</p>"},{"location":"components/self-awareness/workflow-discover/#example","title":"Example","text":"<p>An agent tasked with building a new workflow first checks for existing ones:</p> <pre><code>User: Build me a workflow that monitors a website and sends Telegram alerts.\n\nAgent thinking: Let me check if something similar already exists.\n\nTool call: workflow_discover(\n    requirements='{\"triggers\": [\"trigger_schedule\"], \"node_types\": [\"agent\"], \"tools\": [\"http_request\"], \"tags\": [\"monitoring\"], \"description\": \"Monitor a website and send alerts via Telegram\"}'\n)\n\nResult: {\n    \"success\": true,\n    \"matches\": [\n        {\n            \"slug\": \"site-monitor\",\n            \"score\": 0.72,\n            \"recommendation\": \"fork_and_patch\",\n            \"gaps\": {\"tools\": [], \"node_types\": [], \"triggers\": []}\n        }\n    ],\n    \"total_searched\": 8\n}\n\nAgent: I found an existing workflow \"site-monitor\" with a 72% match.\n       I'll fork it and add Telegram delivery.\n</code></pre> <p>The agent then uses <code>workflow_create</code> with <code>based_on: \"site-monitor\"</code> and patches to add Telegram notification.</p> <p>Discover-Then-Create Pattern</p> <p>The recommended pattern is: discover first, then either reuse (score &gt;= 0.95), fork and patch (score &gt;= 0.50), or create new (score &lt; 0.50). This prevents workflow sprawl and promotes reuse of tested, proven workflows.</p> <p>Scoring Includes Execution History</p> <p>The scoring algorithm considers each workflow's historical success rate and execution count. Workflows with a high success rate and many successful executions score higher, as they are more likely to work reliably.</p>"},{"location":"components/sub-components/","title":"Sub-Components","text":""},{"location":"components/sub-components/#sub-components","title":"Sub-Components","text":"<p>Sub-components are configuration and utility nodes that attach to AI nodes via special diamond-shaped handles. They do not appear as standalone steps in the execution flow -- instead, they provide capabilities that AI nodes consume at build time or during their reasoning loop.</p>"},{"location":"components/sub-components/#overview","title":"Overview","text":"<p>There are three sub-component types:</p> Component Purpose Connects Via AI Model Provides LLM credential and model selection Blue diamond handle (<code>llm</code>) Output Parser Parses raw LLM output into structured data Slate diamond handle (<code>output_parser</code>) Code Execute Executes Python or Bash in a sandboxed subprocess Green diamond handle (<code>tool</code>)"},{"location":"components/sub-components/#how-sub-components-work","title":"How sub-components work","text":"<p>Sub-components connect to AI nodes via the colored diamond handles at the bottom of the node. The connection type determines how the sub-component integrates:</p> Handle Color Edge Label Description model Blue (<code>#3b82f6</code>) <code>llm</code> AI Model provides the LLM configuration output_parser Slate (<code>#94a3b8</code>) <code>output_parser</code> Output Parser processes raw LLM text tools Green (<code>#10b981</code>) <code>tool</code> Code Execute provides a tool function"},{"location":"components/sub-components/#ai-model","title":"AI Model","text":"<p>The AI Model node is unique among sub-components:</p> <ul> <li>It has only a top diamond handle (source) -- it connects upward to nodes that need a model</li> <li>It is non-executable -- it does not run during execution</li> <li>It is required for all AI nodes (agent, categorizer, router, extractor)</li> </ul> <p>Without an AI Model connected, an AI node cannot resolve which LLM to use and will fail at build time.</p>"},{"location":"components/sub-components/#output-parser","title":"Output Parser","text":"<p>The Output Parser takes the raw text output from an AI node and transforms it into structured data (JSON, regex matches, or lists). It is:</p> <ul> <li>Non-executable -- it runs as part of the AI node's post-processing, not as a separate execution step</li> <li>Used by categorizer, router, and extractor nodes (not agents)</li> </ul>"},{"location":"components/sub-components/#code-execute","title":"Code Execute","text":"<p>The Code Execute node provides a sandboxed code execution tool to agents. Unlike the other two sub-components, it is:</p> <ul> <li>Executable -- it runs when the agent's LLM invokes it during the reasoning loop</li> <li>Connected via the tools handle (green diamond), same as other tool nodes</li> <li>A LangChain <code>@tool</code> that accepts code and language parameters</li> </ul>"},{"location":"components/sub-components/#canvas-appearance","title":"Canvas appearance","text":"<p>Sub-components are visually smaller than regular nodes. AI Model nodes sit below AI nodes and connect upward. Output Parser and Code Execute nodes connect to the bottom handles of their parent AI node.</p> <pre><code>flowchart TB\n    A[Agent Node]\n    M[AI Model] -.-&gt;|model| A\n    OP[Output Parser] -.-&gt;|output_parser| A\n    CE[Code Execute] -.-&gt;|tool| A</code></pre> <p>Non-executable nodes</p> <p>AI Model and Output Parser are marked as non-executable in the node type registry. They do not show running/success/failed status badges during execution. Code Execute, as a tool, does show execution status when invoked by an agent.</p>"},{"location":"components/sub-components/ai-model/","title":"AI Model","text":""},{"location":"components/sub-components/ai-model/#ai-model","title":"AI Model","text":"<p>The AI Model sub-component provides LLM configuration to AI nodes. It holds the credential (API key) and model name that determine which language model an agent, categorizer, router, or extractor uses.</p> Property Value Component Type <code>ai_model</code> Category Sub-component Display Name AI Model Executable No (configuration only)"},{"location":"components/sub-components/ai-model/#ports","title":"Ports","text":""},{"location":"components/sub-components/ai-model/#inputs","title":"Inputs","text":"<p>This component has no inputs. It is a source-only node.</p>"},{"location":"components/sub-components/ai-model/#outputs","title":"Outputs","text":"Port Data Type Description <code>model</code> OBJECT LLM configuration object (credential + model name)"},{"location":"components/sub-components/ai-model/#configuration","title":"Configuration","text":"<p>The AI Model node stores its configuration on the <code>ComponentConfig</code> record:</p> Field Description <code>llm_credential</code> ID of the LLM provider credential (from the Credentials page) <code>llm_model</code> Model name string (e.g., <code>gpt-4</code>, <code>claude-3-opus</code>, <code>llama-3.1-70b</code>) <p>Both fields are required. An AI Model node without both values set will cause a build error when any connected AI node attempts to resolve its LLM.</p>"},{"location":"components/sub-components/ai-model/#usage","title":"Usage","text":"<ol> <li>Add an AI Model node from the Node Palette (Sub-components category)</li> <li>Select an LLM credential from the dropdown in the node details panel</li> <li>Select a model name from the available models (populated from the credential's provider)</li> <li>Connect the AI Model to an AI node via the blue diamond model handle</li> </ol>"},{"location":"components/sub-components/ai-model/#canvas-layout","title":"Canvas layout","text":"<p>The AI Model node has a unique handle configuration:</p> <ul> <li>Top diamond handle (source) -- connects upward to AI nodes</li> <li>No bottom handles, no left/right circle handles</li> </ul> <p>This means the AI Model always sits below or beside the AI node it serves, with the connection going upward.</p>"},{"location":"components/sub-components/ai-model/#one-model-per-ai-node","title":"One model per AI node","text":"<p>Each AI node requires exactly one AI Model connection. If multiple AI Model nodes are connected, the behavior depends on which edge the builder encounters first. Best practice is to connect exactly one AI Model per AI node.</p>"},{"location":"components/sub-components/ai-model/#sharing-models","title":"Sharing models","text":"<p>A single AI Model node can be connected to multiple AI nodes on the same canvas. This is useful when you want several agents to use the same LLM:</p> <pre><code>flowchart TB\n    A1[Agent A]\n    A2[Agent B]\n    A3[Categorizer]\n    M[AI Model&lt;br/&gt;gpt-4] -.-&gt;|model| A1\n    M -.-&gt;|model| A2\n    M -.-&gt;|model| A3</code></pre>"},{"location":"components/sub-components/ai-model/#llm-resolution","title":"LLM resolution","text":"<p>At build time, the <code>resolve_llm_for_node()</code> function in <code>services/llm.py</code> follows this path:</p> <ol> <li>Find the AI Model node connected via an <code>edge_label=\"llm\"</code> edge</li> <li>Read the <code>llm_credential</code> and <code>llm_model</code> from its <code>ComponentConfig</code></li> <li>Load the credential from the database and decrypt the API key</li> <li>Instantiate the appropriate LangChain LLM class (ChatOpenAI, ChatAnthropic, etc.)</li> </ol>"},{"location":"components/sub-components/ai-model/#example","title":"Example","text":"<p>A basic chat workflow with an agent and its model:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model&lt;br/&gt;claude-3-opus] -.-&gt;|model| A</code></pre> <p>The AI Model is configured with:</p> <ul> <li>Credential: <code>anthropic-prod</code> (an Anthropic API key from the Credentials page)</li> <li>Model: <code>claude-3-opus-20240229</code></li> </ul> <p>The Agent automatically uses this model for all LLM calls during execution.</p> <p>Missing model connection</p> <p>If an AI node does not have an AI Model connected, the workflow will fail at build time with an error indicating that the LLM could not be resolved. Always verify the blue model connection is present before executing.</p> <p>Available models</p> <p>The model name dropdown in the node details panel is populated by calling the credential's provider API (e.g., OpenAI's models endpoint). The available models depend on the provider and your API key's access level.</p>"},{"location":"components/sub-components/code-execute/","title":"Code Execute","text":""},{"location":"components/sub-components/code-execute/#code-execute","title":"Code Execute","text":"<p>The Code Execute sub-component provides a sandboxed code execution tool to agents. When connected to an agent, the agent's LLM can write and run Python or Bash code in an isolated subprocess with security restrictions and timeout enforcement.</p> Property Value Component Type <code>code_execute</code> Category Sub-component Display Name Code Execute Executable Yes (runs when invoked by an agent)"},{"location":"components/sub-components/code-execute/#ports","title":"Ports","text":""},{"location":"components/sub-components/code-execute/#inputs","title":"Inputs","text":"<p>This component has no wired inputs. It operates as a LangChain tool that the agent invokes with arguments during its reasoning loop.</p>"},{"location":"components/sub-components/code-execute/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Execution output (stdout, stderr, exit code, and parsed result)"},{"location":"components/sub-components/code-execute/#configuration","title":"Configuration","text":"<p>The Code Execute component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Range Description <code>language</code> string <code>python</code> <code>python</code>, <code>bash</code> Default programming language <code>timeout_seconds</code> integer <code>30</code> 1--300 Maximum execution time in seconds <code>sandbox</code> boolean <code>true</code> -- Enable security restrictions"},{"location":"components/sub-components/code-execute/#usage","title":"Usage","text":"<ol> <li>Add a Code Execute node from the Node Palette (Sub-components category)</li> <li>Connect it to an agent node via the green diamond tools handle</li> <li>Optionally configure the default language, timeout, and sandbox settings in Extra Config</li> </ol> <p>The agent's LLM will then have a <code>code_execute</code> tool available. The tool accepts two parameters:</p> Parameter Required Description <code>code</code> Yes Code to execute <code>language</code> No Override the configured default language (<code>python</code> or <code>bash</code>)"},{"location":"components/sub-components/code-execute/#execution-environment","title":"Execution environment","text":"<p>Code runs in a subprocess (not in the Pipelit process):</p> <ul> <li>Python -- written to a temp file in <code>/tmp</code> and executed with <code>python3</code></li> <li>Bash -- written to a temp file in <code>/tmp</code> with <code>#!/bin/bash</code> and <code>set -e</code>, then executed with <code>/bin/bash</code></li> </ul> <p>Both languages run with a working directory of <code>/tmp</code>.</p>"},{"location":"components/sub-components/code-execute/#sandbox-mode","title":"Sandbox mode","text":"<p>When <code>sandbox</code> is enabled (the default), two protections are applied:</p> <ol> <li>Security pattern checking -- code is scanned for forbidden patterns before execution</li> <li>Environment restriction -- the subprocess runs with a restricted <code>PATH</code> (<code>/usr/bin:/bin:/usr/local/bin</code>) and without <code>HOME</code> or <code>USER</code> environment variables</li> </ol>"},{"location":"components/sub-components/code-execute/#forbidden-patterns","title":"Forbidden patterns","text":"<p>The security scanner blocks code containing these patterns:</p> <p>Python:</p> <ul> <li><code>import os</code>, <code>from os import</code>, <code>import subprocess</code>, <code>from subprocess import</code></li> <li><code>import shutil</code>, <code>from shutil import</code></li> <li><code>__import__()</code>, <code>eval()</code>, <code>exec()</code>, <code>compile()</code></li> <li><code>open()</code> targeting <code>/etc</code>, <code>/proc</code>, <code>/sys</code>, <code>/dev</code></li> </ul> <p>Bash:</p> <ul> <li><code>rm -rf /</code>, <code>rm -rf ~</code>, <code>rm -rf $HOME</code></li> <li><code>dd if=... of=/dev/...</code>, <code>mkfs.</code></li> <li>Writes to <code>/etc/</code> or <code>/dev/</code></li> <li>Piped remote execution (<code>curl ... | sh</code>, <code>wget ... | sh</code>)</li> <li><code>chmod 777</code>, <code>chmod -R 777</code></li> </ul>"},{"location":"components/sub-components/code-execute/#return-format","title":"Return format","text":"<p>The tool returns a multi-line string with:</p> <pre><code>stdout:\n&lt;captured stdout&gt;\nstderr:\n&lt;captured stderr&gt;\nexit_code: 0\nresult: &lt;JSON-parsed last line, if applicable&gt;\n</code></pre> <p>If the code times out, the output is: <code>Execution timed out after N seconds</code>.</p> <p>If a security violation is detected, the output is: <code>Security violation: &lt;details&gt;</code>.</p>"},{"location":"components/sub-components/code-execute/#example","title":"Example","text":"<p>An agent with Code Execute can perform computations, data processing, and system queries:</p> <pre><code>User: Calculate the first 20 Fibonacci numbers.\nAgent: [calls code_execute(code=\"a,b=0,1\\nfor _ in range(20):\\n    print(a)\\n    a,b=b,a+b\")]\n       \u2192 stdout:\n         0\n         1\n         1\n         2\n         3\n         5\n         8\n         13\n         ...\n         exit_code: 0\nAgent: The first 20 Fibonacci numbers are: 0, 1, 1, 2, 3, 5, 8, 13, ...\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    CE[Code Execute] -.-&gt;|tool| A\n\n    style CE fill:#10b981,color:white</code></pre> <p>Sandbox limitations</p> <p>The sandbox security patterns are a blocklist, not an allowlist. Determined users may find ways around them. For production deployments, consider running Pipelit in a container or VM to provide OS-level isolation. See Security for recommendations.</p> <p>Code Execute vs. Code node</p> <p>Code Execute is a sub-component tool -- it runs in a sandboxed subprocess when an agent decides to use it. The Code node (Logic category) is a direct workflow step that runs inline via <code>exec()</code> with full access to the workflow state. Use Code Execute when agents need to run arbitrary code safely; use the Code node for predetermined data transformations in the workflow graph.</p>"},{"location":"components/sub-components/output-parser/","title":"Output Parser","text":""},{"location":"components/sub-components/output-parser/#output-parser","title":"Output Parser","text":"<p>The Output Parser sub-component transforms raw LLM text output into structured data. It supports JSON extraction, regex matching, and list parsing, making it essential for nodes that need to produce machine-readable outputs from natural language responses.</p> Property Value Component Type <code>output_parser</code> Category Sub-component Display Name Output Parser Executable No (configuration only)"},{"location":"components/sub-components/output-parser/#ports","title":"Ports","text":""},{"location":"components/sub-components/output-parser/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>text</code> STRING No Raw text to parse (typically from an AI node's LLM response)"},{"location":"components/sub-components/output-parser/#outputs","title":"Outputs","text":"Port Data Type Description <code>parsed</code> OBJECT Structured data extracted from the raw text"},{"location":"components/sub-components/output-parser/#configuration","title":"Configuration","text":"<p>The Output Parser component accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Description <code>parser_type</code> string <code>json</code> Parsing strategy: <code>json</code>, <code>regex</code>, or <code>list</code> <code>source_node</code> string -- Node ID to read raw text from (optional) <code>pattern</code> string -- Regex pattern (required when <code>parser_type</code> is <code>regex</code>)"},{"location":"components/sub-components/output-parser/#parser-types","title":"Parser types","text":""},{"location":"components/sub-components/output-parser/#json-parser-json","title":"JSON parser (<code>json</code>)","text":"<p>Extracts JSON from the LLM response. Handles two formats:</p> <ol> <li>Direct JSON -- the entire response is valid JSON</li> <li>Markdown code blocks -- JSON wrapped in <code>```json ... ```</code> fences</li> </ol> <p>If neither format is found, the raw text is returned as-is.</p>"},{"location":"components/sub-components/output-parser/#regex-parser-regex","title":"Regex parser (<code>regex</code>)","text":"<p>Applies the configured <code>pattern</code> as a Python regular expression to the text and returns all matches via <code>re.findall()</code>. If no matches are found, the raw text is returned.</p>"},{"location":"components/sub-components/output-parser/#list-parser-list","title":"List parser (<code>list</code>)","text":"<p>Splits the text by newlines and strips common list prefixes (bullets, numbers, dashes). Each non-empty line becomes an element in the output array.</p> <p>Input: </p><pre><code>1. First item\n2. Second item\n- Third item\n* Fourth item\n</code></pre><p></p> <p>Output: </p><pre><code>[\"First item\", \"Second item\", \"Third item\", \"Fourth item\"]\n</code></pre><p></p>"},{"location":"components/sub-components/output-parser/#usage","title":"Usage","text":"<ol> <li>Add an Output Parser node from the Node Palette (Sub-components category)</li> <li>Configure the <code>parser_type</code> and any parser-specific settings in Extra Config</li> <li>Connect the Output Parser to an AI node via the slate diamond output_parser handle</li> </ol>"},{"location":"components/sub-components/output-parser/#source-resolution","title":"Source resolution","text":"<p>The Output Parser reads its input text in this order:</p> <ol> <li>If <code>source_node</code> is set, reads that node's output from <code>state.node_outputs</code></li> <li>Otherwise, reads the last message's content from the <code>messages</code> list in state</li> </ol>"},{"location":"components/sub-components/output-parser/#compatible-ai-nodes","title":"Compatible AI nodes","text":"<p>The Output Parser connects to these AI node types:</p> AI Node Uses Output Parser Categorizer Parses the LLM response into a category label Router Parses the LLM response into a route identifier Extractor Parses the LLM response into structured data Agent Not supported (agents use tools, not parsers)"},{"location":"components/sub-components/output-parser/#example","title":"Example","text":"<p>A categorizer uses an output parser to extract the category from the LLM's JSON response:</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; C[Categorizer]\n    M[AI Model] -.-&gt;|model| C\n    OP[Output Parser] -.-&gt;|output_parser| C\n\n    style OP fill:#94a3b8,color:white</code></pre> <p>Output Parser Extra Config:</p> <pre><code>{\n  \"parser_type\": \"json\"\n}\n</code></pre> <p>If the LLM responds with:</p> <pre><code>{\"category\": \"technical_support\", \"confidence\": 0.92}\n</code></pre> <p>The Output Parser produces <code>{\"category\": \"technical_support\", \"confidence\": 0.92}</code> as structured data that the Categorizer can use to set its <code>category</code> output.</p>"},{"location":"components/sub-components/output-parser/#regex-example","title":"Regex example","text":"<p>Extract email addresses from LLM output:</p> <pre><code>{\n  \"parser_type\": \"regex\",\n  \"pattern\": \"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\\\.[a-zA-Z]{2,}\"\n}\n</code></pre> <p>Input: <code>\"Contact us at support@example.com or sales@example.com\"</code></p> <p>Output: <code>[\"support@example.com\", \"sales@example.com\"]</code></p> <p>Graceful fallback</p> <p>If parsing fails (e.g., invalid JSON, no regex matches), the Output Parser returns the raw text rather than raising an error. This ensures the workflow continues even when the LLM produces unexpected output formats.</p>"},{"location":"components/tools/","title":"Tools","text":""},{"location":"components/tools/#tools","title":"Tools","text":"<p>Tools are sub-component nodes that give agents capabilities beyond language generation. They provide LangChain tool functions that an agent can invoke during its reasoning loop to interact with the outside world -- run shell commands, make HTTP requests, search the web, evaluate math, or check the current time.</p>"},{"location":"components/tools/#how-tools-work","title":"How tools work","text":"<p>Tools connect to agent nodes via the green diamond tools handle on the canvas. At build time, the agent queries all edges with <code>edge_label=\"tool\"</code>, loads each connected tool node's factory function, and registers the resulting LangChain <code>@tool</code> functions for LLM function calling.</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    RC[Run Command] -.-&gt;|tool| A\n    HR[HTTP Request] -.-&gt;|tool| A\n    WS[Web Search] -.-&gt;|tool| A\n    C[Calculator] -.-&gt;|tool| A\n    DT[Date &amp; Time] -.-&gt;|tool| A</code></pre> <p>When the agent's LLM decides to call a tool during execution, WebSocket <code>node_status</code> events are published so the tool node shows running, success, or failed badges on the canvas in real time.</p>"},{"location":"components/tools/#built-in-tools","title":"Built-in tools","text":"<p>Pipelit ships with 5 built-in utility tools:</p> Tool Component Type Description Run Command <code>run_command</code> Execute shell commands on the host system HTTP Request <code>http_request</code> Make HTTP requests to external APIs Web Search <code>web_search</code> Search the web via a SearXNG instance Calculator <code>calculator</code> Evaluate mathematical expressions safely Date &amp; Time <code>datetime</code> Get the current date and time"},{"location":"components/tools/#connecting-tools-to-agents","title":"Connecting tools to agents","text":"<ol> <li>Add a tool node from the Node Palette (under the Tools category)</li> <li>Add an agent node if you have not already</li> <li>Drag an edge from the tool node to the agent's green diamond tools handle at the bottom</li> <li>The edge will be created with <code>edge_label=\"tool\"</code> automatically</li> </ol> <p>An agent can have any number of tools connected. Each tool becomes available to the agent's LLM for function calling.</p> <p>Tools are optional</p> <p>An agent does not require any tools. Without tools, the agent acts as a pure conversational LLM that can only generate text responses.</p>"},{"location":"components/tools/#tool-execution-lifecycle","title":"Tool execution lifecycle","text":"<ol> <li>The agent receives input and begins its reasoning loop</li> <li>The LLM decides to call a tool and emits a tool-call message</li> <li>LangGraph dispatches the call to the corresponding tool function</li> <li>The tool node's status changes to <code>running</code> (visible on the canvas)</li> <li>The tool executes and returns a result string</li> <li>The tool node's status changes to <code>success</code> or <code>failed</code></li> <li>The result is fed back into the agent's reasoning loop</li> <li>The LLM can call more tools or produce a final response</li> </ol>"},{"location":"components/tools/#configuration","title":"Configuration","text":"<p>Most tools accept optional configuration via their <code>extra_config</code> field in the node details panel. See each tool's page for specific configuration options.</p> <p>Security considerations</p> <p>Some tools (particularly Run Command and HTTP Request) can interact with the host system and external services. Review the Security documentation before deploying workflows with these tools in production.</p>"},{"location":"components/tools/calculator/","title":"Calculator","text":""},{"location":"components/tools/calculator/#calculator","title":"Calculator","text":"<p>The Calculator tool evaluates mathematical expressions safely and returns the numeric result. It gives agents the ability to perform accurate arithmetic without relying on the LLM's inherently unreliable math capabilities.</p> Property Value Component Type <code>calculator</code> Category Sub-component (Tool) Display Name Calculator"},{"location":"components/tools/calculator/#ports","title":"Ports","text":""},{"location":"components/tools/calculator/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>expression</code> STRING No Mathematical expression to evaluate <p>The <code>expression</code> input is provided by the agent's LLM at invocation time.</p>"},{"location":"components/tools/calculator/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING The numeric result as a string"},{"location":"components/tools/calculator/#configuration","title":"Configuration","text":"<p>The Calculator tool has no configuration options. It works out of the box with no <code>extra_config</code> needed.</p>"},{"location":"components/tools/calculator/#usage","title":"Usage","text":"<ol> <li>Add a Calculator node from the Node Palette</li> <li>Connect it to an agent node via the green diamond tools handle</li> </ol> <p>The agent's LLM can then call the <code>calculator</code> tool with any supported mathematical expression.</p>"},{"location":"components/tools/calculator/#supported-operators","title":"Supported operators","text":"Operator Description Example <code>+</code> Addition <code>2 + 3</code> <code>-</code> Subtraction <code>10 - 4</code> <code>*</code> Multiplication <code>6 * 7</code> <code>/</code> Division <code>15 / 4</code> <code>//</code> Floor division <code>15 // 4</code> <code>%</code> Modulo (remainder) <code>17 % 5</code> <code>**</code> Exponentiation <code>2 ** 10</code> <code>-</code> (unary) Negation <code>-5</code> <code>+</code> (unary) Positive <code>+5</code> <p>Parentheses are supported for grouping: <code>(2 + 3) * 4</code>.</p>"},{"location":"components/tools/calculator/#safety","title":"Safety","text":"<p>The calculator uses Python's <code>ast</code> module to parse expressions into an abstract syntax tree, then evaluates only numeric constants and the operators listed above. It does not use <code>eval()</code> and cannot execute arbitrary code. Function calls, variable references, string operations, and all other Python syntax are rejected.</p>"},{"location":"components/tools/calculator/#example","title":"Example","text":"<p>An agent helping with a financial calculation:</p> <pre><code>calculator(\"(1500 * 12) + (500 * 0.08)\")\n</code></pre> <p>Returns:</p> <pre><code>18040.0\n</code></pre> <p>A more complex expression:</p> <pre><code>calculator(\"2 ** 32 - 1\")\n</code></pre> <p>Returns:</p> <pre><code>4294967295\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    C[Calculator] -.-&gt;|tool| A</code></pre> <p>When to use Calculator</p> <p>LLMs frequently make arithmetic errors, especially with large numbers, decimals, or multi-step calculations. Connect a Calculator tool whenever your agent needs to perform math -- even simple operations -- to ensure accurate results.</p> <p>Numeric types</p> <p>The calculator handles both integers and floating-point numbers. Division (<code>/</code>) always returns a float. Floor division (<code>//</code>) returns an integer when both operands are integers.</p>"},{"location":"components/tools/datetime/","title":"Date & Time","text":""},{"location":"components/tools/datetime/#date-time","title":"Date &amp; Time","text":"<p>The Date &amp; Time tool returns the current date and time. It gives agents awareness of the current moment, which is essential for time-sensitive tasks, scheduling, logging, and answering questions about \"now.\"</p> Property Value Component Type <code>datetime</code> Category Sub-component (Tool) Display Name Date &amp; Time"},{"location":"components/tools/datetime/#ports","title":"Ports","text":""},{"location":"components/tools/datetime/#inputs","title":"Inputs","text":"<p>The Date &amp; Time tool has no inputs. It takes no parameters from the agent's LLM -- the tool simply returns the current timestamp when called.</p>"},{"location":"components/tools/datetime/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Current date and time as a formatted string <p>The output format is <code>YYYY-MM-DD HH:MM:SS TZ</code> (e.g., <code>2026-02-16 14:30:00 UTC</code>).</p>"},{"location":"components/tools/datetime/#configuration","title":"Configuration","text":"<p>The Date &amp; Time tool accepts the following optional configuration in <code>extra_config</code>:</p> Field Type Default Description <code>timezone</code> string UTC IANA timezone name (e.g., <code>America/New_York</code>, <code>Europe/London</code>, <code>Asia/Tokyo</code>)"},{"location":"components/tools/datetime/#example-extra_config","title":"Example extra_config","text":"<pre><code>{\n  \"timezone\": \"America/New_York\"\n}\n</code></pre> <p>If no timezone is configured, the tool defaults to UTC.</p>"},{"location":"components/tools/datetime/#usage","title":"Usage","text":"<ol> <li>Add a Date &amp; Time node from the Node Palette</li> <li>Connect it to an agent node via the green diamond tools handle</li> <li>Optionally set a timezone in the node's Extra Config field</li> </ol> <p>The agent's LLM can then call the <code>get_datetime</code> tool with no arguments to get the current time.</p>"},{"location":"components/tools/datetime/#example","title":"Example","text":"<p>An agent answering \"What time is it?\":</p> <pre><code>get_datetime()\n</code></pre> <p>Returns (with default UTC timezone):</p> <pre><code>2026-02-16 14:30:00 UTC\n</code></pre> <p>With <code>timezone</code> set to <code>Asia/Tokyo</code>:</p> <pre><code>2026-02-16 23:30:00 JST\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    DT[Date &amp; Time] -.-&gt;|tool| A</code></pre> <p>Why agents need a clock</p> <p>LLMs have no inherent sense of time. Their training data has a cutoff date, and they cannot determine the current moment. Connecting a Date &amp; Time tool is the simplest way to give an agent temporal awareness for tasks like \"send a reminder tomorrow\" or \"what day of the week is it?\"</p> <p>Timezone support</p> <p>The tool uses Python's <code>zoneinfo</code> module, which supports all IANA timezone names. Common examples: <code>US/Eastern</code>, <code>Europe/Berlin</code>, <code>Asia/Shanghai</code>, <code>Pacific/Auckland</code>.</p>"},{"location":"components/tools/http-request/","title":"HTTP Request","text":""},{"location":"components/tools/http-request/#http-request","title":"HTTP Request","text":"<p>The HTTP Request tool makes HTTP requests to external URLs and returns the status code and response body. It gives agents the ability to interact with REST APIs, fetch web pages, post data to webhooks, and communicate with any HTTP-accessible service.</p> Property Value Component Type <code>http_request</code> Category Sub-component (Tool) Display Name HTTP Request"},{"location":"components/tools/http-request/#ports","title":"Ports","text":""},{"location":"components/tools/http-request/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>url</code> STRING Yes The URL to send the request to <p>The <code>url</code> input is provided by the agent's LLM at invocation time. The agent can also specify <code>method</code> and <code>body</code> parameters in the tool call.</p>"},{"location":"components/tools/http-request/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING HTTP status code and response body <p>The output format is <code>HTTP {status_code}\\n{response_body}</code>.</p>"},{"location":"components/tools/http-request/#configuration","title":"Configuration","text":"<p>The HTTP Request tool accepts the following optional configuration in <code>extra_config</code>:</p> Field Type Default Description <code>method</code> string <code>\"GET\"</code> Default HTTP method (GET, POST, PUT, DELETE, PATCH, etc.) <code>headers</code> object <code>{}</code> Default headers to include with every request <code>timeout</code> integer <code>30</code> Request timeout in seconds"},{"location":"components/tools/http-request/#example-extra_config","title":"Example extra_config","text":"<pre><code>{\n  \"method\": \"POST\",\n  \"headers\": {\n    \"Content-Type\": \"application/json\",\n    \"Authorization\": \"Bearer sk-...\"\n  },\n  \"timeout\": 60\n}\n</code></pre>"},{"location":"components/tools/http-request/#usage","title":"Usage","text":"<ol> <li>Add an HTTP Request node from the Node Palette</li> <li>Connect it to an agent node via the green diamond tools handle</li> <li>Optionally configure default method, headers, and timeout in Extra Config</li> </ol> <p>The agent's LLM can then call the <code>http_request</code> tool with the following parameters:</p> Parameter Required Description <code>url</code> Yes Target URL <code>method</code> No HTTP method (overrides the default from extra_config) <code>body</code> No Request body content"},{"location":"components/tools/http-request/#response-handling","title":"Response handling","text":"<ul> <li>Response bodies longer than 4,000 characters are truncated</li> <li>The result always starts with <code>HTTP {status_code}</code> followed by the response body</li> <li>Network errors and timeouts return <code>Error: {details}</code></li> </ul>"},{"location":"components/tools/http-request/#example","title":"Example","text":"<p>An agent with an HTTP Request tool can fetch data from an API:</p> <pre><code>http_request(url=\"https://api.github.com/repos/theuselessai/Pipelit\")\n</code></pre> <p>Returns:</p> <pre><code>HTTP 200\n{\"id\":123456,\"name\":\"Pipelit\",\"full_name\":\"theuselessai/Pipelit\",...}\n</code></pre> <p>A more advanced example with a POST request:</p> <pre><code>http_request(\n    url=\"https://hooks.slack.com/services/T.../B.../xxx\",\n    method=\"POST\",\n    body='{\"text\": \"Workflow completed successfully\"}'\n)\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    HR[HTTP Request] -.-&gt;|tool| A</code></pre> <p>Setting default headers</p> <p>If your agent frequently calls the same API, set the <code>Authorization</code> and <code>Content-Type</code> headers in extra_config so the LLM does not need to include them in every tool call.</p> <p>HTTP client</p> <p>The tool uses httpx for making requests, which supports HTTP/2, connection pooling, and modern TLS.</p>"},{"location":"components/tools/run-command/","title":"Run Command","text":""},{"location":"components/tools/run-command/#run-command","title":"Run Command","text":"<p>The Run Command tool executes shell commands on the host system and returns the combined stdout/stderr output. It gives agents the ability to interact with the operating system, run scripts, inspect files, manage processes, and perform any operation available from the command line.</p> Property Value Component Type <code>run_command</code> Category Sub-component (Tool) Display Name Run Command"},{"location":"components/tools/run-command/#ports","title":"Ports","text":""},{"location":"components/tools/run-command/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>command</code> STRING No Shell command to execute <p>The <code>command</code> input is provided by the agent's LLM at invocation time, not wired from an upstream node.</p>"},{"location":"components/tools/run-command/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Combined stdout and stderr from the command <p>The output includes stderr (prefixed with <code>STDERR:</code>) and the exit code if non-zero.</p>"},{"location":"components/tools/run-command/#configuration","title":"Configuration","text":"<p>The Run Command tool accepts the following optional configuration in <code>extra_config</code>:</p> Field Type Default Description <code>timeout</code> integer <code>300</code> Maximum execution time in seconds"},{"location":"components/tools/run-command/#usage","title":"Usage","text":"<ol> <li>Add a Run Command node from the Node Palette</li> <li>Connect it to an agent node via the green diamond tools handle</li> <li>Optionally set a custom timeout in the node's Extra Config field</li> </ol> <p>The agent's LLM will then be able to call the <code>run_command</code> tool with any shell command string. The tool runs the command via <code>subprocess.run()</code> with <code>shell=True</code> and returns the output.</p>"},{"location":"components/tools/run-command/#output-handling","title":"Output handling","text":"<ul> <li>Output longer than 50,000 characters is truncated, keeping the first and last 25,000 characters with a truncation notice in between</li> <li>If the command produces no output, the result is <code>(no output)</code></li> <li>If the command times out, the result is <code>Error: command timed out after {timeout} seconds</code></li> <li>Non-zero exit codes are appended as <code>[exit code: N]</code></li> </ul>"},{"location":"components/tools/run-command/#example","title":"Example","text":"<p>An agent with a Run Command tool connected can answer questions like \"How much disk space is available?\" by calling:</p> <pre><code>run_command(\"df -h\")\n</code></pre> <p>The tool returns:</p> <pre><code>Filesystem      Size  Used Avail Use% Mounted on\n/dev/sda1       100G   45G   55G  45% /\ntmpfs           7.8G     0  7.8G   0% /dev/shm\n</code></pre> <p>The agent then interprets this output and formulates a natural language response.</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    RC[Run Command] -.-&gt;|tool| A</code></pre> <p>Security warning</p> <p>The Run Command tool executes arbitrary shell commands with the same permissions as the Pipelit process. This means it can read and write files, install packages, modify system configuration, and perform any operation the process user has access to. Do not expose workflows with this tool to untrusted users. Consider running Pipelit in a sandboxed environment (container, VM) when using this tool. See Security for recommendations.</p> <p>Subprocess isolation</p> <p>Commands run in a new session (<code>start_new_session=True</code>) with stdin set to <code>/dev/null</code>. This prevents interactive commands from blocking execution and provides basic process group isolation.</p>"},{"location":"components/tools/web-search/","title":"Web Search","text":""},{"location":"components/tools/web-search/#web-search","title":"Web Search","text":"<p>The Web Search tool searches the web using a SearXNG instance and returns the top results. It gives agents the ability to find current information, research topics, and answer questions that require up-to-date knowledge beyond their training data.</p> Property Value Component Type <code>web_search</code> Category Sub-component (Tool) Display Name Web Search"},{"location":"components/tools/web-search/#ports","title":"Ports","text":""},{"location":"components/tools/web-search/#inputs","title":"Inputs","text":"Port Data Type Required Description <code>query</code> STRING Yes Search query string <p>The <code>query</code> input is provided by the agent's LLM at invocation time.</p>"},{"location":"components/tools/web-search/#outputs","title":"Outputs","text":"Port Data Type Description <code>result</code> STRING Formatted list of top search results <p>Each result includes the title, URL, and a content snippet (up to 200 characters).</p>"},{"location":"components/tools/web-search/#configuration","title":"Configuration","text":"<p>The Web Search tool accepts the following configuration in <code>extra_config</code>:</p> Field Type Default Required Description <code>searxng_url</code> string <code>\"http://localhost:8888\"</code> Yes Base URL of your SearXNG instance"},{"location":"components/tools/web-search/#example-extra_config","title":"Example extra_config","text":"<pre><code>{\n  \"searxng_url\": \"http://localhost:8888\"\n}\n</code></pre>"},{"location":"components/tools/web-search/#prerequisites","title":"Prerequisites","text":"<p>The Web Search tool requires a running SearXNG instance. SearXNG is a free, privacy-respecting metasearch engine that aggregates results from multiple search providers.</p>"},{"location":"components/tools/web-search/#quick-searxng-setup-with-docker","title":"Quick SearXNG setup with Docker","text":"<pre><code>docker run -d \\\n  --name searxng \\\n  -p 8888:8080 \\\n  -e SEARXNG_SECRET=$(openssl rand -hex 32) \\\n  searxng/searxng\n</code></pre> <p>SearXNG is required</p> <p>Without a running SearXNG instance, every search call will fail with a connection error. Make sure SearXNG is accessible at the URL configured in <code>extra_config</code> before using this tool.</p>"},{"location":"components/tools/web-search/#usage","title":"Usage","text":"<ol> <li>Ensure a SearXNG instance is running and accessible</li> <li>Add a Web Search node from the Node Palette</li> <li>Connect it to an agent node via the green diamond tools handle</li> <li>Set the <code>searxng_url</code> in the node's Extra Config field</li> </ol> <p>The agent's LLM can then call the <code>web_search</code> tool with a search query string.</p>"},{"location":"components/tools/web-search/#result-format","title":"Result format","text":"<p>The tool returns the top 5 results in the following format:</p> <pre><code>- Result Title\n  https://example.com/page\n  Content snippet up to 200 characters...\n\n- Another Result\n  https://example.com/other\n  Another content snippet...\n</code></pre> <p>If no results are found, the tool returns <code>No results found.</code></p>"},{"location":"components/tools/web-search/#example","title":"Example","text":"<p>An agent with a Web Search tool can answer current-events questions:</p> <pre><code>web_search(\"Pipelit workflow automation platform\")\n</code></pre> <p>Returns:</p> <pre><code>- Pipelit - Visual Workflow Automation\n  https://github.com/theuselessai/Pipelit\n  Build, connect, and orchestrate LLM-powered agents visually. Design workflows on a React Flow canvas...\n\n- Getting Started with Pipelit\n  https://theuselessai.github.io/Pipelit/getting-started/\n  Installation guide for the Pipelit visual workflow platform...\n</code></pre> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    WS[Web Search] -.-&gt;|tool| A</code></pre> <p>Combine with other tools</p> <p>Web Search works well alongside HTTP Request. The agent can search for information, then use HTTP Request to fetch full page content or interact with APIs discovered through search results.</p>"},{"location":"components/triggers/","title":"Triggers","text":""},{"location":"components/triggers/#triggers","title":"Triggers","text":"<p>Trigger</p> <p>Triggers are the entry points of every workflow. They receive events from external sources -- a chat message, a Telegram update, a scheduled interval, or an error condition -- and initiate workflow execution.</p>"},{"location":"components/triggers/#triggers-are-nodes","title":"Triggers Are Nodes","text":"<p>In Pipelit, triggers are not separate entities. They are first-class nodes on the canvas, sharing the same unified node model as agents, tools, and logic components. This means:</p> <ul> <li>Triggers appear on the canvas with the same drag-and-drop behavior as other nodes.</li> <li>They have defined output ports that emit typed data downstream.</li> <li>They connect to other nodes via standard edges.</li> <li>Multiple triggers can exist on the same canvas, each firing independently.</li> </ul> <p>On the canvas, all trigger nodes display with an orange border (<code>#f97316</code>) and strip the <code>trigger_</code> prefix in their label (e.g., <code>trigger_telegram</code> displays as <code>telegram</code>).</p>"},{"location":"components/triggers/#trigger-types","title":"Trigger Types","text":"Component Type Display Name Description <code>trigger_chat</code> Chat Trigger Built-in web chat interface <code>trigger_telegram</code> Telegram Trigger Receives messages from Telegram bots <code>trigger_manual</code> Manual Trigger One-click execution from the UI <code>trigger_schedule</code> Schedule Trigger Fired by the scheduler system on intervals <code>trigger_workflow</code> Workflow Trigger Triggered by a parent workflow <code>trigger_error</code> Error Trigger Triggered when errors occur in the workflow"},{"location":"components/triggers/#trigger-scoped-execution","title":"Trigger-Scoped Execution","text":"<p>When a trigger fires, the execution engine does not compile the entire workflow graph. Instead, it performs a BFS (breadth-first search) from the fired trigger node and only compiles nodes that are reachable downstream from that trigger via direct edges.</p> <p>This design has two important consequences:</p> <ol> <li> <p>Multiple trigger branches: A single workflow can have a Chat Trigger feeding one agent and a Telegram Trigger feeding a different agent. Each trigger fires independently and only executes its own branch.</p> </li> <li> <p>Unused nodes are ignored: Nodes on the canvas that are not connected to the firing trigger are skipped entirely. This allows you to keep draft or experimental nodes on the canvas without causing build errors.</p> </li> </ol> <pre><code>graph LR\n    TC[Chat Trigger] --&gt; A1[Agent A]\n    TT[Telegram Trigger] --&gt; A2[Agent B]\n    TM[Manual Trigger] --&gt; A1\n\n    style TC fill:#f97316,color:white\n    style TT fill:#f97316,color:white\n    style TM fill:#f97316,color:white</code></pre> <p>In this example, firing the Chat Trigger executes only Agent A. Firing the Telegram Trigger executes only Agent B. The Manual Trigger also routes to Agent A, providing a second entry point to the same branch.</p>"},{"location":"components/triggers/#trigger-resolution","title":"Trigger Resolution","text":"<p>When an event arrives (e.g., a Telegram message), the TriggerResolver matches the event type to the appropriate <code>component_type</code> and finds the first active trigger node that matches:</p> Event Type Component Type <code>telegram_message</code> / <code>telegram_chat</code> <code>trigger_telegram</code> <code>schedule</code> <code>trigger_schedule</code> <code>manual</code> <code>trigger_manual</code> <code>workflow</code> <code>trigger_workflow</code> <code>error</code> <code>trigger_error</code> <p>Chat triggers are handled differently -- they are invoked directly via the <code>POST /workflows/{slug}/chat/</code> API endpoint rather than going through the resolver.</p>"},{"location":"components/triggers/#trigger-payload","title":"Trigger Payload","text":"<p>Every trigger receives an event payload that becomes available to downstream nodes via the <code>trigger</code> Jinja2 shorthand:</p> <pre><code>{{ trigger.text }}       {# message text from chat or telegram #}\n{{ trigger.payload }}    {# full event payload object #}\n</code></pre> <p>The exact fields available depend on the trigger type. See each trigger's documentation for its specific output ports.</p>"},{"location":"components/triggers/#non-executable-status","title":"Non-Executable Status","text":"<p>Triggers themselves do not \"execute\" in the traditional sense -- they initiate execution. On the canvas, trigger nodes do not show running/success/failed status badges during execution. Their role is to receive events and pass data downstream to the first executable node in the chain.</p>"},{"location":"components/triggers/chat/","title":"Chat","text":""},{"location":"components/triggers/chat/#chat-trigger","title":"Chat Trigger","text":"<p>Trigger</p> <p>The Chat Trigger provides a built-in web chat interface for interacting with workflows directly from the Pipelit frontend. Users type messages in the ChatPanel, and each message fires the trigger to start a new workflow execution.</p> <p>Component type: <code>trigger_chat</code></p>"},{"location":"components/triggers/chat/#ports","title":"Ports","text":""},{"location":"components/triggers/chat/#outputs","title":"Outputs","text":"Port Type Description <code>text</code> STRING The message text sent by the user <code>payload</code> OBJECT Full trigger payload including text and metadata"},{"location":"components/triggers/chat/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/chat/#configuration","title":"Configuration","text":"<p>The Chat Trigger requires no configuration. Add it to the canvas and connect it to downstream nodes.</p>"},{"location":"components/triggers/chat/#usage","title":"Usage","text":"<ol> <li>Drag a Chat Trigger node onto the canvas from the Node Palette (under Triggers).</li> <li>Connect its output to an Agent, Code, or any other downstream node.</li> <li>Connect an AI Model sub-component to your agent.</li> <li>Open the ChatPanel in the workflow editor (bottom panel).</li> <li>Type a message and press Enter.</li> </ol> <p>Each message sent through the ChatPanel creates a new workflow execution scoped to the Chat Trigger. The user's message text is available on the <code>text</code> output port, and the full payload (including metadata) on the <code>payload</code> port.</p>"},{"location":"components/triggers/chat/#accessing-chat-input-downstream","title":"Accessing Chat Input Downstream","text":"<p>In your agent's system prompt or any node's configuration, reference the chat input using Jinja2 expressions:</p> <pre><code>{{ trigger.text }}\n</code></pre> <p>Or reference the specific trigger node by its ID:</p> <pre><code>{{ trigger_chat_abc123.text }}\n</code></pre>"},{"location":"components/triggers/chat/#conversation-memory","title":"Conversation Memory","text":"<p>When the Chat Trigger connects to an Agent with Conversation Memory enabled, the agent maintains conversation history across multiple chat messages. This gives the agent continuity -- it remembers what was said in previous messages within the same workflow.</p> <p>The thread ID for conversation memory is constructed from the user's profile ID and the workflow ID, so each user gets their own conversation thread per workflow.</p>"},{"location":"components/triggers/chat/#example","title":"Example","text":"<p>A minimal chat-based workflow:</p> <pre><code>graph LR\n    CT[Chat Trigger] --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <ol> <li>Chat Trigger receives the user's message.</li> <li>Agent processes the message using the connected AI Model, reasons through the response, and produces output.</li> <li>The response is displayed back in the ChatPanel.</li> </ol>"},{"location":"components/triggers/chat/#multi-trigger-workflow","title":"Multi-trigger workflow","text":"<p>A Chat Trigger and a Telegram Trigger can both feed the same agent:</p> <pre><code>graph LR\n    CT[Chat Trigger] --&gt; AG[Agent]\n    TT[Telegram Trigger] --&gt; AG\n    AM[AI Model] -.-&gt; AG\n\n    style CT fill:#f97316,color:white\n    style TT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <p>In this layout, the same agent handles messages from both the web chat and Telegram. The <code>{{ trigger.text }}</code> expression works regardless of which trigger fired.</p>"},{"location":"components/triggers/chat/#api-endpoint","title":"API Endpoint","text":"<p>Chat messages are sent via:</p> <pre><code>POST /api/v1/workflows/{slug}/chat/\n</code></pre> <p>Request body:</p> <pre><code>{\n  \"text\": \"Hello, can you help me with something?\",\n  \"trigger_node_id\": \"trigger_chat_abc123\"\n}\n</code></pre> <p>The <code>trigger_node_id</code> field is optional. If omitted, Pipelit uses the first <code>trigger_chat</code> node found in the workflow.</p>"},{"location":"components/triggers/error/","title":"Error","text":""},{"location":"components/triggers/error/#error-trigger","title":"Error Trigger","text":"<p>Trigger</p> <p>The Error Trigger fires when an error occurs during workflow execution. It enables error-handling branches that can log failures, send notifications, retry operations, or escalate issues -- all within the workflow graph itself.</p> <p>Component type: <code>trigger_error</code></p>"},{"location":"components/triggers/error/#ports","title":"Ports","text":""},{"location":"components/triggers/error/#outputs","title":"Outputs","text":"Port Type Description <code>error</code> OBJECT Error details including message, error code, source node, and stack trace"},{"location":"components/triggers/error/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/error/#configuration","title":"Configuration","text":"<p>The Error Trigger requires no configuration. It activates automatically when an error event is dispatched within the workflow.</p>"},{"location":"components/triggers/error/#usage","title":"Usage","text":"<ol> <li>Drag an Error Trigger onto the canvas.</li> <li>Connect it to nodes that handle the error (e.g., an Agent that formats an alert, a Code node that logs to an external service).</li> <li>When any node in the workflow fails, the Error Trigger fires with the error details.</li> </ol>"},{"location":"components/triggers/error/#accessing-error-data","title":"Accessing Error Data","text":"<p>The error payload is available as an object on the <code>error</code> output port:</p> <pre><code>{{ trigger.error }}\n</code></pre> <p>The error object typically contains:</p> <pre><code>{\n  \"message\": \"Connection refused\",\n  \"error_code\": \"CONNECTION_ERROR\",\n  \"source_node_id\": \"agent_abc123\",\n  \"source_node_type\": \"agent\",\n  \"execution_id\": \"...\",\n  \"timestamp\": \"2026-01-15T10:30:00Z\"\n}\n</code></pre>"},{"location":"components/triggers/error/#error-handling-patterns","title":"Error Handling Patterns","text":"<p>Notification on failure: Connect the Error Trigger to an Agent with HTTP Request tools to send alerts to Slack, email, or other notification channels when something goes wrong.</p> <p>Logging: Connect the Error Trigger to a Code node that writes error details to an external logging service or database.</p> <p>Graceful degradation: Use the Error Trigger to invoke a fallback workflow that provides a default response when the primary path fails.</p>"},{"location":"components/triggers/error/#example","title":"Example","text":"<p>A workflow with error handling:</p> <pre><code>graph LR\n    CT[Chat Trigger] --&gt; AG1[Primary Agent]\n    TE[Error Trigger] --&gt; AG2[Error Handler Agent]\n    AM1[AI Model] -.-&gt; AG1\n    AM2[AI Model] -.-&gt; AG2\n    HR[HTTP Request] -.-&gt; AG2\n\n    style CT fill:#f97316,color:white\n    style TE fill:#f97316,color:white\n    style AM1 fill:#3b82f6,color:white\n    style AM2 fill:#3b82f6,color:white\n    style HR fill:#10b981,color:white</code></pre> <ol> <li>Chat Trigger receives a user message and routes to the Primary Agent.</li> <li>If the Primary Agent fails (e.g., LLM API timeout, tool error), the Error Trigger fires.</li> <li>The Error Handler Agent receives the error details and uses HTTP Request to send an alert to the operations team.</li> </ol>"},{"location":"components/triggers/error/#error-trigger-with-code-based-logging","title":"Error trigger with code-based logging","text":"<pre><code>graph LR\n    ST[Schedule Trigger] --&gt; AG[Agent]\n    TE[Error Trigger] --&gt; CD[Code&lt;br/&gt;log to file]\n    AM[AI Model] -.-&gt; AG\n\n    style ST fill:#f97316,color:white\n    style TE fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <p>A scheduled workflow with an Error Trigger connected to a Code node. If the scheduled agent fails, the Code node logs the error details for later analysis.</p>"},{"location":"components/triggers/error/#trigger-resolution","title":"Trigger Resolution","text":"<p>The Error Trigger matches all error events unconditionally -- there is no filtering by error type or source node. If you need conditional error handling, connect the Error Trigger to a Switch node that routes based on the error code or source node type.</p>"},{"location":"components/triggers/manual/","title":"Manual","text":""},{"location":"components/triggers/manual/#manual-trigger","title":"Manual Trigger","text":"<p>Trigger</p> <p>The Manual Trigger provides one-click workflow execution from the Pipelit UI. It is the simplest trigger type -- click a button and the workflow runs. This is useful for testing, administrative tasks, and workflows that should be run on demand.</p> <p>Component type: <code>trigger_manual</code></p>"},{"location":"components/triggers/manual/#ports","title":"Ports","text":""},{"location":"components/triggers/manual/#outputs","title":"Outputs","text":"Port Type Description <code>payload</code> OBJECT Trigger payload containing optional text and metadata"},{"location":"components/triggers/manual/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/manual/#configuration","title":"Configuration","text":"<p>The Manual Trigger requires no configuration. Add it to the canvas and connect it to downstream nodes.</p> <p>An optional <code>text</code> field can be provided at execution time, which is included in the payload.</p>"},{"location":"components/triggers/manual/#usage","title":"Usage","text":"<ol> <li>Drag a Manual Trigger onto the canvas from the Node Palette (under Triggers).</li> <li>Connect its output to downstream nodes.</li> <li>Execute the workflow by clicking the Run button in the workflow editor or by calling the API endpoint.</li> </ol>"},{"location":"components/triggers/manual/#accessing-manual-trigger-data","title":"Accessing Manual Trigger Data","text":"<p>The manual trigger payload is available via Jinja2 expressions:</p> <pre><code>{{ trigger.payload }}       {# full payload object #}\n{{ trigger.payload.text }}  {# optional text if provided #}\n</code></pre>"},{"location":"components/triggers/manual/#running-via-the-ui","title":"Running via the UI","text":"<p>In the workflow editor, when a Manual Trigger is present on the canvas, you can click the execute button to fire it. If the workflow has multiple Manual Trigger nodes, you can specify which one to target.</p>"},{"location":"components/triggers/manual/#running-via-the-api","title":"Running via the API","text":"<pre><code>POST /api/v1/workflows/{workflow_slug}/execute/\n</code></pre> <p>Request body:</p> <pre><code>{\n  \"text\": \"optional input text\",\n  \"trigger_node_id\": \"trigger_manual_abc123\"\n}\n</code></pre> <p>Both fields are optional. If <code>trigger_node_id</code> is omitted, the first <code>trigger_manual</code> node in the workflow is used. If <code>text</code> is omitted, it defaults to an empty string.</p>"},{"location":"components/triggers/manual/#example","title":"Example","text":"<p>A manual workflow for running a maintenance task:</p> <pre><code>graph LR\n    MT[Manual Trigger] --&gt; CD[Code]\n    CD --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n\n    style MT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <ol> <li>Manual Trigger is fired by clicking Run.</li> <li>Code node runs a preparation script.</li> <li>Agent processes the results and produces a summary.</li> </ol>"},{"location":"components/triggers/manual/#dual-entry-workflow","title":"Dual-entry workflow","text":"<p>A Manual Trigger can coexist with other triggers on the same workflow, providing a way to test the same pipeline manually:</p> <pre><code>graph LR\n    MT[Manual Trigger] --&gt; AG[Agent]\n    CT[Chat Trigger] --&gt; AG\n    AM[AI Model] -.-&gt; AG\n\n    style MT fill:#f97316,color:white\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <p>Both triggers feed the same Agent. Use the Chat Trigger for interactive use and the Manual Trigger for quick test runs.</p>"},{"location":"components/triggers/schedule/","title":"Schedule","text":""},{"location":"components/triggers/schedule/#schedule-trigger","title":"Schedule Trigger","text":"<p>Trigger</p> <p>The Schedule Trigger is fired by the Pipelit scheduler system at configured intervals. It enables recurring workflow execution without external cron -- interval-based scheduling with retry logic, pause/resume, and automatic crash recovery.</p> <p>Component type: <code>trigger_schedule</code></p>"},{"location":"components/triggers/schedule/#ports","title":"Ports","text":""},{"location":"components/triggers/schedule/#outputs","title":"Outputs","text":"Port Type Description <code>timestamp</code> STRING ISO 8601 timestamp of when the trigger fired"},{"location":"components/triggers/schedule/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/schedule/#configuration","title":"Configuration","text":"<p>The Schedule Trigger itself requires no canvas-level configuration. Scheduling is managed through ScheduledJob records, which are created and controlled via the Schedules API.</p>"},{"location":"components/triggers/schedule/#scheduledjob-properties","title":"ScheduledJob Properties","text":"Field Description <code>workflow_id</code> The workflow to execute <code>trigger_node_id</code> The specific Schedule Trigger node to fire <code>interval_seconds</code> Time between executions (e.g., 3600 for hourly) <code>repeat_count</code> How many times to repeat (0 = infinite) <code>retry_max</code> Maximum retries on failure <code>status</code> <code>active</code>, <code>paused</code>, <code>done</code>, or <code>dead</code> <code>next_run_at</code> Timestamp of the next scheduled execution"},{"location":"components/triggers/schedule/#trigger-level-matching","title":"Trigger-Level Matching","text":"<p>The trigger's configuration supports an optional <code>scheduled_job_id</code> field. When set, the trigger only fires for events from that specific ScheduledJob. This allows multiple Schedule Triggers on the same workflow to be targeted by different schedules.</p>"},{"location":"components/triggers/schedule/#usage","title":"Usage","text":"<ol> <li>Drag a Schedule Trigger onto the canvas.</li> <li>Connect it to downstream nodes that should execute on a recurring basis.</li> <li>Create a ScheduledJob via the API that targets this workflow and trigger node.</li> </ol>"},{"location":"components/triggers/schedule/#creating-a-scheduled-job","title":"Creating a Scheduled Job","text":"<pre><code>POST /api/v1/schedules/\n</code></pre> <pre><code>{\n  \"workflow_id\": 1,\n  \"trigger_node_id\": \"trigger_schedule_abc123\",\n  \"interval_seconds\": 3600,\n  \"repeat_count\": 0,\n  \"retry_max\": 3\n}\n</code></pre> <p>This creates a job that fires every hour, repeats indefinitely, and retries up to 3 times on failure.</p>"},{"location":"components/triggers/schedule/#managing-schedules","title":"Managing Schedules","text":"Endpoint Action <code>POST /schedules/{id}/pause/</code> Pause the schedule <code>POST /schedules/{id}/resume/</code> Resume a paused schedule <code>DELETE /schedules/{id}/</code> Delete the schedule <code>GET /schedules/</code> List all schedules"},{"location":"components/triggers/schedule/#accessing-schedule-data-downstream","title":"Accessing Schedule Data Downstream","text":"<p>Reference the trigger timestamp in downstream nodes:</p> <pre><code>{{ trigger.timestamp }}\n</code></pre> <p>The payload also contains the <code>scheduled_job_id</code> for identifying which schedule triggered the execution.</p>"},{"location":"components/triggers/schedule/#how-the-scheduler-works","title":"How the Scheduler Works","text":"<p>The Pipelit scheduler uses a self-rescheduling architecture built on RQ (Redis Queue):</p> <ol> <li>A ScheduledJob is created and enqueued as an RQ job.</li> <li>When the job fires, it dispatches the workflow via <code>dispatch_event(\"schedule\", ...)</code>.</li> <li>After execution, the scheduler calls <code>_enqueue_next()</code> to schedule itself again using <code>Queue.enqueue_in()</code>.</li> <li>Each enqueued job gets a deterministic RQ job ID (<code>sched-{id}-n{repeat}-rc{retry}</code>) to prevent duplicate enqueues.</li> <li>On failure, exponential backoff is applied, capped at 10x the interval.</li> <li>On startup, <code>recover_scheduled_jobs()</code> re-enqueues any active jobs whose <code>next_run_at</code> is in the past.</li> </ol>"},{"location":"components/triggers/schedule/#example","title":"Example","text":"<p>A scheduled monitoring workflow:</p> <pre><code>graph LR\n    ST[Schedule Trigger] --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n    SH[System Health] -.-&gt; AG\n    HR[HTTP Request] -.-&gt; AG\n\n    style ST fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style SH fill:#10b981,color:white\n    style HR fill:#10b981,color:white</code></pre> <ol> <li>Schedule Trigger fires every hour.</li> <li>Agent checks system health and makes HTTP requests to external services.</li> <li>Results are logged or sent via a delivery channel.</li> </ol>"},{"location":"components/triggers/schedule/#scheduled-report-with-telegram-delivery","title":"Scheduled report with Telegram delivery","text":"<pre><code>graph LR\n    ST[Schedule Trigger] --&gt; CD[Code]\n    CD --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n\n    style ST fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre> <p>A daily report workflow: the Schedule Trigger fires at a set interval, a Code node gathers data, and an Agent summarizes and formats the report for delivery.</p>"},{"location":"components/triggers/telegram/","title":"Telegram","text":""},{"location":"components/triggers/telegram/#telegram-trigger","title":"Telegram Trigger","text":"<p>Trigger</p> <p>The Telegram Trigger receives messages from Telegram bots via webhook integration. When a user sends a message to your Telegram bot, the trigger fires and passes the message text, chat ID, and full payload to downstream nodes.</p> <p>Component type: <code>trigger_telegram</code></p>"},{"location":"components/triggers/telegram/#ports","title":"Ports","text":""},{"location":"components/triggers/telegram/#outputs","title":"Outputs","text":"Port Type Description <code>text</code> STRING The message text sent by the Telegram user <code>chat_id</code> NUMBER The Telegram chat ID (used for sending replies) <code>payload</code> OBJECT Full trigger payload including user ID, message ID, and bot token"},{"location":"components/triggers/telegram/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/telegram/#configuration","title":"Configuration","text":""},{"location":"components/triggers/telegram/#telegram-bot-credential","title":"Telegram Bot Credential","text":"<p>The Telegram Trigger requires a Telegram credential to be configured on the platform. This credential contains:</p> <ul> <li>Bot Token: The token from BotFather (e.g., <code>123456:ABC-DEF...</code>)</li> <li>Allowed User IDs (optional): Comma-separated list of Telegram user IDs that are permitted to interact with the bot. If empty, all users are allowed.</li> </ul> <p>Create a Telegram credential on the Credentials page before using this trigger.</p>"},{"location":"components/triggers/telegram/#trigger-level-matching","title":"Trigger-Level Matching","text":"<p>The trigger resolver supports optional matching rules in the trigger's configuration:</p> Config Field Description <code>allowed_user_ids</code> List of Telegram user IDs to accept (empty = all) <code>pattern</code> Regex pattern to match against message text <code>command</code> Telegram command to match (e.g., <code>start</code> matches <code>/start</code>) <p>These rules determine which workflow handles a given Telegram message when multiple workflows have Telegram triggers.</p>"},{"location":"components/triggers/telegram/#usage","title":"Usage","text":"<ol> <li>Create a Telegram bot via BotFather and obtain the bot token.</li> <li>Add a Telegram credential on the Credentials page with the bot token.</li> <li>Drag a Telegram Trigger onto the canvas.</li> <li>Connect it to an Agent or other downstream nodes.</li> <li>Set up the webhook URL to point to your Pipelit instance:</li> </ol> <pre><code>https://your-pipelit-domain/api/v1/telegram/webhook/{bot_token}/\n</code></pre>"},{"location":"components/triggers/telegram/#accessing-telegram-data-downstream","title":"Accessing Telegram Data Downstream","text":"<p>Reference trigger outputs using Jinja2 expressions:</p> <pre><code>{{ trigger.text }}       {# message text #}\n{{ trigger.chat_id }}    {# chat ID for replies #}\n{{ trigger.payload }}    {# full payload object #}\n</code></pre> <p>The payload object includes:</p> <pre><code>{\n  \"user_id\": 123456789,\n  \"chat_id\": 123456789,\n  \"message_id\": 42,\n  \"text\": \"Hello bot!\",\n  \"bot_token\": \"123456:ABC-DEF...\"\n}\n</code></pre>"},{"location":"components/triggers/telegram/#automatic-replies","title":"Automatic Replies","text":"<p>When the workflow execution completes, the delivery service automatically sends the agent's final output back to the Telegram chat as a reply. A typing indicator is displayed while the workflow is processing.</p>"},{"location":"components/triggers/telegram/#human-confirmation-via-telegram","title":"Human Confirmation via Telegram","text":"<p>If the workflow includes a Human Confirmation node downstream of the Telegram Trigger, the confirmation prompt is sent to the Telegram chat with inline buttons. The user can approve or cancel directly from Telegram using <code>/confirm_{task_id}</code> and <code>/cancel_{task_id}</code> commands, or the <code>/pending</code> command to list all pending confirmations.</p>"},{"location":"components/triggers/telegram/#example","title":"Example","text":"<p>A Telegram bot workflow with tool access:</p> <pre><code>graph LR\n    TT[Telegram Trigger] --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n    RC[Run Command] -.-&gt; AG\n    WS[Web Search] -.-&gt; AG\n\n    style TT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style RC fill:#10b981,color:white\n    style WS fill:#10b981,color:white</code></pre> <ol> <li>Telegram Trigger receives a message from a Telegram user.</li> <li>Agent processes the message with access to shell commands and web search tools.</li> <li>The agent's response is automatically delivered back to the Telegram chat.</li> </ol>"},{"location":"components/triggers/telegram/#filtered-trigger-for-specific-commands","title":"Filtered trigger for specific commands","text":"<pre><code>graph LR\n    TT1[Telegram Trigger&lt;br/&gt;pattern: /help] --&gt; A1[Help Agent]\n    TT2[Telegram Trigger&lt;br/&gt;catch-all] --&gt; A2[General Agent]\n\n    style TT1 fill:#f97316,color:white\n    style TT2 fill:#f97316,color:white</code></pre> <p>With pattern matching, different Telegram triggers can route specific commands to specialized agents while a catch-all handles everything else.</p>"},{"location":"components/triggers/telegram/#user-management","title":"User Management","text":"<p>When a Telegram user first interacts with the bot, Pipelit automatically creates a <code>UserProfile</code> for them using their Telegram user data (username, first name, last name). Subsequent messages from the same Telegram user ID are associated with the existing profile, enabling conversation memory continuity.</p>"},{"location":"components/triggers/workflow/","title":"Workflow","text":""},{"location":"components/triggers/workflow/#workflow-trigger","title":"Workflow Trigger","text":"<p>Trigger</p> <p>The Workflow Trigger is fired when a parent workflow invokes this workflow as a child. It receives the payload passed by the parent through a Subworkflow node or a Spawn &amp; Await tool, enabling hierarchical workflow composition.</p> <p>Component type: <code>trigger_workflow</code></p>"},{"location":"components/triggers/workflow/#ports","title":"Ports","text":""},{"location":"components/triggers/workflow/#outputs","title":"Outputs","text":"Port Type Description <code>payload</code> OBJECT Data passed from the parent workflow"},{"location":"components/triggers/workflow/#inputs","title":"Inputs","text":"<p>This component has no input ports. It is an entry point.</p>"},{"location":"components/triggers/workflow/#configuration","title":"Configuration","text":"<p>The Workflow Trigger supports an optional <code>source_workflow</code> field in its trigger configuration. When set, the trigger only fires for invocations from the specified parent workflow slug. When not set, it accepts invocations from any parent.</p>"},{"location":"components/triggers/workflow/#usage","title":"Usage","text":"<ol> <li>Create a child workflow that performs a specific task.</li> <li>Drag a Workflow Trigger onto the child workflow's canvas.</li> <li>Connect it to the nodes that process the incoming payload.</li> <li>In the parent workflow, use either:<ul> <li>A Subworkflow node (logic category) to invoke the child synchronously.</li> <li>A Spawn &amp; Await tool (self-awareness category) to invoke the child from within an agent's reasoning loop.</li> </ul> </li> </ol>"},{"location":"components/triggers/workflow/#accessing-parent-data","title":"Accessing Parent Data","text":"<p>The parent workflow's data is available through the <code>payload</code> output port:</p> <pre><code>{{ trigger.payload }}\n</code></pre> <p>The contents of the payload depend on what the parent sends. For a Subworkflow node, the payload is defined by the <code>input_mapping</code> configuration. For Spawn &amp; Await, the agent determines what data to pass.</p>"},{"location":"components/triggers/workflow/#source-workflow-filtering","title":"Source Workflow Filtering","text":"<p>When multiple parent workflows might invoke the same child, you can use the <code>source_workflow</code> trigger config to restrict which parent is allowed:</p> <pre><code>{\n  \"trigger_config\": {\n    \"source_workflow\": \"parent-workflow-slug\"\n  }\n}\n</code></pre> <p>If omitted, the trigger accepts invocations from any workflow.</p>"},{"location":"components/triggers/workflow/#example","title":"Example","text":"<p>A child workflow invoked by a parent:</p> <p>Parent workflow: </p><pre><code>graph LR\n    CT[Chat Trigger] --&gt; AG[Agent]\n    AG --&gt; SW[Subworkflow&lt;br/&gt;target: report-gen]\n    AM[AI Model] -.-&gt; AG\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre><p></p> <p>Child workflow (<code>report-gen</code>): </p><pre><code>graph LR\n    WT[Workflow Trigger] --&gt; CD[Code]\n    CD --&gt; AG2[Agent]\n    AM2[AI Model] -.-&gt; AG2\n\n    style WT fill:#f97316,color:white\n    style AM2 fill:#3b82f6,color:white</code></pre><p></p> <ol> <li>The parent's Chat Trigger receives a user request.</li> <li>The parent Agent decides to delegate to the <code>report-gen</code> child workflow.</li> <li>The Subworkflow node invokes the child, passing data via <code>input_mapping</code>.</li> <li>The child's Workflow Trigger receives the payload.</li> <li>The child's Code and Agent nodes process the request.</li> <li>The child's final output is returned to the parent's Subworkflow node.</li> </ol>"},{"location":"components/triggers/workflow/#agent-driven-child-invocation","title":"Agent-driven child invocation","text":"<p>When using Spawn &amp; Await as a tool connected to an agent, the agent autonomously decides when to invoke the child workflow and what data to pass:</p> <pre><code>graph LR\n    CT[Chat Trigger] --&gt; AG[Agent]\n    AM[AI Model] -.-&gt; AG\n    SA[Spawn &amp; Await] -.-&gt; AG\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style SA fill:#10b981,color:white</code></pre> <p>The agent calls the Spawn &amp; Await tool during its reasoning loop, specifying the target workflow slug and payload. The child workflow must have a Workflow Trigger to receive the invocation.</p>"},{"location":"concepts/","title":"Concepts","text":""},{"location":"concepts/#concepts","title":"Concepts","text":"<p>This section explains the core ideas behind Pipelit. Understanding these concepts will help you design effective workflows and get the most out of the platform.</p>"},{"location":"concepts/#workflows","title":"Workflows","text":"<p>The central organizing unit in Pipelit. A workflow is a visual pipeline you design on a canvas, connecting triggers, agents, tools, and logic nodes into an executable graph.</p>"},{"location":"concepts/#nodes-edges","title":"Nodes &amp; Edges","text":"<p>Nodes are the building blocks of workflows. Edges are the connections between them. Together they form a typed, directed graph with validated data flow.</p>"},{"location":"concepts/#triggers","title":"Triggers","text":"<p>Triggers are specialized nodes that initiate workflow execution. Pipelit supports chat, Telegram, manual, scheduled, workflow, and error triggers -- all as first-class nodes on the canvas.</p>"},{"location":"concepts/#agents","title":"Agents","text":"<p>LLM-powered nodes that reason, call tools, and produce responses. Agents use LangGraph's ReAct architecture and support conversation memory, tool calling, and model selection.</p>"},{"location":"concepts/#tools","title":"Tools","text":"<p>Sub-component nodes that give agents capabilities: execute shell commands, make HTTP requests, search the web, evaluate math, and check the current time.</p>"},{"location":"concepts/#expressions","title":"Expressions","text":"<p>Jinja2 template expressions let you reference upstream node outputs in system prompts and configuration fields. Use <code>{{ nodeId.portName }}</code> syntax with filters and fallbacks.</p>"},{"location":"concepts/#execution","title":"Execution","text":"<p>How workflows run: trigger-scoped compilation, topological node ordering, real-time WebSocket status updates, and result propagation through the graph.</p>"},{"location":"concepts/#memory","title":"Memory","text":"<p>Persistent knowledge storage across executions. Conversation memory gives agents continuity. Global memory stores facts, episodes, and procedures that any agent can recall.</p>"},{"location":"concepts/#epics-tasks","title":"Epics &amp; Tasks","text":"<p>A task delegation system for multi-agent coordination. Epics group related tasks with budgets and deadlines. Agents can create, query, and update them autonomously.</p>"},{"location":"concepts/#cost-tracking","title":"Cost Tracking","text":"<p>Per-execution token counting and USD cost calculation. Tracks input/output tokens across all LLM calls with Epic-level budget enforcement.</p>"},{"location":"concepts/#scheduler","title":"Scheduler","text":"<p>Self-rescheduling recurring execution without external cron. Configurable intervals, repeat counts, retry with exponential backoff, pause/resume, and crash recovery.</p>"},{"location":"concepts/#security","title":"Security","text":"<p>Authentication, authorization, credential encryption, and sandboxed code execution. Bearer token API keys, Fernet-encrypted secrets, and restricted execution environments.</p>"},{"location":"concepts/agents/","title":"Agents","text":""},{"location":"concepts/agents/#agents","title":"Agents","text":"<p>Agents are the core AI nodes in Pipelit. Each agent is a LangGraph ReAct agent -- an LLM that can reason about a task, decide which tools to call, observe the results, and iterate until it produces a final answer.</p>"},{"location":"concepts/agents/#how-react-agents-work","title":"How ReAct Agents Work","text":"<p>The ReAct (Reason + Act) pattern gives an LLM a loop:</p> <ol> <li>Reason -- the LLM reads the conversation so far and decides what to do next.</li> <li>Act -- if it needs more information, it calls one of its connected tools.</li> <li>Observe -- the tool result is appended to the conversation as a <code>ToolMessage</code>.</li> <li>Repeat -- the LLM reasons again with the new information, calling more tools or producing a final response.</li> </ol> <p>In Pipelit, this loop is powered by LangGraph's <code>create_react_agent()</code>. The agent continues reasoning and acting until it produces a text response without any tool calls.</p> <pre><code>sequenceDiagram\n    participant T as Trigger\n    participant O as Orchestrator\n    participant A as Agent Node\n    participant LLM as Language Model\n    participant Tool1 as run_command\n    participant Tool2 as web_search\n\n    T-&gt;&gt;O: User message arrives\n    O-&gt;&gt;A: Execute agent with messages\n    A-&gt;&gt;LLM: Messages + system prompt\n    LLM--&gt;&gt;A: Tool call: web_search(\"latest news\")\n    A-&gt;&gt;Tool2: Invoke web_search\n    Tool2--&gt;&gt;A: Search results\n    A-&gt;&gt;LLM: Messages + tool result\n    LLM--&gt;&gt;A: Tool call: run_command(\"curl ...\")\n    A-&gt;&gt;Tool1: Invoke run_command\n    Tool1--&gt;&gt;A: Command output\n    A-&gt;&gt;LLM: Messages + tool result\n    LLM--&gt;&gt;A: Final text response\n    A--&gt;&gt;O: {\"output\": \"Here is what I found...\", \"_messages\": [...]}</code></pre>"},{"location":"concepts/agents/#agent-sub-components","title":"Agent Sub-Components","text":"<p>Every agent node has diamond-shaped handles on its bottom edge for connecting sub-components:</p> Sub-Component Handle Color Required Purpose Model Blue (<code>#3b82f6</code>) Yes The LLM provider and model to use Tools Green (<code>#10b981</code>) No LangChain tools the agent can call Memory Amber (<code>#f59e0b</code>) No Global memory read/write access <p>Model is Required</p> <p>Every agent node must have an AI Model sub-component connected via the blue \"model\" handle. Without it, the agent cannot resolve which LLM to use and will fail at build time. The model node's credential and model name (e.g., <code>gpt-4o</code>, <code>claude-sonnet-4-20250514</code>) are set in its configuration panel.</p>"},{"location":"concepts/agents/#system-prompts","title":"System Prompts","text":"<p>The system prompt defines the agent's personality, instructions, and constraints. It is delivered to the LLM in two ways:</p> <ol> <li>SystemMessage -- passed via <code>create_react_agent(prompt=SystemMessage(...))</code> for the standard system role.</li> <li>HumanMessage fallback -- a <code>HumanMessage</code> with a stable ID prefixed with <code>[System instructions]</code> is prepended to the conversation. This handles LLM providers (e.g., Venice.ai) that ignore the system role entirely.</li> </ol> <p>The stable ID (<code>system_prompt_fallback</code>) prevents the fallback message from being duplicated across checkpointer invocations, thanks to LangGraph's <code>add_messages</code> reducer which deduplicates by message ID.</p>"},{"location":"concepts/agents/#jinja2-template-support","title":"Jinja2 Template Support","text":"<p>System prompts support Jinja2 template expressions. Before the agent executes, the orchestrator resolves <code>{{ }}</code> expressions against upstream node outputs and trigger data:</p> <pre><code>You are a customer support agent for {{ trigger.payload.company_name }}.\nThe user said: {{ trigger.text }}\nPrevious analysis: {{ categorizer_abc123.category }}\n</code></pre> <p>See the Expressions concept page for full details.</p>"},{"location":"concepts/agents/#tool-calling","title":"Tool Calling","text":"<p>Agents invoke tools through LangChain's function-calling interface. At build time, the agent queries all edges with <code>edge_label=\"tool\"</code> pointing to it, loads each connected tool node's factory, and registers the resulting <code>@tool</code> functions.</p> <p>When the LLM decides to call a tool during reasoning:</p> <ol> <li>The tool's wrapper publishes a <code>node_status</code> WebSocket event with <code>status: \"running\"</code> for the tool node.</li> <li>The tool function executes (e.g., running a shell command, making an HTTP request).</li> <li>On completion, a <code>node_status</code> event with <code>status: \"success\"</code> or <code>status: \"failed\"</code> is published.</li> <li>The tool result is returned to the LLM as a <code>ToolMessage</code>.</li> </ol> <p>This means tool nodes on the canvas show real-time status badges (spinning circle, checkmark, or X) as the agent uses them.</p> <p>Tools Without Tool Calls</p> <p>If an agent has no tools connected, it strips any <code>ToolMessage</code> and tool-call AI messages from upstream agents to avoid confusing the LLM with foreign tool calls it cannot handle.</p>"},{"location":"concepts/agents/#conversation-memory","title":"Conversation Memory","text":"<p>By default, agents are stateless -- each execution starts with a fresh conversation. Enabling Conversation Memory persists the conversation history across executions so the agent remembers prior interactions.</p>"},{"location":"concepts/agents/#how-it-works","title":"How It Works","text":"<p>When conversation memory is enabled (toggle in the Node Details Panel):</p> <ul> <li>A SqliteSaver checkpointer stores the full conversation state in <code>platform/checkpoints.db</code>.</li> <li>Each invocation uses a thread ID to identify which conversation to resume.</li> <li>The checkpointer is a lazy singleton -- initialized once and reused across all executions.</li> </ul>"},{"location":"concepts/agents/#thread-id-construction","title":"Thread ID Construction","text":"<p>The thread ID determines which conversation history an agent loads. It is constructed from three components:</p> <pre><code>{user_profile_id}:{telegram_chat_id}:{workflow_id}\n</code></pre> Component Source Purpose <code>user_profile_id</code> <code>state[\"user_context\"]</code> Identifies the human user <code>telegram_chat_id</code> <code>state[\"user_context\"]</code> Separates Telegram chats (omitted if empty) <code>workflow_id</code> Agent node's workflow Isolates conversations per workflow <p>This means:</p> <ul> <li>The same user talking to the same workflow always gets the same conversation thread.</li> <li>Different users get separate threads even on the same workflow.</li> <li>Different Telegram chats (group vs. DM) get separate threads.</li> <li>If there is no Telegram chat ID, the thread ID simplifies to <code>{user_profile_id}:{workflow_id}</code>.</li> </ul> <p>Ephemeral Checkpoints for Spawn &amp; Await</p> <p>If an agent has a <code>spawn_and_await</code> tool connected but conversation memory is disabled, a RedisSaver checkpointer is used instead of SqliteSaver. This ephemeral checkpointer only persists state long enough for the child workflow to complete and the agent to resume. The thread ID uses the format <code>exec:{execution_id}:{node_id}</code>.</p>"},{"location":"concepts/agents/#stale-checkpoint-cleanup","title":"Stale Checkpoint Cleanup","text":"<p>When an execution fails (especially mid-interrupt during <code>spawn_and_await</code>), the SqliteSaver checkpoint may retain orphaned tool calls with no matching <code>ToolMessage</code>. On the next conversation turn, this would cause an <code>INVALID_CHAT_HISTORY</code> error. Pipelit automatically detects and deletes stale checkpoints for failed executions to prevent this.</p>"},{"location":"concepts/agents/#agent-output","title":"Agent Output","text":"<p>When an agent finishes its reasoning loop, the component returns:</p> Key Type Description <code>output</code> <code>string</code> The final text content from the last AI message <code>_messages</code> <code>list</code> All messages from the agent's execution (appended to workflow state) <code>_token_usage</code> <code>dict</code> Token counts, cost in USD, and tool invocation count <p>The <code>output</code> value is what downstream nodes see in <code>{{ agent_abc123.output }}</code>. The <code>_messages</code> list preserves the full conversation including tool calls and responses for logging and downstream agents.</p>"},{"location":"concepts/agents/#configuration-reference","title":"Configuration Reference","text":"Setting Location Description System Prompt Node Details Panel Instructions and persona for the agent Conversation Memory Extra Config toggle Enable/disable cross-execution memory LLM Model Connected AI Model node Which provider and model to use Tools Connected tool nodes Which tools the agent can call"},{"location":"concepts/cost-tracking/","title":"Cost Tracking","text":""},{"location":"concepts/cost-tracking/#cost-tracking","title":"Cost Tracking","text":"<p>Pipelit tracks token usage and USD costs for every LLM call across every execution. Costs roll up from individual nodes to executions, from executions to tasks, and from tasks to epics -- giving you visibility at every level and enabling budget enforcement that prevents runaway spending.</p>"},{"location":"concepts/cost-tracking/#how-costs-are-tracked","title":"How costs are tracked","text":"<pre><code>flowchart TB\n    subgraph Execution\n        N1[Node 1\\n+150 input, +80 output] --&gt; Acc[Accumulator\\n_execution_token_usage]\n        N2[Node 2\\n+200 input, +120 output] --&gt; Acc\n        N3[Node 3\\n+500 input, +300 output] --&gt; Acc\n    end\n\n    Acc --&gt;|persist on completion| Exec[WorkflowExecution\\ntotal_tokens, total_cost_usd]\n    Exec --&gt;|sync to linked task| Task[Task\\nactual_tokens, actual_usd]\n    Task --&gt;|roll up to epic| Epic[Epic\\nspent_tokens, spent_usd]</code></pre>"},{"location":"concepts/cost-tracking/#per-node-token-extraction","title":"Per-node token extraction","text":"<p>After each node executes, the orchestrator extracts token usage from the component's output via the <code>_token_usage</code> reserved key. The token usage dict contains:</p> Field Description <code>input_tokens</code> Tokens sent to the LLM (prompt + context) <code>output_tokens</code> Tokens generated by the LLM (response) <code>total_tokens</code> Sum of input and output tokens <code>llm_calls</code> Number of LLM API calls in this node <p>For agent nodes that make multiple LLM calls (e.g., during a ReAct reasoning loop with tool calls), the usage is extracted from all AI messages in the conversation via <code>extract_usage_from_messages()</code>.</p>"},{"location":"concepts/cost-tracking/#execution-level-accumulation","title":"Execution-level accumulation","text":"<p>Token usage from each node is merged into a running total stored in the execution state as <code>_execution_token_usage</code>:</p> <pre><code>state[\"_execution_token_usage\"] = merge_usage(existing_usage, node_usage)\n</code></pre> <p>The <code>merge_usage()</code> function sums all numeric fields across the two dicts. When the execution completes (success or failure), the accumulated totals are persisted to the <code>WorkflowExecution</code> model.</p>"},{"location":"concepts/cost-tracking/#usd-cost-calculation","title":"USD cost calculation","text":"<p>USD cost is calculated using a built-in pricing table that maps model name prefixes to per-million-token rates:</p> Model Prefix Input (per 1M tokens) Output (per 1M tokens) <code>gpt-4o-mini</code> $0.15 $0.60 <code>gpt-4o</code> $2.50 $10.00 <code>gpt-4-turbo</code> $10.00 $30.00 <code>gpt-4</code> $30.00 $60.00 <code>gpt-3.5-turbo</code> $0.50 $1.50 <code>o3-mini</code> $1.10 $4.40 <code>o1-mini</code> $3.00 $12.00 <code>o1</code> $15.00 $60.00 <code>claude-3-5-sonnet</code> $3.00 $15.00 <code>claude-3-5-haiku</code> $0.80 $4.00 <code>claude-3-opus</code> $15.00 $75.00 <code>claude-sonnet-4</code> $3.00 $15.00 <code>claude-opus-4</code> $15.00 $75.00 <p>The pricing lookup uses longest prefix matching -- the model name is compared against prefixes in order, so <code>gpt-4o-mini-2024-07-18</code> correctly matches the <code>gpt-4o-mini</code> rate rather than the more expensive <code>gpt-4o</code> rate.</p> <p>Unknown models</p> <p>Models that do not match any known prefix are tracked with <code>$0.00</code> cost. Token counts are still recorded accurately -- only the USD calculation is skipped.</p> <p>The cost formula is:</p> <pre><code>cost_usd = (input_tokens * input_rate + output_tokens * output_rate) / 1,000,000\n</code></pre>"},{"location":"concepts/cost-tracking/#execution-cost-fields","title":"Execution cost fields","text":"<p>Every <code>WorkflowExecution</code> records:</p> Field Type Description <code>total_input_tokens</code> int Total input tokens across all nodes <code>total_output_tokens</code> int Total output tokens across all nodes <code>total_tokens</code> int Sum of input + output tokens <code>total_cost_usd</code> decimal Calculated USD cost <code>llm_calls</code> int Total number of LLM API calls <p>These fields are populated when the execution completes (or fails) via <code>_persist_execution_costs()</code>.</p>"},{"location":"concepts/cost-tracking/#epic-level-budget-enforcement","title":"Epic-level budget enforcement","text":"<p>When an execution is linked to a task within an epic, the orchestrator enforces budget limits before every node execution.</p> <pre><code>flowchart TD\n    Start[Node about to execute] --&gt; Check{Budget check}\n    Check --&gt;|within budget| Execute[Execute node]\n    Check --&gt;|tokens exceeded| Fail[Fail execution]\n    Check --&gt;|USD exceeded| Fail\n    Check --&gt;|no epic linked| Execute\n    Execute --&gt; Next[Continue workflow]\n    Fail --&gt; Stop[Execution status: failed]</code></pre>"},{"location":"concepts/cost-tracking/#how-budget-enforcement-works","title":"How budget enforcement works","text":"<p>The <code>_check_budget()</code> function runs before each node in the orchestrator:</p> <ol> <li>Look up the <code>Task</code> linked to this execution (via <code>Task.execution_id</code>)</li> <li>If no task or no epic, skip budget checks</li> <li>Read the current execution's accumulated token usage from state</li> <li>Token budget: Add current execution tokens to the epic's <code>spent_tokens</code>. If the total exceeds <code>epic.budget_tokens</code>, fail the execution.</li> <li>USD budget: Add current execution cost to the epic's <code>spent_usd</code>. If the total exceeds <code>epic.budget_usd</code>, fail the execution.</li> </ol> <p>Budget overruns are hard stops</p> <p>When a budget is exceeded, the execution is immediately marked as <code>failed</code> with a descriptive error message. The execution's accumulated costs are persisted, and the task and epic costs are synced before the failure is broadcast.</p>"},{"location":"concepts/cost-tracking/#cost-roll-up","title":"Cost roll-up","text":"<p>When a child execution completes, the orchestrator syncs costs in two steps:</p> <p>Step 1 -- Execution to task:</p> <pre><code>task.actual_tokens = execution.total_tokens\ntask.actual_usd = float(execution.total_cost_usd)\ntask.llm_calls = execution.llm_calls\ntask.tool_invocations = exec_usage.get(\"tool_invocations\", 0)\n</code></pre> <p>Step 2 -- Tasks to epic (recalculated, not incremental):</p> <pre><code>epic.spent_tokens = SUM(task.actual_tokens) for all tasks in epic\nepic.spent_usd = SUM(task.actual_usd) for all tasks in epic\n</code></pre> <p>The epic totals are always recalculated from scratch by summing all task costs. This avoids double-counting issues that could arise from incremental updates.</p>"},{"location":"concepts/cost-tracking/#monitoring-costs","title":"Monitoring costs","text":""},{"location":"concepts/cost-tracking/#execution-detail-page","title":"Execution detail page","text":"<p>The Execution Detail page (<code>/executions/:id</code>) displays token counts and cost for each completed execution.</p>"},{"location":"concepts/cost-tracking/#websocket-events","title":"WebSocket events","text":"<p>Node-level token usage is included in <code>node_status</code> WebSocket events when a node completes with <code>status: success</code>:</p> <pre><code>{\n  \"type\": \"node_status\",\n  \"node_id\": \"agent_abc123\",\n  \"status\": \"success\",\n  \"token_usage\": {\n    \"input_tokens\": 1500,\n    \"output_tokens\": 450,\n    \"total_tokens\": 1950,\n    \"llm_calls\": 3\n  }\n}\n</code></pre>"},{"location":"concepts/cost-tracking/#api-endpoints","title":"API endpoints","text":"<p>Query execution costs via the REST API:</p> Endpoint Description <code>GET /api/v1/executions/</code> List executions with cost fields <code>GET /api/v1/executions/{id}/</code> Execution detail including token counts and USD cost <p>Epic and task costs are available through the <code>epic_tools</code> and <code>task_tools</code> agent tools (e.g., <code>epic_status</code> returns <code>spent_tokens</code> and <code>spent_usd</code>).</p>"},{"location":"concepts/cost-tracking/#whats-next","title":"What's next?","text":"<ul> <li>Learn how epics organize tasks with budgets: Epics &amp; Tasks</li> <li>Understand how workflows execute: Execution</li> <li>Configure recurring executions: Scheduler</li> </ul>"},{"location":"concepts/epics-and-tasks/","title":"Epics & Tasks","text":""},{"location":"concepts/epics-and-tasks/#epics-tasks","title":"Epics &amp; Tasks","text":"<p>Epics and tasks form Pipelit's multi-agent delegation system. An epic is a high-level objective that gets decomposed into individual tasks, each of which can be executed by a separate workflow. This enables a main orchestrator agent to plan, delegate, track, and budget complex multi-step operations.</p>"},{"location":"concepts/epics-and-tasks/#overview","title":"Overview","text":"<pre><code>flowchart TB\n    MainAgent[\"Main Agent\\n(orchestrator)\"] --&gt;|creates| Epic\n    MainAgent --&gt;|decomposes into| T1[Task 1]\n    MainAgent --&gt;|decomposes into| T2[Task 2]\n    MainAgent --&gt;|decomposes into| T3[Task 3]\n    T2 --&gt;|depends_on| T1\n    T3 --&gt;|depends_on| T1\n\n    T1 --&gt;|spawn_and_await| W1[\"Child Workflow A\"]\n    T2 --&gt;|spawn_and_await| W2[\"Child Workflow B\"]\n    T3 --&gt;|spawn_and_await| W3[\"Child Workflow C\"]\n\n    W1 --&gt;|result| T1\n    W2 --&gt;|result| T2\n    W3 --&gt;|result| T3</code></pre> <p>The pattern works as follows:</p> <ol> <li>A main agent receives a complex objective</li> <li>It creates an epic to represent the objective</li> <li>It decomposes the epic into tasks with dependencies</li> <li>Each task is executed by spawning a child workflow via <code>spawn_and_await</code></li> <li>Results flow back, costs are tracked, and the epic status updates automatically</li> </ol>"},{"location":"concepts/epics-and-tasks/#epics","title":"Epics","text":"<p>An epic is a high-level objective that groups related tasks. It carries metadata for tracking progress, managing budgets, and recording outcomes.</p>"},{"location":"concepts/epics-and-tasks/#epic-fields","title":"Epic fields","text":"Field Type Description <code>id</code> string Auto-generated ID (e.g., <code>ep-a1b2c3d4e5f6</code>) <code>title</code> string Human-readable objective title <code>description</code> text Detailed description of the objective <code>tags</code> JSON list Labels for categorization and search <code>status</code> string Current lifecycle state <code>priority</code> int Priority level 1--5 (1 = highest) <code>budget_tokens</code> int Optional token budget limit <code>budget_usd</code> decimal Optional USD budget limit <code>spent_tokens</code> int Total tokens consumed across all tasks <code>spent_usd</code> decimal Total USD spent across all tasks <code>total_tasks</code> int Number of tasks in this epic <code>completed_tasks</code> int Number of successfully completed tasks <code>failed_tasks</code> int Number of failed tasks <code>result_summary</code> text Summary of the outcome when completed"},{"location":"concepts/epics-and-tasks/#epic-lifecycle","title":"Epic lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; planning\n    planning --&gt; active : start work\n    active --&gt; paused : pause\n    paused --&gt; active : resume\n    active --&gt; completed : all tasks done\n    active --&gt; failed : unrecoverable error\n    active --&gt; cancelled : user cancels\n    planning --&gt; cancelled : user cancels\n    paused --&gt; cancelled : user cancels\n    completed --&gt; [*]\n    failed --&gt; [*]\n    cancelled --&gt; [*]</code></pre> Status Meaning <code>planning</code> Epic created, tasks being defined <code>active</code> Work is in progress <code>paused</code> Temporarily halted <code>completed</code> All tasks finished successfully <code>failed</code> Unrecoverable failure <code>cancelled</code> Manually cancelled (cascades to pending/blocked/running tasks) <p>Cancellation cascade</p> <p>When an epic is cancelled, all of its tasks with status <code>pending</code>, <code>blocked</code>, or <code>running</code> are automatically set to <code>cancelled</code>.</p>"},{"location":"concepts/epics-and-tasks/#cost-tracking-on-epics","title":"Cost tracking on epics","text":"<p>Epics track spending at two levels:</p> <ul> <li>Task-level costs (<code>spent_tokens</code>, <code>spent_usd</code>): Rolled up from the <code>actual_tokens</code> and <code>actual_usd</code> fields of all tasks in the epic.</li> <li>Agent overhead (<code>agent_overhead_tokens</code>, <code>agent_overhead_usd</code>): Tokens consumed by the orchestrator agent itself (planning, reasoning, tool calls) as distinct from child workflow execution.</li> </ul> <p>Budget enforcement is checked before every node execution. See Cost Tracking for details.</p>"},{"location":"concepts/epics-and-tasks/#tasks","title":"Tasks","text":"<p>A task is an individual work item within an epic. Tasks have dependencies, lifecycle tracking, cost accounting, and can be linked to workflow executions.</p>"},{"location":"concepts/epics-and-tasks/#task-fields","title":"Task fields","text":"Field Type Description <code>id</code> string Auto-generated ID (e.g., <code>tk-a1b2c3d4e5f6</code>) <code>epic_id</code> string Parent epic (cascade delete) <code>title</code> string What this task accomplishes <code>description</code> text Detailed instructions <code>tags</code> JSON list Labels for filtering <code>status</code> string Current lifecycle state <code>priority</code> int Priority 1--5 <code>depends_on</code> JSON list List of task IDs that must complete first <code>workflow_slug</code> string Target workflow to execute for this task <code>execution_id</code> string Linked execution ID once spawned <code>estimated_tokens</code> int Token cost estimate <code>actual_tokens</code> int Actual tokens consumed <code>actual_usd</code> decimal Actual USD spent <code>llm_calls</code> int Number of LLM API calls made <code>tool_invocations</code> int Number of tool calls made <code>duration_ms</code> int Execution wall-clock time <code>result_summary</code> text Outcome summary <code>error_message</code> text Error details if failed <code>retry_count</code> int Current retry attempt <code>max_retries</code> int Maximum retry attempts (default 2) <code>notes</code> JSON list Append-only notes log"},{"location":"concepts/epics-and-tasks/#task-lifecycle","title":"Task lifecycle","text":"<pre><code>stateDiagram-v2\n    [*] --&gt; pending\n    [*] --&gt; blocked : has unfinished dependencies\n    blocked --&gt; pending : dependencies completed\n    pending --&gt; running : execution starts\n    running --&gt; completed : success\n    running --&gt; failed : error\n    failed --&gt; pending : retry\n    pending --&gt; cancelled : cancelled\n    blocked --&gt; cancelled : cancelled\n    running --&gt; cancelled : cancelled\n    completed --&gt; [*]\n    cancelled --&gt; [*]</code></pre> Status Meaning <code>pending</code> Ready to execute (all dependencies met) <code>blocked</code> Waiting for dependent tasks to complete <code>running</code> Currently executing in a child workflow <code>completed</code> Finished successfully <code>failed</code> Execution failed <code>cancelled</code> Manually cancelled <p>Automatic dependency resolution</p> <p>When a task is created with <code>depends_on</code> IDs, it automatically starts in <code>blocked</code> status if any dependencies are not yet completed. When a dependency completes, all tasks that were blocked on it are automatically checked and unblocked if all their dependencies are now satisfied.</p>"},{"location":"concepts/epics-and-tasks/#multi-agent-delegation","title":"Multi-agent delegation","text":"<p>The delegation pattern connects epic/task management with Pipelit's workflow execution engine through the <code>spawn_and_await</code> tool.</p> <pre><code>sequenceDiagram\n    participant Main as Main Agent\n    participant Epic as Epic Tools\n    participant Task as Task Tools\n    participant Spawn as spawn_and_await\n    participant Child as Child Workflow\n\n    Main-&gt;&gt;Epic: create_epic(title, budget)\n    Epic--&gt;&gt;Main: epic_id\n\n    Main-&gt;&gt;Task: create_task(epic_id, title, depends_on)\n    Task--&gt;&gt;Main: task_id (status: pending)\n\n    Main-&gt;&gt;Task: update_task(task_id, status: running)\n    Main-&gt;&gt;Spawn: spawn_and_await(workflow_slug, task_id)\n\n    Note over Main: Agent pauses (LangGraph interrupt)\n\n    Spawn-&gt;&gt;Child: Execute child workflow\n    Child--&gt;&gt;Spawn: Result + cost data\n\n    Note over Main: Agent resumes\n\n    Spawn--&gt;&gt;Main: Child output (JSON)\n\n    Note over Main: Orchestrator syncs costs to task and epic\n\n    Main-&gt;&gt;Task: update_task(task_id, status: completed, result_summary)\n    Main-&gt;&gt;Epic: update_epic(epic_id, status: completed)</code></pre>"},{"location":"concepts/epics-and-tasks/#spawn_and_await","title":"spawn_and_await","text":"<p>The <code>spawn_and_await</code> tool is how an agent launches a child workflow and waits for its result:</p> <ol> <li>The agent calls <code>spawn_and_await(workflow_slug, input_text, task_id)</code></li> <li>LangGraph's <code>interrupt()</code> pauses the agent at the tool-call boundary</li> <li>The orchestrator spawns the child workflow execution</li> <li>When the child completes, the orchestrator resumes the parent with the child's output</li> <li>If the child fails, a <code>ToolException</code> is raised so the agent can handle the error</li> </ol> <p>Long-running operations</p> <p><code>spawn_and_await</code> uses LangGraph checkpointing to pause the parent agent. The parent workflow's execution is interrupted and resumed asynchronously. This means the parent is not consuming resources while waiting.</p>"},{"location":"concepts/epics-and-tasks/#cost-synchronization","title":"Cost synchronization","text":"<p>When a child execution completes, the orchestrator automatically:</p> <ol> <li>Copies token counts and USD cost from the execution to the linked task</li> <li>Recalculates the epic's <code>spent_tokens</code> and <code>spent_usd</code> by summing all task costs</li> <li>Records <code>llm_calls</code> and <code>tool_invocations</code> on the task</li> </ol> <p>This ensures the epic always reflects the true total cost across all child executions without double-counting.</p>"},{"location":"concepts/epics-and-tasks/#tool-components","title":"Tool components","text":""},{"location":"concepts/epics-and-tasks/#epic_tools","title":"epic_tools","text":"<p>The <code>epic_tools</code> component provides four LangChain tools for agents:</p> Tool Description <code>create_epic</code> Create a new epic with title, description, tags, priority, and optional budget <code>epic_status</code> Get detailed epic status including task breakdown and cost summary <code>update_epic</code> Update any epic field (status, title, priority, budgets, result summary) <code>search_epics</code> Search epics by text, tags, or status with aggregate statistics"},{"location":"concepts/epics-and-tasks/#task_tools","title":"task_tools","text":"<p>The <code>task_tools</code> component provides four LangChain tools for agents:</p> Tool Description <code>create_task</code> Create a task within an epic, with dependencies, tags, and token estimates <code>list_tasks</code> List tasks in an epic, optionally filtered by status or tags <code>update_task</code> Update task fields (status, title, priority, result summary, notes) <code>cancel_task</code> Cancel a task and optionally its linked execution"},{"location":"concepts/epics-and-tasks/#connecting-tools-to-an-agent","title":"Connecting tools to an agent","text":"<p>On the workflow canvas, connect <code>epic_tools</code> and <code>task_tools</code> nodes to an agent via the tools handle (green diamond). You will typically also connect <code>spawn_and_await</code> so the agent can delegate tasks to child workflows.</p> <pre><code>flowchart LR\n    Trigger[Chat Trigger] --&gt; Agent\n    Model[AI Model] -.-&gt;|model| Agent\n    ET[epic_tools] -.-&gt;|tool| Agent\n    TT[task_tools] -.-&gt;|tool| Agent\n    SA[spawn_and_await] -.-&gt;|tool| Agent</code></pre>"},{"location":"concepts/epics-and-tasks/#websocket-events","title":"WebSocket events","text":"<p>Epic and task mutations broadcast real-time events over the global WebSocket:</p> Event Channel Payload <code>epic_created</code> <code>epic:{epic_id}</code> Full epic serialization <code>epic_updated</code> <code>epic:{epic_id}</code> Full epic serialization <code>task_created</code> <code>epic:{epic_id}</code> Full task serialization <code>task_updated</code> <code>epic:{epic_id}</code> Full task serialization"},{"location":"concepts/epics-and-tasks/#whats-next","title":"What's next?","text":"<ul> <li>Understand how costs are tracked and budgets enforced: Cost Tracking</li> <li>Learn about agent capabilities: Agents</li> <li>See how workflows are scheduled: Scheduler</li> </ul>"},{"location":"concepts/execution/","title":"Execution","text":""},{"location":"concepts/execution/#execution","title":"Execution","text":"<p>An execution is a single run of a workflow. When a trigger fires, Pipelit compiles the reachable portion of the workflow into a directed graph, then the orchestrator runs each node asynchronously via RQ workers, broadcasting status updates over WebSocket in real time.</p>"},{"location":"concepts/execution/#execution-lifecycle","title":"Execution Lifecycle","text":"<pre><code>sequenceDiagram\n    participant Trigger as Trigger (chat/telegram/schedule)\n    participant Handler as Trigger Handler\n    participant DB as Database\n    participant Builder as Topology Builder\n    participant Redis as Redis State\n    participant RQ as RQ Worker\n    participant Orch as Orchestrator\n    participant WS as WebSocket\n    participant UI as Frontend\n\n    Trigger-&gt;&gt;Handler: Event arrives\n    Handler-&gt;&gt;DB: Create WorkflowExecution (status: pending)\n    Handler-&gt;&gt;RQ: Enqueue start_execution job\n\n    RQ-&gt;&gt;Orch: start_execution(execution_id)\n    Orch-&gt;&gt;DB: Set status: running\n    Orch-&gt;&gt;WS: execution_started\n    WS-&gt;&gt;UI: Reset node statuses\n\n    Orch-&gt;&gt;Builder: build_topology(workflow, trigger_node_id)\n    Builder-&gt;&gt;DB: Query nodes &amp; edges\n    Builder--&gt;&gt;Orch: Topology (entry nodes, edges, fan-in counts)\n    Orch-&gt;&gt;Redis: Save topology + initial state\n\n    loop For each entry node\n        Orch-&gt;&gt;RQ: Enqueue execute_node_job\n    end\n\n    RQ-&gt;&gt;Orch: execute_node_job(execution_id, node_id)\n    Orch-&gt;&gt;WS: node_status: running\n    WS-&gt;&gt;UI: Show spinning badge\n    Orch-&gt;&gt;Orch: Resolve expressions, load component, execute\n    Orch-&gt;&gt;Redis: Merge result into state\n    Orch-&gt;&gt;DB: Write ExecutionLog\n    Orch-&gt;&gt;WS: node_status: success (with output)\n    WS-&gt;&gt;UI: Show checkmark badge + output link\n\n    Orch-&gt;&gt;Orch: Advance to successor nodes\n    Note over Orch,RQ: Repeat for each downstream node\n\n    Orch-&gt;&gt;DB: Set status: completed, extract final output\n    Orch-&gt;&gt;WS: execution_completed\n    WS-&gt;&gt;UI: Update execution status\n    Orch-&gt;&gt;Redis: Cleanup execution keys</code></pre>"},{"location":"concepts/execution/#trigger-scoped-execution","title":"Trigger-Scoped Execution","text":"<p>When a trigger fires, the builder does not compile the entire workflow. Instead, it performs a BFS (breadth-first search) from the trigger node over direct edges to find all reachable downstream nodes. Only these nodes are included in the execution.</p> <p>This design enables several patterns:</p> <ul> <li>Multiple trigger branches -- a single workflow can have a chat trigger and a Telegram trigger, each leading to different processing paths. Firing one trigger does not execute the other branch.</li> <li>Unused nodes -- nodes that are not connected to any trigger (e.g., nodes being configured but not yet wired in) are silently ignored.</li> <li>No build errors from disconnected nodes -- incomplete branches do not cause validation failures during execution.</li> </ul> <p>Sub-Component Exclusion</p> <p>Sub-components (<code>ai_model</code>, tools, <code>output_parser</code>, <code>memory_read</code>, <code>memory_write</code>, etc.) are excluded from the execution graph even if reachable. They are resolved at build time by their parent nodes, not executed independently by the orchestrator.</p>"},{"location":"concepts/execution/#node-status-lifecycle","title":"Node Status Lifecycle","text":"<p>Each node in an execution progresses through a status lifecycle:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; pending : Node enqueued on RQ\n    pending --&gt; running : Worker picks up job\n    running --&gt; success : Component returns result\n    running --&gt; failed : Component raises exception\n    running --&gt; waiting : Subworkflow spawned\n    running --&gt; skipped : Condition not met\n    failed --&gt; running : Retry (up to 3 attempts)\n    waiting --&gt; running : Child execution completes</code></pre> Status Description Canvas Badge <code>pending</code> Node is queued on RQ, waiting for a worker -- <code>running</code> Node component is currently executing Spinning circle <code>success</code> Node completed and produced output Green checkmark <code>failed</code> Node raised an exception after all retries Red X <code>skipped</code> Node was skipped (e.g., conditional routing took another path) Gray dash <code>waiting</code> Node is waiting for a child subworkflow to complete --"},{"location":"concepts/execution/#retry-logic","title":"Retry Logic","text":"<p>If a node raises an exception, the orchestrator retries it up to 3 times with exponential backoff:</p> Attempt Delay 1st retry 1 second 2nd retry 2 seconds 3rd retry 4 seconds <p>After 3 failed attempts, the execution fails with the error from the last attempt, unless the node is inside a loop body with <code>on_error=continue</code>, in which case the loop advances to the next iteration.</p>"},{"location":"concepts/execution/#executionlog-entries","title":"ExecutionLog Entries","text":"<p>Every node execution produces an <code>ExecutionLog</code> entry in the database:</p> Field Type Description <code>execution_id</code> <code>UUID</code> Parent execution <code>node_id</code> <code>string</code> Which node ran <code>status</code> <code>string</code> <code>completed</code> or <code>failed</code> <code>duration_ms</code> <code>int</code> Wall-clock execution time in milliseconds <code>output</code> <code>dict</code> Node output (for successful executions) <code>error</code> <code>string</code> Error message (for failed executions, truncated to 2,000 chars) <code>error_code</code> <code>string</code> Exception class name (e.g., <code>ValueError</code>, <code>TimeoutError</code>) <code>log_metadata</code> <code>dict</code> Additional metadata including token usage <p>Logs are visible on the Execution Detail page, where each row can be expanded to show the full output in a <code>&lt;pre&gt;</code> block.</p>"},{"location":"concepts/execution/#noderesult","title":"NodeResult","text":"<p>The orchestrator wraps every node's raw output into a <code>NodeResult</code> Pydantic model:</p> <pre><code>class NodeResult(BaseModel):\n    status: NodeStatus       # success, failed, skipped\n    data: dict[str, Any]     # The component's output data\n    error: NodeError | None  # Error details if failed\n    metadata: dict[str, Any] # Token usage, timing, etc.\n    started_at: datetime\n    completed_at: datetime\n</code></pre> <p>Factory methods provide a clean API for creating results:</p> <ul> <li><code>NodeResult.success(data={...})</code> -- successful execution with output data.</li> <li><code>NodeResult.failed(error_code=\"ValueError\", message=\"...\")</code> -- failed execution with error details.</li> <li><code>NodeResult.skipped(reason=\"Route did not match\")</code> -- skipped node with explanation.</li> </ul> <p>All <code>NodeResult</code> objects are stored in <code>state[\"node_results\"]</code> keyed by node ID and persisted to Redis during execution.</p>"},{"location":"concepts/execution/#rq-worker-processing","title":"RQ Worker Processing","text":"<p>Executions run asynchronously on RQ (Redis Queue) workers:</p> <ol> <li>Trigger handlers enqueue a <code>start_execution</code> job on the <code>workflows</code> queue.</li> <li>The <code>start_execution</code> job builds the topology, initializes state, and enqueues one <code>execute_node_job</code> per entry node.</li> <li>Each <code>execute_node_job</code> executes a single node, then enqueues jobs for successor nodes.</li> <li>When no more in-flight nodes remain, the orchestrator finalizes the execution.</li> </ol> <pre><code>RQ Queue: \"workflows\"\n\u251c\u2500\u2500 start_execution(exec_id)\n\u2502   \u251c\u2500\u2500 execute_node_job(exec_id, node_A)\n\u2502   \u2502   \u251c\u2500\u2500 execute_node_job(exec_id, node_B)\n\u2502   \u2502   \u2514\u2500\u2500 execute_node_job(exec_id, node_C)  # fan-out\n\u2502   \u2502       \u2514\u2500\u2500 execute_node_job(exec_id, node_D)\n</code></pre> <p>The default job timeout is 600 seconds (10 minutes). An in-flight counter in Redis tracks how many nodes are currently executing. When it reaches zero, <code>_finalize()</code> is called.</p> <p>Worker Requirement</p> <p>At least one RQ worker must be running to process executions. Without a worker, jobs will queue indefinitely. Start a worker with: <code>rq worker workflows --url $REDIS_URL</code></p>"},{"location":"concepts/execution/#component-output-convention","title":"Component Output Convention","text":"<p>Components (the Python functions that implement each node type) return flat dictionaries. The orchestrator interprets the keys:</p>"},{"location":"concepts/execution/#regular-keys","title":"Regular Keys","text":"<p>Any key that does not start with an underscore is treated as a port output value and stored in <code>state[\"node_outputs\"][node_id]</code>:</p> <pre><code># Component returns:\n{\"output\": \"Hello world\", \"confidence\": 0.95}\n\n# Orchestrator stores:\nstate[\"node_outputs\"][\"agent_abc123\"] = {\n    \"output\": \"Hello world\",\n    \"confidence\": 0.95\n}\n</code></pre> <p>These values are accessible to downstream nodes via expressions: <code>{{ agent_abc123.output }}</code>.</p>"},{"location":"concepts/execution/#reserved-underscore-prefixed-keys","title":"Reserved Underscore-Prefixed Keys","text":"<p>Keys starting with <code>_</code> are side-effect directives that control execution state:</p> Key Type Effect <code>_route</code> <code>string</code> Sets <code>state[\"route\"]</code> for conditional edge routing. Used by switch nodes and AI routers. <code>_messages</code> <code>list</code> Appended to <code>state[\"messages\"]</code> (the LangGraph message list). Used by agent nodes to persist the full conversation. <code>_state_patch</code> <code>dict</code> Merged into the global state dict. Protected keys (<code>messages</code>, <code>node_outputs</code>, <code>node_results</code>) cannot be overwritten. <code>_delay_seconds</code> <code>float</code> Delays enqueuing successor nodes by this many seconds. Used by wait nodes. <code>_loop</code> <code>dict</code> Contains <code>items</code> list for loop node iteration. <code>_subworkflow</code> <code>dict</code> Contains <code>child_execution_id</code> for subworkflow nodes waiting on a child. <code>_token_usage</code> <code>dict</code> Token counts, cost, and tool invocation stats. Accumulated into execution-level totals. <p>Legacy Output Format</p> <p>For backwards compatibility, components that return <code>{\"node_outputs\": {...}}</code> directly (the legacy format) are also supported. The orchestrator detects this and merges accordingly.</p>"},{"location":"concepts/execution/#state-management","title":"State Management","text":"<p>Execution state is stored in Redis with a 1-hour TTL. The state dict contains:</p> Key Description <code>messages</code> LangGraph message list (HumanMessage, AIMessage, ToolMessage, etc.) <code>trigger</code> The trigger payload that started the execution <code>user_context</code> User profile ID and Telegram chat ID <code>execution_id</code> UUID of the current execution <code>route</code> Current routing value for conditional edges <code>node_outputs</code> Dict of <code>{node_id: {port: value}}</code> for all completed nodes <code>node_results</code> Dict of <code>{node_id: NodeResult}</code> for all completed nodes <code>current_node</code> ID of the node currently being executed <code>loop</code> Loop iteration context (item, index, total) when inside a loop body <p>State is loaded and saved around each node execution. Multiple RQ workers can process different nodes of the same execution concurrently, with Redis providing the shared state.</p>"},{"location":"concepts/execution/#fan-out-and-fan-in","title":"Fan-Out and Fan-In","text":"<p>The orchestrator supports parallel execution branches:</p> <ul> <li>Fan-out -- when a node has multiple direct outgoing edges, all target nodes are enqueued simultaneously on RQ.</li> <li>Fan-in -- merge nodes track incoming edge counts. A merge node only executes when all of its upstream branches have completed. This is tracked with a Redis counter per merge node.</li> </ul>"},{"location":"concepts/execution/#conditional-routing","title":"Conditional Routing","text":"<p>Switch nodes and AI router nodes set <code>state[\"route\"]</code> via the <code>_route</code> key. The orchestrator matches this value against <code>condition_value</code> on each outgoing conditional edge to determine which branch to take. Only the matched target node is enqueued.</p>"},{"location":"concepts/execution/#finalization","title":"Finalization","text":"<p>When all in-flight nodes complete (the Redis counter reaches zero), the orchestrator finalizes:</p> <ol> <li>Extracts the final output from state (last AI message, or <code>node_outputs</code>).</li> <li>Sets <code>execution.status = \"completed\"</code> and persists cost data.</li> <li>Publishes <code>execution_completed</code> via WebSocket.</li> <li>Runs output delivery (Telegram reply, webhook callback, etc.).</li> <li>Completes the memory episode for the execution.</li> <li>If this is a child execution, resumes the parent at its waiting node.</li> <li>Cleans up all Redis keys for the execution.</li> </ol>"},{"location":"concepts/expressions/","title":"Expressions","text":""},{"location":"concepts/expressions/#expressions","title":"Expressions","text":"<p>Pipelit uses Jinja2 template expressions to pass data between nodes. Expressions let you reference the output of any upstream node or the trigger payload inside system prompts, code snippets, and extra config fields -- without writing code.</p>"},{"location":"concepts/expressions/#syntax","title":"Syntax","text":"<p>The basic syntax is:</p> <pre><code>{{ nodeId.portName }}\n</code></pre> <p>Where:</p> <ul> <li>nodeId is the unique identifier of an upstream node (e.g., <code>categorizer_abc123</code>).</li> <li>portName is the name of an output port on that node (e.g., <code>category</code>, <code>output</code>, <code>text</code>).</li> </ul>"},{"location":"concepts/expressions/#examples","title":"Examples","text":"<pre><code>{# Reference an upstream categorizer's output #}\nThe category is: {{ categorizer_abc123.category }}\n\n{# Reference the trigger text #}\nUser said: {{ trigger.text }}\n\n{# Use a Jinja2 filter #}\nCATEGORY: {{ categorizer_abc123.category | upper }}\n\n{# Combine multiple sources #}\nBased on the {{ categorizer_abc123.category }} classification,\nhere is the extracted data: {{ extractor_def456.extracted }}\n</code></pre>"},{"location":"concepts/expressions/#where-expressions-are-available","title":"Where Expressions Are Available","text":"<p>Expressions are resolved in three node configuration fields:</p> Field Description Typical Use System Prompt Agent, categorizer, router, extractor instructions Injecting trigger data or upstream results into the LLM prompt Code Snippet Code node Python/Bash source Templating dynamic values into code Extra Config Key-value pairs in <code>extra_config</code> Dynamic URLs, parameters, or settings based on upstream output <p>Resolution Timing</p> <p>Expressions are resolved just before a node executes, not at workflow build time. This means the values reflect the actual runtime output from upstream nodes in the current execution.</p>"},{"location":"concepts/expressions/#context-variables","title":"Context Variables","text":"<p>When the orchestrator resolves expressions, the following variables are available in the template context:</p>"},{"location":"concepts/expressions/#upstream-node-outputs","title":"Upstream Node Outputs","text":"<p>Every node that has already executed in the current run is available by its <code>node_id</code>. Each node's output is a dict keyed by port name:</p> <pre><code># If categorizer_abc123 produced {\"category\": \"billing\", \"raw\": \"...\"}\n# then in a template:\n{{ categorizer_abc123.category }}  # -&gt; \"billing\"\n{{ categorizer_abc123.raw }}       # -&gt; \"...\"\n</code></pre>"},{"location":"concepts/expressions/#the-trigger-shorthand","title":"The <code>trigger</code> Shorthand","text":"<p>The special <code>trigger</code> variable refers to whichever trigger fired the current execution. This is particularly useful in workflows with multiple triggers (e.g., a chat trigger and a Telegram trigger feeding the same downstream agent).</p> Property Type Description <code>trigger.text</code> <code>string</code> The message text from the trigger <code>trigger.payload</code> <code>dict</code> The full trigger payload (varies by trigger type) <pre><code>{# Works regardless of which trigger fired #}\nYou are responding to: {{ trigger.text }}\n\n{# Access nested payload data #}\nChat ID: {{ trigger.payload.chat_id }}\n</code></pre> <p>Multi-Trigger Workflows</p> <p>The <code>trigger</code> shorthand always resolves to the trigger that initiated the current execution. If a workflow has both a chat trigger and a Telegram trigger connected to the same agent, <code>{{ trigger.text }}</code> works correctly in both cases.</p>"},{"location":"concepts/expressions/#loop-context","title":"Loop Context","text":"<p>Inside a loop body, the <code>loop</code> variable provides information about the current iteration:</p> Property Type Description <code>loop.item</code> <code>any</code> The current item being iterated <code>loop.index</code> <code>int</code> Zero-based index of the current iteration <code>loop.total</code> <code>int</code> Total number of items in the loop <pre><code>Processing item {{ loop.index }} of {{ loop.total }}: {{ loop.item }}\n</code></pre>"},{"location":"concepts/expressions/#jinja2-filters","title":"Jinja2 Filters","text":"<p>Standard Jinja2 filters are supported for transforming values inline:</p> <pre><code>{{ trigger.text | upper }}           {# UPPERCASE #}\n{{ trigger.text | lower }}           {# lowercase #}\n{{ trigger.text | title }}           {# Title Case #}\n{{ trigger.text | length }}          {# character count #}\n{{ trigger.text | truncate(100) }}   {# truncate to 100 chars #}\n{{ trigger.text | default(\"N/A\") }} {# fallback if undefined #}\n</code></pre>"},{"location":"concepts/expressions/#graceful-fallback","title":"Graceful Fallback","text":"<p>If an expression cannot be resolved -- because the referenced node has not executed yet, the port does not exist, or there is a syntax error -- the original template string is returned unchanged. This prevents crashes from misconfigured expressions.</p> <pre><code>{# If node_xyz has not executed, this returns the literal string: #}\n{{ node_xyz.output }}\n{# -&gt; \"{{ node_xyz.output }}\" (unchanged) #}\n</code></pre> <p>StrictUndefined with Graceful Recovery</p> <p>Internally, the expression resolver uses Jinja2's <code>StrictUndefined</code> mode, which raises an error on undefined variables. The resolver catches this error and falls back to the original template string. This means partial resolution does not happen -- either the entire template resolves successfully, or none of it does.</p>"},{"location":"concepts/expressions/#frontend-variable-picker","title":"Frontend Variable Picker","text":"<p>The workflow editor provides a visual way to insert expressions without typing them manually.</p>"},{"location":"concepts/expressions/#the-button","title":"The { } Button","text":"<p>On System Prompt, Code Snippet, and Extra Config fields, a { } button appears next to the text area. Clicking it opens the Variable Picker popover:</p> <ol> <li>The picker performs a BFS traversal of upstream nodes from the current node.</li> <li>It displays each reachable node with its output ports.</li> <li>Clicking a port inserts <code>{{ nodeId.portName }}</code> at the cursor position in the text area.</li> </ol> <p>This ensures you only see variables that are actually available to the current node based on the workflow topology.</p>"},{"location":"concepts/expressions/#syntax-highlighting","title":"Syntax Highlighting","text":"<p>All three CodeMirror modal editors (System Prompt, Code Snippet, Extra Config) apply Jinja2 syntax highlighting:</p> Element Style <code>{{ }}</code>, <code>{% %}</code>, <code>{# #}</code> brackets Bold, lighter green Inner content between brackets Bold, amber/orange <p>The highlighting is implemented as a CodeMirror 6 <code>ViewPlugin</code> that applies decorations to regex-matched Jinja2 delimiters in visible ranges. Both light and dark theme variants are provided. Whitespace-control variants (<code>{{-</code>, <code>-%}}</code>, <code>{%-</code>, etc.) are also recognized.</p>"},{"location":"concepts/expressions/#resolution-implementation","title":"Resolution Implementation","text":"<p>Expression resolution happens in <code>platform/services/expressions.py</code> and is invoked by the orchestrator before each node executes:</p> <ol> <li><code>resolve_expressions(template_str, node_outputs, trigger)</code> -- resolves a single string template.</li> <li><code>resolve_config_expressions(config, node_outputs, trigger)</code> -- recursively resolves all string values in a config dict, including nested dicts and lists.</li> </ol> <p>The orchestrator calls these on both <code>system_prompt</code> and <code>extra_config</code> before passing the node configuration to its component factory:</p> <pre><code># In orchestrator.py, before executing a component:\nif db_node.component_config.system_prompt:\n    db_node.component_config.system_prompt = resolve_expressions(\n        db_node.component_config.system_prompt, node_outputs, trigger\n    )\nif db_node.component_config.extra_config:\n    db_node.component_config.extra_config = resolve_config_expressions(\n        db_node.component_config.extra_config, node_outputs, trigger\n    )\n</code></pre> <p>Short-Circuit Optimization</p> <p>If the template string does not contain <code>{{</code>, the resolver returns it immediately without invoking the Jinja2 engine. This keeps resolution fast for nodes that do not use expressions.</p>"},{"location":"concepts/memory/","title":"Memory","text":""},{"location":"concepts/memory/#memory","title":"Memory","text":"<p>Pipelit provides two distinct memory systems that give agents persistent knowledge across executions: conversation memory for per-agent chat continuity, and global memory for shared facts, episodes, and procedures that any agent can read and write.</p>"},{"location":"concepts/memory/#two-memory-systems","title":"Two memory systems","text":"<pre><code>flowchart TB\n    subgraph Conversation[\"Conversation Memory (per-agent)\"]\n        direction LR\n        CP[SQLite Checkpointer] --&gt; TH[Thread History]\n        TH --&gt; Agent\n    end\n\n    subgraph Global[\"Global Memory (shared)\"]\n        direction LR\n        Facts[Facts] --&gt; MS[MemoryService]\n        Episodes[Episodes] --&gt; MS\n        Procedures[Procedures] --&gt; MS\n        Users[Memory Users] --&gt; MS\n        MS --&gt; AnyAgent[Any Agent]\n    end</code></pre>"},{"location":"concepts/memory/#conversation-memory","title":"Conversation memory","text":"<p>Conversation memory is a per-agent, opt-in feature that persists chat history across executions. When enabled, the agent remembers previous turns in a conversation, even across separate workflow runs.</p> <p>Under the hood, conversation memory uses a SQLite checkpointer (<code>platform/checkpoints.db</code>) backed by LangGraph's <code>SqliteSaver</code>. The checkpointer is a lazy singleton -- it is created once on first use and shared across all agents.</p> <p>Thread ID construction:</p> <p>Each conversation thread is identified by a composite key:</p> <pre><code>thread_id = user_profile_id + telegram_chat_id + workflow_id\n</code></pre> <p>This means the same user talking to the same workflow gets continuity, regardless of whether the conversation happens over chat, Telegram, or any other channel. Different users on the same workflow get separate threads.</p> <p>Enabling conversation memory</p> <p>Toggle the Conversation Memory switch in the Node Details Panel for any agent node. The setting is stored as <code>conversation_memory: true</code> in the agent's <code>extra_config</code>.</p> <p>System prompt delivery:</p> <p>When conversation memory is enabled, the system prompt is delivered in two ways:</p> <ol> <li>Via <code>create_react_agent(prompt=SystemMessage(...))</code> for the <code>system</code> role</li> <li>As a <code>HumanMessage</code> fallback with a stable ID for providers that ignore the system role (e.g., Venice.ai)</li> </ol> <p>The stable ID prevents the system prompt from being duplicated across checkpointer invocations, thanks to LangGraph's <code>add_messages</code> reducer.</p>"},{"location":"concepts/memory/#global-memory","title":"Global memory","text":"<p>Global memory is a shared knowledge store that persists independently of any single conversation. It is organized into four entity types, each serving a different purpose.</p>"},{"location":"concepts/memory/#facts","title":"Facts","text":"<p>Facts are the agent's semantic memory -- extracted knowledge not tied to a specific episode. Like knowing \"Paris is the capital of France.\"</p> Field Description <code>key</code> Human-readable identifier (e.g., <code>\"user_timezone\"</code>) <code>value</code> JSON value (string, number, object, etc.) <code>fact_type</code> Classification of the fact (see table below) <code>scope</code> Visibility level: <code>session</code>, <code>user</code>, <code>agent</code>, or <code>global</code> <code>confidence</code> Float 0.0 -- 1.0, tracking how reliable the fact is <code>times_confirmed</code> How many times the fact has been re-asserted <code>times_contradicted</code> How many times contradictory information was seen <p>Fact types:</p> Type Example <code>user_preference</code> \"User likes concise answers\" <code>world_knowledge</code> \"API endpoint is https://api.example.com\" <code>self_knowledge</code> \"My success rate for code review is 73%\" <code>correction</code> \"Don't use deprecated API v1, use v2 instead\" <code>relationship</code> \"User works at Acme Corp\" <p>Scope hierarchy:</p> <p>Facts follow a scope hierarchy where the most specific scope wins during lookup:</p> <pre><code>flowchart LR\n    Session[\"session\\n(this conversation)\"] --&gt; User[\"user\\n(this user, all conversations)\"]\n    User --&gt; AgentScope[\"agent\\n(this agent, all users)\"]\n    AgentScope --&gt; GlobalScope[\"global\\n(all agents, all users)\"]</code></pre> <p>When looking up a fact by key, the <code>MemoryService</code> checks scopes from most specific (session) to least specific (global), returning the first match.</p>"},{"location":"concepts/memory/#episodes","title":"Episodes","text":"<p>Episodes are the agent's episodic memory -- full records of past executions. Like remembering \"that conversation last Tuesday.\"</p> <p>Each episode captures:</p> <ul> <li>Trigger context: what started the execution and what input was provided</li> <li>Conversation log: the full message exchange</li> <li>Actions taken: tool calls and their results</li> <li>Outcome: success/failure status, final output, error details</li> <li>Timing: start time, end time, duration</li> <li>Human feedback: optional rating and comments</li> </ul> <p>Episodes support future capabilities like semantic search via embeddings and automatic fact extraction.</p>"},{"location":"concepts/memory/#procedures","title":"Procedures","text":"<p>Procedures are the agent's procedural memory -- learned how-to instructions. Like knowing \"how to ride a bike.\"</p> <p>Procedures can emerge from:</p> <ul> <li>Human teaching: explicit instructions (\"when X happens, do Y\")</li> <li>Self-learning: patterns extracted from successful episodes</li> <li>Evolution: modifications of existing procedures</li> </ul> <p>Each procedure has:</p> <ul> <li>Trigger conditions: when to apply the procedure (e.g., <code>{\"goal_contains\": [\"weather\"]}</code>)</li> <li>Procedure type: <code>workflow_graph</code>, <code>prompt_template</code>, <code>code_snippet</code>, or <code>tool_sequence</code></li> <li>Procedure content: the actual instructions in the appropriate format</li> <li>Performance tracking: times used, success rate, average duration</li> </ul>"},{"location":"concepts/memory/#memory-users","title":"Memory users","text":"<p>Memory users provide cross-channel identity tracking. They allow the same person on Telegram, email, or other channels to be recognized as a single identity.</p> <p>Each memory user has:</p> <ul> <li>A <code>canonical_id</code> (e.g., <code>telegram:12345</code>)</li> <li>Channel-specific identifiers (<code>telegram_id</code>, <code>email</code>)</li> <li>A <code>display_name</code></li> <li>Cached preferences (denormalized from facts for fast lookup)</li> <li>Conversation statistics</li> </ul> <p>Users can be merged when the same person is identified across multiple channels via the <code>merged_into_id</code> field.</p>"},{"location":"concepts/memory/#memory-tools","title":"Memory tools","text":"<p>Pipelit provides three tool components that agents can use to interact with memory at runtime.</p>"},{"location":"concepts/memory/#memory_read-recall","title":"memory_read (recall)","text":"<p>The <code>memory_read</code> component gives agents a tool called <code>recall</code> that retrieves information from global memory.</p> <pre><code>flowchart LR\n    Agent --&gt;|\"recall(key='timezone')\"| MR[memory_read]\n    MR --&gt;|\"timezone = Australia/Adelaide\"| Agent</code></pre> <p>Behavior:</p> <ul> <li>No arguments: lists all facts visible to the agent</li> <li><code>key</code> argument: exact key lookup, falls back to fuzzy search if no exact match</li> <li><code>query</code> argument: searches across facts, procedures, and/or episodes depending on <code>memory_type</code></li> </ul> <p>Configuration (<code>extra_config</code>):</p> Field Default Description <code>memory_type</code> <code>\"facts\"</code> Which memory types to search: <code>facts</code>, <code>procedures</code>, <code>episodes</code>, or <code>all</code> <code>limit</code> <code>10</code> Maximum number of results to return <code>min_confidence</code> <code>0.5</code> Minimum confidence score for fact results"},{"location":"concepts/memory/#memory_write-remember","title":"memory_write (remember)","text":"<p>The <code>memory_write</code> component gives agents a tool called <code>remember</code> that stores facts in global memory.</p> <pre><code>flowchart LR\n    Agent --&gt;|\"remember(key='color', value='blue')\"| MW[memory_write]\n    MW --&gt;|\"Remembered: color = blue (created)\"| Agent</code></pre> <p>Behavior:</p> <ul> <li>Stores a key-value fact in global scope</li> <li>If the key already exists and <code>overwrite</code> is true, updates the value and increments <code>times_confirmed</code></li> <li>If the key already exists and <code>overwrite</code> is false, skips the write</li> </ul> <p>Configuration (<code>extra_config</code>):</p> Field Default Description <code>fact_type</code> <code>\"world_knowledge\"</code> Default fact type for new facts <code>overwrite</code> <code>true</code> Whether to overwrite existing facts with the same key"},{"location":"concepts/memory/#identify_user","title":"identify_user","text":"<p>The <code>identify_user</code> component is a graph node (not an agent tool) that identifies who is interacting with the workflow and loads their full context from memory.</p> <p>It works by:</p> <ol> <li>Extracting the channel and user identifier from the trigger payload</li> <li>Looking up or creating a <code>MemoryUser</code> record</li> <li>Loading all user-scoped facts and recent episodes</li> <li>Patching the workflow state with <code>user_context</code> for downstream nodes</li> </ol> <p>Use identify_user early in your workflow</p> <p>Place the <code>identify_user</code> node immediately after your trigger so that downstream agents have access to user context, preferences, and history via <code>{{ identify_user.user_context }}</code>.</p>"},{"location":"concepts/memory/#search-implementation","title":"Search implementation","text":"<p>Memory search currently uses SQL ILIKE pattern matching with fuzzy normalization. The search query is preprocessed so that spaces, underscores, and hyphens are treated as equivalent. For example, a search for <code>\"local time\"</code> will match a fact with the key <code>\"lesson_local_time_command\"</code>.</p> <pre><code>query: \"local time\"\npattern: %local%time%\nmatches: lesson_local_time_command, local_time_zone, get-local-time\n</code></pre> <p>Facts are filtered by confidence score (<code>min_confidence</code>) and ordered by confidence descending.</p> <p>Future: vector search</p> <p>The <code>MemoryFact</code> and <code>MemoryEpisode</code> models include <code>embedding</code> fields (currently unused) reserved for future semantic vector search capabilities.</p>"},{"location":"concepts/memory/#api-endpoints","title":"API endpoints","text":"<p>Memory entities are managed through the REST API:</p> Endpoint Description <code>GET /api/v1/facts/</code> List facts <code>POST /api/v1/facts/batch-delete/</code> Batch delete facts <code>GET /api/v1/episodes/</code> List episodes <code>POST /api/v1/episodes/batch-delete/</code> Batch delete episodes <code>GET /api/v1/procedures/</code> List procedures <code>POST /api/v1/procedures/batch-delete/</code> Batch delete procedures <code>GET /api/v1/memory-users/</code> List memory users <code>POST /api/v1/memory-users/batch-delete/</code> Batch delete memory users <code>GET /api/v1/checkpoints/</code> List checkpoints (conversation memory) <code>POST /api/v1/checkpoints/batch-delete/</code> Batch delete checkpoints <p>All memory entities can be browsed and managed in the frontend at <code>/memories</code>, which provides tabbed views for Facts, Episodes, Checkpoints, Procedures, and Users.</p>"},{"location":"concepts/memory/#whats-next","title":"What's next?","text":"<ul> <li>Learn about multi-agent task delegation: Epics &amp; Tasks</li> <li>Understand cost tracking for memory-heavy workflows: Cost Tracking</li> <li>See how agents use tools: Tools</li> </ul>"},{"location":"concepts/nodes-and-edges/","title":"Nodes & Edges","text":""},{"location":"concepts/nodes-and-edges/#nodes-edges","title":"Nodes &amp; Edges","text":"<p>Nodes are the building blocks of workflows. Edges are the typed connections between them. Together, they form a directed graph with validated data flow that Pipelit compiles and executes.</p>"},{"location":"concepts/nodes-and-edges/#nodes","title":"Nodes","text":"<p>Every element on the workflow canvas is a node. Each node has a <code>component_type</code> that determines its behavior, a unique <code>node_id</code> within the workflow, and a configuration that controls how it runs.</p>"},{"location":"concepts/nodes-and-edges/#node-categories","title":"Node categories","text":"<p>Pipelit organizes its node types into seven categories:</p> <pre><code>graph TD\n    subgraph Triggers[\"Triggers (6 types)\"]\n        direction LR\n        TC[Chat] ~~~ TT[Telegram] ~~~ TM[Manual]\n        TS[Schedule] ~~~ TW[Workflow] ~~~ TE[Error]\n    end\n\n    subgraph AI[\"AI (4 types)\"]\n        direction LR\n        Agent ~~~ Categorizer ~~~ Router ~~~ Extractor\n    end\n\n    subgraph Tools[\"Tools (5 types)\"]\n        direction LR\n        RunCmd[Run Command] ~~~ HTTP[HTTP Request] ~~~ WebSearch[Web Search]\n        Calc[Calculator] ~~~ DT[Date &amp; Time]\n    end\n\n    subgraph Logic[\"Logic (9 types)\"]\n        direction LR\n        Switch ~~~ Code ~~~ Merge\n        Filter ~~~ Loop ~~~ Wait\n        HC[Human Confirm] ~~~ Agg[Aggregator] ~~~ Sub[Subworkflow]\n    end\n\n    subgraph SubComp[\"Sub-Components (3 types)\"]\n        direction LR\n        AIM[AI Model] ~~~ OP[Output Parser] ~~~ CE[Code Execute]\n    end\n\n    subgraph SelfAware[\"Self-Awareness (11 types)\"]\n        direction LR\n        CAU[Create Agent User] ~~~ PA[Platform API] ~~~ WhoAmI\n        TOTP[Get TOTP] ~~~ Epic[Epic Tools] ~~~ Task[Task Tools]\n        SA[Spawn &amp; Await] ~~~ WC[Workflow Create] ~~~ WD[Workflow Discover]\n        ST[Scheduler Tools] ~~~ SH[System Health]\n    end\n\n    subgraph Memory[\"Memory (3 types)\"]\n        direction LR\n        MR[Memory Read] ~~~ MW[Memory Write] ~~~ IU[Identify User]\n    end</code></pre> Category Types Purpose Triggers <code>trigger_chat</code>, <code>trigger_telegram</code>, <code>trigger_manual</code>, <code>trigger_schedule</code>, <code>trigger_workflow</code>, <code>trigger_error</code> Initiate workflow execution from external events AI <code>agent</code>, <code>categorizer</code>, <code>router</code>, <code>extractor</code> LLM-powered reasoning, classification, routing, and data extraction Tools <code>run_command</code>, <code>http_request</code>, <code>web_search</code>, <code>calculator</code>, <code>datetime</code> Capabilities that agents can invoke during reasoning Logic <code>switch</code>, <code>code</code>, <code>merge</code>, <code>filter</code>, <code>loop</code>, <code>wait</code>, <code>human_confirmation</code>, <code>aggregator</code>, <code>workflow</code> Flow control, data transformation, and branching Sub-Components <code>ai_model</code>, <code>output_parser</code>, <code>code_execute</code> Configuration nodes that attach to other nodes (not independently executable) Self-Awareness <code>create_agent_user</code>, <code>platform_api</code>, <code>whoami</code>, <code>get_totp_code</code>, <code>epic_tools</code>, <code>task_tools</code>, <code>spawn_and_await</code>, <code>workflow_create</code>, <code>workflow_discover</code>, <code>scheduler_tools</code>, <code>system_health</code> Tools that let agents inspect and modify the platform itself Memory <code>memory_read</code>, <code>memory_write</code>, <code>identify_user</code> Persistent knowledge storage and user identification"},{"location":"concepts/nodes-and-edges/#executable-vs-non-executable-nodes","title":"Executable vs. non-executable nodes","text":"<p>Not all nodes run during execution:</p> <ul> <li>Trigger nodes initiate execution but do not execute themselves -- they produce output that flows to downstream nodes.</li> <li>Sub-component nodes (<code>ai_model</code>, <code>output_parser</code>) are configuration-only. They attach to AI nodes to provide model and parser settings.</li> <li>Tool nodes (<code>run_command</code>, <code>http_request</code>, etc.) are executable -- they run when an agent invokes them during its reasoning loop.</li> </ul> <p>Note</p> <p>The <code>executable</code> flag on each node type controls whether the canvas shows execution status badges (spinning circle, checkmark, X) during a run. Non-executable nodes remain visually static.</p>"},{"location":"concepts/nodes-and-edges/#typed-ports","title":"Typed ports","text":"<p>Every node declares typed input ports and output ports. Ports define what data a node accepts and what it produces.</p>"},{"location":"concepts/nodes-and-edges/#datatype-enum","title":"DataType enum","text":"<p>Pipelit uses a type system for port definitions:</p> DataType Description <code>STRING</code> Text content <code>NUMBER</code> Numeric value <code>BOOLEAN</code> True/false <code>OBJECT</code> JSON object (dict) <code>ARRAY</code> JSON array (list) <code>MESSAGE</code> A single LangChain message <code>MESSAGES</code> A list of LangChain messages <code>IMAGE</code> Image data <code>FILE</code> File data <code>ANY</code> Accepts or produces any type"},{"location":"concepts/nodes-and-edges/#port-examples","title":"Port examples","text":"<p>Here are the port definitions for a few common node types:</p> AgentChat TriggerSwitch <p>Inputs:</p> Port Type Required <code>messages</code> <code>MESSAGES</code> Yes <p>Outputs:</p> Port Type <code>messages</code> <code>MESSAGES</code> <code>output</code> <code>STRING</code> <p>Outputs:</p> Port Type <code>text</code> <code>STRING</code> <code>payload</code> <code>OBJECT</code> <p>Inputs:</p> Port Type Required <code>input</code> <code>ANY</code> Yes <p>Outputs:</p> Port Type <code>route</code> <code>STRING</code>"},{"location":"concepts/nodes-and-edges/#type-compatibility","title":"Type compatibility","text":"<p>When you connect two nodes, Pipelit checks that the source output type is compatible with the target input type. The compatibility rules are:</p> <ul> <li>Same type -- always compatible</li> <li>Any to Any -- the <code>ANY</code> type is universally compatible as source or target</li> <li>String coercions -- <code>STRING</code> can connect to <code>MESSAGE</code> or <code>MESSAGES</code> inputs</li> <li>Message coercions -- <code>MESSAGE</code> can connect to <code>MESSAGES</code> inputs</li> </ul> <p>Incompatible connections are rejected at edge creation time with a <code>422</code> error.</p> <p>Use ANY for flexibility</p> <p>Logic nodes like <code>code</code>, <code>switch</code>, and <code>merge</code> accept <code>ANY</code> type inputs, making them versatile adapters between differently-typed nodes.</p>"},{"location":"concepts/nodes-and-edges/#edges","title":"Edges","text":"<p>Edges are directed connections between nodes. They carry data from a source node's output to a target node's input.</p>"},{"location":"concepts/nodes-and-edges/#edge-types","title":"Edge types","text":"Edge Type Description Originating Node direct Standard data flow from one node to another Any node conditional Route-based branching, selected by matching <code>condition_value</code> against the <code>_route</code> output <code>switch</code> nodes only"},{"location":"concepts/nodes-and-edges/#edge-labels","title":"Edge labels","text":"<p>Edge labels identify the purpose of a connection. They determine which handle the edge connects to on the target node.</p> Label Purpose Visual Handle <code>\"\"</code> (empty) Standard data flow between nodes Left/right circle handles <code>\"llm\"</code> Connects an AI Model to a node that requires one Bottom diamond (blue) <code>\"tool\"</code> Connects a tool node to an agent Bottom diamond (green) <code>\"memory\"</code> Connects memory to a node that supports it Bottom diamond (amber) <code>\"output_parser\"</code> Connects an output parser to a categorizer, router, or extractor Bottom diamond (slate) <code>\"loop_body\"</code> Connects a loop node to the first node in its body Special flow-control edge <code>\"loop_return\"</code> Returns from the last body node back to the loop Dashed edge routed below nodes"},{"location":"concepts/nodes-and-edges/#edge-validation","title":"Edge validation","text":"<p>Pipelit validates edges at two levels:</p> <ol> <li> <p>At creation time -- When you draw an edge on the canvas or call the API, the system checks type compatibility between the source output and target input. Invalid connections return a <code>422</code> error.</p> </li> <li> <p>At workflow validation time -- The <code>POST /api/v1/workflows/{slug}/validate/</code> endpoint (or the Validate button) runs comprehensive checks across all edges:</p> <ul> <li>All source and target nodes exist</li> <li>Conditional edges have a <code>condition_value</code> and originate from <code>switch</code> nodes</li> <li>Type compatibility holds for all direct edges</li> <li>Nodes that require a model connection have one</li> </ul> </li> </ol> <p>Conditional edges require switch nodes</p> <p>Only <code>switch</code> nodes can originate conditional edges. The switch evaluates rules against its input and emits a <code>_route</code> value. Each conditional edge carries a <code>condition_value</code> that must match one of the switch's possible routes.</p>"},{"location":"concepts/nodes-and-edges/#sub-component-connections","title":"Sub-component connections","text":"<p>AI nodes require sub-component connections to function:</p> AI Node Requires Model Requires Tools Requires Memory Requires Output Parser <code>agent</code> Yes Yes Yes No <code>categorizer</code> Yes No Yes Yes <code>router</code> Yes No Yes Yes <code>extractor</code> Yes No Yes Yes <p>Sub-component connections use the diamond-shaped handles at the bottom of AI nodes. You connect an <code>ai_model</code> node via the blue handle, tool nodes via the green handle, and so on.</p> <pre><code>flowchart TB\n    Model[AI Model&lt;br/&gt;GPT-4o] -.-&gt;|\"llm (blue)\"| Agent\n    Search[Web Search] -.-&gt;|\"tool (green)\"| Agent\n    Command[Run Command] -.-&gt;|\"tool (green)\"| Agent\n    MemRead[Memory Read] -.-&gt;|\"memory (amber)\"| Agent\n    Trigger[Chat Trigger] --&gt; Agent\n    Agent --&gt; Output[Code: Format]</code></pre>"},{"location":"concepts/nodes-and-edges/#node-output-convention","title":"Node output convention","text":"<p>When a component finishes executing, it returns a flat dictionary of its port values (e.g., <code>{\"output\": \"Hello!\", \"messages\": [...]}</code>). The orchestrator automatically stores all non-underscore-prefixed keys in <code>node_outputs[node_id]</code>, making them available to downstream nodes via Jinja2 expressions like <code>{{ agent_abc123.output }}</code>.</p> <p>Reserved underscore-prefixed keys control side effects:</p> Key Effect <code>_route</code> Sets the route for conditional edge matching <code>_messages</code> Appends to the global LangGraph message list <code>_state_patch</code> Merges into the global workflow state"},{"location":"concepts/nodes-and-edges/#whats-next","title":"What's next?","text":"<ul> <li>Learn how workflows start: Triggers</li> <li>Understand LLM-powered nodes: Agents</li> <li>Reference upstream data: Expressions</li> </ul>"},{"location":"concepts/scheduler/","title":"Scheduler","text":""},{"location":"concepts/scheduler/#scheduler","title":"Scheduler","text":"<p>Pipelit's scheduler provides recurring workflow execution without external cron. It uses a self-rescheduling pattern built on top of RQ (Redis Queue), where each execution enqueues the next one before completing. This gives you configurable intervals, repeat counts, retry with exponential backoff, pause/resume, and automatic crash recovery.</p>"},{"location":"concepts/scheduler/#architecture","title":"Architecture","text":"<pre><code>flowchart LR\n    API[Schedule API] --&gt;|create| Job[(ScheduledJob\\nin DB)]\n    Job --&gt;|enqueue_in| RQ[RQ Worker]\n    RQ --&gt;|execute_scheduled_job| Dispatch[Dispatch Trigger]\n    Dispatch --&gt;|success| Enqueue[Enqueue Next Run]\n    Dispatch --&gt;|failure| Backoff[Backoff + Retry]\n    Enqueue --&gt;|enqueue_in| RQ\n    Backoff --&gt;|enqueue_in| RQ</code></pre> <p>The key insight is that there is no persistent scheduler process or cron daemon. Each scheduled run is a one-shot RQ job that, upon completion, schedules the next one. The chain continues until the job is paused, exhausts its repeat count, or hits too many failures.</p>"},{"location":"concepts/scheduler/#scheduledjob-model","title":"ScheduledJob model","text":"<p>Every scheduled job is stored as a <code>ScheduledJob</code> row in the database:</p> Field Type Description <code>id</code> UUID Primary key <code>name</code> string Human-readable name <code>description</code> text Optional description <code>workflow_id</code> FK Workflow to execute <code>trigger_node_id</code> string Specific trigger node to fire (optional) <code>user_profile_id</code> FK Owner who created the schedule <code>interval_seconds</code> int Time between runs <code>total_repeats</code> int Maximum runs (0 = infinite) <code>max_retries</code> int Max consecutive failures before death (default 3) <code>timeout_seconds</code> int Per-execution timeout (default 600) <code>trigger_payload</code> JSON Data passed to the trigger on each run <code>status</code> string Current state machine status <code>current_repeat</code> int How many successful runs have completed <code>current_retry</code> int Current retry attempt for this run <code>last_run_at</code> datetime When the last run started <code>next_run_at</code> datetime When the next run is scheduled <code>run_count</code> int Total successful runs <code>error_count</code> int Total errors encountered <code>last_error</code> text Most recent error message"},{"location":"concepts/scheduler/#state-machine","title":"State machine","text":"<p>The scheduler uses a simple state machine to track job lifecycle:</p> <pre><code>stateDiagram-v2\n    [*] --&gt; active : create\n    active --&gt; paused : pause\n    paused --&gt; active : resume\n    active --&gt; done : repeat limit reached\n    active --&gt; dead : max retries exceeded\n    done --&gt; [*]\n    dead --&gt; [*]</code></pre> Status Meaning <code>active</code> Job is running normally; the next run is enqueued in Redis <code>paused</code> Job is temporarily halted; no runs are enqueued <code>done</code> Job completed all configured repeats <code>dead</code> Job failed too many times consecutively and was stopped <p>Pause is non-destructive</p> <p>Pausing a job sets its status to <code>paused</code> and clears <code>next_run_at</code>. The RQ wrapper checks status at the start of each run and returns early if the job is not <code>active</code>. This means an already-enqueued job will simply no-op when it fires, rather than being removed from Redis.</p>"},{"location":"concepts/scheduler/#execution-flow","title":"Execution flow","text":""},{"location":"concepts/scheduler/#execute_scheduled_job","title":"execute_scheduled_job()","text":"<p>This is the core function that runs as an RQ job. It follows a strict sequence:</p> <pre><code>flowchart TD\n    Start[RQ fires job] --&gt; Load[Load ScheduledJob from DB]\n    Load --&gt; Check{status == active?}\n    Check --&gt;|no| Return[Return early]\n    Check --&gt;|yes| Overlap{Previous execution\\nstill running?}\n    Overlap --&gt;|yes| Skip[Skip + enqueue next]\n    Overlap --&gt;|no| Dispatch[Dispatch workflow trigger]\n    Dispatch --&gt;|success| Success[Increment run_count\\nReset retries\\nEnqueue next]\n    Dispatch --&gt;|failure| Fail{Retries exceeded?}\n    Fail --&gt;|no| Retry[Increment retry\\nBackoff delay\\nEnqueue next]\n    Fail --&gt;|yes| Dead[Set status = dead]\n    Success --&gt; CheckDone{Repeat limit reached?}\n    CheckDone --&gt;|yes| Done[Set status = done]\n    CheckDone --&gt;|no| EnqueueNext[Enqueue next at interval]</code></pre> <p>Step by step:</p> <ol> <li>Load: Read the <code>ScheduledJob</code> from the database</li> <li>Status check: If status is not <code>active</code>, return immediately (handles pause/stop)</li> <li>Overlap protection: Check if a previous execution from this job is still running. If so, skip this run and enqueue the next one at the normal interval.</li> <li>Dispatch: Call <code>dispatch_event(\"schedule\", event_data, user, db)</code> to fire the workflow trigger</li> <li>On success:<ul> <li>Increment <code>run_count</code> and <code>current_repeat</code></li> <li>Reset <code>current_retry</code> to 0</li> <li>Check if <code>total_repeats &gt; 0</code> and repeat limit is reached -- if so, set status to <code>done</code></li> <li>Otherwise, enqueue the next run at <code>interval_seconds</code></li> </ul> </li> <li>On failure:<ul> <li>Increment <code>error_count</code> and <code>current_retry</code></li> <li>If retries exceeded <code>max_retries</code>, set status to <code>dead</code></li> <li>Otherwise, enqueue the next attempt with exponential backoff</li> </ul> </li> </ol>"},{"location":"concepts/scheduler/#trigger-dispatch","title":"Trigger dispatch","text":"<p>When the scheduler fires, it constructs a trigger event with:</p> <pre><code>event_data = {\n    \"scheduled_job_id\": job.id,\n    \"scheduled_job_name\": job.name,\n    \"repeat_number\": job.current_repeat,\n    \"payload\": job.trigger_payload or {},\n}\n</code></pre> <p>This is dispatched via <code>dispatch_event(\"schedule\", ...)</code>, which finds the appropriate trigger node and starts a workflow execution. The <code>trigger_payload</code> field lets you pass custom data to the trigger on each run.</p>"},{"location":"concepts/scheduler/#deterministic-job-ids","title":"Deterministic job IDs","text":"<p>Each enqueued RQ job gets a deterministic job ID based on the scheduled job state:</p> <pre><code>sched-{job_id}-n{repeat_number}-rc{retry_count}\n</code></pre> <p>For example: <code>sched-a1b2c3d4-n5-rc0</code> (5th repeat, no retries).</p> <p>This prevents duplicate enqueues during recovery. If the same job ID already exists in Redis, the enqueue is a no-op rather than creating a duplicate.</p> <p>Why deterministic IDs matter</p> <p>Without deterministic IDs, a crash-recovery cycle could enqueue a job that is already waiting in Redis, causing it to run twice. The deterministic ID ensures idempotent enqueuing.</p>"},{"location":"concepts/scheduler/#exponential-backoff","title":"Exponential backoff","text":"<p>When a scheduled run fails, the next retry is delayed using exponential backoff:</p> <pre><code>delay = min(interval * 2^(retry_count - 1), interval * 10)\n</code></pre> Retry Interval: 60s Interval: 300s 1st 60s 300s 2nd 120s 600s 3rd 240s 1200s Cap 600s (10x) 3000s (10x) <p>The backoff is capped at 10x the base interval. This prevents unreasonably long delays while still giving transient failures time to resolve.</p>"},{"location":"concepts/scheduler/#crash-recovery","title":"Crash recovery","text":"<p>On application startup, <code>recover_scheduled_jobs()</code> scans for active jobs that missed their scheduled run time:</p> <pre><code>stale_jobs = ScheduledJob.filter(\n    status == \"active\",\n    next_run_at &lt; now\n)\n</code></pre> <p>For each stale job, it calls <code>start_scheduled_job()</code> to re-enqueue the next run. Because enqueuing uses deterministic job IDs, this is safe to call even if some jobs are already queued in Redis.</p> <p>Recovery is automatic</p> <p>Call <code>recover_scheduled_jobs()</code> during application startup. It returns the number of jobs recovered, which is useful for logging. Jobs that were paused or completed are not affected.</p>"},{"location":"concepts/scheduler/#api-endpoints","title":"API endpoints","text":"<p>The scheduler is managed entirely through the REST API:</p> Endpoint Method Description <code>/api/v1/schedules/</code> <code>GET</code> List all scheduled jobs (supports <code>status</code> and <code>workflow_id</code> filters) <code>/api/v1/schedules/</code> <code>POST</code> Create a new scheduled job and enqueue its first run <code>/api/v1/schedules/{id}/</code> <code>GET</code> Get scheduled job details <code>/api/v1/schedules/{id}/</code> <code>PATCH</code> Update job configuration <code>/api/v1/schedules/{id}/</code> <code>DELETE</code> Delete a scheduled job <code>/api/v1/schedules/{id}/pause/</code> <code>POST</code> Pause an active job <code>/api/v1/schedules/{id}/resume/</code> <code>POST</code> Resume a paused job <code>/api/v1/schedules/batch-delete/</code> <code>POST</code> Delete multiple jobs at once"},{"location":"concepts/scheduler/#creating-a-schedule","title":"Creating a schedule","text":"<pre><code>POST /api/v1/schedules/\n{\n    \"name\": \"Daily report\",\n    \"workflow_id\": 1,\n    \"trigger_node_id\": \"trigger_schedule_abc123\",\n    \"interval_seconds\": 86400,\n    \"total_repeats\": 0,\n    \"max_retries\": 3,\n    \"timeout_seconds\": 600,\n    \"trigger_payload\": {\"report_type\": \"daily\"}\n}\n</code></pre> <p>Pause vs. Delete</p> <p>Pausing a job preserves its state (repeat count, error count, etc.) so it can be resumed later. Deleting a job permanently removes it. Use pause when you want to temporarily stop a schedule.</p>"},{"location":"concepts/scheduler/#pause-and-resume","title":"Pause and resume","text":"<ul> <li>Pause: Sets status to <code>paused</code> and clears <code>next_run_at</code>. Any already-enqueued RQ job will no-op on fire.</li> <li>Resume: Sets status back to <code>active</code> and enqueues the next run at <code>interval_seconds</code> from now.</li> </ul> <p>Only <code>active</code> jobs can be paused, and only <code>paused</code> jobs can be resumed. Attempting to pause/resume a job in any other state returns HTTP 400.</p>"},{"location":"concepts/scheduler/#whats-next","title":"What's next?","text":"<ul> <li>Learn how workflows execute: Execution</li> <li>Understand triggers that start workflows: Triggers</li> <li>Track costs for scheduled executions: Cost Tracking</li> </ul>"},{"location":"concepts/security/","title":"Security","text":""},{"location":"concepts/security/#security","title":"Security","text":"<p>Pipelit includes multiple layers of security for authentication, credential management, and agent identity verification.</p>"},{"location":"concepts/security/#authentication","title":"Authentication","text":"<p>All API endpoints require Bearer token authentication:</p> <pre><code>Authorization: Bearer &lt;api-key&gt;\n</code></pre> <p>API keys are generated per user and stored hashed in the database. There is no session-based auth, no OAuth, and no basic auth.</p> <p>No Default API Key</p> <p>API keys are created during user setup or via the admin interface. There are no hardcoded or default keys.</p>"},{"location":"concepts/security/#credential-encryption","title":"Credential Encryption","text":"<p>Sensitive credential data (LLM provider API keys, Telegram bot tokens, etc.) is encrypted at rest using Fernet symmetric encryption:</p> <ul> <li>Encryption key configured via <code>FIELD_ENCRYPTION_KEY</code> environment variable</li> <li>Uses <code>EncryptedString</code> SQLAlchemy column type</li> <li>Credentials are decrypted only when needed for execution</li> <li>API responses mask sensitive fields (show only last 4 characters)</li> </ul> <p>Protect Your Encryption Key</p> <p>If you lose the <code>FIELD_ENCRYPTION_KEY</code>, all stored credentials become unrecoverable. Back it up securely.</p>"},{"location":"concepts/security/#totp-based-mfa","title":"TOTP-Based MFA","text":"<p>Pipelit supports Time-based One-Time Password (TOTP) for multi-factor authentication:</p> <ul> <li>Standard TOTP compatible with authenticator apps (Google Authenticator, Authy, etc.)</li> <li>Rate limiting on failed attempts</li> <li>Account lockout after repeated failures</li> </ul>"},{"location":"concepts/security/#agent-identity-verification","title":"Agent Identity Verification","text":"<p>When agents communicate with each other (e.g., via <code>spawn_and_await</code>), they can verify identity using TOTP:</p> <ul> <li>Each agent user has a TOTP secret</li> <li>The <code>get_totp_code</code> tool retrieves the current code</li> <li>Receiving agents can verify the code to confirm the sender's identity</li> <li>Prevents unauthorized agent impersonation</li> </ul>"},{"location":"concepts/security/#credential-scope","title":"Credential Scope","text":"<p>Credentials are global \u2014 any authenticated user can use any credential for workflow execution. The <code>user_profile</code> field on credentials tracks who created them, not ownership.</p>"},{"location":"concepts/security/#agent-users","title":"Agent Users","text":"<p>Agent users are special accounts created for automated operations:</p> <ul> <li>Created without passwords (API key only) via <code>create_agent_user</code></li> <li>Separate API keys from the owner's personal key</li> <li>Used for agent-to-agent communication and self-modification</li> </ul> <p>Best Practice</p> <p>Never use your personal API key for agent operations. Always create separate agent users with their own API keys.</p>"},{"location":"concepts/security/#security-checklist","title":"Security Checklist","text":"Item Development Production <code>FIELD_ENCRYPTION_KEY</code> Generate any key Generate and securely store <code>SECRET_KEY</code> Default OK Must change <code>CORS_ALLOW_ALL_ORIGINS</code> <code>true</code> OK Set to <code>false</code> <code>DEBUG</code> <code>true</code> OK Must be <code>false</code> HTTPS Not required Required Redis auth Not required Enable <code>requirepass</code>"},{"location":"concepts/tools/","title":"Tools","text":""},{"location":"concepts/tools/#tools","title":"Tools","text":"<p>Tools are sub-component nodes that give agents the ability to take actions in the world -- running shell commands, making HTTP requests, searching the web, and even modifying the platform itself. Each tool is implemented as a LangChain <code>@tool</code> function that the LLM can invoke through function calling.</p>"},{"location":"concepts/tools/#how-tools-connect-to-agents","title":"How Tools Connect to Agents","text":"<p>Tools are sub-component nodes that connect to agent nodes via the green diamond tools handle on the agent's bottom edge:</p> <pre><code>                    +------------------+\n                    |     Agent        |\n                    |                  |\n                    +--[model][tools]--+\n                         |       |\n                    AI Model   run_command\n                               web_search\n                               calculator\n</code></pre> <p>The connection uses <code>edge_label=\"tool\"</code> on the workflow edge. At build time, the agent queries all tool edges pointing to it, loads each tool node's component factory, and registers the resulting LangChain <code>@tool</code> functions for LLM function calling.</p> <p>Multiple Tools per Agent</p> <p>An agent can have any number of tools connected. The LLM sees all of them in its function schema and decides which to call based on the conversation context.</p>"},{"location":"concepts/tools/#real-time-tool-status","title":"Real-Time Tool Status","text":"<p>When an agent invokes a tool during its reasoning loop, the tool node on the canvas shows live status badges via WebSocket:</p> <ol> <li>Running (spinning circle) -- tool function is executing.</li> <li>Success (checkmark) -- tool completed without errors.</li> <li>Failed (X) -- tool raised an exception.</li> </ol> <p>This is implemented by wrapping each tool function with a status publisher that broadcasts <code>node_status</code> events to the <code>workflow:{slug}</code> WebSocket channel before and after execution.</p>"},{"location":"concepts/tools/#built-in-utility-tools","title":"Built-In Utility Tools","text":"<p>These five tools provide general-purpose capabilities for agents:</p> Tool Component Type Description Config (<code>extra_config</code>) Run Command <code>run_command</code> Execute shell commands via subprocess. Returns stdout, stderr, and exit code. <code>timeout</code> (default: 300s) HTTP Request <code>http_request</code> Make HTTP requests using httpx. Returns status code and response body. <code>method</code> (default: GET), <code>headers</code>, <code>timeout</code> (default: 30s) Web Search <code>web_search</code> Search the web via a SearXNG instance. Returns top 5 results with title, URL, and snippet. <code>searxng_url</code> (required) Calculator <code>calculator</code> Safely evaluate math expressions using Python's AST parser. Supports <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>//</code>, <code>%</code>, <code>**</code>. -- Date &amp; Time <code>datetime</code> Get the current date and time. Returns formatted timestamp. <code>timezone</code> (optional, default: UTC)"},{"location":"concepts/tools/#run-command","title":"Run Command","text":"<p>Executes arbitrary shell commands in a subprocess with configurable timeout. Output is capped at 50,000 characters (truncated from the middle if exceeded). The subprocess runs with <code>stdin=DEVNULL</code> and <code>start_new_session=True</code> for isolation.</p> <pre><code>Agent: \"List files in the project directory\"\nTool call: run_command(command=\"ls -la /home/user/project\")\nTool result: \"total 48\\ndrwxr-xr-x  6 user user 4096 ...\"\n</code></pre> <p>Security Consideration</p> <p><code>run_command</code> executes shell commands with the same permissions as the Pipelit process. Only connect this tool to agents in trusted environments.</p>"},{"location":"concepts/tools/#http-request","title":"HTTP Request","text":"<p>Makes HTTP requests with configurable default method, headers, and timeout. The agent can override the method and provide a request body per call. Response bodies are truncated to 4,000 characters.</p>"},{"location":"concepts/tools/#web-search","title":"Web Search","text":"<p>Queries a SearXNG metasearch engine instance. Requires a running SearXNG deployment -- configure the URL in the node's <code>extra_config</code>. Returns the top 5 results formatted as title, URL, and content snippet.</p>"},{"location":"concepts/tools/#calculator","title":"Calculator","text":"<p>Uses Python's <code>ast</code> module to safely parse and evaluate mathematical expressions. Only numeric constants and basic arithmetic operators are allowed -- no function calls, variable access, or imports.</p>"},{"location":"concepts/tools/#date-time","title":"Date &amp; Time","text":"<p>Returns the current timestamp formatted as <code>YYYY-MM-DD HH:MM:SS TZ</code>. Supports any timezone from Python's <code>zoneinfo</code> module (e.g., <code>America/New_York</code>, <code>Europe/London</code>). Defaults to UTC if no timezone is configured.</p>"},{"location":"concepts/tools/#self-awareness-tools","title":"Self-Awareness Tools","text":"<p>These tools enable agents to introspect, manage the platform, and orchestrate other workflows. They are the building blocks for self-improving agents that can modify their own configuration, create new workflows, and delegate work.</p> Tool Component Type Description Create Agent User <code>create_agent_user</code> Provision API credentials (username + API key) for the agent to authenticate with the platform API. Idempotent -- returns existing credentials if already created. Platform API <code>platform_api</code> Make authenticated HTTP requests to the Pipelit REST API. Agents can call any endpoint -- CRUD workflows, nodes, edges, credentials, and more. Who Am I <code>whoami</code> Get the agent's identity -- workflow slug, node ID, current system prompt, and instructions for self-modification via the API. Get TOTP Code <code>get_totp_code</code> Retrieve the current TOTP code for the agent's user account, used for identity verification in multi-agent scenarios. Epic Tools <code>epic_tools</code> Create, query, update, and search epics for organizing multi-step task delegation. Task Tools <code>task_tools</code> Create, list, update, and cancel tasks within epics. Tasks link to workflow executions for tracking. Spawn &amp; Await <code>spawn_and_await</code> Spawn a child workflow execution and pause the agent until it completes. The child's output is returned to the agent's reasoning loop. Workflow Create <code>workflow_create</code> Create entire workflows programmatically from a YAML DSL specification -- triggers, nodes, edges, and configurations in one call. Workflow Discover <code>workflow_discover</code> Search existing workflows by requirements. Returns scored matches with gap analysis and reuse/fork/create recommendations. Scheduler Tools <code>scheduler_tools</code> Create, pause, resume, stop, and list scheduled recurring jobs for any workflow. System Health <code>system_health</code> Check platform infrastructure health -- Redis connectivity, RQ worker status, queue depths, stuck executions, failed executions, and scheduled job state."},{"location":"concepts/tools/#create-agent-user-platform-api","title":"Create Agent User + Platform API","text":"<p>These two tools work together to give an agent full API access:</p> <ol> <li>The agent calls <code>create_agent_user</code> to get an API key.</li> <li>The agent calls <code>platform_api</code> with that API key to interact with any REST endpoint.</li> <li>Common first call: <code>platform_api(path=\"/openapi.json\")</code> to discover available endpoints.</li> </ol> <p>Self-Modification Pattern</p> <p>An agent with <code>whoami</code> + <code>create_agent_user</code> + <code>platform_api</code> can read its own configuration, modify its system prompt, add or remove tool connections, and even restructure its own workflow -- all through the standard REST API.</p>"},{"location":"concepts/tools/#spawn-await","title":"Spawn &amp; Await","text":"<p>This tool enables multi-agent orchestration. When an agent calls <code>spawn_and_await</code>:</p> <ol> <li>The tool calls LangGraph's <code>interrupt()</code> to checkpoint the agent mid-reasoning.</li> <li>The orchestrator creates a child <code>WorkflowExecution</code> and enqueues it on RQ.</li> <li>The parent agent's node enters a <code>waiting</code> state.</li> <li>When the child execution completes, its output is injected into the parent's state.</li> <li>The parent agent resumes from the checkpoint -- <code>interrupt()</code> returns the child's output as a JSON string.</li> </ol> <p>This requires either conversation memory (SqliteSaver) or an ephemeral RedisSaver checkpointer to persist the agent's state during the wait.</p>"},{"location":"concepts/tools/#epic-tools-task-tools","title":"Epic Tools + Task Tools","text":"<p>These tools provide a project management layer for agents:</p> <ul> <li>Epics group related tasks with optional token/USD budgets.</li> <li>Tasks are individual work items within an epic, each linked to a workflow execution.</li> <li>Budget enforcement happens at the orchestrator level -- if an epic's budget is exceeded, the execution fails.</li> </ul>"},{"location":"concepts/tools/#system-health","title":"System Health","text":"<p>Returns a comprehensive JSON health report including:</p> <ul> <li>Redis connectivity and ping latency</li> <li>RQ worker count and status</li> <li>Queue depths (pending jobs)</li> <li>Stuck executions (running for too long)</li> <li>Recent failed executions</li> <li>Scheduled job status</li> </ul>"},{"location":"concepts/tools/#complete-tool-reference","title":"Complete Tool Reference","text":"Tool Category Input Output <code>run_command</code> Utility <code>command: str</code> stdout/stderr string <code>http_request</code> Utility <code>url: str</code>, <code>method: str</code>, <code>body: str</code> HTTP status + response body <code>web_search</code> Utility <code>query: str</code> Formatted search results <code>calculator</code> Utility <code>expression: str</code> Numeric result string <code>datetime</code> Utility -- Formatted timestamp string <code>create_agent_user</code> Self-Awareness <code>purpose: str</code> JSON with username, api_key, api_base_url <code>platform_api</code> Self-Awareness <code>method</code>, <code>path</code>, <code>body</code>, <code>api_key</code>, <code>base_url</code> JSON API response <code>whoami</code> Self-Awareness -- JSON with identity and self-modification instructions <code>get_totp_code</code> Self-Awareness <code>username: str</code> JSON with username and TOTP code <code>epic_tools</code> Self-Awareness varies per sub-tool JSON result from epic operations <code>task_tools</code> Self-Awareness varies per sub-tool JSON result from task operations <code>spawn_and_await</code> Self-Awareness <code>workflow_slug</code>, <code>input_text</code>, <code>task_id</code>, <code>input_data</code> JSON child workflow output <code>workflow_create</code> Self-Awareness <code>dsl: str</code>, <code>tags: str</code> JSON with workflow_id, slug, counts <code>workflow_discover</code> Self-Awareness <code>requirements: str</code>, <code>limit: int</code> JSON with matches, scores, recommendations <code>scheduler_tools</code> Self-Awareness varies per sub-tool JSON result from schedule operations <code>system_health</code> Self-Awareness -- JSON health report"},{"location":"concepts/triggers/","title":"Triggers","text":""},{"location":"concepts/triggers/#triggers","title":"Triggers","text":"<p>Triggers are the entry points of a workflow. They define how and when a workflow starts executing. In Pipelit, triggers are not a separate concept from nodes -- they are nodes, placed directly on the canvas alongside agents, tools, and logic.</p>"},{"location":"concepts/triggers/#triggers-are-nodes","title":"Triggers are nodes","text":"<p>Unlike many automation platforms that treat triggers as external configuration, Pipelit uses a unified node model. A trigger is a regular workflow node with:</p> <ul> <li>A <code>component_type</code> prefixed with <code>trigger_</code> (e.g., <code>trigger_chat</code>, <code>trigger_telegram</code>)</li> <li>Output ports that produce data when the trigger fires</li> <li>A position on the canvas, connected to downstream nodes via edges</li> <li>An orange border (<code>#f97316</code>) for visual identification</li> </ul> <p>This unified design means you can:</p> <ul> <li>Place multiple triggers on the same canvas</li> <li>Connect the same downstream node to different triggers</li> <li>See trigger nodes alongside all other nodes in the editor</li> <li>Inspect trigger output after execution, just like any other node</li> </ul> <p>Display names</p> <p>On the canvas, trigger nodes strip the <code>trigger_</code> prefix for cleaner display. For example, a <code>trigger_telegram</code> node shows as telegram, and a <code>trigger_chat</code> node shows as chat.</p>"},{"location":"concepts/triggers/#trigger-types","title":"Trigger types","text":"<p>Pipelit includes six trigger types, each designed for a different input channel:</p> Trigger Component Type Description Output Ports Chat <code>trigger_chat</code> Receives messages from the built-in chat interface <code>text</code> (STRING), <code>payload</code> (OBJECT) Telegram <code>trigger_telegram</code> Receives messages from a Telegram bot <code>text</code> (STRING), <code>chat_id</code> (NUMBER), <code>payload</code> (OBJECT) Manual <code>trigger_manual</code> Fired manually from the UI or API <code>payload</code> (OBJECT) Schedule <code>trigger_schedule</code> Fires on a recurring interval via the scheduler <code>timestamp</code> (STRING) Workflow <code>trigger_workflow</code> Fires when another workflow invokes this one as a subworkflow <code>payload</code> (OBJECT) Error <code>trigger_error</code> Fires when an error occurs during execution <code>error</code> (OBJECT)"},{"location":"concepts/triggers/#chat-trigger","title":"Chat Trigger","text":"<p>The most common trigger for interactive workflows. When a user sends a message through the built-in chat panel or the chat API (<code>POST /api/v1/workflows/{slug}/chat/</code>), the chat trigger fires with the message text and full payload.</p> <pre><code>flowchart LR\n    T[\"Chat Trigger&lt;br/&gt;&lt;small&gt;text, payload&lt;/small&gt;\"] --&gt; Agent\n    M[AI Model] -.-&gt;|model| Agent\n    Agent --&gt; Response[\"Response\"]</code></pre>"},{"location":"concepts/triggers/#telegram-trigger","title":"Telegram Trigger","text":"<p>Connects your workflow to a Telegram bot. When a message arrives via the Telegram webhook, the trigger fires with the message text, the chat ID (for reply routing), and the full Telegram payload.</p> <p>Telegram credentials</p> <p>To use the Telegram trigger, create a Telegram credential in the Credentials page with your bot token. The platform handles webhook registration and message routing.</p>"},{"location":"concepts/triggers/#manual-trigger","title":"Manual Trigger","text":"<p>The simplest trigger -- fire it on demand from the executions UI or via the API. Useful for testing, one-off tasks, or workflows triggered by external systems through the API.</p>"},{"location":"concepts/triggers/#schedule-trigger","title":"Schedule Trigger","text":"<p>Fires on a recurring interval using Pipelit's self-rescheduling scheduler. Configure the interval, repeat count, and retry behavior through the Schedules API. The trigger output includes a <code>timestamp</code> of when it fired.</p> <p>No cron syntax</p> <p>The scheduler uses interval-based timing (e.g., every 30 minutes), not cron expressions. It supports pause/resume, exponential backoff on failure, and automatic recovery after platform restarts.</p>"},{"location":"concepts/triggers/#workflow-trigger","title":"Workflow Trigger","text":"<p>Fires when another workflow invokes this one as a child via a <code>workflow</code> (subworkflow) node or a <code>spawn_and_await</code> tool. The parent workflow passes data through the <code>payload</code> output port. This enables workflow composition and multi-agent delegation patterns.</p>"},{"location":"concepts/triggers/#error-trigger","title":"Error Trigger","text":"<p>A special trigger that fires when an error occurs during execution. This allows you to build error-handling branches that run automatically when something goes wrong -- for example, sending an alert via Telegram or logging the error to an external system.</p>"},{"location":"concepts/triggers/#trigger-scoped-execution","title":"Trigger-scoped execution","text":"<p>One of Pipelit's most important execution behaviors is trigger-scoped compilation. When a trigger fires, the execution engine does not compile or run the entire workflow. Instead, it:</p> <ol> <li>Starts at the firing trigger node</li> <li>Performs a breadth-first search (BFS) following all outgoing edges</li> <li>Collects only the nodes reachable from that trigger</li> <li>Compiles and executes just those nodes</li> </ol> <pre><code>flowchart LR\n    subgraph active[\"Executed (chat fires)\"]\n        TC[\"Chat Trigger\"] --&gt; Agent\n        Agent --&gt; Format[\"Code: Format\"]\n    end\n\n    subgraph inactive[\"Not executed\"]\n        TS[\"Schedule Trigger\"] --&gt; Report[\"Code: Report\"]\n    end\n\n    M[AI Model] -.-&gt;|model| Agent\n    Tool[Web Search] -.-&gt;|tool| Agent\n\n    style inactive fill:none,stroke:#666,stroke-dasharray: 5 5\n    style active fill:none,stroke:#22c55e</code></pre> <p>In this example, when the chat trigger fires, only the Chat Trigger, Agent, and Format nodes execute. The Schedule Trigger and Report nodes are completely ignored -- they belong to a separate branch that only runs on a schedule.</p>"},{"location":"concepts/triggers/#why-trigger-scoped-execution-matters","title":"Why trigger-scoped execution matters","text":"<p>This design has several practical benefits:</p> <ul> <li>Multiple entry points -- One workflow can serve multiple channels (chat, Telegram, scheduled tasks) without interference.</li> <li>Safe iteration -- You can add new nodes to the canvas without affecting existing trigger branches. Unconnected work-in-progress nodes will not cause build errors.</li> <li>Efficient execution -- Only the relevant portion of the graph is compiled and run, keeping execution fast even for large workflows.</li> <li>Independent error handling -- An error in one trigger's branch does not affect other branches.</li> </ul> <p>Shared nodes need explicit connections</p> <p>If you want a node to be reachable from multiple triggers, you must connect it downstream of each trigger. There is no implicit sharing -- a node only executes if there is a path from the firing trigger to that node.</p>"},{"location":"concepts/triggers/#the-trigger-expression-shorthand","title":"The <code>trigger</code> expression shorthand","text":"<p>In Jinja2 expressions within node configuration, you can reference the firing trigger's output using the <code>trigger</code> shorthand:</p> <ul> <li><code>{{ trigger.text }}</code> -- The text content from the trigger</li> <li><code>{{ trigger.payload }}</code> -- The full trigger payload</li> </ul> <p>This shorthand always refers to whichever trigger fired the current execution, making it safe to use in nodes that are downstream of multiple triggers.</p> <p>Use <code>trigger</code> for portable expressions</p> <p>Instead of referencing a specific trigger node ID (like <code>{{ trigger_chat_abc123.text }}</code>), use <code>{{ trigger.text }}</code>. This works regardless of which trigger fired and survives node replacements.</p>"},{"location":"concepts/triggers/#whats-next","title":"What's next?","text":"<ul> <li>Understand the nodes that triggers connect to: Nodes &amp; Edges</li> <li>Learn about LLM-powered agents: Agents</li> <li>Build a chat workflow: Quickstart Tutorial</li> </ul>"},{"location":"concepts/workflows/","title":"Workflows","text":""},{"location":"concepts/workflows/#workflows","title":"Workflows","text":"<p>A workflow is the central organizing unit in Pipelit. It represents a visual pipeline that you design on a drag-and-drop canvas, connecting triggers, AI agents, tools, and logic nodes into a directed graph that executes automatically.</p>"},{"location":"concepts/workflows/#what-is-a-workflow","title":"What is a workflow?","text":"<p>A workflow is a collection of nodes (processing steps) connected by edges (data flow paths) arranged on a 2D canvas. When a trigger fires, Pipelit compiles the downstream portion of the graph into a LangGraph execution plan and runs each node in topological order, passing data along the edges.</p> <pre><code>flowchart LR\n    T[Chat Trigger] --&gt; A[Agent]\n    M[AI Model] -.-&gt;|model| A\n    Tool1[Web Search] -.-&gt;|tool| A\n    Tool2[Calculator] -.-&gt;|tool| A\n    A --&gt; S[Switch]\n    S --&gt;|\"route: summary\"| Sum[Code: Summarize]\n    S --&gt;|\"route: detail\"| Det[Code: Detail]</code></pre> <p>The canvas is your primary design surface. You add nodes from the Node Palette on the left, configure them in the Details Panel on the right, and wire them together by dragging edges between handles.</p>"},{"location":"concepts/workflows/#workflow-lifecycle","title":"Workflow lifecycle","text":"<p>Every workflow moves through four stages:</p> <pre><code>flowchart LR\n    Create --&gt; Design --&gt; Validate --&gt; Execute\n    Execute --&gt;|iterate| Design</code></pre>"},{"location":"concepts/workflows/#1-create","title":"1. Create","text":"<p>Create a new workflow from the dashboard. Each workflow gets a name and an auto-generated slug (a URL-friendly identifier like <code>my-chat-bot</code>). The slug is used throughout the API, WebSocket subscriptions, and browser URLs.</p>"},{"location":"concepts/workflows/#2-design","title":"2. Design","text":"<p>Open the workflow editor to build your pipeline on the canvas:</p> <ul> <li>Add nodes from the palette (triggers, agents, tools, logic, sub-components)</li> <li>Connect nodes by dragging from output handles to input handles</li> <li>Configure nodes by selecting them and editing settings in the details panel</li> <li>Attach sub-components like AI models, tools, and memory to agent nodes via diamond-shaped handles</li> </ul>"},{"location":"concepts/workflows/#3-validate","title":"3. Validate","text":"<p>Before execution, validate your workflow to catch structural issues:</p> <ul> <li>Missing required connections (e.g., an agent without a model)</li> <li>Type mismatches between connected ports</li> <li>Orphaned conditional edges</li> <li>Unknown node references</li> </ul> <p>Validate early, validate often</p> <p>Use the Validate button in the editor toolbar or call <code>POST /api/v1/workflows/{slug}/validate/</code> from the API. Validation runs automatically before execution, but catching issues during design saves time.</p>"},{"location":"concepts/workflows/#4-execute","title":"4. Execute","text":"<p>Trigger the workflow to run it. Execution happens in the background via an RQ worker:</p> <ol> <li>The trigger fires (chat message, Telegram message, schedule tick, manual dispatch, etc.)</li> <li>The builder compiles only the nodes reachable from that trigger</li> <li>The orchestrator executes nodes in topological order</li> <li>Each node receives data from upstream nodes via resolved Jinja2 expressions</li> <li>Real-time status updates stream to the frontend over WebSocket</li> </ol> <p>After execution, you can inspect results, logs, and per-node outputs in the Executions page.</p>"},{"location":"concepts/workflows/#workflow-slugs","title":"Workflow slugs","text":"<p>Every workflow is identified by a slug -- a URL-friendly string derived from the workflow name. Slugs are unique across the platform and used as stable identifiers in:</p> <ul> <li>Browser URLs: <code>/workflows/my-chat-bot</code></li> <li>API paths: <code>/api/v1/workflows/my-chat-bot/</code></li> <li>WebSocket channels: <code>workflow:my-chat-bot</code></li> <li>Subworkflow references: a <code>workflow</code> node targets another workflow by slug</li> </ul> <p>Note</p> <p>Slugs are generated automatically when you create a workflow. They remain stable even if you rename the workflow later.</p>"},{"location":"concepts/workflows/#multi-trigger-support","title":"Multi-trigger support","text":"<p>A single workflow can contain multiple trigger nodes, each defining an independent entry point into the graph. This is a powerful design pattern that lets you reuse downstream logic across different input channels.</p> <pre><code>flowchart LR\n    TC[Chat Trigger] --&gt; Agent\n    TT[Telegram Trigger] --&gt; Agent\n    TS[Schedule Trigger] --&gt; Reporter[Code: Daily Report]\n    M[AI Model] -.-&gt;|model| Agent\n    Agent --&gt; Output[Code: Format]</code></pre> <p>In the example above, the same Agent node handles both chat and Telegram inputs, while a separate Schedule Trigger feeds a completely independent reporting branch.</p>"},{"location":"concepts/workflows/#trigger-scoped-execution","title":"Trigger-scoped execution","text":"<p>When a trigger fires, Pipelit does not execute the entire workflow. Instead, it performs a BFS (breadth-first search) from the firing trigger and compiles only the nodes reachable downstream. Unconnected branches and unused nodes on the same canvas are ignored entirely.</p> <p>This means:</p> <ul> <li>A chat message only runs the chat branch, not the Telegram branch</li> <li>A schedule tick only runs the scheduled branch, not the chat branch</li> <li>Nodes you are still building (not yet connected) will not cause errors during execution</li> </ul> <p>Each trigger branch is independent</p> <p>Nodes that are not reachable from the firing trigger will not execute. If you need a node to run from multiple triggers, connect it downstream of each one.</p>"},{"location":"concepts/workflows/#whats-next","title":"What's next?","text":"<ul> <li>Learn about the building blocks: Nodes &amp; Edges</li> <li>Understand how workflows start: Triggers</li> <li>Build your first workflow: Quickstart Tutorial</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Thank you for your interest in contributing to Pipelit! This section covers everything you need to get started as a developer.</p>"},{"location":"contributing/#guides","title":"Guides","text":""},{"location":"contributing/#development-setup","title":"Development Setup","text":"<p>Fork the repository, install dependencies, and run the backend, worker, and frontend in development mode.</p>"},{"location":"contributing/#testing","title":"Testing","text":"<p>Run the test suite, understand the test structure, write new tests with Bearer token authentication, and check coverage.</p>"},{"location":"contributing/#adding-components","title":"Adding Components","text":"<p>Step-by-step guide to creating new workflow node types: registry entries, component implementations, SQLAlchemy models, Pydantic schemas, and frontend types.</p>"},{"location":"contributing/#migrations","title":"Migrations","text":"<p>Alembic migration best practices: checking for conflicts, handling SQLite batch operations, testing against existing data, and common commands.</p>"},{"location":"contributing/#code-style","title":"Code Style","text":"<p>Python and TypeScript conventions, type hints, formatting, and the most important rule: this project uses FastAPI + SQLAlchemy, not Django.</p>"},{"location":"contributing/#quick-contribution-checklist","title":"Quick Contribution Checklist","text":"<p>Before submitting a pull request:</p> <ol> <li>Branch -- create a feature branch from <code>master</code></li> <li>Code -- follow the project's code style and conventions</li> <li>Test -- add or update tests for your changes</li> <li>Migrate -- create an Alembic migration if you changed database models</li> <li>Register -- if adding a new component type, register it in all required places</li> <li>Run tests -- ensure the full test suite passes</li> <li>Commit -- write clear, descriptive commit messages</li> </ol>"},{"location":"contributing/#tech-stack-reminder","title":"Tech Stack Reminder","text":"<p>This project uses:</p> Layer Technologies Backend FastAPI, SQLAlchemy 2.0, Alembic, Pydantic, RQ (Redis Queue) Frontend React, Vite, TypeScript, Shadcn/ui, React Flow, TanStack Query Execution LangGraph, LangChain, Redis pub/sub, WebSocket <p>Not Django</p> <p>This project uses FastAPI + SQLAlchemy + RQ. Never reference Django models, Django ORM, Django settings, or any Django concepts. The backend is Python/FastAPI with SQLAlchemy models and Alembic migrations.</p>"},{"location":"contributing/adding-components/","title":"Adding Components","text":""},{"location":"contributing/adding-components/#adding-components","title":"Adding Components","text":"<p>This guide walks through the complete process of adding a new workflow component type to Pipelit. A component type is a kind of node that can be placed on the workflow canvas.</p> <p>Register in ALL required places</p> <p>New component types must be registered in every layer of the stack. Missing any registration point will cause build errors, validation failures, or missing UI elements. Follow all steps below.</p>"},{"location":"contributing/adding-components/#overview","title":"Overview","text":"<p>Adding a new component requires changes in up to six places:</p> Step File(s) Layer 1. Register node type <code>platform/schemas/node_type_defs.py</code> Schema 2. Implement component <code>platform/components/your_component.py</code> Backend 3. Register import <code>platform/components/__init__.py</code> Backend 4. Add polymorphic identity <code>platform/models/node.py</code> (if needed) ORM 5. Add Pydantic literal <code>platform/frontend/src/types/models.ts</code> Frontend 6. Create migration <code>platform/alembic/versions/</code> (if schema changes) Database"},{"location":"contributing/adding-components/#step-1-register-the-node-type","title":"Step 1: Register the Node Type","text":"<p>Define the component's ports (inputs and outputs) in <code>platform/schemas/node_type_defs.py</code>:</p> <pre><code>register_node_type(NodeTypeSpec(\n    component_type=\"my_component\",\n    display_name=\"My Component\",\n    description=\"Does something useful\",\n    category=\"logic\",  # trigger, ai, tool, logic, memory, sub_component, self_awareness\n    inputs=[\n        PortDefinition(\n            name=\"input\",\n            data_type=DataType.STRING,\n            required=True,\n            description=\"The input text\",\n        ),\n    ],\n    outputs=[\n        PortDefinition(\n            name=\"output\",\n            data_type=DataType.STRING,\n            description=\"The processed result\",\n        ),\n    ],\n))\n</code></pre>"},{"location":"contributing/adding-components/#available-data-types","title":"Available Data Types","text":"<p>The <code>DataType</code> enum defines the types that ports can carry:</p> DataType Description <code>STRING</code> Text data <code>NUMBER</code> Numeric data (int or float) <code>BOOLEAN</code> True/false <code>OBJECT</code> JSON object (dict) <code>ARRAY</code> JSON array (list) <code>MESSAGES</code> LangGraph message list <code>ANY</code> Accepts any type"},{"location":"contributing/adding-components/#nodetypespec-fields","title":"NodeTypeSpec Fields","text":"Field Type Description <code>component_type</code> <code>str</code> Unique identifier (used everywhere) <code>display_name</code> <code>str</code> Human-readable name for the UI <code>description</code> <code>str</code> Short description shown in the node palette <code>category</code> <code>str</code> Grouping in the palette <code>inputs</code> <code>list[PortDefinition]</code> Input ports <code>outputs</code> <code>list[PortDefinition]</code> Output ports <code>requires_model</code> <code>bool</code> Whether this node needs an AI model sub-component <code>requires_tools</code> <code>bool</code> Whether this node accepts tool connections <code>requires_memory</code> <code>bool</code> Whether this node accepts a memory connection <code>requires_output_parser</code> <code>bool</code> Whether this node accepts an output parser <code>config_schema</code> <code>dict</code> JSON Schema for <code>extra_config</code> fields <code>executable</code> <code>bool</code> Whether this node shows execution badges (default <code>True</code>)"},{"location":"contributing/adding-components/#step-2-implement-the-component","title":"Step 2: Implement the Component","text":"<p>Create a new file in <code>platform/components/</code>. The component is a factory function decorated with <code>@register</code>:</p> platform/components/my_component.py<pre><code>\"\"\"My component \u2014 does something useful.\"\"\"\n\nfrom __future__ import annotations\n\nfrom components import register\n\n\n@register(\"my_component\")\ndef my_component_factory(node):\n    \"\"\"Build a LangGraph node function for this component.\n\n    Args:\n        node: The WorkflowNode ORM instance (with config, edges, etc.)\n\n    Returns:\n        A callable that takes WorkflowState dict and returns an output dict.\n    \"\"\"\n    # Read configuration from the node\n    config = node.component_config\n    extra = config.extra_config or {}\n    my_setting = extra.get(\"my_setting\", \"default_value\")\n\n    def run(state: dict) -&gt; dict:\n        # Access input data from upstream nodes via state\n        # The orchestrator resolves Jinja2 expressions before calling this\n        input_text = state.get(\"input\", \"\")\n\n        # Do your processing\n        result = f\"Processed: {input_text}\"\n\n        # Return output ports as a flat dict\n        return {\"output\": result}\n\n    return run\n</code></pre>"},{"location":"contributing/adding-components/#component-conventions","title":"Component Conventions","text":"<ul> <li>Return a flat dict with keys matching your output port names</li> <li>Underscore-prefixed keys are reserved for side effects:<ul> <li><code>_route</code> -- sets <code>state[\"route\"]</code> for conditional routing</li> <li><code>_messages</code> -- appended to the LangGraph message list</li> <li><code>_state_patch</code> -- merged into global state</li> </ul> </li> <li>Do not use <code>node_id</code> in the component logic; components are node-agnostic</li> <li>Tool components return a LangChain <code>@tool</code> function instead of a state function</li> </ul>"},{"location":"contributing/adding-components/#tool-component-example","title":"Tool Component Example","text":"<p>Tool components are used as sub-components attached to agent nodes. They return a LangChain tool:</p> platform/components/my_tool.py<pre><code>from __future__ import annotations\n\nfrom langchain_core.tools import tool\n\nfrom components import register\n\n\n@register(\"my_tool\")\ndef my_tool_factory(node):\n    \"\"\"Return a LangChain tool.\"\"\"\n    config = node.component_config\n    extra = config.extra_config or {}\n\n    @tool\n    def my_tool(query: str) -&gt; str:\n        \"\"\"Description of what this tool does (shown to the LLM).\"\"\"\n        # Tool implementation\n        return f\"Result for: {query}\"\n\n    return my_tool\n</code></pre>"},{"location":"contributing/adding-components/#step-3-register-the-import","title":"Step 3: Register the Import","text":"<p>Add your component module to the imports in <code>platform/components/__init__.py</code>:</p> platform/components/__init__.py<pre><code># Import all component modules to trigger @register decorators\nfrom components import (  # noqa: E402, F401\n    # ... existing imports ...\n    my_component,    # &lt;-- Add your component here\n)\n</code></pre> <p>This import triggers the <code>@register</code> decorator, adding your factory to the <code>COMPONENT_REGISTRY</code>.</p>"},{"location":"contributing/adding-components/#step-4-add-polymorphic-identity-if-needed","title":"Step 4: Add Polymorphic Identity (If Needed)","text":"<p>If your component requires custom fields on <code>BaseComponentConfig</code> beyond what <code>extra_config</code> provides, you may need to add columns to the <code>component_configs</code> table.</p> <p>For most components, the existing <code>extra_config</code> JSON field is sufficient -- store custom settings there:</p> <pre><code>extra = config.extra_config or {}\nmy_setting = extra.get(\"my_setting\", \"default_value\")\n</code></pre> <p>If you do need new columns on <code>BaseComponentConfig</code>, add them to <code>platform/models/node.py</code> and create an Alembic migration.</p>"},{"location":"contributing/adding-components/#step-5-add-frontend-type-definition","title":"Step 5: Add Frontend Type Definition","text":"<p>Add your component type to the <code>ComponentType</code> union in <code>platform/frontend/src/types/models.ts</code>:</p> <pre><code>export type ComponentType =\n    | \"trigger_telegram\"\n    | \"trigger_manual\"\n    // ... existing types ...\n    | \"my_component\"    // &lt;-- Add here\n</code></pre> <p>The frontend dynamically loads node type specifications from the <code>/api/v1/workflows/node-types/</code> endpoint, so the palette entry and port handles appear automatically once the backend registration is complete.</p>"},{"location":"contributing/adding-components/#step-6-create-migration-if-needed","title":"Step 6: Create Migration (If Needed)","text":"<p>If you modified SQLAlchemy models (added columns, changed constraints), create an Alembic migration:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\n\n# Check for conflicting heads\nalembic heads\n\n# Generate migration\nalembic revision --autogenerate -m \"add my_component support\"\n\n# Review the generated file, then apply\nalembic upgrade head\n</code></pre> <p>See Migrations for best practices.</p>"},{"location":"contributing/adding-components/#testing-your-component","title":"Testing Your Component","text":"<p>Write tests for the new component in <code>platform/tests/</code>:</p> platform/tests/test_my_component.py<pre><code>\"\"\"Tests for my_component.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom pathlib import Path\n\nimport pytest\n\n_platform_dir = str(Path(__file__).resolve().parent.parent)\nif _platform_dir not in sys.path:\n    sys.path.insert(0, _platform_dir)\n\nfrom components import get_component_factory\n\n\ndef test_my_component_basic():\n    \"\"\"Test basic component behavior.\"\"\"\n    factory = get_component_factory(\"my_component\")\n\n    # Create a mock node with minimal config\n    class MockConfig:\n        extra_config = {\"my_setting\": \"test_value\"}\n\n    class MockNode:\n        component_config = MockConfig()\n\n    run = factory(MockNode())\n    result = run({\"input\": \"hello\"})\n\n    assert \"output\" in result\n    assert result[\"output\"] == \"Processed: hello\"\n</code></pre>"},{"location":"contributing/adding-components/#verification-checklist","title":"Verification Checklist","text":"<p>After completing all steps, verify:</p> <ul> <li>[ ] <code>python -c \"from components import get_component_factory; get_component_factory('my_component')\"</code> succeeds</li> <li>[ ] The component appears in <code>GET /api/v1/workflows/node-types/</code></li> <li>[ ] The node can be added to a workflow canvas in the UI</li> <li>[ ] Edges can be created to/from the node respecting port types</li> <li>[ ] The node executes correctly in a workflow</li> <li>[ ] Tests pass: <code>python -m pytest tests/ -v</code></li> </ul>"},{"location":"contributing/code-style/","title":"Code Style","text":""},{"location":"contributing/code-style/#code-style","title":"Code Style","text":"<p>This page documents the coding conventions and style guidelines for contributing to Pipelit.</p>"},{"location":"contributing/code-style/#the-most-important-rule","title":"The Most Important Rule","text":"<p>This project uses FastAPI + SQLAlchemy, NOT Django</p> <p>Pipelit's backend is built on FastAPI, SQLAlchemy 2.0, Alembic, and RQ (Redis Queue). Never reference Django models, Django ORM, Django settings, Django views, or any Django concepts in code, comments, commit messages, or documentation.</p> <ul> <li>Models are SQLAlchemy <code>declarative_base</code> classes, not <code>django.db.models.Model</code></li> <li>Migrations use Alembic, not <code>manage.py migrate</code></li> <li>Settings use Pydantic <code>BaseSettings</code>, not <code>django.conf.settings</code></li> <li>Background tasks use RQ, not Celery (though Celery is also not Django-specific)</li> <li>Authentication uses FastAPI dependencies with Bearer tokens, not Django middleware</li> </ul>"},{"location":"contributing/code-style/#python","title":"Python","text":""},{"location":"contributing/code-style/#general","title":"General","text":"<ul> <li>Follow PEP 8 for formatting and naming</li> <li>Maximum line length: 100 characters (relaxed from PEP 8's 79)</li> <li>Use absolute imports from <code>platform/</code> as the root (e.g., <code>from models.node import WorkflowNode</code>)</li> <li>Prefer f-strings over <code>.format()</code> or <code>%</code> formatting</li> </ul>"},{"location":"contributing/code-style/#type-hints","title":"Type Hints","text":"<p>Use type hints on all function signatures:</p> <pre><code># Good\ndef resolve_llm_for_node(node: WorkflowNode, db: Session) -&gt; BaseChatModel:\n    ...\n\n# Bad\ndef resolve_llm_for_node(node, db):\n    ...\n</code></pre> <p>Use <code>from __future__ import annotations</code> at the top of every module for modern annotation syntax:</p> <pre><code>from __future__ import annotations\n\nfrom typing import Any\n\ndef process(data: dict[str, Any]) -&gt; list[str]:\n    ...\n</code></pre>"},{"location":"contributing/code-style/#naming-conventions","title":"Naming Conventions","text":"Element Convention Example Modules <code>snake_case</code> <code>node_type_defs.py</code> Classes <code>PascalCase</code> <code>WorkflowNode</code>, <code>NodeTypeSpec</code> Functions <code>snake_case</code> <code>get_component_factory()</code> Constants <code>UPPER_SNAKE_CASE</code> <code>COMPONENT_REGISTRY</code>, <code>NODE_TYPE_REGISTRY</code> Variables <code>snake_case</code> <code>edge_type</code>, <code>node_id</code> Private Leading underscore <code>_safe_eval()</code>, <code>_platform_dir</code>"},{"location":"contributing/code-style/#imports","title":"Imports","text":"<p>Organize imports in three groups, separated by blank lines:</p> <pre><code># 1. Standard library\nfrom __future__ import annotations\n\nimport os\nfrom pathlib import Path\n\n# 2. Third-party\nfrom fastapi import APIRouter, Depends, HTTPException\nfrom sqlalchemy.orm import Session\n\n# 3. Local\nfrom auth import get_current_user\nfrom database import get_db\nfrom models.workflow import Workflow\n</code></pre>"},{"location":"contributing/code-style/#sqlalchemy-models","title":"SQLAlchemy Models","text":"<ul> <li>Use SQLAlchemy 2.0 style with <code>Mapped</code> type annotations</li> <li>Use <code>mapped_column()</code> instead of <code>Column()</code></li> <li>Define relationships with explicit <code>Mapped</code> types</li> </ul> <pre><code># Good (SQLAlchemy 2.0)\nclass WorkflowNode(Base):\n    __tablename__ = \"workflow_nodes\"\n\n    id: Mapped[int] = mapped_column(primary_key=True)\n    node_id: Mapped[str] = mapped_column(String(100))\n    workflow_id: Mapped[int] = mapped_column(ForeignKey(\"workflows.id\"))\n\n# Bad (SQLAlchemy 1.x style)\nclass WorkflowNode(Base):\n    __tablename__ = \"workflow_nodes\"\n\n    id = Column(Integer, primary_key=True)\n    node_id = Column(String(100))\n</code></pre>"},{"location":"contributing/code-style/#fastapi-endpoints","title":"FastAPI Endpoints","text":"<ul> <li>Use <code>APIRouter</code> for route grouping</li> <li>Use dependency injection for database sessions and authentication</li> <li>Return Pydantic models or dicts, never raw ORM objects</li> <li>Use appropriate HTTP status codes</li> </ul> <pre><code>@router.post(\"/workflows/\", status_code=201)\ndef create_workflow(\n    data: WorkflowCreate,\n    db: Session = Depends(get_db),\n    user: UserProfile = Depends(get_current_user),\n):\n    ...\n</code></pre>"},{"location":"contributing/code-style/#pydantic-schemas","title":"Pydantic Schemas","text":"<ul> <li>Use <code>Literal</code> types for enum-like fields (<code>component_type</code>, <code>edge_type</code>)</li> <li>Use <code>model_config = ConfigDict(from_attributes=True)</code> for ORM compatibility</li> <li>Separate create, update, and response schemas</li> </ul>"},{"location":"contributing/code-style/#authentication","title":"Authentication","text":"<ul> <li>API uses Bearer token authentication exclusively</li> <li>Always use the <code>get_current_user</code> dependency for authenticated endpoints</li> <li>Agent users are created without passwords via <code>create_agent_user</code></li> <li>Never use the user's personal API key for agent operations</li> </ul>"},{"location":"contributing/code-style/#typescript","title":"TypeScript","text":""},{"location":"contributing/code-style/#general_1","title":"General","text":"<ul> <li>Use TypeScript strict mode (enabled in <code>tsconfig.json</code>)</li> <li>Prefer <code>const</code> over <code>let</code>; never use <code>var</code></li> <li>Use arrow functions for callbacks and inline functions</li> <li>Use template literals over string concatenation</li> </ul>"},{"location":"contributing/code-style/#types","title":"Types","text":"<ul> <li>Define interfaces for API response types in <code>types/models.ts</code></li> <li>Use <code>interface</code> for object shapes, <code>type</code> for unions and intersections</li> <li>Avoid <code>any</code> -- use <code>unknown</code> and narrow with type guards when the type is uncertain</li> </ul> <pre><code>// Good\ninterface WorkflowNode {\n    id: number;\n    node_id: string;\n    component_type: ComponentType;\n}\n\n// Bad\nconst node: any = response.data;\n</code></pre>"},{"location":"contributing/code-style/#react-components","title":"React Components","text":"<ul> <li>Use functional components with hooks</li> <li>Use TanStack Query for all API data fetching</li> <li>Use Shadcn/ui components for UI elements</li> <li>Colocate component-specific types with the component file</li> </ul> <pre><code>// Good\nexport function WorkflowCanvas({ slug }: { slug: string }) {\n    const { data: nodes } = useNodes(slug);\n    // ...\n}\n\n// Bad - class component\nclass WorkflowCanvas extends React.Component { ... }\n</code></pre>"},{"location":"contributing/code-style/#api-hooks","title":"API Hooks","text":"<p>All API interactions go through TanStack Query hooks defined in <code>frontend/src/api/</code>:</p> <pre><code>// Queries (GET)\nexport function useWorkflows() {\n    return useQuery({ queryKey: [\"workflows\"], queryFn: fetchWorkflows });\n}\n\n// Mutations (POST/PATCH/DELETE)\nexport function useCreateWorkflow() {\n    return useMutation({ mutationFn: createWorkflow });\n}\n</code></pre>"},{"location":"contributing/code-style/#file-organization","title":"File Organization","text":"<ul> <li>One concern per file. Do not mix unrelated functionality.</li> <li>Keep files focused. If a file grows beyond 300-400 lines, consider splitting it.</li> <li>Mirror backend structure in frontend. API hooks in <code>api/</code>, page components in <code>features/</code>, shared components in <code>components/</code>.</li> </ul>"},{"location":"contributing/code-style/#commit-messages","title":"Commit Messages","text":"<ul> <li>Use present tense, imperative mood: \"add feature\" not \"added feature\"</li> <li>Start with a category when appropriate: <code>fix:</code>, <code>feat:</code>, <code>test:</code>, <code>docs:</code>, <code>refactor:</code></li> <li>Keep the first line under 72 characters</li> <li>Reference issue numbers when applicable: <code>fix: resolve edge validation crash (#42)</code></li> </ul>"},{"location":"contributing/code-style/#documentation","title":"Documentation","text":"<ul> <li>Document public functions and classes with docstrings</li> <li>Use <code>\"\"\"triple double quotes\"\"\"</code> for Python docstrings</li> <li>Use <code>/** JSDoc */</code> comments for exported TypeScript functions</li> <li>Keep comments focused on \"why\" rather than \"what\"</li> </ul>"},{"location":"contributing/development-setup/","title":"Development Setup","text":""},{"location":"contributing/development-setup/#development-setup","title":"Development Setup","text":"<p>This guide walks through setting up a complete Pipelit development environment from scratch.</p>"},{"location":"contributing/development-setup/#prerequisites","title":"Prerequisites","text":"Tool Minimum Version Purpose Python 3.10+ Backend runtime Redis 8.0+ Task queue, pub/sub, search Node.js 18+ Frontend build and dev server Git 2.0+ Source control"},{"location":"contributing/development-setup/#fork-and-clone","title":"Fork and Clone","text":"<ol> <li> <p>Fork the repository on GitHub: theuselessai/Pipelit</p> </li> <li> <p>Clone your fork:</p> <pre><code>git clone git@github.com:YOUR_USERNAME/Pipelit.git\ncd Pipelit\n</code></pre> </li> <li> <p>Add the upstream remote:</p> <pre><code>git remote add upstream git@github.com:theuselessai/Pipelit.git\n</code></pre> </li> </ol>"},{"location":"contributing/development-setup/#backend-setup","title":"Backend Setup","text":"<p>Create a Python virtual environment and install dependencies:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -r platform/requirements.txt\n</code></pre> <p>The <code>requirements.txt</code> includes FastAPI, SQLAlchemy, LangGraph, LangChain, and all other backend dependencies.</p>"},{"location":"contributing/development-setup/#frontend-setup","title":"Frontend Setup","text":"<p>Install Node.js dependencies:</p> <pre><code>cd platform/frontend\nnpm install\ncd ../..\n</code></pre>"},{"location":"contributing/development-setup/#configuration","title":"Configuration","text":"<p>Create a <code>.env</code> file in the repository root:</p> <pre><code># Generate the encryption key\necho \"FIELD_ENCRYPTION_KEY=$(python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())')\" &gt; .env\necho \"REDIS_URL=redis://localhost:6379/0\" &gt;&gt; .env\n</code></pre> <p>See Environment Variables for the full list of configuration options.</p>"},{"location":"contributing/development-setup/#running-in-development","title":"Running in Development","text":"<p>You need three terminals running simultaneously:</p>"},{"location":"contributing/development-setup/#terminal-1-backend-fastapi","title":"Terminal 1: Backend (FastAPI)","text":"<pre><code>cd platform\nsource ../.venv/bin/activate\nuvicorn main:app --host 0.0.0.0 --port 8000 --reload\n</code></pre> <p>The <code>--reload</code> flag enables auto-restart on file changes. The backend auto-creates the SQLite database on first startup.</p>"},{"location":"contributing/development-setup/#terminal-2-rq-worker","title":"Terminal 2: RQ Worker","text":"<pre><code>cd platform\nsource ../.venv/bin/activate\nrq worker workflows --with-scheduler\n</code></pre> <p>The worker processes background jobs (workflow executions, scheduled tasks). The <code>--with-scheduler</code> flag enables the RQ scheduler for delayed job execution.</p> <p>Note</p> <p>The worker does not auto-reload on file changes. Restart it manually after backend code changes that affect execution logic.</p>"},{"location":"contributing/development-setup/#terminal-3-frontend-vite-dev-server","title":"Terminal 3: Frontend (Vite Dev Server)","text":"<pre><code>cd platform/frontend\nnpm run dev\n</code></pre> <p>The Vite dev server runs at <code>http://localhost:5173</code> and proxies all <code>/api</code> requests to the FastAPI backend at port 8000.</p>"},{"location":"contributing/development-setup/#first-login","title":"First Login","text":"<p>Open <code>http://localhost:5173</code> in your browser. The setup wizard prompts you to create an admin account on first visit.</p>"},{"location":"contributing/development-setup/#project-structure","title":"Project Structure","text":"<pre><code>Pipelit/\n\u251c\u2500\u2500 .env                    # Environment variables (not committed)\n\u251c\u2500\u2500 platform/\n\u2502   \u251c\u2500\u2500 main.py             # FastAPI app entry point\n\u2502   \u251c\u2500\u2500 config.py           # Pydantic Settings\n\u2502   \u251c\u2500\u2500 database.py         # SQLAlchemy engine + session\n\u2502   \u251c\u2500\u2500 auth.py             # Bearer token auth\n\u2502   \u251c\u2500\u2500 api/                # REST endpoint routers\n\u2502   \u251c\u2500\u2500 models/             # SQLAlchemy ORM models\n\u2502   \u251c\u2500\u2500 schemas/            # Pydantic schemas + node type registry\n\u2502   \u251c\u2500\u2500 services/           # Business logic (orchestrator, builder, etc.)\n\u2502   \u251c\u2500\u2500 components/         # LangGraph node implementations\n\u2502   \u251c\u2500\u2500 handlers/           # Trigger handlers (Telegram, webhook, manual)\n\u2502   \u251c\u2500\u2500 validation/         # Edge type compatibility checks\n\u2502   \u251c\u2500\u2500 ws/                 # WebSocket endpoints + broadcast\n\u2502   \u251c\u2500\u2500 tasks/              # RQ job wrappers\n\u2502   \u251c\u2500\u2500 triggers/           # Trigger resolver\n\u2502   \u251c\u2500\u2500 alembic/            # Database migrations\n\u2502   \u251c\u2500\u2500 tests/              # Test suite\n\u2502   \u251c\u2500\u2500 conftest.py         # Shared test fixtures\n\u2502   \u2514\u2500\u2500 frontend/           # React SPA\n\u2502       \u251c\u2500\u2500 src/\n\u2502       \u2502   \u251c\u2500\u2500 api/        # TanStack Query hooks\n\u2502       \u2502   \u251c\u2500\u2500 features/   # Page components\n\u2502       \u2502   \u251c\u2500\u2500 components/ # Shared UI components\n\u2502       \u2502   \u251c\u2500\u2500 hooks/      # Custom React hooks\n\u2502       \u2502   \u251c\u2500\u2500 lib/        # Utilities (wsManager, etc.)\n\u2502       \u2502   \u2514\u2500\u2500 types/      # TypeScript type definitions\n\u2502       \u2514\u2500\u2500 package.json\n\u2514\u2500\u2500 docs/                   # Design documents\n</code></pre>"},{"location":"contributing/development-setup/#ide-setup-tips","title":"IDE Setup Tips","text":""},{"location":"contributing/development-setup/#vs-code","title":"VS Code","text":"<p>Recommended extensions:</p> <ul> <li>Python (ms-python.python) -- Linting, IntelliSense, debugging</li> <li>Pylance (ms-python.vscode-pylance) -- Type checking</li> <li>ESLint (dbaeumer.vscode-eslint) -- TypeScript linting</li> <li>Prettier (esbenp.prettier-vscode) -- Code formatting</li> </ul> <p>Workspace settings (<code>.vscode/settings.json</code>):</p> <pre><code>{\n    \"python.defaultInterpreterPath\": \"${workspaceFolder}/.venv/bin/python\",\n    \"python.analysis.extraPaths\": [\"${workspaceFolder}/platform\"],\n    \"editor.formatOnSave\": true,\n    \"typescript.tsdk\": \"platform/frontend/node_modules/typescript/lib\"\n}\n</code></pre>"},{"location":"contributing/development-setup/#pycharm-intellij","title":"PyCharm / IntelliJ","text":"<ol> <li>Set the Python interpreter to <code>.venv/bin/python</code></li> <li>Mark <code>platform/</code> as a Sources Root</li> <li>Mark <code>platform/frontend/src/</code> as a Resource Root</li> </ol>"},{"location":"contributing/development-setup/#common-development-tasks","title":"Common Development Tasks","text":""},{"location":"contributing/development-setup/#creating-a-feature-branch","title":"Creating a Feature Branch","text":"<p>Always create a new branch before starting work:</p> <pre><code>git checkout master\ngit pull upstream master\ngit checkout -b feature/your-feature-name\n</code></pre>"},{"location":"contributing/development-setup/#rebuilding-the-frontend","title":"Rebuilding the Frontend","text":"<p>If you only need to test backend changes without the Vite dev server:</p> <pre><code>cd platform/frontend\nnpm run build\n</code></pre> <p>Then access the app at <code>http://localhost:8000</code> (served directly by FastAPI).</p>"},{"location":"contributing/development-setup/#resetting-the-database","title":"Resetting the Database","text":"<p>To start fresh with a clean database:</p> <pre><code>rm platform/db.sqlite3\nrm platform/checkpoints.db\n# Restart the backend \u2014 tables are recreated automatically\n</code></pre>"},{"location":"contributing/development-setup/#checking-redis","title":"Checking Redis","text":"<pre><code>redis-cli ping              # Should return PONG\nredis-cli MODULE LIST        # Should include \"search\" module\nrq info                      # Show queue status\n</code></pre>"},{"location":"contributing/migrations/","title":"Migrations","text":""},{"location":"contributing/migrations/#migrations","title":"Migrations","text":"<p>Pipelit uses Alembic for database schema migrations. This guide covers best practices for creating and managing migrations safely.</p>"},{"location":"contributing/migrations/#before-you-start","title":"Before You Start","text":"<p>Before creating any migration, always check the current state:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\n\n# Check for multiple heads (conflicting migrations)\nalembic heads\n\n# Show current database version\nalembic current\n\n# Show recent migration history\nalembic history --verbose -n 5\n</code></pre> <p>Always check for conflicting heads</p> <p>Multiple heads indicate that two migrations were created in parallel without merging. You must resolve this before creating a new migration. Creating a migration on top of conflicting heads will make the situation worse.</p>"},{"location":"contributing/migrations/#resolving-conflicting-heads","title":"Resolving Conflicting Heads","text":"<p>If <code>alembic heads</code> shows more than one head:</p> <pre><code># Create a merge migration\nalembic merge heads -m \"merge conflicting heads\"\n\n# Apply it\nalembic upgrade head\n</code></pre>"},{"location":"contributing/migrations/#creating-a-migration","title":"Creating a Migration","text":"<p>After modifying SQLAlchemy models in <code>platform/models/</code>:</p> <pre><code># 1. Verify only one head exists\nalembic heads\n\n# 2. Auto-generate the migration\nalembic revision --autogenerate -m \"describe your change\"\n\n# 3. Review the generated file in platform/alembic/versions/\n#    ALWAYS review auto-generated migrations before applying\n\n# 4. Apply the migration\nalembic upgrade head\n</code></pre>"},{"location":"contributing/migrations/#reviewing-auto-generated-migrations","title":"Reviewing Auto-generated Migrations","text":"<p>Alembic's <code>--autogenerate</code> compares your SQLAlchemy models against the database and generates upgrade/downgrade functions. Always review the generated file because auto-generation can:</p> <ul> <li>Miss some changes (e.g., renaming columns looks like drop + add)</li> <li>Generate incorrect operations for complex changes</li> <li>Include unintended changes from model imports</li> </ul> <p>Look for the generated file in <code>platform/alembic/versions/</code> and verify that the <code>upgrade()</code> and <code>downgrade()</code> functions match your intentions.</p>"},{"location":"contributing/migrations/#sqlite-considerations","title":"SQLite Considerations","text":"<p>Pipelit uses SQLite by default. SQLite has significant limitations for schema migrations:</p> <p>batch_alter_table is dangerous with SQLite</p> <p>SQLite does not support most <code>ALTER TABLE</code> operations natively. Alembic works around this with <code>batch_alter_table</code>, which:</p> <ol> <li>Creates a new temporary table with the desired schema</li> <li>Copies all data from the old table</li> <li>Drops the old table</li> <li>Renames the new table</li> </ol> <p>This process can cascade and delete data if foreign key constraints are involved. Test thoroughly.</p>"},{"location":"contributing/migrations/#safe-practices-for-sqlite-migrations","title":"Safe Practices for SQLite Migrations","text":"<ul> <li>Test against existing data, not just empty databases</li> <li>Back up your database before running migrations: <code>cp db.sqlite3 db.sqlite3.backup</code></li> <li>Avoid dropping columns if possible -- add new columns instead</li> <li>Be careful with foreign key changes -- these trigger full table rebuilds</li> <li>Test the downgrade path as well as the upgrade path</li> </ul>"},{"location":"contributing/migrations/#example-safe-column-addition","title":"Example: Safe Column Addition","text":"<p>Adding a nullable column is the safest migration for SQLite:</p> <pre><code>def upgrade():\n    op.add_column(\"workflow_nodes\", sa.Column(\"new_field\", sa.String(255), nullable=True))\n\n\ndef downgrade():\n    # For SQLite, dropping columns requires batch_alter_table\n    with op.batch_alter_table(\"workflow_nodes\") as batch_op:\n        batch_op.drop_column(\"new_field\")\n</code></pre>"},{"location":"contributing/migrations/#example-avoiding-data-loss","title":"Example: Avoiding Data Loss","text":"<p>When a migration involves <code>batch_alter_table</code>, explicitly verify that data survives:</p> <pre><code>def upgrade():\n    # Use batch_alter_table for SQLite compatibility\n    with op.batch_alter_table(\"component_configs\") as batch_op:\n        batch_op.add_column(sa.Column(\"new_setting\", sa.String(100), nullable=True))\n        # Do NOT drop existing columns in the same batch unless absolutely necessary\n</code></pre>"},{"location":"contributing/migrations/#common-migration-commands","title":"Common Migration Commands","text":"<pre><code># Apply all pending migrations\nalembic upgrade head\n\n# Rollback one migration\nalembic downgrade -1\n\n# Rollback to a specific revision\nalembic downgrade abc123\n\n# Show current version\nalembic current\n\n# Show migration history\nalembic history --verbose\n\n# Show pending migrations\nalembic upgrade head --sql  # Preview SQL without executing\n\n# Create an empty migration (for manual SQL)\nalembic revision -m \"manual migration description\"\n</code></pre>"},{"location":"contributing/migrations/#testing-migrations","title":"Testing Migrations","text":""},{"location":"contributing/migrations/#against-an-empty-database","title":"Against an Empty Database","text":"<pre><code># Remove the database and re-run all migrations\nrm platform/db.sqlite3\ncd platform\nalembic upgrade head\n</code></pre>"},{"location":"contributing/migrations/#against-existing-data","title":"Against Existing Data","text":"<pre><code># Back up your database\ncp platform/db.sqlite3 platform/db.sqlite3.backup\n\n# Run the migration\ncd platform\nalembic upgrade head\n\n# Verify the application works\nuvicorn main:app --host 0.0.0.0 --port 8000\n\n# If something went wrong, restore\ncp platform/db.sqlite3.backup platform/db.sqlite3\n</code></pre>"},{"location":"contributing/migrations/#in-the-test-suite","title":"In the Test Suite","text":"<p>The test suite uses an in-memory SQLite database and calls <code>Base.metadata.create_all()</code> directly (bypassing Alembic). This means test passes do not guarantee migration correctness. Always test migrations manually against a real database with existing data.</p>"},{"location":"contributing/migrations/#migration-tips","title":"Migration Tips","text":"<ol> <li> <p>One migration per logical change. Do not combine unrelated schema changes in a single migration.</p> </li> <li> <p>Write descriptive messages. Use <code>-m \"add token_count column to execution_logs\"</code> not <code>-m \"update models\"</code>.</p> </li> <li> <p>Make migrations reversible. Always implement both <code>upgrade()</code> and <code>downgrade()</code> functions.</p> </li> <li> <p>Avoid data migrations in schema migrations. If you need to transform existing data, create a separate data migration after the schema migration.</p> </li> <li> <p>Coordinate with team members. If multiple people are working on migrations simultaneously, communicate to avoid conflicting heads.</p> </li> </ol>"},{"location":"contributing/testing/","title":"Testing","text":""},{"location":"contributing/testing/#testing","title":"Testing","text":"<p>Pipelit uses pytest for its test suite. All tests are located in <code>platform/tests/</code> and use an in-memory SQLite database for isolation.</p>"},{"location":"contributing/testing/#running-the-test-suite","title":"Running the Test Suite","text":"<pre><code>cd platform\nsource ../.venv/bin/activate\nexport FIELD_ENCRYPTION_KEY=$(python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\")\npython -m pytest tests/ -v\n</code></pre> <p>Encryption key required</p> <p>The <code>FIELD_ENCRYPTION_KEY</code> environment variable must be set before running tests. The <code>conftest.py</code> auto-generates a temporary key if one is not provided, but setting it explicitly is recommended for consistency.</p>"},{"location":"contributing/testing/#running-specific-tests","title":"Running Specific Tests","text":"<pre><code># Run a single test file\npython -m pytest tests/test_api.py -v\n\n# Run a specific test function\npython -m pytest tests/test_api.py::test_create_workflow -v\n\n# Run tests matching a keyword\npython -m pytest tests/ -k \"scheduler\" -v\n\n# Run with short traceback\npython -m pytest tests/ -v --tb=short\n</code></pre>"},{"location":"contributing/testing/#test-structure","title":"Test Structure","text":"<p>Tests are organized by the subsystem they exercise:</p> Test File Coverage Area <code>test_api.py</code> REST API endpoints (workflow CRUD, nodes, edges) <code>test_api_extended.py</code> Extended API tests (credentials, executions, batch operations) <code>test_views.py</code> HTTP view layer tests <code>test_builder.py</code> Workflow compilation (LangGraph graph building) <code>test_orchestrator.py</code> Node execution orchestration <code>test_orchestrator_core.py</code> Core orchestrator logic <code>test_orchestrator_e2e.py</code> End-to-end orchestrator tests <code>test_orchestrator_loops.py</code> Loop component execution <code>test_orchestrator_helpers.py</code> Orchestrator utility functions <code>test_orchestrator_checkpoints.py</code> Conversation memory checkpointing <code>test_components.py</code> Individual component implementations <code>test_components_http.py</code> HTTP request component <code>test_components_db.py</code> Database-dependent components <code>test_components_remaining.py</code> Additional component tests <code>test_edge_validation.py</code> Edge type compatibility validation <code>test_node_io.py</code> Node I/O schemas and type system <code>test_expressions.py</code> Jinja2 template expression resolution <code>test_topology.py</code> DAG topology analysis (BFS reachability) <code>test_database_and_models.py</code> SQLAlchemy model tests <code>test_scheduler.py</code> Self-rescheduling scheduler (29 tests) <code>test_ws.py</code> WebSocket endpoint tests <code>test_ws_async.py</code> Async WebSocket tests <code>test_broadcast.py</code> Redis pub/sub broadcast <code>test_memory.py</code> Memory system tests <code>test_memory_service.py</code> Memory service layer <code>test_dispatch.py</code> Trigger dispatch logic <code>test_handlers.py</code> Event handler tests <code>test_telegram_handler.py</code> Telegram trigger handler <code>test_manual_handler.py</code> Manual trigger handler <code>test_mfa.py</code> Multi-factor authentication <code>test_token_usage.py</code> Token counting and cost tracking <code>test_epics_tasks.py</code> Epic and task management"},{"location":"contributing/testing/#test-fixtures","title":"Test Fixtures","text":"<p>Shared fixtures are defined in <code>platform/conftest.py</code>:</p> Fixture Provides <code>db</code> SQLAlchemy test session (in-memory SQLite) <code>user_profile</code> A <code>UserProfile</code> with username <code>testuser</code> <code>api_key</code> An <code>APIKey</code> linked to the test user <code>workflow</code> A <code>Workflow</code> with slug <code>test-workflow</code> <code>telegram_credential</code> A <code>BaseCredential</code> with Telegram bot token <code>telegram_trigger</code> A <code>WorkflowNode</code> for a Telegram trigger <code>manual_trigger</code> A <code>WorkflowNode</code> for a manual trigger <p>The <code>_setup_db</code> fixture runs automatically before each test, creating all tables and dropping them afterward for complete isolation.</p>"},{"location":"contributing/testing/#authentication-in-tests","title":"Authentication in Tests","text":"<p>All API tests must use Bearer token authentication. Never use session auth, basic auth, or OAuth in tests.</p>"},{"location":"contributing/testing/#pattern-authenticated-test-client","title":"Pattern: Authenticated Test Client","text":"<pre><code>@pytest.fixture\ndef auth_client(client, api_key):\n    client.headers[\"Authorization\"] = f\"Bearer {api_key.key}\"\n    return client\n\n\ndef test_create_workflow(auth_client):\n    response = auth_client.post(\"/api/v1/workflows/\", json={\n        \"name\": \"My Workflow\",\n    })\n    assert response.status_code == 201\n</code></pre>"},{"location":"contributing/testing/#pattern-database-override","title":"Pattern: Database Override","text":"<p>Tests override the <code>get_db</code> dependency to use the in-memory test database:</p> <pre><code>@pytest.fixture\ndef app(db):\n    from main import app as _app\n    from database import get_db\n\n    def _override_get_db():\n        try:\n            yield db\n        finally:\n            pass\n\n    _app.dependency_overrides[get_db] = _override_get_db\n    yield _app\n    _app.dependency_overrides.clear()\n</code></pre>"},{"location":"contributing/testing/#writing-new-tests","title":"Writing New Tests","text":""},{"location":"contributing/testing/#test-file-template","title":"Test File Template","text":"<pre><code>\"\"\"Tests for &lt;subsystem&gt;.\"\"\"\n\nfrom __future__ import annotations\n\nimport sys\nfrom pathlib import Path\n\nimport pytest\n\n# Ensure platform/ is importable\n_platform_dir = str(Path(__file__).resolve().parent.parent)\nif _platform_dir not in sys.path:\n    sys.path.insert(0, _platform_dir)\n\n\ndef test_my_feature(db, workflow, api_key):\n    \"\"\"Test description.\"\"\"\n    # Arrange\n    # ...\n\n    # Act\n    # ...\n\n    # Assert\n    assert result == expected\n</code></pre>"},{"location":"contributing/testing/#guidelines","title":"Guidelines","text":"<ul> <li>Use descriptive test function names (<code>test_switch_routes_to_matching_condition</code>)</li> <li>Use the <code>db</code>, <code>workflow</code>, and other shared fixtures from <code>conftest.py</code></li> <li>Always authenticate API requests with <code>Bearer {api_key.key}</code></li> <li>Test both success and error paths</li> <li>Mock external services (Redis, LLM providers) where appropriate</li> <li>Keep tests independent -- do not rely on test execution order</li> </ul>"},{"location":"contributing/testing/#coverage","title":"Coverage","text":"<p>Check test coverage with:</p> <pre><code>python -m pytest tests/ --cov=. --cov-report=term-missing -v\n</code></pre> <p>Generate an HTML coverage report:</p> <pre><code>python -m pytest tests/ --cov=. --cov-report=html -v\n# Open htmlcov/index.html in a browser\n</code></pre> <p>The project uses Codecov for tracking coverage on pull requests. Coverage badges are displayed on the repository README.</p>"},{"location":"deployment/","title":"Deployment","text":""},{"location":"deployment/#deployment","title":"Deployment","text":"<p>This section covers everything you need to deploy Pipelit in development and production environments.</p>"},{"location":"deployment/#overview","title":"Overview","text":"<p>Pipelit is a self-hosted platform consisting of three runtime services:</p> Service Technology Purpose Backend FastAPI + Uvicorn REST API, WebSocket, static file serving Worker RQ (Redis Queue) Background workflow execution, scheduled jobs Redis Redis 8.0+ Task queue, pub/sub, search (RediSearch) <p>The frontend is a React SPA that is either served by the Vite dev server during development or built into static files and served directly by FastAPI in production.</p>"},{"location":"deployment/#deployment-options","title":"Deployment Options","text":""},{"location":"deployment/#docker","title":"Docker","text":"<p>The recommended approach for most deployments. A multi-stage Dockerfile builds the frontend and backend into a single image, with docker-compose orchestrating all services.</p>"},{"location":"deployment/#production","title":"Production","text":"<p>Bare-metal or VM deployment with Gunicorn, systemd process management, and a production-ready security checklist.</p>"},{"location":"deployment/#redis","title":"Redis","text":"<p>Redis 8.0+ is required for task queuing, pub/sub, and full-text search. This page covers installation on all major platforms.</p>"},{"location":"deployment/#reverse-proxy","title":"Reverse Proxy","text":"<p>Nginx and Caddy configurations for HTTPS termination, WebSocket proxying, and domain-based routing.</p>"},{"location":"deployment/#environment-variables","title":"Environment Variables","text":"<p>Complete reference for all environment variables that control Pipelit's behavior.</p>"},{"location":"deployment/#database","title":"Database","text":"<p>Database setup for SQLite (development) and PostgreSQL (production), plus Alembic migration management and backup strategies.</p>"},{"location":"deployment/#minimum-architecture","title":"Minimum Architecture","text":"<p>At minimum, a Pipelit deployment consists of:</p> <pre><code>flowchart LR\n    Browser --&gt;|HTTP / WS| FastAPI\n    FastAPI --&gt;|enqueue jobs| Redis\n    Redis --&gt;|dequeue jobs| RQ[RQ Worker]\n    RQ --&gt;|read/write| SQLite/PostgreSQL\n    FastAPI --&gt;|read/write| SQLite/PostgreSQL\n    RQ --&gt;|pub/sub| Redis</code></pre> <p>All three services (FastAPI, RQ worker, Redis) must be running for workflows to execute. The backend and worker share the same codebase and database.</p>"},{"location":"deployment/database/","title":"Database","text":""},{"location":"deployment/database/#database-setup","title":"Database Setup","text":"<p>Pipelit uses SQLAlchemy 2.0 as its ORM and supports both SQLite and PostgreSQL as database backends. The database stores workflows, nodes, edges, executions, credentials, user accounts, and all other persistent state.</p>"},{"location":"deployment/database/#sqlite-development","title":"SQLite (Development)","text":"<p>SQLite is the default database backend and requires zero configuration. On first startup, Pipelit automatically creates the database file at <code>platform/db.sqlite3</code>.</p> .env<pre><code># This is the default \u2014 no configuration needed\nDATABASE_URL=sqlite:///platform/db.sqlite3\n</code></pre> <p>SQLite is a good choice for:</p> <ul> <li>Local development</li> <li>Single-user or small-team deployments</li> <li>Quick prototyping and testing</li> </ul> <p>SQLite limitations</p> <p>SQLite allows only one writer at a time. Under heavy concurrent load (multiple RQ workers, many simultaneous API requests), you may encounter <code>database is locked</code> errors. For production deployments with significant traffic, use PostgreSQL.</p>"},{"location":"deployment/database/#checkpoints-database","title":"Checkpoints Database","text":"<p>Agent conversation memory uses a separate SQLite database at <code>platform/checkpoints.db</code>. This file is created automatically when an agent with <code>conversation_memory</code> enabled runs for the first time.</p>"},{"location":"deployment/database/#postgresql-production","title":"PostgreSQL (Production)","text":"<p>For production deployments, PostgreSQL is recommended. It handles concurrent reads and writes efficiently and supports advanced features like connection pooling.</p>"},{"location":"deployment/database/#setup","title":"Setup","text":"<ol> <li> <p>Install PostgreSQL:</p> <pre><code># Debian/Ubuntu\nsudo apt install postgresql postgresql-contrib\n\n# macOS\nbrew install postgresql &amp;&amp; brew services start postgresql\n</code></pre> </li> <li> <p>Create a database and user:</p> <pre><code>sudo -u postgres psql\n\nCREATE USER pipelit WITH PASSWORD 'your-password';\nCREATE DATABASE pipelit OWNER pipelit;\n\\q\n</code></pre> </li> <li> <p>Update your <code>.env</code> file:</p> <pre><code>DATABASE_URL=postgresql://pipelit:your-password@localhost/pipelit\n</code></pre> </li> <li> <p>Install the PostgreSQL driver:</p> <pre><code>pip install psycopg2-binary\n</code></pre> </li> <li> <p>Restart the backend \u2014 tables are created automatically on startup.</p> </li> </ol>"},{"location":"deployment/database/#alembic-migrations","title":"Alembic Migrations","text":"<p>Pipelit uses Alembic for database schema migrations. Migrations track every change to the database schema over time, allowing safe upgrades and rollbacks.</p>"},{"location":"deployment/database/#automatic-migration-on-startup","title":"Automatic Migration on Startup","text":"<p>The FastAPI application calls <code>Base.metadata.create_all()</code> during its <code>lifespan</code> startup handler. This ensures that all tables exist when the application starts. For development, this is sufficient.</p>"},{"location":"deployment/database/#running-migrations-manually","title":"Running Migrations Manually","text":"<p>For production deployments, you can run Alembic migrations explicitly:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\n\n# Apply all pending migrations\nalembic upgrade head\n\n# Check current migration version\nalembic current\n\n# View migration history\nalembic history --verbose\n</code></pre>"},{"location":"deployment/database/#creating-new-migrations","title":"Creating New Migrations","text":"<p>When you modify SQLAlchemy models, generate a new migration:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\n\n# Check for conflicting migration heads first\nalembic heads\n\n# Auto-generate a migration from model changes\nalembic revision --autogenerate -m \"describe your change\"\n\n# Review the generated migration file in platform/alembic/versions/\n# Then apply it\nalembic upgrade head\n</code></pre> <p>Always check for conflicts</p> <p>Before creating a new migration, run <code>alembic heads</code> to verify there is only one head. Multiple heads indicate conflicting migrations that must be merged before proceeding. See Migrations for details.</p>"},{"location":"deployment/database/#backup-strategies","title":"Backup Strategies","text":""},{"location":"deployment/database/#sqlite-backups","title":"SQLite Backups","text":"<p>SQLite databases are single files, making backups straightforward:</p> <pre><code># Simple file copy (stop the application first for consistency)\ncp platform/db.sqlite3 backups/db-$(date +%Y%m%d-%H%M%S).sqlite3\n\n# Using SQLite's online backup API (safe while running)\nsqlite3 platform/db.sqlite3 \".backup 'backups/db-backup.sqlite3'\"\n\n# Also back up the checkpoints database\nsqlite3 platform/checkpoints.db \".backup 'backups/checkpoints-backup.db'\"\n</code></pre> <p>Set up a cron job for automated backups:</p> <pre><code># Daily backup at 2 AM\n0 2 * * * sqlite3 /opt/pipelit/platform/db.sqlite3 \".backup '/opt/backups/pipelit-$(date +\\%Y\\%m\\%d).sqlite3'\"\n</code></pre>"},{"location":"deployment/database/#postgresql-backups","title":"PostgreSQL Backups","text":"<pre><code># Full database dump\npg_dump -U pipelit pipelit &gt; backups/pipelit-$(date +%Y%m%d-%H%M%S).sql\n\n# Compressed dump\npg_dump -U pipelit pipelit | gzip &gt; backups/pipelit-$(date +%Y%m%d).sql.gz\n\n# Restore from backup\npsql -U pipelit pipelit &lt; backups/pipelit-20260215.sql\n</code></pre>"},{"location":"deployment/database/#what-to-back-up","title":"What to Back Up","text":"Item Location Purpose Main database <code>platform/db.sqlite3</code> or PostgreSQL All workflows, nodes, executions, users, credentials Checkpoints database <code>platform/checkpoints.db</code> Agent conversation memory <code>.env</code> file Repository root Configuration and encryption key <code>FIELD_ENCRYPTION_KEY</code> In <code>.env</code> Required to decrypt stored credentials <p>Back up your encryption key</p> <p>The <code>FIELD_ENCRYPTION_KEY</code> is essential. Without it, all encrypted credentials in the database are permanently unreadable. Store a copy of this key in a secure location separate from your database backups.</p>"},{"location":"deployment/database/#migrating-from-sqlite-to-postgresql","title":"Migrating from SQLite to PostgreSQL","text":"<p>To migrate an existing SQLite deployment to PostgreSQL:</p> <ol> <li>Export data from SQLite (application-level, not raw SQL)</li> <li>Set up PostgreSQL as described above</li> <li>Update <code>DATABASE_URL</code> in <code>.env</code></li> <li>Start the application (tables are created automatically)</li> <li>Import the data</li> </ol> <p>Note</p> <p>There is no built-in migration tool for moving data between database backends. For small deployments, re-creating workflows through the UI or API is often simpler than attempting a raw data migration.</p>"},{"location":"deployment/docker/","title":"Docker","text":""},{"location":"deployment/docker/#docker-deployment","title":"Docker Deployment","text":"<p>Docker is the recommended way to deploy Pipelit. This guide covers the Dockerfile structure, docker-compose configuration, and persistent storage setup.</p>"},{"location":"deployment/docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker 24+ and Docker Compose v2</li> <li>At least 2 GB of RAM available for containers</li> </ul>"},{"location":"deployment/docker/#dockerfile-structure","title":"Dockerfile Structure","text":"<p>Pipelit uses a multi-stage build to keep the final image small:</p> <pre><code># Stage 1: Build the frontend\nFROM node:20-alpine AS frontend-build\nWORKDIR /app/frontend\nCOPY platform/frontend/package*.json ./\nRUN npm ci\nCOPY platform/frontend/ ./\nRUN npm run build\n\n# Stage 2: Python backend\nFROM python:3.12-slim AS backend\nWORKDIR /app\n\n# Install system dependencies\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \\\n    gcc libffi-dev &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n\n# Install Python dependencies\nCOPY platform/requirements.txt ./\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Copy backend source\nCOPY platform/ ./\n\n# Copy built frontend from stage 1\nCOPY --from=frontend-build /app/frontend/dist ./frontend/dist\n\nEXPOSE 8000\n\nCMD [\"uvicorn\", \"main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"]\n</code></pre> <p>Stage 1 installs Node.js dependencies and runs <code>npm run build</code> to produce the optimized static SPA in <code>frontend/dist/</code>. Stage 2 installs Python dependencies, copies the backend source, and copies the built frontend assets. FastAPI serves the frontend from the <code>frontend/dist/</code> directory via its static file mount.</p>"},{"location":"deployment/docker/#docker-compose","title":"Docker Compose","text":"<p>Create a <code>docker-compose.yml</code> in the project root:</p> <pre><code>version: \"3.9\"\n\nservices:\n  redis:\n    image: redis:8\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis-data:/data\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 3s\n      retries: 5\n\n  backend:\n    build: .\n    ports:\n      - \"8000:8000\"\n    env_file: .env\n    environment:\n      - REDIS_URL=redis://redis:6379/0\n      - DATABASE_URL=sqlite:////app/data/db.sqlite3\n    volumes:\n      - app-data:/app/data\n    depends_on:\n      redis:\n        condition: service_healthy\n    command: &gt;\n      uvicorn main:app\n      --host 0.0.0.0\n      --port 8000\n      --workers 2\n\n  worker:\n    build: .\n    env_file: .env\n    environment:\n      - REDIS_URL=redis://redis:6379/0\n      - DATABASE_URL=sqlite:////app/data/db.sqlite3\n    volumes:\n      - app-data:/app/data\n    depends_on:\n      redis:\n        condition: service_healthy\n    command: rq worker workflows --with-scheduler\n\nvolumes:\n  redis-data:\n  app-data:\n</code></pre>"},{"location":"deployment/docker/#environment-variables","title":"Environment Variables","text":"<p>Create a <code>.env</code> file in the project root before starting:</p> <pre><code>FIELD_ENCRYPTION_KEY=your-generated-fernet-key\nSECRET_KEY=change-me-to-a-random-string\nDEBUG=false\nCORS_ALLOW_ALL_ORIGINS=false\nALLOWED_HOSTS=your-domain.com\n</code></pre> <p>Generate a Fernet encryption key:</p> <pre><code>python3 -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\n</code></pre> <p>See Environment Variables for the full reference.</p>"},{"location":"deployment/docker/#volume-mounts","title":"Volume Mounts","text":"<p>Two volumes ensure data persists across container restarts:</p> Volume Mount Path Contents <code>app-data</code> <code>/app/data/</code> SQLite database, checkpoints database <code>redis-data</code> <code>/data/</code> Redis persistence (RDB/AOF) <p>SQLite concurrency</p> <p>SQLite allows only one writer at a time. When using SQLite with Docker, the backend and worker containers share the same volume-mounted database file. This works for small deployments but can cause <code>database is locked</code> errors under heavy load. For production deployments, use PostgreSQL instead.</p>"},{"location":"deployment/docker/#starting-the-stack","title":"Starting the Stack","text":"<pre><code># Build and start all services\ndocker compose up -d --build\n\n# Check status\ndocker compose ps\n\n# View logs\ndocker compose logs -f backend\ndocker compose logs -f worker\n\n# Stop everything\ndocker compose down\n</code></pre> <p>After starting, open <code>http://localhost:8000</code> in your browser. The setup wizard will prompt you to create your admin account on first visit.</p>"},{"location":"deployment/docker/#scaling-workers","title":"Scaling Workers","text":"<p>You can run multiple RQ workers for higher throughput:</p> <pre><code>  worker:\n    build: .\n    env_file: .env\n    environment:\n      - REDIS_URL=redis://redis:6379/0\n      - DATABASE_URL=sqlite:////app/data/db.sqlite3\n    volumes:\n      - app-data:/app/data\n    depends_on:\n      redis:\n        condition: service_healthy\n    deploy:\n      replicas: 3\n    command: rq worker workflows --with-scheduler\n</code></pre> <p>Note</p> <p>When using SQLite, scaling workers beyond 1--2 may cause database lock contention. Switch to PostgreSQL for multi-worker deployments.</p>"},{"location":"deployment/docker/#updating","title":"Updating","text":"<p>To update to a newer version:</p> <pre><code>git pull\ndocker compose up -d --build\n</code></pre> <p>Alembic migrations run automatically on startup, so database schema changes are applied when the new backend container starts.</p>"},{"location":"deployment/docker/#health-checks","title":"Health Checks","text":"<p>The backend exposes the setup status endpoint at <code>/api/v1/auth/setup-status/</code> which can be used for container health checks:</p> <pre><code>  backend:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/api/v1/auth/setup-status/\"]\n      interval: 30s\n      timeout: 5s\n      retries: 3\n</code></pre>"},{"location":"deployment/environment/","title":"Environment Variables","text":""},{"location":"deployment/environment/#environment-variables","title":"Environment Variables","text":"<p>Pipelit is configured through environment variables, loaded from a <code>.env</code> file in the repository root (one level above <code>platform/</code>). The configuration is managed by Pydantic Settings in <code>platform/config.py</code>.</p>"},{"location":"deployment/environment/#variable-reference","title":"Variable Reference","text":"Variable Default Required Description <code>FIELD_ENCRYPTION_KEY</code> <code>\"\"</code> (empty) Yes Fernet encryption key for securing stored credentials (API keys, bot tokens, etc.). Generate with <code>python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"</code>. Without this key, credential storage will not work. <code>SECRET_KEY</code> <code>change-me-in-production</code> Yes (production) Secret key used for cryptographic signing. Must be changed from the default in production deployments. Use a long, random string. <code>DATABASE_URL</code> <code>sqlite:///platform/db.sqlite3</code> No SQLAlchemy database connection string. Defaults to a SQLite file inside the <code>platform/</code> directory. Set to a PostgreSQL URL for production (e.g., <code>postgresql://user:pass@localhost/pipelit</code>). <code>REDIS_URL</code> <code>redis://localhost:6379/0</code> No Redis connection URL. Used for RQ task queuing, pub/sub broadcasting, and RediSearch. Format: <code>redis://[:password]@host:port/db_number</code>. <code>DEBUG</code> <code>false</code> No Enable debug mode. Set to <code>true</code> for development. Should always be <code>false</code> in production. <code>ALLOWED_HOSTS</code> <code>localhost</code> No Comma-separated list of allowed hostnames. Set to your domain name in production (e.g., <code>pipelit.example.com</code>). <code>CORS_ALLOW_ALL_ORIGINS</code> <code>true</code> No Allow cross-origin requests from any domain. Set to <code>false</code> in production and configure specific allowed origins through your reverse proxy. <code>ZOMBIE_EXECUTION_THRESHOLD_SECONDS</code> <code>900</code> (15 min) No Time in seconds after which a running execution is considered a zombie and eligible for cleanup. The system marks stale executions as failed and releases their resources."},{"location":"deployment/environment/#env-file-location","title":"<code>.env</code> File Location","text":"<p>The <code>.env</code> file should be placed in the repository root (the directory containing <code>platform/</code>), not inside the <code>platform/</code> directory:</p> <pre><code>Pipelit/\n\u251c\u2500\u2500 .env              &lt;-- here\n\u251c\u2500\u2500 platform/\n\u2502   \u251c\u2500\u2500 main.py\n\u2502   \u251c\u2500\u2500 config.py\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 ...\n</code></pre> <p>Pipelit uses <code>python-dotenv</code> to load the <code>.env</code> file from <code>BASE_DIR.parent</code> (one level above <code>platform/</code>).</p>"},{"location":"deployment/environment/#minimal-development-configuration","title":"Minimal Development Configuration","text":".env<pre><code>FIELD_ENCRYPTION_KEY=your-generated-fernet-key\nREDIS_URL=redis://localhost:6379/0\n</code></pre>"},{"location":"deployment/environment/#production-configuration","title":"Production Configuration","text":".env<pre><code>FIELD_ENCRYPTION_KEY=your-generated-fernet-key\nSECRET_KEY=a-long-random-string-at-least-32-characters\nDEBUG=false\nALLOWED_HOSTS=pipelit.example.com\nCORS_ALLOW_ALL_ORIGINS=false\nREDIS_URL=redis://localhost:6379/0\nDATABASE_URL=sqlite:///opt/pipelit/platform/db.sqlite3\nZOMBIE_EXECUTION_THRESHOLD_SECONDS=900\n</code></pre>"},{"location":"deployment/environment/#generating-the-encryption-key","title":"Generating the Encryption Key","text":"<p>The <code>FIELD_ENCRYPTION_KEY</code> is a Fernet key used to encrypt sensitive credential data (LLM API keys, Telegram bot tokens, etc.) at rest in the database. Generate one with:</p> <pre><code>python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\"\n</code></pre> <p>Keep your encryption key safe</p> <p>If you lose the <code>FIELD_ENCRYPTION_KEY</code>, all stored credentials become unreadable. Back up this key securely. If you change the key, existing encrypted credentials cannot be decrypted -- you will need to re-enter them.</p>"},{"location":"deployment/environment/#environment-variables-for-tests","title":"Environment Variables for Tests","text":"<p>Tests require <code>FIELD_ENCRYPTION_KEY</code> to be set. The test <code>conftest.py</code> auto-generates a temporary key if one is not provided:</p> <pre><code>cd platform\nexport FIELD_ENCRYPTION_KEY=$(python -c \"from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())\")\npython -m pytest tests/ -v\n</code></pre>"},{"location":"deployment/environment/#how-configuration-is-loaded","title":"How Configuration is Loaded","text":"<p>Configuration is managed by Pydantic Settings (<code>platform/config.py</code>):</p> <ol> <li>Values from the <code>.env</code> file are loaded via <code>python-dotenv</code></li> <li>Environment variables override <code>.env</code> file values</li> <li>Default values are used if neither is provided</li> <li>The <code>Settings</code> class validates types and provides the <code>settings</code> singleton</li> </ol> <pre><code>from config import settings\n\n# Access any setting\nprint(settings.REDIS_URL)\nprint(settings.DATABASE_URL)\nprint(settings.DEBUG)\n</code></pre>"},{"location":"deployment/production/","title":"Production","text":""},{"location":"deployment/production/#production-deployment","title":"Production Deployment","text":"<p>This guide covers deploying Pipelit on a bare-metal server or VM with production-grade process management, frontend builds, and security hardening.</p>"},{"location":"deployment/production/#overview","title":"Overview","text":"<p>A production Pipelit deployment consists of:</p> <ol> <li>Gunicorn with Uvicorn workers serving the FastAPI application</li> <li>RQ worker processing background jobs</li> <li>Redis 8.0+ for task queuing and pub/sub</li> <li>A reverse proxy (Nginx or Caddy) handling HTTPS and WebSocket upgrade</li> <li>A database (SQLite for small deployments, PostgreSQL recommended)</li> </ol>"},{"location":"deployment/production/#building-the-frontend","title":"Building the Frontend","text":"<p>In production, the frontend is compiled into static files and served directly by FastAPI. There is no need for the Vite dev server.</p> <pre><code>cd platform/frontend\nnpm install\nnpm run build\n</code></pre> <p>This produces optimized static assets in <code>platform/frontend/dist/</code>. FastAPI automatically serves these files and the SPA's <code>index.html</code> for all non-API routes.</p> <p>Tip</p> <p>Run <code>npm run build</code> once after each update. The built files are served directly by FastAPI at <code>http://your-server:8000/</code>.</p>"},{"location":"deployment/production/#gunicorn-with-uvicorn-workers","title":"Gunicorn with Uvicorn Workers","text":"<p>For production, use Gunicorn as the process manager with Uvicorn workers:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\n\ngunicorn main:app \\\n    --worker-class uvicorn.workers.UvicornWorker \\\n    --workers 4 \\\n    --bind 0.0.0.0:8000 \\\n    --timeout 120 \\\n    --graceful-timeout 30 \\\n    --access-logfile - \\\n    --error-logfile -\n</code></pre> <p>Worker count: A common rule of thumb is <code>(2 * CPU_CORES) + 1</code>. For a 2-core server, use 4--5 workers.</p> <p>WebSocket and worker count</p> <p>Each WebSocket connection is held open by a single worker. With Gunicorn's pre-fork model, WebSocket connections are pinned to the worker that accepted them. Ensure you have enough workers to handle both HTTP requests and persistent WebSocket connections.</p>"},{"location":"deployment/production/#process-management-with-systemd","title":"Process Management with systemd","text":"<p>Create systemd service files to ensure Pipelit starts on boot and restarts on failure.</p>"},{"location":"deployment/production/#backend-service","title":"Backend Service","text":"/etc/systemd/system/pipelit.service<pre><code>[Unit]\nDescription=Pipelit Backend\nAfter=network.target redis.service\nRequires=redis.service\n\n[Service]\nType=simple\nUser=pipelit\nGroup=pipelit\nWorkingDirectory=/opt/pipelit/platform\nEnvironment=\"PATH=/opt/pipelit/.venv/bin:/usr/bin\"\nEnvironmentFile=/opt/pipelit/.env\nExecStart=/opt/pipelit/.venv/bin/gunicorn main:app \\\n    --worker-class uvicorn.workers.UvicornWorker \\\n    --workers 4 \\\n    --bind 127.0.0.1:8000 \\\n    --timeout 120 \\\n    --access-logfile -\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"deployment/production/#rq-worker-service","title":"RQ Worker Service","text":"/etc/systemd/system/pipelit-worker.service<pre><code>[Unit]\nDescription=Pipelit RQ Worker\nAfter=network.target redis.service\nRequires=redis.service\n\n[Service]\nType=simple\nUser=pipelit\nGroup=pipelit\nWorkingDirectory=/opt/pipelit/platform\nEnvironment=\"PATH=/opt/pipelit/.venv/bin:/usr/bin\"\nEnvironmentFile=/opt/pipelit/.env\nExecStart=/opt/pipelit/.venv/bin/rq worker workflows --with-scheduler\nRestart=always\nRestartSec=5\n\n[Install]\nWantedBy=multi-user.target\n</code></pre>"},{"location":"deployment/production/#enable-and-start","title":"Enable and Start","text":"<pre><code>sudo systemctl daemon-reload\nsudo systemctl enable pipelit pipelit-worker\nsudo systemctl start pipelit pipelit-worker\n\n# Check status\nsudo systemctl status pipelit\nsudo systemctl status pipelit-worker\n\n# View logs\nsudo journalctl -u pipelit -f\nsudo journalctl -u pipelit-worker -f\n</code></pre>"},{"location":"deployment/production/#environment-file","title":"Environment File","text":"<p>Create <code>/opt/pipelit/.env</code> with production values:</p> <pre><code>FIELD_ENCRYPTION_KEY=your-generated-fernet-key\nSECRET_KEY=a-long-random-string-here\nDEBUG=false\nALLOWED_HOSTS=your-domain.com\nCORS_ALLOW_ALL_ORIGINS=false\nREDIS_URL=redis://localhost:6379/0\nDATABASE_URL=sqlite:////opt/pipelit/platform/db.sqlite3\n</code></pre> <p>See Environment Variables for the full reference.</p>"},{"location":"deployment/production/#security-checklist","title":"Security Checklist","text":"<p>Before exposing Pipelit to the internet, verify each item:</p> <ul> <li>[ ] <code>SECRET_KEY</code> is set to a long, random value (not <code>change-me-in-production</code>)</li> <li>[ ] <code>DEBUG</code> is set to <code>false</code></li> <li>[ ] <code>CORS_ALLOW_ALL_ORIGINS</code> is set to <code>false</code></li> <li>[ ] <code>ALLOWED_HOSTS</code> is set to your actual domain name(s)</li> <li>[ ] <code>FIELD_ENCRYPTION_KEY</code> is generated and stored securely (never committed to version control)</li> <li>[ ] HTTPS is configured via a reverse proxy with valid SSL certificates</li> <li>[ ] Firewall blocks direct access to ports 8000 (backend) and 6379 (Redis) from the public internet</li> <li>[ ] Redis is bound to <code>127.0.0.1</code> or uses authentication (Redis does not require a password by default)</li> <li>[ ] Database file (if using SQLite) has restrictive file permissions (<code>chmod 600</code>)</li> <li>[ ] System user runs Pipelit with minimal privileges (do not run as root)</li> <li>[ ] MFA is enabled for admin accounts via the Settings page</li> </ul> <p>Never expose Redis to the internet</p> <p>Redis has no authentication by default. Always bind Redis to <code>127.0.0.1</code> or use a firewall to restrict access. An exposed Redis instance can be trivially exploited.</p>"},{"location":"deployment/production/#reverse-proxy","title":"Reverse Proxy","text":"<p>A reverse proxy is strongly recommended for production to handle HTTPS termination and WebSocket upgrades. See the Reverse Proxy guide for Nginx and Caddy configurations.</p>"},{"location":"deployment/production/#updating-in-production","title":"Updating in Production","text":"<pre><code>cd /opt/pipelit\ngit pull\n\n# Rebuild frontend\ncd platform/frontend &amp;&amp; npm install &amp;&amp; npm run build &amp;&amp; cd ../..\n\n# Restart services (migrations run automatically on startup)\nsudo systemctl restart pipelit pipelit-worker\n</code></pre> <p>Alembic migrations are applied automatically when the FastAPI application starts. The <code>lifespan</code> handler in <code>main.py</code> calls <code>Base.metadata.create_all()</code> on startup for development convenience. In production, you can also run migrations explicitly:</p> <pre><code>cd /opt/pipelit/platform\nsource ../.venv/bin/activate\nalembic upgrade head\n</code></pre>"},{"location":"deployment/production/#monitoring","title":"Monitoring","text":"<p>Monitor the following for a healthy deployment:</p> <ul> <li>systemd service status -- both <code>pipelit</code> and <code>pipelit-worker</code> should be <code>active (running)</code></li> <li>Redis connectivity -- <code>redis-cli ping</code> should return <code>PONG</code></li> <li>Worker queue depth -- <code>rq info</code> shows pending/active/failed job counts</li> <li>Application logs -- watch for unhandled exceptions via <code>journalctl</code></li> <li>Disk space -- SQLite databases and Redis persistence files grow over time</li> </ul>"},{"location":"deployment/redis/","title":"Redis","text":""},{"location":"deployment/redis/#redis-setup","title":"Redis Setup","text":"<p>Pipelit requires Redis 8.0+ which includes the RediSearch module natively. This module powers full-text search capabilities used by the memory system. Older Redis versions will fail with <code>unknown command 'FT._LIST'</code>.</p>"},{"location":"deployment/redis/#why-redis-8","title":"Why Redis 8+?","text":"<p>Prior to Redis 8, the RediSearch module had to be installed separately (via Redis Stack or manual module loading). Redis 8.0 integrated RediSearch directly into the core server, removing the need for separate module installation.</p> <p>Pipelit uses Redis for three purposes:</p> Purpose Redis Feature Task queue RQ (Redis Queue) for background job processing Pub/sub Real-time WebSocket event broadcasting Full-text search RediSearch (<code>FT.*</code> commands) for memory recall"},{"location":"deployment/redis/#installation","title":"Installation","text":"Docker (easiest)Debian / UbuntumacOS <pre><code>docker run -d --name redis -p 6379:6379 redis:8\n</code></pre> <p>This is the fastest way to get Redis 8 running. The container exposes port 6379 on localhost.</p> <p>Add the official Redis repository and install:</p> <pre><code>curl -fsSL https://packages.redis.io/gpg | \\\n    sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\nsudo chmod 644 /usr/share/keyrings/redis-archive-keyring.gpg\n\necho \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] \\\n    https://packages.redis.io/deb $(lsb_release -cs) main\" | \\\n    sudo tee /etc/apt/sources.list.d/redis.list\n\nsudo apt-get update\nsudo apt-get install redis\n</code></pre> <p>The service starts automatically after installation.</p> <pre><code>brew install redis\nbrew services start redis\n</code></pre> <p>Homebrew installs the latest Redis version (8.0+) by default.</p>"},{"location":"deployment/redis/#verification","title":"Verification","text":"<p>After installation, verify that the RediSearch module is available:</p> <pre><code>redis-cli MODULE LIST\n</code></pre> <p>The output should include the <code>search</code> module. Example:</p> <pre><code>1) 1) \"name\"\n   2) \"search\"\n   3) \"ver\"\n   4) 80000\n</code></pre> <p>You can also verify with a quick connectivity check:</p> <pre><code>redis-cli ping\n# Expected: PONG\n\nredis-cli FT._LIST\n# Expected: (empty array) \u2014 no error means the module is loaded\n</code></pre>"},{"location":"deployment/redis/#removing-older-redis-versions","title":"Removing Older Redis Versions","text":"<p>If you have an older Redis version installed, remove it before installing Redis 8:</p> Debian / UbuntumacOSDocker <pre><code>sudo systemctl stop redis-server\nsudo systemctl disable redis-server\nsudo apt remove --purge redis-server\n</code></pre> <pre><code>brew services stop redis\nbrew uninstall redis\n</code></pre> <pre><code>docker stop redis\ndocker rm redis\n</code></pre> <p>After removal, follow the installation instructions above to install Redis 8.</p>"},{"location":"deployment/redis/#configuration","title":"Configuration","text":"<p>For production deployments, edit <code>/etc/redis/redis.conf</code> (or the equivalent for your platform):</p> <pre><code># Bind to localhost only (security)\nbind 127.0.0.1\n\n# Set a password (recommended for production)\nrequirepass your-redis-password\n\n# Enable persistence\nsave 900 1\nsave 300 10\nsave 60 10000\n\n# Set max memory (adjust for your server)\nmaxmemory 256mb\nmaxmemory-policy allkeys-lru\n</code></pre> <p>If you set a Redis password, update your <code>.env</code> file:</p> <pre><code>REDIS_URL=redis://:your-redis-password@localhost:6379/0\n</code></pre>"},{"location":"deployment/redis/#workaround-without-redis-8","title":"Workaround Without Redis 8","text":"<p>If you cannot upgrade to Redis 8, there is a partial workaround:</p> <p>Enable <code>conversation_memory</code> on agent nodes that use <code>spawn_and_await</code>. This switches the checkpointer from <code>RedisSaver</code> to <code>SqliteSaver</code>, bypassing the RediSearch requirement for that specific feature.</p> <p>Limited functionality</p> <p>This workaround only addresses the checkpointer. Other features that rely on RediSearch (such as memory recall with full-text search) will not function without Redis 8+. Upgrading Redis is strongly recommended.</p>"},{"location":"deployment/redis/#troubleshooting","title":"Troubleshooting","text":""},{"location":"deployment/redis/#unknown-command-ft_list","title":"<code>unknown command 'FT._LIST'</code>","text":"<p>Your Redis version is older than 8.0. Check your version:</p> <pre><code>redis-cli INFO server | grep redis_version\n</code></pre> <p>If the version is below 8.0, follow the installation instructions to upgrade.</p>"},{"location":"deployment/redis/#connection-refused-on-port-6379","title":"<code>Connection refused</code> on port 6379","text":"<p>Redis is not running. Start it:</p> <pre><code># systemd\nsudo systemctl start redis\n\n# Docker\ndocker start redis\n\n# macOS\nbrew services start redis\n</code></pre>"},{"location":"deployment/redis/#noauth-authentication-required","title":"<code>NOAUTH Authentication required</code>","text":"<p>Redis has a password set. Update your <code>REDIS_URL</code> in <code>.env</code>:</p> <pre><code>REDIS_URL=redis://:your-password@localhost:6379/0\n</code></pre>"},{"location":"deployment/reverse-proxy/","title":"Reverse Proxy","text":""},{"location":"deployment/reverse-proxy/#reverse-proxy","title":"Reverse Proxy","text":"<p>A reverse proxy sits in front of Pipelit to handle HTTPS termination, WebSocket upgrades, and optional domain-based routing. This page provides configurations for Nginx and Caddy.</p>"},{"location":"deployment/reverse-proxy/#key-requirements","title":"Key Requirements","text":"<p>Pipelit uses both standard HTTP and WebSocket connections, so your reverse proxy must:</p> <ol> <li>Proxy HTTP requests to the FastAPI backend (default port 8000)</li> <li>Upgrade WebSocket connections at the <code>/ws/</code> path</li> <li>Terminate TLS/SSL with a valid certificate</li> <li>Pass client IP headers for logging and rate limiting</li> </ol>"},{"location":"deployment/reverse-proxy/#nginx","title":"Nginx","text":""},{"location":"deployment/reverse-proxy/#basic-configuration","title":"Basic Configuration","text":"/etc/nginx/sites-available/pipelit<pre><code>upstream pipelit_backend {\n    server 127.0.0.1:8000;\n}\n\nserver {\n    listen 80;\n    server_name your-domain.com;\n\n    # Redirect HTTP to HTTPS\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name your-domain.com;\n\n    # SSL certificates (Let's Encrypt)\n    ssl_certificate /etc/letsencrypt/live/your-domain.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/your-domain.com/privkey.pem;\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers HIGH:!aNULL:!MD5;\n\n    # Max upload size (for file uploads, webhook payloads)\n    client_max_body_size 50M;\n\n    # Proxy all requests to FastAPI\n    location / {\n        proxy_pass http://pipelit_backend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    # WebSocket endpoint\n    location /ws/ {\n        proxy_pass http://pipelit_backend;\n        proxy_http_version 1.1;\n        proxy_set_header Upgrade $http_upgrade;\n        proxy_set_header Connection \"upgrade\";\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # WebSocket timeouts\n        proxy_read_timeout 86400s;\n        proxy_send_timeout 86400s;\n    }\n}\n</code></pre>"},{"location":"deployment/reverse-proxy/#enable-the-site","title":"Enable the Site","text":"<pre><code>sudo ln -s /etc/nginx/sites-available/pipelit /etc/nginx/sites-enabled/\nsudo nginx -t\nsudo systemctl reload nginx\n</code></pre> <p>WebSocket timeouts</p> <p>The <code>proxy_read_timeout</code> and <code>proxy_send_timeout</code> values are set to 24 hours (86400 seconds) for the WebSocket endpoint. Pipelit's WebSocket uses a 30-second ping/pong heartbeat to keep the connection alive, but Nginx's default 60-second timeout can still close idle connections prematurely.</p>"},{"location":"deployment/reverse-proxy/#caddy","title":"Caddy","text":"<p>Caddy is a simpler alternative that automatically handles HTTPS certificate issuance and renewal via Let's Encrypt.</p>"},{"location":"deployment/reverse-proxy/#caddyfile","title":"Caddyfile","text":"/etc/caddy/Caddyfile<pre><code>your-domain.com {\n    reverse_proxy localhost:8000\n}\n</code></pre> <p>That is the complete Caddy configuration. Caddy automatically:</p> <ul> <li>Obtains and renews Let's Encrypt certificates</li> <li>Redirects HTTP to HTTPS</li> <li>Handles WebSocket upgrade headers</li> <li>Sets appropriate proxy headers</li> </ul>"},{"location":"deployment/reverse-proxy/#start-caddy","title":"Start Caddy","text":"<pre><code>sudo systemctl enable caddy\nsudo systemctl start caddy\n</code></pre> <p>Caddy and WebSocket</p> <p>Caddy natively supports WebSocket proxying with no additional configuration. The <code>reverse_proxy</code> directive handles HTTP upgrade headers transparently.</p>"},{"location":"deployment/reverse-proxy/#ssltls-with-lets-encrypt","title":"SSL/TLS with Let's Encrypt","text":""},{"location":"deployment/reverse-proxy/#using-certbot-for-nginx","title":"Using Certbot (for Nginx)","text":"<pre><code># Install certbot\nsudo apt install certbot python3-certbot-nginx\n\n# Obtain a certificate\nsudo certbot --nginx -d your-domain.com\n\n# Verify auto-renewal\nsudo certbot renew --dry-run\n</code></pre> <p>Certbot automatically modifies your Nginx configuration to include the SSL certificate paths and enables auto-renewal via a systemd timer.</p>"},{"location":"deployment/reverse-proxy/#using-caddy","title":"Using Caddy","text":"<p>Caddy handles certificate management automatically. No additional setup is needed. Ensure that:</p> <ul> <li>Port 80 and 443 are open on your firewall</li> <li>DNS A/AAAA records point to your server's IP address</li> </ul>"},{"location":"deployment/reverse-proxy/#firewall-configuration","title":"Firewall Configuration","text":"<p>After setting up the reverse proxy, block direct access to the backend port:</p> <pre><code># Allow only HTTPS and HTTP (for redirect)\nsudo ufw allow 80/tcp\nsudo ufw allow 443/tcp\n\n# Block direct backend access from external networks\n# (port 8000 should only be accessible from localhost)\nsudo ufw deny 8000/tcp\n\n# Block Redis from external access\nsudo ufw deny 6379/tcp\n</code></pre>"},{"location":"deployment/reverse-proxy/#verifying-websocket-connectivity","title":"Verifying WebSocket Connectivity","text":"<p>After configuring the reverse proxy, verify that WebSocket connections work:</p> <pre><code># Using websocat (install: cargo install websocat)\nwebsocat wss://your-domain.com/ws/?token=your-api-key\n\n# Or use the browser's developer tools:\n# 1. Open your Pipelit instance\n# 2. Open DevTools -&gt; Network -&gt; WS tab\n# 3. You should see a WebSocket connection to /ws/\n</code></pre> <p>A successful connection will show periodic <code>ping</code>/<code>pong</code> messages every 30 seconds.</p>"},{"location":"frontend/","title":"Frontend Guide","text":""},{"location":"frontend/#frontend-guide","title":"Frontend Guide","text":"<p>Pipelit ships with a React single-page application (SPA) that provides the full visual interface for designing workflows, managing credentials, inspecting executions, and more.</p>"},{"location":"frontend/#tech-stack","title":"Tech Stack","text":"Library Role React 18 + Vite Component framework and build toolchain TypeScript Type-safe frontend codebase Shadcn/ui Accessible UI primitives (dialogs, tables, selects, etc.) @xyflow/react v12 (React Flow) Drag-and-drop workflow canvas TanStack Query Server state management with caching and mutations React Router Client-side routing CodeMirror 6 Modal editors with Jinja2 syntax highlighting Lucide React + Font Awesome Icons in the sidebar and on canvas nodes"},{"location":"frontend/#source-structure","title":"Source Structure","text":"<pre><code>platform/frontend/src/\n\u251c\u2500\u2500 api/            # TanStack Query hooks + fetch client\n\u251c\u2500\u2500 components/     # Shared components (ExpressionTextarea, VariablePicker, layout)\n\u251c\u2500\u2500 features/       # Page-level feature modules\n\u2502   \u251c\u2500\u2500 auth/       # Login, setup, AuthProvider\n\u2502   \u251c\u2500\u2500 workflows/  # Dashboard + editor (canvas, palette, details panel)\n\u2502   \u251c\u2500\u2500 credentials/\n\u2502   \u251c\u2500\u2500 executions/\n\u2502   \u251c\u2500\u2500 epics/\n\u2502   \u251c\u2500\u2500 memories/\n\u2502   \u251c\u2500\u2500 users/\n\u2502   \u2514\u2500\u2500 settings/\n\u251c\u2500\u2500 hooks/          # useTheme, useWebSocket\n\u251c\u2500\u2500 lib/            # WebSocket manager, Jinja2 highlighting plugin\n\u251c\u2500\u2500 types/          # TypeScript type definitions\n\u251c\u2500\u2500 App.tsx         # Route definitions\n\u2514\u2500\u2500 main.tsx        # QueryClient + AuthProvider + Router\n</code></pre>"},{"location":"frontend/#routes","title":"Routes","text":"<p>All pages except <code>/login</code> and <code>/setup</code> are protected by authentication. The authenticated layout wraps pages in a collapsible sidebar with navigation links.</p> Route Page Description <code>/login</code> Login Username and password form <code>/setup</code> Setup First-time admin account creation <code>/</code> Dashboard Workflow list with create/delete <code>/workflows/:slug</code> Workflow Editor Three-panel canvas editor <code>/credentials</code> Credentials API key and bot token management <code>/executions</code> Executions Execution list with status filters <code>/executions/:id</code> Execution Detail Per-execution logs and output <code>/epics</code> Epics Epic list with task tracking <code>/epics/:epicId</code> Epic Detail Tasks, budget, and cost breakdown <code>/memories</code> Memories Facts, episodes, checkpoints, procedures, users <code>/agent-users</code> Agent Users Agent user management <code>/settings</code> Settings Theme and MFA configuration"},{"location":"frontend/#running-the-frontend","title":"Running the Frontend","text":""},{"location":"frontend/#development-mode","title":"Development Mode","text":"<p>In development, Vite runs a hot-reloading dev server that proxies API requests to the FastAPI backend.</p> <pre><code>cd platform/frontend\nnpm install\nnpm run dev\n</code></pre> <p>The Vite dev server starts on <code>http://localhost:5173</code> and proxies all <code>/api</code> requests to the FastAPI backend at <code>http://localhost:8000</code>. You need both the FastAPI server and the Vite dev server running simultaneously.</p> <p>Hot module replacement</p> <p>Vite provides instant hot module replacement (HMR). Saving a React component file updates the browser immediately without a full page reload.</p>"},{"location":"frontend/#production-mode","title":"Production Mode","text":"<p>For production, build the frontend into static files that FastAPI serves directly.</p> <pre><code>cd platform/frontend\nnpm run build\n</code></pre> <p>This compiles the SPA into <code>platform/frontend/dist/</code>, which FastAPI mounts as a static file directory. No separate frontend server is required -- access everything through the FastAPI process at port 8000.</p>"},{"location":"frontend/#authentication-flow","title":"Authentication Flow","text":"<p>The frontend uses Bearer token authentication. On login, the client sends credentials to <code>POST /api/v1/auth/token/</code> and receives an API key. This key is stored in memory (via <code>AuthProvider</code> context) and injected into all subsequent API requests via the <code>Authorization: Bearer &lt;key&gt;</code> header.</p> <p>A <code>401 Unauthorized</code> response from any API call triggers an automatic redirect to the login page.</p>"},{"location":"frontend/#real-time-updates-via-websocket","title":"Real-time Updates via WebSocket","text":"<p>The frontend maintains a single persistent WebSocket connection to the backend at <code>/ws/?token=&lt;api_key&gt;</code>. This connection, managed by the <code>WebSocketManager</code> singleton, provides:</p> <ul> <li>Automatic reconnection with exponential backoff</li> <li>Channel subscriptions -- subscribe to <code>workflow:&lt;slug&gt;</code> or <code>execution:&lt;id&gt;</code> channels</li> <li>TanStack Query cache updates -- incoming WebSocket events directly update the query cache, eliminating the need for polling or refetching after mutations</li> </ul> <p>Event types received over WebSocket include:</p> <ul> <li><code>node_created</code>, <code>node_updated</code>, <code>node_deleted</code> -- canvas mutations</li> <li><code>edge_created</code>, <code>edge_updated</code>, <code>edge_deleted</code> -- connection changes</li> <li><code>workflow_updated</code> -- workflow metadata changes</li> <li><code>node_status</code> -- per-node execution status (pending, running, success, failed, skipped)</li> <li><code>execution_completed</code>, <code>execution_failed</code>, <code>execution_interrupted</code> -- execution lifecycle</li> </ul>"},{"location":"frontend/#whats-next","title":"What's Next?","text":"<ul> <li>Dashboard -- Manage your workflows</li> <li>Workflow Editor -- Design workflows on the visual canvas</li> <li>Executions -- Monitor and inspect workflow runs</li> </ul>"},{"location":"frontend/credentials-ui/","title":"Credentials","text":""},{"location":"frontend/credentials-ui/#credentials","title":"Credentials","text":"<p>The Credentials page at <code>/credentials</code> manages API keys, bot tokens, and other secrets used by workflow nodes. Credentials are global -- any workflow can reference any credential.</p>"},{"location":"frontend/credentials-ui/#credentials-table","title":"Credentials Table","text":"<p>The main view is a paginated table with the following columns:</p> Column Description Checkbox Row selection for batch operations Name The credential's display name Type Badge showing the credential type Detail Provider type for LLM credentials (e.g., \"openai_compatible\") Created Creation date Actions Test button (LLM only) and delete button"},{"location":"frontend/credentials-ui/#pagination","title":"Pagination","text":"<p>Credentials are paginated with 50 items per page. Navigation controls appear at the bottom.</p>"},{"location":"frontend/credentials-ui/#credential-types","title":"Credential Types","text":"<p>The platform supports four credential types:</p> Type Purpose Fields LLM LLM provider API access Provider type, API key, base URL, organization ID Telegram Telegram bot authentication Bot token Git Git repository access (Configured via Extra Config) Tool Tool-specific credentials (Configured via Extra Config)"},{"location":"frontend/credentials-ui/#creating-a-credential","title":"Creating a Credential","text":"<p>Click Add Credential to open the creation dialog.</p>"},{"location":"frontend/credentials-ui/#common-fields","title":"Common Fields","text":"<ul> <li> <p>Name (required) -- A descriptive label for the credential</p> </li> <li> <p>Type (required) -- Select from LLM, Telegram, Git, or Tool</p> </li> </ul>"},{"location":"frontend/credentials-ui/#llm-specific-fields","title":"LLM-Specific Fields","text":"<p>When the type is set to LLM, additional fields appear:</p> <ul> <li>Provider Type -- Choose from:<ul> <li>OpenAI -- For OpenAI's API</li> <li>Anthropic -- For Anthropic's Claude API</li> <li>OpenAI Compatible -- For any provider with an OpenAI-compatible API (e.g., local models, Venice.ai, Together AI)</li> </ul> </li> <li>API Key -- Your provider's API key (masked as a password field)</li> <li>Base URL (optional) -- Override the default API endpoint. Useful for OpenAI-compatible providers that use a custom URL.</li> <li>Organization ID (optional) -- For OpenAI organization-scoped access</li> </ul>"},{"location":"frontend/credentials-ui/#telegram-specific-fields","title":"Telegram-Specific Fields","text":"<p>When the type is set to Telegram:</p> <ul> <li>Bot Token -- Your Telegram bot token from @BotFather (masked as a password field)</li> </ul>"},{"location":"frontend/credentials-ui/#testing-credentials","title":"Testing Credentials","text":"<p>LLM credentials display a Test button in the actions column. Clicking it:</p> <ol> <li>Sends a test request to the provider's API</li> <li>Shows a loading spinner while the test runs</li> <li>Displays the result:<ul> <li>Green checkmark -- The credential is valid</li> <li>Red X -- The test failed (hover for details)</li> </ul> </li> </ol> <p>Test before using</p> <p>Always test a new LLM credential before referencing it in a workflow. Invalid credentials cause execution failures that can be hard to diagnose.</p>"},{"location":"frontend/credentials-ui/#api-key-security","title":"API Key Security","text":"<p>Sensitive fields (API keys, bot tokens) are encrypted at rest using Fernet encryption via the <code>FIELD_ENCRYPTION_KEY</code> environment variable. In the UI:</p> <ul> <li>API keys are entered as password fields (masked input)</li> <li>The API never returns raw key values -- only the encrypted reference is stored</li> <li>Credential detail shown in the table is limited to non-sensitive metadata (provider type, base URL)</li> </ul>"},{"location":"frontend/credentials-ui/#deleting-credentials","title":"Deleting Credentials","text":""},{"location":"frontend/credentials-ui/#single-delete","title":"Single Delete","text":"<p>Click the trash icon on any row to open a confirmation dialog.</p>"},{"location":"frontend/credentials-ui/#batch-delete","title":"Batch Delete","text":"<p>Select multiple credentials using checkboxes, then click Delete Selected (N). A confirmation dialog shows the count.</p> <p>Credential deletion</p> <p>Deleting a credential that is referenced by workflow nodes will cause those nodes to fail during execution. Verify no active workflows depend on a credential before removing it.</p>"},{"location":"frontend/dashboard/","title":"Dashboard","text":""},{"location":"frontend/dashboard/#dashboard","title":"Dashboard","text":"<p>The Dashboard is the landing page after login, accessible at <code>/</code>. It displays all workflows in a paginated table and provides controls for creating, selecting, and deleting workflows.</p>"},{"location":"frontend/dashboard/#workflow-table","title":"Workflow Table","text":"<p>The dashboard presents workflows in a data table with the following columns:</p> Column Description Checkbox Row selection for batch operations Name Workflow display name (clickable to open editor) Slug URL-friendly identifier (auto-generated from name) Status Active/Inactive badge Nodes Number of nodes in the workflow Edges Number of edges (connections) in the workflow Triggers Number of trigger nodes Created Creation date Actions Delete button per row <p>Clicking anywhere on a row navigates to the Workflow Editor for that workflow.</p>"},{"location":"frontend/dashboard/#pagination","title":"Pagination","text":"<p>The table displays 50 workflows per page (the platform default page size). Pagination controls appear at the bottom of the table when the total number of workflows exceeds the page size.</p>"},{"location":"frontend/dashboard/#loading-state","title":"Loading State","text":"<p>While workflows are loading, the dashboard displays animated skeleton placeholders to indicate content is being fetched.</p>"},{"location":"frontend/dashboard/#creating-a-workflow","title":"Creating a Workflow","text":"<p>Click the Create Workflow button in the top-right corner to open a dialog with three fields:</p> <ul> <li>Name (required) -- The display name for the workflow.</li> <li>Slug (required) -- Auto-generated from the name by converting to lowercase and replacing non-alphanumeric characters with hyphens. You can override the auto-generated slug before creating.</li> <li>Description (optional) -- A free-text description of the workflow's purpose.</li> </ul> <p>Slug generation</p> <p>As you type the workflow name, the slug field updates automatically. For example, typing \"My Chat Bot\" generates the slug <code>my-chat-bot</code>. You can manually edit the slug if you prefer a different identifier.</p> <p>After clicking Create, the new workflow appears in the table. Navigate to it to start designing on the canvas.</p>"},{"location":"frontend/dashboard/#deleting-workflows","title":"Deleting Workflows","text":""},{"location":"frontend/dashboard/#single-delete","title":"Single Delete","text":"<p>Each row has a trash icon button on the right side. Clicking it opens a confirmation dialog:</p> <p>\"Are you sure you want to delete this workflow? This action cannot be undone.\"</p>"},{"location":"frontend/dashboard/#batch-delete","title":"Batch Delete","text":"<p>Select multiple workflows using the checkboxes, then click the Delete Selected (N) button that appears in the header. A confirmation dialog shows the count of workflows to be deleted.</p> <p>Use the header checkbox to toggle all workflows on the current page.</p> <p>Deletion is permanent</p> <p>Deleting a workflow removes it along with all its nodes, edges, and associated configuration. Execution history is preserved separately on the Executions page.</p>"},{"location":"frontend/dashboard/#layout","title":"Layout","text":"<p>The dashboard, like all authenticated pages, is wrapped in the App Layout which provides:</p> <ul> <li>A collapsible sidebar on the left with navigation links (Workflows, Credentials, Executions, Epics, Memories, Agent Users)</li> <li>A user menu at the bottom of the sidebar with links to Settings and Logout</li> <li>The sidebar collapse state is persisted to <code>localStorage</code></li> </ul> <p>The sidebar can be collapsed to a narrow icon-only view by clicking the chevron button in the header.</p>"},{"location":"frontend/editor/","title":"Workflow Editor","text":""},{"location":"frontend/editor/#workflow-editor","title":"Workflow Editor","text":"<p>The Workflow Editor is the core interface for designing and testing workflows. It opens when you navigate to <code>/workflows/:slug</code> and provides a three-panel layout built around an interactive React Flow canvas.</p>"},{"location":"frontend/editor/#layout","title":"Layout","text":"<p>The editor is split into three panels:</p> <pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          \u2502                          \u2502          \u2502\n\u2502  Node    \u2502      Workflow Canvas     \u2502  Node    \u2502\n\u2502  Palette \u2502      (React Flow)        \u2502  Details \u2502\n\u2502  (left)  \u2502                          \u2502  Panel   \u2502\n\u2502          \u2502                          \u2502  (right) \u2502\n\u2502          \u2502                          \u2502          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <ul> <li>Node Palette (left, 240px) -- Categorized list of node types you can add to the canvas</li> <li>Workflow Canvas (center, flexible) -- Drag-and-drop canvas where you build the workflow graph</li> <li>Node Details Panel (right, 320px) -- Configuration form for the selected node; hidden when no node is selected</li> </ul> <p>The editor subscribes to the <code>workflow:&lt;slug&gt;</code> WebSocket channel on mount, enabling real-time updates when nodes or edges change.</p>"},{"location":"frontend/editor/#node-palette","title":"Node Palette","text":"<p>The left panel displays all available component types organized into categories:</p> Category Node Types Triggers Chat, Telegram, Schedule, Manual, Workflow, Error AI AI Model, Agent Routing Categorizer, Extractor Memory Memory Read, Memory Write, Identify User Agent WhoAmI, Create Agent User, Get TOTP Code, Platform API, Epic Tools, Task Tools, Scheduler Tools, System Health, Spawn &amp; Await, Workflow Create Tools Run Command, HTTP Request, Web Search, Calculator, DateTime, Code Execute, Workflow Discover Logic Switch, Loop, Filter, Merge, Wait Other Workflow, Code, Human Confirmation, Aggregator, Error Handler, Output Parser <p>Click any node type to add it to the canvas. Each click creates a new node instance with a unique auto-generated ID (e.g., <code>agent_m1abc2</code>).</p>"},{"location":"frontend/editor/#canvas","title":"Canvas","text":"<p>The canvas is powered by React Flow (@xyflow/react v12) and supports:</p> <ul> <li>Pan and zoom -- Scroll to zoom, drag the background to pan</li> <li>Node dragging -- Drag nodes to reposition them; positions are saved to the backend on drag end</li> <li>Edge creation -- Drag from an output handle to an input handle to create a connection</li> <li>Selection -- Click a node to select it and open its details panel</li> <li>Deletion -- Press Del or Backspace to delete selected nodes or edges</li> <li>MiniMap -- Small overview map in the corner for navigating large workflows</li> <li>Controls -- Zoom in/out and fit-to-view buttons</li> <li>Dark mode -- Canvas theme follows the application theme setting</li> </ul>"},{"location":"frontend/editor/#node-visual-design","title":"Node Visual Design","text":"<p>Each node on the canvas displays:</p> <ul> <li>Icon -- Font Awesome icon identifying the component type</li> <li>Type label -- The component type name (e.g., \"Agent\", \"Telegram\", \"Switch\")</li> <li>Node ID -- Shortened display label (strips the component type prefix)</li> <li>Color-coded border -- Each component category has a distinct color:</li> </ul> Category Color Hex Triggers Orange <code>#f97316</code> AI nodes (Agent, Categorizer, Router, Extractor) Purple <code>#8b5cf6</code> AI Model Blue <code>#3b82f6</code> Tools Green <code>#10b981</code> Self-Awareness Teal <code>#14b8a6</code> Logic (Switch, Loop, Filter, Merge, Wait) Indigo <code>#6366f1</code> Memory Amber <code>#f59e0b</code> Error Handler Red <code>#ef4444</code>"},{"location":"frontend/editor/#node-handles","title":"Node Handles","text":"<p>Handles are the connection points on nodes. Their shape and position indicate their purpose:</p> <p>Circle handles (data flow):</p> <ul> <li>Left -- Target/input. Accepts incoming data from upstream nodes.</li> <li>Right -- Source/output. Sends data to downstream nodes.</li> </ul> <p>Diamond handles (sub-component connections):</p> <ul> <li>Bottom -- Sub-component slots on AI-type nodes (model, tools, memory, output_parser)</li> <li>Top -- Source on <code>ai_model</code> nodes, connecting upward to the AI node that uses the model</li> </ul>"},{"location":"frontend/editor/#ai-type-node-sub-components","title":"AI-Type Node Sub-Components","text":"<p>Agent, categorizer, router, and extractor nodes have a fixed 250px width with a separator line and sub-component pill icons at the bottom:</p> Sub-Component Icon Handle Color Available On Model Microchip Blue (<code>#3b82f6</code>) Agent, Categorizer, Router, Extractor Tools Wrench Green (<code>#10b981</code>) Agent only Memory Brain Amber (<code>#f59e0b</code>) Agent, Categorizer, Router, Extractor Output Parser File Export Slate (<code>#94a3b8</code>) Categorizer, Router, Extractor"},{"location":"frontend/editor/#switch-node","title":"Switch Node","text":"<p>Switch nodes display their routing rules as labeled output handles on the right side. Each rule has its own handle that you drag to a downstream node. If the fallback route is enabled, an \"other\" handle appears at the bottom.</p>"},{"location":"frontend/editor/#loop-node","title":"Loop Node","text":"<p>Loop nodes have special handles:</p> <ul> <li>Each Item (amber, right) -- Connect to the first body node</li> <li>Done (emerald, right) -- Connect to nodes that run after all items</li> <li>Return (amber, left, bottom) -- Connect from the last body node back to the loop</li> </ul> <p>Loop return edges render with a distinctive smoothstep path that routes below the nodes with dashed stroke and a \"return\" label.</p>"},{"location":"frontend/editor/#drawing-connections","title":"Drawing Connections","text":"<p>To connect two nodes:</p> <ol> <li>Hover over a source handle (right side or bottom diamond) -- the cursor changes to a crosshair</li> <li>Click and drag to the target handle on another node</li> <li>Release to create the edge</li> </ol> <p>The system automatically determines the edge type:</p> <ul> <li>Dragging from a regular output to a regular input creates a data flow edge</li> <li>Dragging from a diamond handle creates a sub-component edge with the appropriate label (<code>llm</code>, <code>tool</code>, <code>memory</code>, <code>output_parser</code>)</li> <li>Dragging from a switch rule handle creates a conditional edge with the rule ID as the condition value</li> <li>Dragging from a loop's \"Each Item\" handle creates a loop_body edge</li> </ul> <p>Edge validation</p> <p>The backend validates edge type compatibility when you create a connection. If the source output type is incompatible with the target input type, the edge creation returns a 422 error.</p>"},{"location":"frontend/editor/#live-execution-badges","title":"Live Execution Badges","text":"<p>During workflow execution, each executable node displays a real-time status badge in the top-right corner:</p> Badge Status Visual Spinning circle Running Blue, animated spin Hourglass Waiting Cyan, animated pulse Checkmark Success Green X mark Failed Red Dash Idle Gray, low opacity <p>Badges only appear on executable nodes (as determined by the <code>executable</code> flag from the node type registry). Sub-components like <code>ai_model</code> and tool nodes show smaller badges in the bottom-right corner.</p>"},{"location":"frontend/editor/#node-output-display","title":"Node Output Display","text":"<p>After a successful execution:</p> <ul> <li>Success nodes show a clickable \"output\" link in emerald green that opens a popover with the pretty-printed JSON output.</li> <li>Failed nodes show a clickable \"error\" link in red that opens a popover with error details and error code.</li> </ul> <p>Execution statuses reset automatically when a new execution starts.</p>"},{"location":"frontend/editor/#node-details-panel","title":"Node Details Panel","text":"<p>Selecting a node opens the details panel on the right. The panel content varies by node type but always includes:</p>"},{"location":"frontend/editor/#common-controls","title":"Common Controls","text":"<ul> <li>Node ID -- Displayed at the top, not editable</li> <li>Component type -- Shown as a secondary label</li> <li>Interrupt Before / Interrupt After -- Toggle switches for human-in-the-loop breakpoints</li> <li>Save button -- Persists all configuration changes to the backend</li> <li>Delete button -- Removes the node and all its connected edges</li> </ul>"},{"location":"frontend/editor/#trigger-node-configuration","title":"Trigger Node Configuration","text":"<p>Trigger nodes show additional fields:</p> <ul> <li>Credential -- Select a credential for the trigger (e.g., Telegram bot token)</li> <li>Active -- Toggle whether the trigger is actively listening</li> <li>Priority -- Numeric priority for ordering when multiple triggers can handle the same event</li> <li>Trigger Config -- JSON editor for trigger-specific settings</li> </ul> <p>The Manual Trigger has a Run button to immediately dispatch the workflow.</p> <p>The Schedule Trigger has a dedicated section with interval, repeat count, retry, timeout, and payload settings, plus start/pause/stop controls and a live status display showing run count, errors, retries, last/next run timestamps, and expandable error details.</p>"},{"location":"frontend/editor/#ai-model-configuration","title":"AI Model Configuration","text":"<p>The <code>ai_model</code> node provides:</p> <ul> <li>LLM Credential -- Dropdown of available LLM credentials</li> <li>Model -- Either a dropdown of models fetched from the provider or a free-text input</li> <li>Temperature, Max Tokens, Top P, Frequency Penalty, Presence Penalty -- Numeric fields for LLM parameters</li> </ul>"},{"location":"frontend/editor/#agent-configuration","title":"Agent Configuration","text":"<p>Agent nodes expose:</p> <ul> <li>System Prompt -- Text area with an expand button (opens CodeMirror modal) and pop-out button (opens a separate browser window). Supports the variable picker for inserting Jinja2 expressions.</li> <li>Conversation Memory -- Toggle to persist conversation history across executions</li> </ul>"},{"location":"frontend/editor/#categorizer-router-extractor","title":"Categorizer, Router, Extractor","text":"<p>These AI-type nodes share the system prompt editor. The Categorizer additionally provides a category editor where you can add, edit, and remove categories with name and description fields.</p>"},{"location":"frontend/editor/#switch-rules-editor","title":"Switch Rules Editor","text":"<p>The switch node details panel provides a full rule editor:</p> <ul> <li>Add Rule -- Creates a new routing rule</li> <li>Each rule has: Label, Source Node (dropdown of upstream nodes), Output Field, Operator (grouped: Universal, String, Number, Datetime, Boolean, Array), and Value</li> <li>Fallback Route -- Toggle to add an \"other\" catch-all route</li> </ul>"},{"location":"frontend/editor/#logic-nodes","title":"Logic Nodes","text":"<ul> <li>Wait -- Duration and unit (seconds/minutes/hours)</li> <li>Filter -- Source node, field, and a list of filter rules</li> <li>Merge -- Mode selector (Append or Combine)</li> <li>Loop -- Source node, array field, error handling (stop or continue)</li> <li>Code -- Language selector (Python/JavaScript/Bash) and a code editor with expand and pop-out options</li> <li>Workflow (subworkflow) -- Target workflow selector and trigger mode (implicit/explicit)</li> </ul>"},{"location":"frontend/editor/#extra-config","title":"Extra Config","text":"<p>All non-trigger nodes have an Extra Config (JSON) editor at the bottom. This JSON field can be expanded into a CodeMirror modal or popped out to a separate window. It supports Jinja2 expression insertion via the variable picker.</p>"},{"location":"frontend/editor/#expression-editor-and-variable-picker","title":"Expression Editor and Variable Picker","text":"<p>Text fields that support Jinja2 expressions (System Prompt, Code, Extra Config) include a <code>{ }</code> button that opens the Variable Picker. The picker:</p> <ol> <li>Performs a BFS backward through data edges to find all upstream nodes</li> <li>Lists each upstream node's output ports</li> <li>Clicking a port inserts <code>{{ nodeId.portName }}</code> at the cursor position</li> </ol> <p>The expanded CodeMirror editors provide Jinja2 syntax highlighting via a custom ViewPlugin:</p> <ul> <li><code>{{ }}</code> delimiters appear in bold green</li> <li>Inner expressions appear in bold amber/orange</li> <li><code>{% %}</code> block tags and <code>{# #}</code> comments are also highlighted</li> </ul>"},{"location":"frontend/editor/#chat-panel","title":"Chat Panel","text":"<p>Double-clicking a Chat Trigger node opens a dedicated chat interface instead of the standard configuration panel. The chat panel provides:</p> <ul> <li>Message history -- Last 10 messages, loaded from the server. A date picker allows filtering older messages.</li> <li>Send message -- Type a message and press Enter or click Send. The message dispatches through the workflow and the response appears when the execution completes.</li> <li>Pop-out -- Open the chat in a separate browser window for a larger view</li> <li>Clear history -- Delete all chat messages for the workflow</li> <li>Reload -- Refresh the message history from the server</li> </ul> <p>The chat panel listens for <code>execution_completed</code> and <code>execution_failed</code> WebSocket events to display the assistant's response in real time.</p>"},{"location":"frontend/editor/#keyboard-shortcuts","title":"Keyboard Shortcuts","text":"Key Action Del / Backspace Delete selected nodes or edges Mouse wheel Zoom in/out Click + drag (background) Pan the canvas Click (node) Select node and open details panel Double-click (chat trigger) Open chat panel"},{"location":"frontend/epics-ui/","title":"Epics","text":""},{"location":"frontend/epics-ui/#epics","title":"Epics","text":"<p>The Epics page at <code>/epics</code> provides project-level tracking for multi-step agent operations. Epics group related tasks, track progress, and enforce budgets. This page is used to monitor autonomous agent work and manage long-running operations.</p>"},{"location":"frontend/epics-ui/#epic-list","title":"Epic List","text":"<p>The list page displays a paginated table of all epics with the following columns:</p> Column Description Checkbox Row selection for batch operations Title The epic's display title (clickable to open detail) Status Color-coded status badge Progress Completed tasks out of total tasks (e.g., \"3/5 tasks\") Priority Epic priority level Created Creation timestamp"},{"location":"frontend/epics-ui/#status-badges","title":"Status Badges","text":"<p>Each epic status has a distinct color:</p> Status Color <code>planning</code> Yellow <code>active</code> Blue <code>paused</code> Orange <code>completed</code> Green <code>failed</code> Red <code>cancelled</code> Gray"},{"location":"frontend/epics-ui/#status-filter","title":"Status Filter","text":"<p>A dropdown in the top-right corner filters epics by status. Options: All, Planning, Active, Paused, Completed, Failed, Cancelled. Changing the filter resets to page 1.</p>"},{"location":"frontend/epics-ui/#batch-delete","title":"Batch Delete","text":"<p>Select multiple epics and click Delete Selected (N) to remove them after confirmation.</p>"},{"location":"frontend/epics-ui/#navigation","title":"Navigation","text":"<p>Click any epic row to navigate to the epic detail page.</p>"},{"location":"frontend/epics-ui/#epic-detail","title":"Epic Detail","text":"<p>Accessible at <code>/epics/:epicId</code>, the detail page provides full information about a single epic. It subscribes to the <code>epic:&lt;id&gt;</code> WebSocket channel for real-time updates.</p>"},{"location":"frontend/epics-ui/#summary-cards","title":"Summary Cards","text":"<p>Four cards across the top display:</p> Card Content Status Color-coded status badge Progress Completed/total task count Budget Budget amount in USD or tokens, or \"No budget\" Cost Spent amount in USD or tokens, or \"No cost\""},{"location":"frontend/epics-ui/#description","title":"Description","text":"<p>If the epic has a description, it is displayed in a card with preformatted whitespace.</p>"},{"location":"frontend/epics-ui/#result-summary","title":"Result Summary","text":"<p>For completed or failed epics:</p> <ul> <li>Completed epics show a \"Result Summary\" card</li> <li>Failed epics show the same content in a red-bordered \"Error\" card</li> </ul>"},{"location":"frontend/epics-ui/#tasks-table","title":"Tasks Table","text":"<p>The main section lists the epic's tasks in a paginated table:</p> Column Description Expand Chevron icon for rows with details Checkbox Selection for batch delete Title Task title Status Color-coded status badge Workflow The workflow slug used to execute the task (or \"--\") Duration Execution time in seconds (or \"--\") Created Creation timestamp"},{"location":"frontend/epics-ui/#task-status-colors","title":"Task Status Colors","text":"Status Color <code>pending</code> Yellow <code>blocked</code> Orange <code>running</code> Blue <code>completed</code> Green <code>failed</code> Red <code>cancelled</code> Gray"},{"location":"frontend/epics-ui/#expandable-task-details","title":"Expandable Task Details","text":"<p>Tasks with additional information (description, dependencies, result, or error) show a clickable chevron. Expanding a task row reveals:</p> <ul> <li>Description -- The task description text</li> <li>Dependencies -- List of task IDs this task depends on (monospace)</li> <li>Result -- The task result summary</li> <li>Error -- Error message in red (for failed tasks)</li> </ul>"},{"location":"frontend/epics-ui/#task-batch-delete","title":"Task Batch Delete","text":"<p>Select multiple tasks and click the Delete (N) button in the table header to remove them.</p>"},{"location":"frontend/epics-ui/#pagination","title":"Pagination","text":"<p>Tasks are paginated with 50 items per page, with independent pagination controls.</p>"},{"location":"frontend/executions-ui/","title":"Executions","text":""},{"location":"frontend/executions-ui/#executions","title":"Executions","text":"<p>The Executions pages let you monitor, inspect, and manage workflow runs. The list page shows all executions across all workflows, and the detail page provides per-node logs with expandable output.</p>"},{"location":"frontend/executions-ui/#execution-list","title":"Execution List","text":"<p>Accessible at <code>/executions</code>, this page displays a paginated table of all workflow executions.</p>"},{"location":"frontend/executions-ui/#table-columns","title":"Table Columns","text":"Column Description Checkbox Row selection for batch operations Execution ID Truncated UUID (first 8 characters), clickable to open detail Workflow The workflow slug that was executed Status Color-coded badge Started Timestamp when execution began Completed Timestamp when execution finished"},{"location":"frontend/executions-ui/#status-badges","title":"Status Badges","text":"<p>Each execution status has a distinct color:</p> Status Color <code>pending</code> Yellow <code>running</code> Blue <code>completed</code> Green <code>failed</code> Red <code>cancelled</code> Gray <code>interrupted</code> Orange"},{"location":"frontend/executions-ui/#status-filter","title":"Status Filter","text":"<p>A dropdown in the top-right corner lets you filter executions by status. Options include: All, Pending, Running, Interrupted, Completed, Failed, Cancelled. Changing the filter resets to page 1.</p>"},{"location":"frontend/executions-ui/#batch-delete","title":"Batch Delete","text":"<p>Select multiple executions using checkboxes and click Delete Selected (N) to remove them. The header checkbox toggles all rows on the current page.</p>"},{"location":"frontend/executions-ui/#pagination","title":"Pagination","text":"<p>Executions are paginated with 50 items per page. Navigation controls appear at the bottom of the table.</p>"},{"location":"frontend/executions-ui/#navigation","title":"Navigation","text":"<p>Click any execution row to navigate to the execution detail page.</p>"},{"location":"frontend/executions-ui/#execution-detail","title":"Execution Detail","text":"<p>Accessible at <code>/executions/:id</code>, this page provides full details for a single execution. It subscribes to the <code>execution:&lt;id&gt;</code> WebSocket channel for real-time status updates.</p>"},{"location":"frontend/executions-ui/#summary-cards","title":"Summary Cards","text":"<p>Four summary cards across the top show:</p> Card Content Workflow The workflow slug Status Current execution status badge Started Start timestamp with seconds precision Completed Completion timestamp with seconds precision"},{"location":"frontend/executions-ui/#cancel-button","title":"Cancel Button","text":"<p>When the execution is in a cancellable state (<code>pending</code>, <code>running</code>, or <code>interrupted</code>), a Cancel Execution button appears in the top-right corner.</p>"},{"location":"frontend/executions-ui/#error-display","title":"Error Display","text":"<p>If the execution has an error message, a red-bordered card displays the error text in a preformatted block.</p>"},{"location":"frontend/executions-ui/#trigger-payload","title":"Trigger Payload","text":"<p>If the execution was initiated with a trigger payload, a card displays the full JSON payload in a scrollable preformatted block (max height 192px).</p>"},{"location":"frontend/executions-ui/#final-output","title":"Final Output","text":"<p>If the execution produced a final output, a card displays the JSON output in the same scrollable format.</p>"},{"location":"frontend/executions-ui/#node-execution-logs","title":"Node Execution Logs","text":"<p>The main section of the detail page is a log table showing per-node execution results:</p> Column Description Expand Chevron icon for rows with output Node The node ID (monospace) Status Status badge (outline variant) Duration Execution time in milliseconds Timestamp When the node executed"},{"location":"frontend/executions-ui/#expandable-output","title":"Expandable Output","text":"<p>Log rows that have an <code>output</code> field display a clickable chevron toggle. Clicking it expands the row to reveal the full output below:</p> <ul> <li>String output is shown as-is in a preformatted block</li> <li>Object output is pretty-printed as JSON</li> </ul> <p>The expanded output area has a maximum height of 192px and scrolls for large outputs.</p> <p>Inspecting node outputs</p> <p>Use the expandable log rows to debug data flow between nodes. Each node's output shows exactly what was passed to downstream nodes via Jinja2 expression resolution.</p>"},{"location":"frontend/memories-ui/","title":"Memories","text":""},{"location":"frontend/memories-ui/#memories","title":"Memories","text":"<p>The Memories page at <code>/memories</code> provides a tabbed interface for viewing and managing the platform's memory system. Agent memory is organized into five categories, each accessible via a dedicated tab.</p>"},{"location":"frontend/memories-ui/#tab-overview","title":"Tab Overview","text":"Tab Description Facts Key-value knowledge entries with scope, type, and confidence Episodes Records of agent interactions including trigger, success status, and duration Checkpoints LangGraph conversation checkpoints for agents with conversation memory enabled Procedures Learned procedures (workflows of actions) that agents can reuse Users Identified users from conversations, with cross-channel identity linking <p>Each tab displays its own paginated table with selection checkboxes and batch delete support.</p>"},{"location":"frontend/memories-ui/#facts-tab","title":"Facts Tab","text":"<p>Facts are discrete knowledge entries stored as key-value pairs. The table columns:</p> Column Description Checkbox Selection for batch delete Key The fact identifier (max 200px, truncated) Value The fact content (max 200px, truncated) Scope Badge showing the fact's scope (e.g., global, workflow, user) Type Badge showing the fact type Confidence Confidence percentage (0-100%) Accessed Number of times the fact has been read Updated Last modification timestamp"},{"location":"frontend/memories-ui/#episodes-tab","title":"Episodes Tab","text":"<p>Episodes record individual agent interactions -- one episode per trigger event handled. The table columns:</p> Column Description Checkbox Selection for batch delete Agent The agent node ID that handled the episode Trigger Badge showing the trigger type (chat, telegram, etc.) Success Green \"Yes\" or red \"No\" badge Summary Truncated episode summary (max 300px) Started When the episode began Duration Execution time in seconds"},{"location":"frontend/memories-ui/#checkpoints-tab","title":"Checkpoints Tab","text":"<p>Checkpoints are LangGraph state snapshots used for conversation memory persistence. This tab includes a thread filter dropdown that shows distinct thread IDs from the current page.</p> Column Description Checkbox Selection for batch delete Thread ID The conversation thread identifier (monospace) Checkpoint ID Truncated checkpoint UUID Parent Truncated parent checkpoint UUID or \"--\" Step The step number in the conversation Source Badge showing the checkpoint source Blob Size Size of the serialized state (B, KB, or MB) <p>Thread IDs</p> <p>Thread IDs are constructed from the user profile ID, Telegram chat ID, and workflow ID. This ensures the same user talking to the same workflow gets continuous conversation history across executions.</p>"},{"location":"frontend/memories-ui/#procedures-tab","title":"Procedures Tab","text":"<p>Procedures are learned action sequences that agents can discover and reuse. The table columns:</p> Column Description Checkbox Selection for batch delete Name The procedure name Agent The agent that created the procedure Type Badge showing the procedure type Used Number of times the procedure has been invoked Success Rate Percentage of successful invocations Active Green \"Yes\" or gray \"No\" badge indicating if the procedure is available for use"},{"location":"frontend/memories-ui/#users-tab","title":"Users Tab","text":"<p>The Users tab shows identified users from conversations. Users can be linked across channels (e.g., a Telegram user matched to a chat user).</p> Column Description Checkbox Selection for batch delete Name Display name (or \"--\" if unknown) Canonical ID Unique user identifier (monospace) Telegram Telegram user ID (or \"--\") Email Email address (or \"--\") Conversations Total number of conversations Last Seen Most recent interaction timestamp"},{"location":"frontend/memories-ui/#batch-delete","title":"Batch Delete","text":"<p>Every tab supports batch deletion:</p> <ol> <li>Select entries using individual checkboxes or the header checkbox (toggles all on current page)</li> <li>Click the Delete Selected (N) button that appears above the table</li> <li>Confirm in the dialog</li> </ol> <p>Memory deletion is permanent</p> <p>Deleted memory entries cannot be recovered. Facts, episodes, and procedures that agents rely on will no longer be available after deletion.</p>"},{"location":"frontend/memories-ui/#pagination","title":"Pagination","text":"<p>Each tab maintains its own independent pagination state with 50 items per page. Switching tabs preserves the page position within each tab.</p>"},{"location":"frontend/settings-ui/","title":"Settings","text":""},{"location":"frontend/settings-ui/#settings","title":"Settings","text":"<p>The Settings page at <code>/settings</code> provides user-level configuration options. Access it from the user menu in the bottom-left corner of the sidebar.</p>"},{"location":"frontend/settings-ui/#appearance","title":"Appearance","text":"<p>The appearance card provides a theme selector with three options:</p> Option Behavior System Follows your operating system's light/dark mode preference. Automatically switches when the OS preference changes. Light Forces light mode regardless of OS preference. Dark Forces dark mode regardless of OS preference. <p>The selected theme is displayed as toggle buttons -- the active option is highlighted with the primary color.</p>"},{"location":"frontend/settings-ui/#persistence","title":"Persistence","text":"<p>The theme preference is saved to <code>localStorage</code> under the key <code>theme</code>. It persists across browser sessions and is applied immediately on page load (before React renders) to prevent a flash of the wrong theme.</p>"},{"location":"frontend/settings-ui/#how-it-works","title":"How It Works","text":"<p>The <code>useTheme</code> hook:</p> <ol> <li>Reads the saved preference from <code>localStorage</code> on mount (defaults to <code>system</code>)</li> <li>Resolves the effective theme (<code>system</code> queries <code>prefers-color-scheme</code> media query)</li> <li>Toggles the <code>dark</code> class on <code>document.documentElement</code></li> <li>When set to <code>system</code>, listens for OS preference changes and updates automatically</li> </ol> <p>The resolved theme is also passed to the React Flow canvas so the workflow editor matches the application theme.</p>"},{"location":"frontend/settings-ui/#two-factor-authentication-mfa","title":"Two-Factor Authentication (MFA)","text":"<p>The MFA card lets you enable or disable TOTP-based two-factor authentication.</p>"},{"location":"frontend/settings-ui/#current-status","title":"Current Status","text":"<p>A badge in the card header shows whether MFA is currently Enabled or Disabled. The status is fetched from the server on page load.</p>"},{"location":"frontend/settings-ui/#enabling-mfa","title":"Enabling MFA","text":"<ol> <li>Click Enable MFA</li> <li>A dialog appears with a QR code generated from a provisioning URI</li> <li>Scan the QR code with your authenticator app (Google Authenticator, Authy, 1Password, etc.)</li> <li>If you cannot scan, a manual entry key is provided below the QR code</li> <li>Enter the 6-digit verification code from your authenticator app</li> <li>Click Verify &amp; Enable</li> </ol> <p>Save your recovery codes</p> <p>Store the manual entry key in a secure location. If you lose access to your authenticator app, you will need this key to regain access.</p>"},{"location":"frontend/settings-ui/#disabling-mfa","title":"Disabling MFA","text":"<ol> <li>Click Disable MFA</li> <li>A dialog asks you to confirm by entering your current TOTP code</li> <li>Enter the 6-digit code and click Disable MFA</li> </ol> <p>Security consideration</p> <p>Disabling MFA removes the second authentication factor. Only disable it if you have a good reason and understand the security implications.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#getting-started","title":"Getting Started","text":"<p>Welcome to Pipelit! This section will guide you through installing, configuring, and running the platform for the first time.</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, make sure you have:</p> <ul> <li>Python 3.10+ \u2014 Backend runtime</li> <li>Redis 8.0+ \u2014 Task queue, pub/sub, and search (includes RediSearch natively)</li> <li>Node.js 18+ \u2014 Frontend build toolchain</li> </ul>"},{"location":"getting-started/#steps","title":"Steps","text":""},{"location":"getting-started/#1-installation","title":"1. Installation","text":"<p>Clone the repository, set up a Python virtual environment, and install backend and frontend dependencies.</p>"},{"location":"getting-started/#2-configuration","title":"2. Configuration","text":"<p>Generate an encryption key, configure Redis, and set up your <code>.env</code> file.</p>"},{"location":"getting-started/#3-first-run","title":"3. First Run","text":"<p>Start the backend, RQ worker, and frontend dev server. Create your admin account through the setup wizard.</p>"},{"location":"getting-started/#4-quickstart-tutorial","title":"4. Quickstart Tutorial","text":"<p>Build your first workflow end-to-end \u2014 a chat agent that can answer questions using tools.</p>"},{"location":"getting-started/configuration/","title":"Configuration","text":""},{"location":"getting-started/configuration/#configuration","title":"Configuration","text":"<p>Pipelit uses a <code>.env</code> file in the project root for configuration. The backend loads it via Pydantic Settings.</p>"},{"location":"getting-started/configuration/#generate-encryption-key","title":"Generate Encryption Key","text":"<p>Pipelit encrypts sensitive credential data (API keys, tokens) at rest using Fernet symmetric encryption. You must generate a key before first use:</p> <pre><code>python -c 'from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())'\n</code></pre> <p>Copy the output \u2014 you'll need it for your <code>.env</code> file.</p>"},{"location":"getting-started/configuration/#create-env-file","title":"Create <code>.env</code> File","text":"<p>Create a <code>.env</code> file in the project root (not inside <code>platform/</code>):</p> <pre><code>FIELD_ENCRYPTION_KEY=your-generated-fernet-key-here\nREDIS_URL=redis://localhost:6379/0\n</code></pre>"},{"location":"getting-started/configuration/#environment-variables","title":"Environment Variables","text":"Variable Default Description <code>FIELD_ENCRYPTION_KEY</code> (required) Fernet key for encrypting credential secrets <code>REDIS_URL</code> <code>redis://localhost:6379/0</code> Redis connection URL for RQ and pub/sub <code>DATABASE_URL</code> <code>sqlite:///platform/db.sqlite3</code> SQLAlchemy database URL <code>SECRET_KEY</code> <code>change-me-in-production</code> Key for token signing <code>DEBUG</code> <code>false</code> Enable debug mode <code>ALLOWED_HOSTS</code> <code>localhost</code> Comma-separated allowed hosts <code>CORS_ALLOW_ALL_ORIGINS</code> <code>true</code> Allow all CORS origins (disable in production) <code>ZOMBIE_EXECUTION_THRESHOLD_SECONDS</code> <code>900</code> Seconds before a running execution is considered stuck (15 min) <p>Production Configuration</p> <p>For production deployments, see the Environment Variables reference for the full list of settings and recommended values.</p>"},{"location":"getting-started/configuration/#database","title":"Database","text":"<p>By default, Pipelit uses SQLite for development. The database file is created automatically at <code>platform/db.sqlite3</code> on first startup. For production, consider PostgreSQL.</p>"},{"location":"getting-started/configuration/#next-step","title":"Next Step","text":"<p>Continue to First Run to start the services.</p>"},{"location":"getting-started/first-run/","title":"First Run","text":""},{"location":"getting-started/first-run/#first-run","title":"First Run","text":"<p>With dependencies installed and your <code>.env</code> configured, you're ready to start Pipelit.</p>"},{"location":"getting-started/first-run/#start-redis","title":"Start Redis","text":"<p>Ensure Redis 8.0+ is running:</p> <pre><code># If installed via package manager\nsudo systemctl start redis\n\n# Or via Docker\ndocker run -d --name redis -p 6379:6379 redis:8\n</code></pre> <p>Verify: <code>redis-cli ping</code> should return <code>PONG</code>.</p>"},{"location":"getting-started/first-run/#start-the-backend","title":"Start the Backend","text":"<p>Open a terminal and start the FastAPI server:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\nuvicorn main:app --host 0.0.0.0 --port 8000 --reload\n</code></pre> <p>The backend auto-creates the SQLite database and runs Alembic migrations on first startup.</p>"},{"location":"getting-started/first-run/#start-the-rq-worker","title":"Start the RQ Worker","text":"<p>Open a second terminal for the background task worker:</p> <pre><code>cd platform\nsource ../.venv/bin/activate\nrq worker workflows --with-scheduler\n</code></pre> <p>The RQ worker executes workflow runs and scheduled jobs. The <code>--with-scheduler</code> flag enables the built-in scheduler for delayed/recurring tasks.</p>"},{"location":"getting-started/first-run/#start-the-frontend-development","title":"Start the Frontend (Development)","text":"<p>Open a third terminal for the Vite dev server:</p> <pre><code>cd platform/frontend\nnpm run dev\n</code></pre> <p>The dev server runs at <code>http://localhost:5173</code> and proxies <code>/api</code> requests to the FastAPI backend at port 8000.</p> <p>Production Mode</p> <p>For production, build the frontend once with <code>npm run build</code> and access everything through the FastAPI server at <code>http://localhost:8000</code>. No separate frontend server needed.</p>"},{"location":"getting-started/first-run/#setup-wizard","title":"Setup Wizard","text":"<p>Open <code>http://localhost:5173</code> in your browser. On first visit, the setup wizard will prompt you to create your admin account:</p> <ol> <li>Choose a username</li> <li>Set a password</li> <li>Click Create Account</li> </ol> <p>This creates the first user with full admin privileges and generates an API key for authentication.</p>"},{"location":"getting-started/first-run/#verify-everything-works","title":"Verify Everything Works","text":"<p>After logging in, you should see the workflow dashboard. Verify the backend is healthy:</p> <pre><code># Check API is responding\ncurl -s http://localhost:8000/api/v1/auth/setup-status/ | python -m json.tool\n\n# Check Redis connection\nredis-cli ping\n</code></pre>"},{"location":"getting-started/first-run/#next-step","title":"Next Step","text":"<p>Continue to the Quickstart Tutorial to build your first workflow.</p>"},{"location":"getting-started/installation/","title":"Installation","text":""},{"location":"getting-started/installation/#installation","title":"Installation","text":""},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"Requirement Minimum Version Purpose Python 3.10+ Backend runtime Redis 8.0+ Task queue, pub/sub, search Node.js 18+ Frontend build <p>Redis 8.0+ Required</p> <p>Pipelit requires Redis 8.0+ which includes RediSearch natively. Older versions will fail with <code>unknown command 'FT._LIST'</code>. See the Redis setup guide for installation instructions.</p>"},{"location":"getting-started/installation/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone git@github.com:theuselessai/Pipelit.git\ncd Pipelit\n</code></pre>"},{"location":"getting-started/installation/#backend-setup","title":"Backend Setup","text":"<p>Create a Python virtual environment and install dependencies:</p> <pre><code>python3 -m venv .venv\nsource .venv/bin/activate\npip install -r platform/requirements.txt\n</code></pre> <p>The backend dependencies include FastAPI, SQLAlchemy, LangGraph, LangChain, and all required libraries.</p>"},{"location":"getting-started/installation/#frontend-setup","title":"Frontend Setup","text":"<p>Install Node.js dependencies:</p> <pre><code>cd platform/frontend\nnpm install\n</code></pre> <p>This installs React, Vite, Shadcn/ui, React Flow, TanStack Query, and other frontend libraries.</p>"},{"location":"getting-started/installation/#verify-installation","title":"Verify Installation","text":"<p>Check that the key commands are available:</p> <pre><code># Python packages\npython -c \"import fastapi; print(f'FastAPI {fastapi.__version__}')\"\npython -c \"import sqlalchemy; print(f'SQLAlchemy {sqlalchemy.__version__}')\"\n\n# Redis\nredis-cli ping  # Should return PONG\n\n# Node\nnode --version   # Should be 18+\n</code></pre>"},{"location":"getting-started/installation/#next-step","title":"Next Step","text":"<p>Continue to Configuration to set up your environment variables.</p>"},{"location":"getting-started/quickstart-tutorial/","title":"Quickstart Tutorial","text":""},{"location":"getting-started/quickstart-tutorial/#quickstart-tutorial","title":"Quickstart Tutorial","text":"<p>Build your first workflow \u2014 a chat agent that can answer questions using the calculator and datetime tools.</p>"},{"location":"getting-started/quickstart-tutorial/#1-create-a-workflow","title":"1. Create a Workflow","text":"<p>From the dashboard, click New Workflow. Give it a name like \"My First Agent\" and click create. You'll be taken to the workflow editor.</p>"},{"location":"getting-started/quickstart-tutorial/#2-add-a-chat-trigger","title":"2. Add a Chat Trigger","text":"<p>The workflow editor has three panels:</p> <ul> <li>Left \u2014 Node Palette (click to add nodes)</li> <li>Center \u2014 Canvas (drag to arrange, click edges to connect)</li> <li>Right \u2014 Node Details Panel (configure selected node)</li> </ul> <p>From the Node Palette, click Chat under Triggers. A chat trigger node appears on the canvas.</p>"},{"location":"getting-started/quickstart-tutorial/#3-add-an-ai-model","title":"3. Add an AI Model","text":"<p>Click AI Model under Sub-Components. An AI model node appears. Select it and configure:</p> <ul> <li>Credential \u2014 Select an LLM provider credential (you'll need to add one first)</li> <li>Model \u2014 Choose a model (e.g., <code>gpt-4o</code>, <code>claude-sonnet-4-20250514</code>)</li> </ul>"},{"location":"getting-started/quickstart-tutorial/#4-add-an-agent","title":"4. Add an Agent","text":"<p>Click Agent under AI. An agent node appears. Select it and configure:</p> <ul> <li>System Prompt \u2014 e.g., \"You are a helpful assistant. Use your tools to answer questions accurately.\"</li> </ul>"},{"location":"getting-started/quickstart-tutorial/#5-connect-the-nodes","title":"5. Connect the Nodes","text":"<p>Draw connections between the nodes:</p> <ol> <li>Chat Trigger \u2192 Agent \u2014 Drag from the Chat Trigger's right handle to the Agent's left handle</li> <li>AI Model \u2192 Agent \u2014 Drag from the AI Model's top diamond handle to the Agent's bottom \"model\" diamond handle</li> </ol>"},{"location":"getting-started/quickstart-tutorial/#6-add-tools","title":"6. Add Tools","text":"<p>Add a Calculator and Date &amp; Time tool from the palette. Connect each to the Agent's \"tools\" diamond handle (green).</p>"},{"location":"getting-started/quickstart-tutorial/#7-test-it","title":"7. Test It","text":"<p>Click the Chat button in the bottom panel to open the chat interface. Send a message:</p> <p>\"What is 42 * 17? Also, what time is it?\"</p> <p>Watch the nodes light up in real time as the agent processes your request:</p> <ul> <li>Chat Trigger \u2192 running (blue) \u2192 success (green)</li> <li>Agent \u2192 running \u2192 calls Calculator tool \u2192 calls DateTime tool \u2192 success</li> </ul> <p>The agent's response appears in the chat panel with the calculated result and current time.</p>"},{"location":"getting-started/quickstart-tutorial/#whats-next","title":"What's Next?","text":"<ul> <li>Concepts \u2014 Understand workflows, nodes, edges, and execution</li> <li>Telegram Bot Tutorial \u2014 Connect your agent to Telegram</li> <li>Conditional Routing \u2014 Route messages to different agents based on content</li> <li>Component Reference \u2014 Explore all available node types</li> </ul>"},{"location":"tutorials/","title":"Tutorials","text":""},{"location":"tutorials/#tutorials","title":"Tutorials","text":"<p>Hands-on, step-by-step guides for building real workflows in Pipelit. Each tutorial walks you through a complete project from start to finish.</p> <p>Prerequisites</p> <p>All tutorials assume you have Pipelit installed and running, with at least one LLM credential configured. If you have not done this yet, start with the Getting Started guide.</p>"},{"location":"tutorials/#build-a-conversational-chatbot","title":"Build a Conversational Chatbot","text":"<p>Beginner</p> <p>Create a chat-based agent with conversation memory. Learn the fundamentals of triggers, agents, AI models, and the chat interface.</p> <p>You will learn: Chat triggers, agent nodes, AI model connection, system prompts, conversation memory.</p>"},{"location":"tutorials/#set-up-a-telegram-bot","title":"Set Up a Telegram Bot","text":"<p>Beginner</p> <p>Connect Pipelit to Telegram via BotFather. Build a bot that receives messages, processes them with an LLM agent, and sends replies automatically.</p> <p>You will learn: Telegram credentials, webhook setup, Telegram triggers, automatic message delivery.</p>"},{"location":"tutorials/#conditional-routing-with-switch-nodes","title":"Conditional Routing with Switch Nodes","text":"<p>Intermediate</p> <p>Route messages to different agents based on content classification. Use a categorizer to analyze input and switch nodes to direct traffic to specialized handlers.</p> <p>You will learn: Categorizer nodes, switch nodes, conditional edges, multi-branch workflows.</p>"},{"location":"tutorials/#scheduled-workflow-execution","title":"Scheduled Workflow Execution","text":"<p>Intermediate</p> <p>Run workflows on a recurring schedule without external cron. Configure intervals, retries, and monitoring for automated tasks like health checks and reports.</p> <p>You will learn: Schedule triggers, the Schedules API, interval configuration, retry and backoff, pause/resume.</p>"},{"location":"tutorials/#multi-agent-delegation","title":"Multi-Agent Delegation","text":"<p>Advanced</p> <p>Build an orchestrator agent that decomposes complex tasks into epics and individual work items, then delegates them to child workflows using spawn_and_await.</p> <p>You will learn: Epics and tasks, spawn_and_await, cost tracking, multi-workflow coordination.</p>"},{"location":"tutorials/#self-improving-agent","title":"Self-Improving Agent","text":"<p>Advanced</p> <p>Create an agent that can inspect its own configuration, modify its system prompt, and create new workflows programmatically -- all through the platform API.</p> <p>You will learn: WhoAmI, create_agent_user, platform_api tools, self-modification patterns, safety considerations.</p>"},{"location":"tutorials/#programmatic-workflow-creation-with-yaml-dsl","title":"Programmatic Workflow Creation with YAML DSL","text":"<p>Advanced</p> <p>Define entire workflows in YAML and have agents build them programmatically. Learn the DSL structure, node and edge definitions, and how agents use the workflow_create tool.</p> <p>You will learn: YAML DSL syntax, workflow_create tool, programmatic workflow construction.</p>"},{"location":"tutorials/#suggested-learning-path","title":"Suggested learning path","text":"<p>If you are new to Pipelit, work through the tutorials in order:</p> <ol> <li>Chatbot -- learn the core concepts</li> <li>Telegram Bot -- add an external channel</li> <li>Conditional Routing -- build branching logic</li> <li>Scheduled Workflows -- automate recurring tasks</li> <li>Multi-Agent -- coordinate multiple workflows</li> <li>Self-Improving Agent -- enable autonomous evolution</li> <li>YAML DSL -- programmatic workflow creation</li> </ol> <p>Each tutorial builds on concepts introduced in earlier ones.</p>"},{"location":"tutorials/chat-agent/","title":"Chat Agent","text":""},{"location":"tutorials/chat-agent/#build-a-conversational-chatbot","title":"Build a Conversational Chatbot","text":"<p>Beginner</p> <p>In this tutorial, you will build a chat agent that can hold a conversation, remember previous messages, and answer questions using tools. By the end, you will have a working chatbot accessible from the Pipelit web interface.</p> <p>Time: 10 minutes</p> <p>What you will build:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    Calc[Calculator] -.-&gt;|tool| Agent\n    DT[Date &amp; Time] -.-&gt;|tool| Agent\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style Calc fill:#10b981,color:white\n    style DT fill:#10b981,color:white</code></pre>"},{"location":"tutorials/chat-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running</li> <li>You have at least one LLM credential configured (e.g., OpenAI, Anthropic, or another provider)</li> </ul>"},{"location":"tutorials/chat-agent/#step-1-create-a-new-workflow","title":"Step 1: Create a new workflow","text":"<ol> <li>Open the Pipelit dashboard at <code>http://localhost:8000</code>.</li> <li>Click New Workflow.</li> <li>Enter a name -- for example, <code>My Chatbot</code>.</li> <li>Click Create. You are taken to the workflow editor.</li> </ol> <p>The editor has three panels:</p> <ul> <li>Left -- Node Palette (click to add nodes to the canvas)</li> <li>Center -- Canvas (arrange and connect nodes)</li> <li>Right -- Node Details Panel (configure the selected node)</li> </ul>"},{"location":"tutorials/chat-agent/#step-2-add-a-chat-trigger","title":"Step 2: Add a Chat Trigger","text":"<p>The chat trigger is the entry point for your workflow. It receives messages from the built-in web chat interface.</p> <ol> <li>In the Node Palette on the left, find the Triggers section.</li> <li>Click Chat. A chat trigger node appears on the canvas.</li> </ol> <p>The Chat Trigger has no configuration -- it simply passes the user's message text downstream.</p>"},{"location":"tutorials/chat-agent/#step-3-add-an-ai-model","title":"Step 3: Add an AI Model","text":"<p>The AI Model node defines which LLM provider and model your agent will use.</p> <ol> <li>In the Node Palette, find the Sub-Components section.</li> <li>Click AI Model. An AI Model node appears on the canvas.</li> <li>Click on the AI Model node to select it. The Node Details Panel opens on the right.</li> <li>Select your Credential from the dropdown (e.g., your OpenAI or Anthropic credential).</li> <li>Select a Model from the dropdown (e.g., <code>gpt-4o</code>, <code>claude-sonnet-4-20250514</code>).</li> </ol> <p>Which model to choose?</p> <p>For a general-purpose chatbot, models like <code>gpt-4o</code> or <code>claude-sonnet-4-20250514</code> work well. Smaller models like <code>gpt-4o-mini</code> are faster and cheaper, suitable for simple conversations.</p>"},{"location":"tutorials/chat-agent/#step-4-add-an-agent","title":"Step 4: Add an Agent","text":"<p>The Agent is the core AI node. It uses the connected model to reason about the user's message and produce a response.</p> <ol> <li>In the Node Palette, find the AI section.</li> <li>Click Agent. An agent node appears on the canvas.</li> <li>Click on the Agent node to select it.</li> <li>In the Node Details Panel, click the System Prompt field to open the editor.</li> <li>Enter a system prompt that defines your chatbot's personality and behavior.</li> </ol> <p>Here is an example system prompt:</p> <pre><code>You are a friendly and helpful assistant. You answer questions clearly and\nconcisely. When you do not know the answer, say so honestly rather than\nguessing. Use your tools when they would help provide a more accurate answer.\n</code></pre>"},{"location":"tutorials/chat-agent/#tips-for-writing-good-system-prompts","title":"Tips for writing good system prompts","text":"Guideline Example Define the persona \"You are a senior software engineer who explains concepts simply.\" Set boundaries \"Only answer questions about Python. For other topics, politely redirect.\" Specify tone \"Be concise and direct. Avoid filler phrases.\" Instruct tool use \"Use the calculator for any math. Use datetime for time-related questions.\" Handle uncertainty \"If you are unsure, say so. Do not fabricate information.\" <p>Jinja2 expressions in system prompts</p> <p>System prompts support Jinja2 template expressions like <code>{{ trigger.text }}</code>. This is useful for injecting dynamic data, but for a basic chatbot, plain text is sufficient. See Expressions for details.</p>"},{"location":"tutorials/chat-agent/#step-5-enable-conversation-memory","title":"Step 5: Enable conversation memory","text":"<p>By default, agents are stateless -- each message starts a fresh conversation. Enabling conversation memory lets the agent remember previous messages.</p> <ol> <li>With the Agent node selected, find the Conversation Memory toggle in the Node Details Panel.</li> <li>Switch it on.</li> </ol> <p>When enabled, the agent persists conversation history across messages. The thread is scoped to your user account and this workflow, so each user gets their own conversation.</p>"},{"location":"tutorials/chat-agent/#step-6-connect-the-nodes","title":"Step 6: Connect the nodes","text":"<p>Now wire the nodes together. Pipelit uses two types of connections:</p> <ul> <li>Data flow edges (solid lines) -- connect output handles (right side) to input handles (left side)</li> <li>Sub-component edges (dotted lines) -- connect diamond handles for model, tools, and memory</li> </ul>"},{"location":"tutorials/chat-agent/#connect-chat-trigger-to-agent","title":"Connect Chat Trigger to Agent","text":"<ol> <li>Hover over the right handle (circle) on the Chat Trigger node.</li> <li>Click and drag to the left handle (circle) on the Agent node.</li> <li>Release to create the connection.</li> </ol>"},{"location":"tutorials/chat-agent/#connect-ai-model-to-agent","title":"Connect AI Model to Agent","text":"<ol> <li>Hover over the top diamond handle on the AI Model node.</li> <li>Click and drag to the bottom \"model\" diamond handle (blue) on the Agent node.</li> <li>Release to create the connection.</li> </ol> <p>Your workflow should now look like this:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white</code></pre>"},{"location":"tutorials/chat-agent/#step-7-add-tools-optional","title":"Step 7: Add tools (optional)","text":"<p>Tools give your agent capabilities beyond text generation. Let's add a calculator and a datetime tool.</p> <ol> <li>In the Node Palette, find the Tools section.</li> <li>Click Calculator. A calculator tool node appears.</li> <li>Click Date &amp; Time. A datetime tool node appears.</li> <li>For each tool, drag from the tool's right handle to the Agent's \"tools\" diamond handle (green).</li> </ol> <p>Tool connection</p> <p>Tool connections use the green diamond handle at the bottom of the Agent node, not the circular handles on the sides. The diamond handles are for sub-components (model, tools, memory).</p>"},{"location":"tutorials/chat-agent/#step-8-test-your-chatbot","title":"Step 8: Test your chatbot","text":"<ol> <li>Click the Chat button in the bottom panel of the workflow editor to open the chat interface.</li> <li> <p>Type a message and press Enter:</p> <p>Hello! What is 42 multiplied by 17?</p> </li> <li> <p>Watch the nodes on the canvas as they execute:</p> <ul> <li>Chat Trigger flashes blue (running), then green (success)</li> <li>Agent flashes blue, invokes the Calculator tool (which also flashes), then turns green</li> <li>The response appears in the chat panel</li> </ul> </li> <li> <p>Try a follow-up message to test conversation memory:</p> <p>What did I just ask you about?</p> <p>The agent should remember the previous question because conversation memory is enabled.</p> </li> <li> <p>Try a datetime question:</p> <p>What is the current date and time?</p> <p>The agent should call the Date &amp; Time tool and return the current time.</p> </li> </ol>"},{"location":"tutorials/chat-agent/#what-you-built","title":"What you built","text":"<p>You now have a conversational chatbot with:</p> <ul> <li>A Chat Trigger that receives messages from the web interface</li> <li>An AI Model providing the LLM backend</li> <li>An Agent with a custom system prompt and conversation memory</li> <li>Calculator and Date &amp; Time tools for enhanced capabilities</li> </ul> <p>Nodes show real-time execution status on the canvas -- blue spinning circles while running, green checkmarks on success, and red X marks on failure. After execution, click the green \"output\" link on any node to see its full output.</p>"},{"location":"tutorials/chat-agent/#next-steps","title":"Next steps","text":"<ul> <li>Set Up a Telegram Bot -- connect your agent to Telegram</li> <li>Conditional Routing -- route different messages to different agents</li> <li>Agent reference -- full configuration details for agent nodes</li> <li>Tools reference -- explore all available tool types</li> </ul>"},{"location":"tutorials/conditional-routing/","title":"Conditional Routing","text":""},{"location":"tutorials/conditional-routing/#conditional-routing-with-switch-nodes","title":"Conditional Routing with Switch Nodes","text":"<p>Intermediate</p> <p>In this tutorial, you will build a workflow that classifies incoming messages and routes them to different specialized agents. A customer support scenario is used as the example: messages are categorized as billing, technical, or general, and each category is handled by a dedicated agent with domain-specific instructions.</p> <p>Time: 20 minutes</p> <p>What you will build:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Cat[Categorizer]\n    CatModel[AI Model&lt;br/&gt;gpt-4o-mini] -.-&gt;|llm| Cat\n    Cat --&gt; SW[Switch]\n    SW --&gt;|billing| BA[Billing Agent]\n    SW --&gt;|technical| TA[Technical Agent]\n    SW --&gt;|general| GA[General Agent]\n    BAModel[AI Model] -.-&gt;|llm| BA\n    TAModel[AI Model] -.-&gt;|llm| TA\n    GAModel[AI Model] -.-&gt;|llm| GA\n\n    style CT fill:#f97316,color:white\n    style CatModel fill:#3b82f6,color:white\n    style BAModel fill:#3b82f6,color:white\n    style TAModel fill:#3b82f6,color:white\n    style GAModel fill:#3b82f6,color:white\n    style SW fill:#3b82f6,color:white</code></pre>"},{"location":"tutorials/conditional-routing/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running</li> <li>You have an LLM credential configured</li> <li>You have completed the Chat Agent tutorial (recommended)</li> </ul>"},{"location":"tutorials/conditional-routing/#concepts","title":"Concepts","text":"<p>Before building, here is how conditional routing works in Pipelit:</p> <ol> <li>A Categorizer node uses an LLM to classify input text into one of several predefined categories.</li> <li>The Categorizer outputs a <code>_route</code> value matching the category name.</li> <li>A Switch node reads the route value from the workflow state.</li> <li>Conditional edges on the Switch node direct execution to different downstream nodes based on the route value.</li> </ol> <p>Only the branch matching the current route executes -- the other branches are skipped.</p>"},{"location":"tutorials/conditional-routing/#step-1-create-the-workflow","title":"Step 1: Create the workflow","text":"<ol> <li>On the Dashboard, click New Workflow.</li> <li>Name it <code>Support Router</code> and click Create.</li> </ol>"},{"location":"tutorials/conditional-routing/#step-2-add-a-chat-trigger","title":"Step 2: Add a Chat Trigger","text":"<ol> <li>From the Node Palette under Triggers, click Chat.</li> <li>A Chat Trigger node appears on the canvas.</li> </ol>"},{"location":"tutorials/conditional-routing/#step-3-add-a-categorizer","title":"Step 3: Add a Categorizer","text":"<p>The Categorizer uses an LLM to classify the incoming message into one of your defined categories.</p> <ol> <li>From the Node Palette under AI, click Categorizer.</li> <li>Click on the Categorizer node to select it.</li> <li> <p>In the Node Details Panel, configure the categories in Extra Config:</p> <pre><code>{\n  \"categories\": [\n    {\n      \"name\": \"billing\",\n      \"description\": \"Questions about invoices, payments, refunds, pricing, or subscription plans\"\n    },\n    {\n      \"name\": \"technical\",\n      \"description\": \"Bug reports, errors, feature requests, integration help, or API questions\"\n    },\n    {\n      \"name\": \"general\",\n      \"description\": \"Greetings, general inquiries, feedback, or anything that does not fit the other categories\"\n    }\n  ]\n}\n</code></pre> </li> <li> <p>Optionally, add a System Prompt to provide classification guidance:</p> <pre><code>You are classifying customer support messages for a SaaS platform.\nBe precise -- questions about feature limits should go to \"technical\",\nnot \"billing\". When in doubt, choose \"general\".\n</code></pre> </li> </ol>"},{"location":"tutorials/conditional-routing/#connect-an-ai-model-to-the-categorizer","title":"Connect an AI Model to the Categorizer","text":"<ol> <li>Add an AI Model node from the Node Palette.</li> <li>Configure it with your credential and a model. A smaller, cheaper model like <code>gpt-4o-mini</code> works well for classification since the task is straightforward.</li> <li>Connect the AI Model's top diamond handle to the Categorizer's \"model\" diamond handle (blue).</li> </ol> <p>Use a cheaper model for classification</p> <p>The Categorizer makes a single LLM call to classify input. A smaller model reduces cost and latency without sacrificing classification quality for well-defined categories.</p>"},{"location":"tutorials/conditional-routing/#step-4-add-a-switch-node","title":"Step 4: Add a Switch node","text":"<p>The Switch node reads the route value set by the Categorizer and directs execution down the matching conditional edge.</p> <ol> <li>From the Node Palette under Routing (or Logic), click Switch.</li> <li>A Switch node appears on the canvas.</li> </ol> <p>The Switch node does not require configuration for this use case -- it reads the <code>_route</code> value from the workflow state, which the Categorizer sets automatically.</p>"},{"location":"tutorials/conditional-routing/#step-5-add-specialized-agents","title":"Step 5: Add specialized agents","text":"<p>Create three agent nodes, one for each category.</p>"},{"location":"tutorials/conditional-routing/#billing-agent","title":"Billing Agent","text":"<ol> <li>Add an Agent from the Node Palette.</li> <li> <p>Set its System Prompt:</p> <pre><code>You are a billing support specialist. Help customers with:\n- Invoice questions and payment issues\n- Subscription plan details and upgrades\n- Refund requests and billing disputes\n- Pricing clarification\n\nBe empathetic and solution-oriented. If the issue requires account\naccess you do not have, escalate to a human agent.\n</code></pre> </li> <li> <p>Add an AI Model node and connect it to this agent's model handle.</p> </li> </ol>"},{"location":"tutorials/conditional-routing/#technical-agent","title":"Technical Agent","text":"<ol> <li>Add another Agent.</li> <li> <p>Set its System Prompt:</p> <pre><code>You are a technical support engineer. Help customers with:\n- Bug reports and error troubleshooting\n- API integration questions\n- Feature requests (acknowledge and log them)\n- Configuration and setup assistance\n\nAsk clarifying questions when the issue is ambiguous. Include\nspecific steps in your solutions.\n</code></pre> </li> <li> <p>Add an AI Model node and connect it.</p> </li> </ol>"},{"location":"tutorials/conditional-routing/#general-agent","title":"General Agent","text":"<ol> <li>Add a third Agent.</li> <li> <p>Set its System Prompt:</p> <pre><code>You are a friendly general support agent. Handle:\n- Greetings and casual conversation\n- General product inquiries\n- Feedback and suggestions\n- Anything that does not fit billing or technical categories\n\nBe warm and helpful. Redirect to specialized support if the\nconversation turns technical or billing-related.\n</code></pre> </li> <li> <p>Add an AI Model node and connect it.</p> </li> </ol> <p>Sharing AI Model nodes</p> <p>Each agent needs its own AI Model connection. You can use the same credential and model across all of them, but each requires a separate AI Model node on the canvas.</p>"},{"location":"tutorials/conditional-routing/#step-6-connect-the-nodes","title":"Step 6: Connect the nodes","text":""},{"location":"tutorials/conditional-routing/#data-flow-connections","title":"Data flow connections","text":"<ol> <li>Chat Trigger -&gt; Categorizer: Right handle to left handle.</li> <li>Categorizer -&gt; Switch: Right handle to left handle.</li> </ol>"},{"location":"tutorials/conditional-routing/#conditional-edges-from-the-switch","title":"Conditional edges from the Switch","text":"<p>Conditional edges are created differently from regular edges. Each conditional edge carries a <code>condition_value</code> that must match the route.</p> <ol> <li>Switch -&gt; Billing Agent: Drag from the Switch's right handle to the Billing Agent's left handle. When the edge creation dialog appears, set the condition value to <code>billing</code>.</li> <li>Switch -&gt; Technical Agent: Same process, with condition value <code>technical</code>.</li> <li>Switch -&gt; General Agent: Same process, with condition value <code>general</code>.</li> </ol> <p>Conditional edge labels</p> <p>On the canvas, conditional edges display their condition value as a label on the edge (e.g., \"billing\", \"technical\", \"general\"). This makes it easy to see the routing logic at a glance.</p>"},{"location":"tutorials/conditional-routing/#the-complete-workflow","title":"The complete workflow","text":"<pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Cat[Categorizer]\n    CM[AI Model] -.-&gt;|llm| Cat\n    Cat --&gt; SW[Switch]\n    SW --&gt;|billing| BA[Billing Agent]\n    SW --&gt;|technical| TA[Technical Agent]\n    SW --&gt;|general| GA[General Agent]\n    BM[AI Model] -.-&gt;|llm| BA\n    TM[AI Model] -.-&gt;|llm| TA\n    GM[AI Model] -.-&gt;|llm| GA\n\n    style CT fill:#f97316,color:white\n    style CM fill:#3b82f6,color:white\n    style BM fill:#3b82f6,color:white\n    style TM fill:#3b82f6,color:white\n    style GM fill:#3b82f6,color:white\n    style SW fill:#3b82f6,color:white</code></pre>"},{"location":"tutorials/conditional-routing/#step-7-validate-and-test","title":"Step 7: Validate and test","text":""},{"location":"tutorials/conditional-routing/#validate-the-workflow","title":"Validate the workflow","text":"<p>Before testing, validate the workflow to catch any configuration errors:</p> <ol> <li>Click the Validate button (or use <code>POST /api/v1/workflows/{slug}/validate/</code>).</li> <li>Fix any reported issues (e.g., missing model connections, unconnected nodes).</li> </ol>"},{"location":"tutorials/conditional-routing/#test-with-different-messages","title":"Test with different messages","text":"<p>Open the Chat panel and try messages that should route to each category:</p> <p>Billing message:</p> <p>I was charged twice on my last invoice. Can you help me get a refund?</p> <p>Expected: Categorizer outputs <code>billing</code> -&gt; Switch routes to Billing Agent.</p> <p>Technical message:</p> <p>I am getting a 500 error when I try to use the API endpoint for user creation.</p> <p>Expected: Categorizer outputs <code>technical</code> -&gt; Switch routes to Technical Agent.</p> <p>General message:</p> <p>Hi there! I just wanted to say I love your product.</p> <p>Expected: Categorizer outputs <code>general</code> -&gt; Switch routes to General Agent.</p>"},{"location":"tutorials/conditional-routing/#observe-execution-on-the-canvas","title":"Observe execution on the canvas","text":"<p>As each message is processed:</p> <ol> <li>The Chat Trigger lights up (running -&gt; success).</li> <li>The Categorizer lights up and makes an LLM call to classify the message.</li> <li>The Switch node lights up and evaluates the route.</li> <li>Only the matching downstream agent lights up -- the other two stay idle.</li> </ol> <p>Click the green \"output\" link on the Categorizer node after execution to see the classification result:</p> <pre><code>{\n  \"category\": \"technical\",\n  \"raw\": \"{\\\"category\\\": \\\"technical\\\"}\"\n}\n</code></pre>"},{"location":"tutorials/conditional-routing/#variations","title":"Variations","text":""},{"location":"tutorials/conditional-routing/#using-a-switch-node-with-custom-rules","title":"Using a Switch node with custom rules","text":"<p>Instead of using a Categorizer (which requires an LLM call), you can configure the Switch node with pattern-matching rules for simpler routing:</p> <pre><code>{\n  \"rules\": [\n    {\"field\": \"text\", \"operator\": \"contains\", \"value\": \"invoice\", \"route\": \"billing\"},\n    {\"field\": \"text\", \"operator\": \"contains\", \"value\": \"refund\", \"route\": \"billing\"},\n    {\"field\": \"text\", \"operator\": \"contains\", \"value\": \"error\", \"route\": \"technical\"},\n    {\"field\": \"text\", \"operator\": \"contains\", \"value\": \"bug\", \"route\": \"technical\"}\n  ],\n  \"default_route\": \"general\"\n}\n</code></pre> <p>This approach is faster and cheaper (no LLM call) but less flexible than LLM-based classification.</p>"},{"location":"tutorials/conditional-routing/#adding-a-defaultfallback-route","title":"Adding a default/fallback route","text":"<p>If the Categorizer returns a category that does not match any conditional edge, the Switch node falls back to a <code>default</code> route. Add a conditional edge with condition value <code>default</code> to handle unrecognized categories:</p> <pre><code>flowchart LR\n    SW[Switch] --&gt;|billing| BA[Billing Agent]\n    SW --&gt;|technical| TA[Technical Agent]\n    SW --&gt;|default| FA[Fallback Agent]</code></pre>"},{"location":"tutorials/conditional-routing/#combining-with-conversation-memory","title":"Combining with conversation memory","text":"<p>Enable Conversation Memory on each specialized agent so they maintain context within their domain. A user who starts with a billing question and follows up with more details will get a continuous conversation thread with the Billing Agent.</p>"},{"location":"tutorials/conditional-routing/#next-steps","title":"Next steps","text":"<ul> <li>Scheduled Workflows -- automate recurring tasks</li> <li>Multi-Agent Delegation -- coordinate agents across workflows</li> <li>Categorizer reference -- full configuration details</li> <li>Expressions -- use upstream outputs in system prompts</li> </ul>"},{"location":"tutorials/multi-agent/","title":"Multi-Agent","text":""},{"location":"tutorials/multi-agent/#multi-agent-delegation","title":"Multi-Agent Delegation","text":"<p>Advanced</p> <p>In this tutorial, you will build a multi-agent system where a main orchestrator agent decomposes complex tasks into epics and individual work items, then delegates them to child workflows using <code>spawn_and_await</code>. The orchestrator tracks progress, costs, and results across all child executions.</p> <p>Time: 30 minutes</p> <p>What you will build:</p> <ul> <li>A main orchestrator workflow with epic/task management and child workflow spawning</li> <li>One or more child worker workflows that perform specific tasks</li> <li>A delegation flow where the orchestrator plans, delegates, and synthesizes results</li> </ul> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Orch[Orchestrator Agent]\n    AM[AI Model] -.-&gt;|llm| Orch\n    ET[Epic Tools] -.-&gt;|tool| Orch\n    TT[Task Tools] -.-&gt;|tool| Orch\n    SA[Spawn &amp; Await] -.-&gt;|tool| Orch\n\n    Orch --&gt;|spawns| CW1[\"Child Workflow: Research\"]\n    Orch --&gt;|spawns| CW2[\"Child Workflow: Code\"]\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style ET fill:#10b981,color:white\n    style TT fill:#10b981,color:white\n    style SA fill:#10b981,color:white</code></pre>"},{"location":"tutorials/multi-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running with Redis and an RQ worker active (required for spawn_and_await)</li> <li>You have an LLM credential configured</li> <li>You have completed the Chat Agent tutorial</li> <li>Familiarity with Epics &amp; Tasks concepts is recommended</li> </ul>"},{"location":"tutorials/multi-agent/#concepts","title":"Concepts","text":"<p>Multi-agent delegation in Pipelit follows this pattern:</p> <ol> <li>An orchestrator agent receives a complex objective.</li> <li>It creates an epic to represent the objective with an optional budget.</li> <li>It decomposes the epic into tasks with dependencies between them.</li> <li>Each task is executed by spawning a child workflow via <code>spawn_and_await</code>.</li> <li>The orchestrator pauses (via LangGraph interrupt) while the child runs.</li> <li>When the child completes, the orchestrator resumes with the result.</li> <li>Costs from child executions are automatically synced to tasks and the epic.</li> </ol> <pre><code>sequenceDiagram\n    participant User\n    participant Orch as Orchestrator\n    participant Epic as Epic Tools\n    participant Task as Task Tools\n    participant Spawn as spawn_and_await\n    participant Child as Child Workflow\n\n    User-&gt;&gt;Orch: Complex request\n    Orch-&gt;&gt;Epic: create_epic(title, budget)\n    Epic--&gt;&gt;Orch: epic_id\n    Orch-&gt;&gt;Task: create_task(epic_id, \"Research\")\n    Orch-&gt;&gt;Task: create_task(epic_id, \"Implementation\")\n    Orch-&gt;&gt;Task: update_task(research_id, status: running)\n    Orch-&gt;&gt;Spawn: spawn_and_await(research-workflow, input)\n    Note over Orch: Paused (LangGraph interrupt)\n    Spawn-&gt;&gt;Child: Execute\n    Child--&gt;&gt;Spawn: Result\n    Note over Orch: Resumed\n    Spawn--&gt;&gt;Orch: Research result\n    Orch-&gt;&gt;Task: update_task(research_id, status: completed)\n    Orch-&gt;&gt;User: Synthesized result</code></pre>"},{"location":"tutorials/multi-agent/#step-1-create-child-worker-workflows","title":"Step 1: Create child worker workflows","text":"<p>Before building the orchestrator, create the workflows it will delegate to. Each child workflow is a standalone workflow with its own trigger and agent.</p>"},{"location":"tutorials/multi-agent/#research-workflow","title":"Research workflow","text":"<p>This workflow handles research tasks -- answering questions by searching the web.</p> <ol> <li>Create a new workflow named <code>Research Worker</code>.</li> <li>Add a Chat Trigger (child workflows are spawned via the chat dispatch mechanism).</li> <li> <p>Add an Agent with this system prompt:</p> <pre><code>You are a research specialist. When given a research task:\n\n1. Use web search to find relevant, current information.\n2. Cross-reference multiple sources when possible.\n3. Provide a structured summary with key findings.\n4. Include source URLs when available.\n\nBe thorough but concise. Focus on actionable information.\n</code></pre> </li> <li> <p>Add an AI Model and connect it to the agent.</p> </li> <li>Add a Web Search tool and connect it to the agent's tools handle.</li> <li>Connect: Chat Trigger -&gt; Agent.</li> </ol>"},{"location":"tutorials/multi-agent/#code-workflow","title":"Code workflow","text":"<p>This workflow handles code-related tasks.</p> <ol> <li>Create a new workflow named <code>Code Worker</code>.</li> <li>Add a Chat Trigger.</li> <li> <p>Add an Agent with this system prompt:</p> <pre><code>You are a code specialist. When given a coding task:\n\n1. Understand the requirements fully before writing code.\n2. Use the run_command tool to test your code.\n3. Handle edge cases and include error handling.\n4. Provide clear explanations alongside the code.\n\nWrite clean, well-documented code.\n</code></pre> </li> <li> <p>Add an AI Model and connect it.</p> </li> <li>Add a Run Command tool and connect it to the agent's tools handle.</li> <li>Connect: Chat Trigger -&gt; Agent.</li> </ol> <p>Child workflow naming</p> <p>Name child workflows with clear, descriptive slugs (e.g., <code>research-worker</code>, <code>code-worker</code>). The orchestrator references them by slug when calling <code>spawn_and_await</code>.</p>"},{"location":"tutorials/multi-agent/#step-2-create-the-orchestrator-workflow","title":"Step 2: Create the orchestrator workflow","text":"<ol> <li>Create a new workflow named <code>Orchestrator</code>.</li> <li>Add a Chat Trigger.</li> <li> <p>Add an Agent -- this is your orchestrator. Configure its system prompt:</p> <pre><code>You are a project orchestrator agent. When given a complex task:\n\n1. PLAN: Break the task down into subtasks. Create an epic with\n   create_epic, then create tasks with create_task.\n\n2. DELEGATE: For each task, use spawn_and_await to execute the\n   appropriate child workflow:\n   - Research tasks -&gt; workflow slug: \"research-worker\"\n   - Coding tasks -&gt; workflow slug: \"code-worker\"\n\n3. TRACK: After each child completes, update the task status with\n   update_task (status: \"completed\" or \"failed\").\n\n4. SYNTHESIZE: Once all tasks are complete, combine results into\n   a coherent final response. Update the epic status to \"completed\"\n   with a result_summary.\n\nAlways create an epic before creating tasks. Set task dependencies\nwhen one task needs the result of another (use depends_on).\n\nAvailable child workflows:\n- \"research-worker\": Web research and information gathering\n- \"code-worker\": Code writing, review, and execution\n</code></pre> </li> <li> <p>Add an AI Model and connect it to the agent.</p> </li> <li>Enable Conversation Memory so the orchestrator remembers the delegation context across spawn_and_await pauses.</li> </ol>"},{"location":"tutorials/multi-agent/#step-3-add-self-awareness-tools-to-the-orchestrator","title":"Step 3: Add self-awareness tools to the orchestrator","text":"<p>The orchestrator needs several tools to manage epics, tasks, and child workflows.</p>"},{"location":"tutorials/multi-agent/#epic-tools","title":"Epic Tools","text":"<ol> <li>From the Node Palette under Self-Awareness, add Epic Tools.</li> <li>Connect it to the orchestrator agent's tools handle (green diamond).</li> </ol> <p>Epic Tools provides four LangChain tools to the agent:</p> Tool Purpose <code>create_epic</code> Create a new epic with title, description, tags, priority, and optional budget <code>epic_status</code> Get detailed status including task breakdown and cost summary <code>update_epic</code> Update status, title, priority, budgets, or result summary <code>search_epics</code> Search epics by text, tags, or status"},{"location":"tutorials/multi-agent/#task-tools","title":"Task Tools","text":"<ol> <li>Add Task Tools from the Node Palette.</li> <li>Connect it to the agent's tools handle.</li> </ol> <p>Task Tools provides:</p> Tool Purpose <code>create_task</code> Create a task within an epic, with dependencies and estimates <code>list_tasks</code> List tasks in an epic, filter by status or tags <code>update_task</code> Update status, result summary, notes <code>cancel_task</code> Cancel a task and optionally its linked execution"},{"location":"tutorials/multi-agent/#spawn-await","title":"Spawn &amp; Await","text":"<ol> <li>Add Spawn &amp; Await from the Node Palette.</li> <li>Connect it to the agent's tools handle.</li> </ol> <p>The <code>spawn_and_await</code> tool takes three parameters:</p> Parameter Description <code>workflow_slug</code> The slug of the child workflow to execute <code>input_text</code> The message to send to the child workflow's trigger <code>task_id</code> Optional task ID to link the execution with for cost tracking <p>RQ worker required</p> <p><code>spawn_and_await</code> uses LangGraph's interrupt mechanism and RQ for async execution. Make sure your RQ worker is running, or the spawn will hang.</p>"},{"location":"tutorials/multi-agent/#step-4-connect-the-orchestrator-workflow","title":"Step 4: Connect the orchestrator workflow","text":"<ol> <li>Chat Trigger -&gt; Orchestrator Agent: Right handle to left handle.</li> <li>AI Model -&gt; Agent: Top diamond to model handle.</li> <li>Epic Tools -&gt; Agent: Right handle to tools handle (green diamond).</li> <li>Task Tools -&gt; Agent: Right handle to tools handle.</li> <li>Spawn &amp; Await -&gt; Agent: Right handle to tools handle.</li> </ol> <p>The complete orchestrator workflow:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Orch[Orchestrator Agent]\n    AM[AI Model] -.-&gt;|llm| Orch\n    ET[Epic Tools] -.-&gt;|tool| Orch\n    TT[Task Tools] -.-&gt;|tool| Orch\n    SA[Spawn &amp; Await] -.-&gt;|tool| Orch\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style ET fill:#10b981,color:white\n    style TT fill:#10b981,color:white\n    style SA fill:#10b981,color:white</code></pre>"},{"location":"tutorials/multi-agent/#step-5-test-with-a-complex-task","title":"Step 5: Test with a complex task","text":"<p>Open the Chat panel on the orchestrator workflow and send a request that requires multiple steps:</p> <p>Research the current best practices for Python error handling in web APIs, then write a FastAPI error handling middleware that implements those practices.</p>"},{"location":"tutorials/multi-agent/#expected-behavior","title":"Expected behavior","text":"<ol> <li>The orchestrator creates an epic: \"Python API Error Handling\"</li> <li>It creates two tasks:<ul> <li>Task 1: \"Research Python API error handling best practices\" (workflow: <code>research-worker</code>)</li> <li>Task 2: \"Write FastAPI error handling middleware\" (workflow: <code>code-worker</code>, depends_on: Task 1)</li> </ul> </li> <li>It spawns the research workflow with <code>spawn_and_await(\"research-worker\", \"Research current best practices for Python error handling in web APIs\", task_id)</code>.</li> <li>The orchestrator pauses while the research workflow runs.</li> <li>When the research completes, the orchestrator resumes with the research results.</li> <li>It updates Task 1 to <code>completed</code>.</li> <li>It spawns the code workflow: <code>spawn_and_await(\"code-worker\", \"Write a FastAPI error handling middleware implementing these practices: [research results]\", task_id)</code>.</li> <li>The code workflow runs and returns the implementation.</li> <li>The orchestrator synthesizes both results into a final response and updates the epic to <code>completed</code>.</li> </ol>"},{"location":"tutorials/multi-agent/#monitor-progress","title":"Monitor progress","text":"<ul> <li>Executions page: Each spawn creates a separate execution. You will see the orchestrator execution (paused/running) and child executions.</li> <li>Canvas: Watch the orchestrator's nodes light up. When paused at <code>spawn_and_await</code>, the agent node shows an interrupted status.</li> <li>Epic status: The orchestrator can call <code>epic_status</code> to check progress mid-flight.</li> </ul>"},{"location":"tutorials/multi-agent/#step-6-track-costs","title":"Step 6: Track costs","text":"<p>Cost tracking is automatic. When a child execution completes:</p> <ol> <li>Token counts and USD cost are copied from the execution to the linked task.</li> <li>The epic's <code>spent_tokens</code> and <code>spent_usd</code> are recalculated by summing all task costs.</li> <li><code>llm_calls</code> and <code>tool_invocations</code> are recorded on each task.</li> </ol>"},{"location":"tutorials/multi-agent/#setting-a-budget","title":"Setting a budget","text":"<p>When creating the epic, the orchestrator can set a budget:</p> <pre><code>create_epic(title=\"Error Handling Project\", budget_usd=0.50, budget_tokens=100000)\n</code></pre> <p>Budget enforcement is checked before every node execution. If the epic exceeds its budget, further executions in linked tasks will fail with a budget-exceeded error.</p>"},{"location":"tutorials/multi-agent/#viewing-cost-data","title":"Viewing cost data","text":"<p>Use <code>epic_status</code> to see a cost breakdown:</p> <pre><code>{\n  \"epic_id\": \"ep-abc123\",\n  \"status\": \"completed\",\n  \"total_tasks\": 2,\n  \"completed_tasks\": 2,\n  \"spent_tokens\": 15420,\n  \"spent_usd\": 0.12,\n  \"budget_usd\": 0.50\n}\n</code></pre>"},{"location":"tutorials/multi-agent/#tips-for-effective-delegation","title":"Tips for effective delegation","text":"Tip Explanation Keep child workflows focused Each child workflow should do one thing well. Avoid cramming multiple responsibilities into one worker. Use task dependencies Set <code>depends_on</code> when one task needs another's output. The orchestrator should respect this ordering. Include context in spawn input Pass relevant context from earlier tasks when spawning dependent work. The child workflow only sees what you send it. Set budgets on epics Prevents runaway costs from recursive or long-running delegations. Use tags for organization Tag epics and tasks (e.g., <code>[\"research\", \"python\"]</code>) for easy filtering and search."},{"location":"tutorials/multi-agent/#next-steps","title":"Next steps","text":"<ul> <li>Self-Improving Agent -- agents that modify their own configuration</li> <li>YAML DSL -- programmatically create child workflows</li> <li>Epics &amp; Tasks reference -- full lifecycle and field documentation</li> <li>Cost Tracking -- detailed cost tracking and budget enforcement</li> </ul>"},{"location":"tutorials/scheduled-workflow/","title":"Scheduled Workflow","text":""},{"location":"tutorials/scheduled-workflow/#scheduled-workflow-execution","title":"Scheduled Workflow Execution","text":"<p>Intermediate</p> <p>In this tutorial, you will build a workflow that runs on a recurring schedule. The example is a system health monitoring workflow that checks infrastructure status every hour, but the pattern applies to any recurring task -- daily reports, periodic data fetches, or automated maintenance.</p> <p>Time: 15 minutes</p> <p>What you will build:</p> <pre><code>flowchart LR\n    ST[Schedule Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    SH[System Health] -.-&gt;|tool| Agent\n    HR[HTTP Request] -.-&gt;|tool| Agent\n\n    style ST fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style SH fill:#10b981,color:white\n    style HR fill:#10b981,color:white</code></pre>"},{"location":"tutorials/scheduled-workflow/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running with Redis and an RQ worker active (required for scheduling)</li> <li>You have an LLM credential configured</li> <li>You are comfortable making API calls (the scheduler is currently API-only)</li> </ul>"},{"location":"tutorials/scheduled-workflow/#concepts","title":"Concepts","text":"<p>Pipelit's scheduler uses a self-rescheduling architecture built on RQ (Redis Queue):</p> <ul> <li>A Schedule Trigger is a trigger node on the canvas that fires when a scheduled job runs.</li> <li>A ScheduledJob record defines the schedule: interval, repeat count, retry policy, and status.</li> <li>After each execution, the scheduler automatically enqueues the next run.</li> <li>On failure, exponential backoff kicks in (capped at 10x the interval).</li> <li>On startup, missed jobs are recovered and re-enqueued automatically.</li> </ul> <p>There is no external cron dependency -- the scheduling is entirely self-contained within Pipelit.</p>"},{"location":"tutorials/scheduled-workflow/#step-1-create-the-workflow","title":"Step 1: Create the workflow","text":"<ol> <li>On the Dashboard, click New Workflow.</li> <li>Name it <code>Health Monitor</code> and click Create.</li> </ol>"},{"location":"tutorials/scheduled-workflow/#step-2-add-a-schedule-trigger","title":"Step 2: Add a Schedule Trigger","text":"<ol> <li>From the Node Palette under Triggers, click Schedule.</li> <li>A Schedule Trigger node appears on the canvas.</li> </ol> <p>The Schedule Trigger has no canvas-level configuration. It outputs a <code>timestamp</code> (ISO 8601) indicating when it fired.</p>"},{"location":"tutorials/scheduled-workflow/#step-3-build-the-workflow-logic","title":"Step 3: Build the workflow logic","text":""},{"location":"tutorials/scheduled-workflow/#add-an-agent","title":"Add an Agent","text":"<ol> <li>Add an Agent from the Node Palette.</li> <li> <p>Configure its System Prompt:</p> <pre><code>You are a system monitoring agent. When triggered:\n\n1. Check the platform health using the system_health tool.\n2. Make an HTTP request to any external services you need to monitor.\n3. Analyze the results and produce a concise health report.\n\nFormat your report as:\n- Overall status: OK / WARNING / CRITICAL\n- Key metrics and any anomalies\n- Recommended actions if issues are found\n\nScheduled run at: {{ trigger.timestamp }}\n</code></pre> <p>Note the use of <code>{{ trigger.timestamp }}</code> -- this Jinja2 expression injects the schedule trigger's timestamp into the prompt.</p> </li> </ol>"},{"location":"tutorials/scheduled-workflow/#add-an-ai-model","title":"Add an AI Model","text":"<ol> <li>Add an AI Model node.</li> <li>Configure it with your credential and model.</li> <li>Connect it to the Agent's model handle (blue diamond).</li> </ol>"},{"location":"tutorials/scheduled-workflow/#add-tools","title":"Add tools","text":"<ol> <li>Add a System Health tool from the Node Palette (under Self-Awareness). This tool checks Redis, RQ workers, queues, and recent execution status.</li> <li>Add an HTTP Request tool (under Tools) for monitoring external services. Optionally set the <code>method</code>, <code>headers</code>, and <code>timeout</code> in Extra Config.</li> <li>Connect both tools to the Agent's tools handle (green diamond).</li> </ol>"},{"location":"tutorials/scheduled-workflow/#connect-the-data-flow","title":"Connect the data flow","text":"<ol> <li>Schedule Trigger -&gt; Agent: Right handle to left handle.</li> </ol>"},{"location":"tutorials/scheduled-workflow/#step-4-create-a-scheduled-job-via-the-api","title":"Step 4: Create a scheduled job via the API","text":"<p>The scheduler is API-driven. You create a <code>ScheduledJob</code> that targets your workflow and the specific Schedule Trigger node.</p>"},{"location":"tutorials/scheduled-workflow/#find-the-trigger-node-id","title":"Find the trigger node ID","text":"<p>You need the exact <code>node_id</code> of your Schedule Trigger. Find it by checking the node on the canvas (the label shows the node ID) or by querying the API:</p> <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  http://localhost:8000/api/v1/workflows/health-monitor/nodes/\n</code></pre> <p>Look for the node with <code>component_type: \"trigger_schedule\"</code> and note its <code>node_id</code> (e.g., <code>trigger_schedule_abc123</code>).</p>"},{"location":"tutorials/scheduled-workflow/#also-find-the-workflow-id","title":"Also find the workflow ID","text":"<p>The Schedules API requires the numeric <code>workflow_id</code>, not the slug. Get it from:</p> <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  http://localhost:8000/api/v1/workflows/health-monitor/\n</code></pre> <p>Note the <code>id</code> field in the response.</p>"},{"location":"tutorials/scheduled-workflow/#create-the-schedule","title":"Create the schedule","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/schedules/ \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"workflow_id\": 1,\n    \"trigger_node_id\": \"trigger_schedule_abc123\",\n    \"interval_seconds\": 3600,\n    \"repeat_count\": 0,\n    \"retry_max\": 3\n  }'\n</code></pre> <p>Parameters explained:</p> Parameter Value Meaning <code>workflow_id</code> <code>1</code> The numeric ID of your workflow <code>trigger_node_id</code> <code>trigger_schedule_abc123</code> The Schedule Trigger node to fire <code>interval_seconds</code> <code>3600</code> Run every hour (3600 seconds) <code>repeat_count</code> <code>0</code> Repeat indefinitely (0 = infinite) <code>retry_max</code> <code>3</code> Retry up to 3 times on failure <p>The response includes the created job with its <code>id</code>, <code>status</code> (initially <code>active</code>), and <code>next_run_at</code>:</p> <pre><code>{\n  \"id\": 1,\n  \"workflow_id\": 1,\n  \"trigger_node_id\": \"trigger_schedule_abc123\",\n  \"interval_seconds\": 3600,\n  \"repeat_count\": 0,\n  \"retry_max\": 3,\n  \"status\": \"active\",\n  \"next_run_at\": \"2026-02-16T15:00:00Z\",\n  \"current_repeat\": 0,\n  \"current_retry\": 0\n}\n</code></pre>"},{"location":"tutorials/scheduled-workflow/#step-5-configure-retry-and-backoff","title":"Step 5: Configure retry and backoff","text":"<p>The scheduler handles failures with exponential backoff:</p> <ul> <li>First failure: Retries after <code>interval_seconds</code>.</li> <li>Second failure: Retries after <code>2 * interval_seconds</code>.</li> <li>Third failure: Retries after <code>4 * interval_seconds</code>.</li> <li>Cap: Backoff is capped at <code>10 * interval_seconds</code>.</li> </ul> <p>After exhausting <code>retry_max</code> retries, the job status changes to <code>dead</code> and stops rescheduling.</p>"},{"location":"tutorials/scheduled-workflow/#adjusting-retry-behavior","title":"Adjusting retry behavior","text":"<p>Update an existing schedule to change retry limits:</p> <pre><code>curl -X PATCH http://localhost:8000/api/v1/schedules/1/ \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"retry_max\": 5,\n    \"interval_seconds\": 1800\n  }'\n</code></pre>"},{"location":"tutorials/scheduled-workflow/#step-6-monitor-execution","title":"Step 6: Monitor execution","text":""},{"location":"tutorials/scheduled-workflow/#list-scheduled-jobs","title":"List scheduled jobs","text":"<pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  http://localhost:8000/api/v1/schedules/\n</code></pre> <p>The response shows each job's status, next run time, and current repeat/retry counts.</p>"},{"location":"tutorials/scheduled-workflow/#view-execution-history","title":"View execution history","text":"<p>Check the Executions page in the web UI or query the API:</p> <pre><code>curl -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  \"http://localhost:8000/api/v1/executions/?workflow_slug=health-monitor\"\n</code></pre> <p>Each scheduled run creates a new execution record with full logs.</p>"},{"location":"tutorials/scheduled-workflow/#pause-a-schedule","title":"Pause a schedule","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/schedules/1/pause/ \\\n  -H \"Authorization: Bearer YOUR_API_KEY\"\n</code></pre> <p>The job status changes to <code>paused</code> and no further runs are enqueued until you resume.</p>"},{"location":"tutorials/scheduled-workflow/#resume-a-schedule","title":"Resume a schedule","text":"<pre><code>curl -X POST http://localhost:8000/api/v1/schedules/1/resume/ \\\n  -H \"Authorization: Bearer YOUR_API_KEY\"\n</code></pre> <p>The scheduler calculates the next run time and enqueues the job.</p>"},{"location":"tutorials/scheduled-workflow/#delete-a-schedule","title":"Delete a schedule","text":"<pre><code>curl -X DELETE http://localhost:8000/api/v1/schedules/1/ \\\n  -H \"Authorization: Bearer YOUR_API_KEY\"\n</code></pre>"},{"location":"tutorials/scheduled-workflow/#common-scheduling-patterns","title":"Common scheduling patterns","text":""},{"location":"tutorials/scheduled-workflow/#every-5-minutes-short-interval-monitoring","title":"Every 5 minutes (short interval monitoring)","text":"<pre><code>{\n  \"interval_seconds\": 300,\n  \"repeat_count\": 0,\n  \"retry_max\": 2\n}\n</code></pre>"},{"location":"tutorials/scheduled-workflow/#daily-report-once-per-day-limited-runs","title":"Daily report (once per day, limited runs)","text":"<pre><code>{\n  \"interval_seconds\": 86400,\n  \"repeat_count\": 30,\n  \"retry_max\": 3\n}\n</code></pre> <p>This runs once a day for 30 days, then stops.</p>"},{"location":"tutorials/scheduled-workflow/#one-shot-delayed-execution","title":"One-shot delayed execution","text":"<pre><code>{\n  \"interval_seconds\": 600,\n  \"repeat_count\": 1,\n  \"retry_max\": 1\n}\n</code></pre> <p>This runs once, 10 minutes after creation, and does not repeat.</p>"},{"location":"tutorials/scheduled-workflow/#crash-recovery","title":"Crash recovery","text":"<p>If Pipelit restarts while a scheduled job is pending, the <code>recover_scheduled_jobs()</code> function runs on startup and re-enqueues any active jobs whose <code>next_run_at</code> is in the past. This means scheduled jobs survive restarts without data loss.</p> <p>Each enqueued RQ job uses a deterministic job ID (<code>sched-{id}-n{repeat}-rc{retry}</code>) to prevent duplicate enqueues during recovery.</p>"},{"location":"tutorials/scheduled-workflow/#next-steps","title":"Next steps","text":"<ul> <li>Multi-Agent Delegation -- use scheduled workflows to trigger complex multi-step operations</li> <li>Self-Improving Agent -- let agents create and manage their own schedules</li> <li>Schedule Trigger reference -- full component details</li> <li>Schedules API reference -- complete API endpoint documentation</li> </ul>"},{"location":"tutorials/self-improving-agent/","title":"Self-Improving Agent","text":""},{"location":"tutorials/self-improving-agent/#self-improving-agent","title":"Self-Improving Agent","text":"<p>Advanced</p> <p>In this tutorial, you will create an agent that can inspect its own configuration, modify its system prompt, create new nodes and edges, and even build entirely new workflows -- all through the Pipelit platform API. This is one of Pipelit's most powerful patterns: agents that evolve autonomously.</p> <p>Time: 25 minutes</p> <p>What you will build:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    WI[WhoAmI] -.-&gt;|tool| Agent\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style WI fill:#10b981,color:white\n    style CAU fill:#10b981,color:white\n    style PA fill:#10b981,color:white</code></pre>"},{"location":"tutorials/self-improving-agent/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running</li> <li>You have an LLM credential configured</li> <li>You have completed the Chat Agent tutorial</li> </ul>"},{"location":"tutorials/self-improving-agent/#concepts","title":"Concepts","text":"<p>Self-improvement in Pipelit works through three tools used together:</p> Tool Role WhoAmI Tells the agent its workflow slug, node ID, current system prompt, and the exact API endpoint for self-modification Create Agent User Provisions API credentials (username + API key) so the agent can authenticate against the platform API Platform API Makes authenticated HTTP requests to any platform REST endpoint -- reading configs, updating nodes, creating workflows <p>The self-modification cycle:</p> <pre><code>sequenceDiagram\n    participant User\n    participant Agent\n    participant WhoAmI\n    participant CAU as Create Agent User\n    participant API as Platform API\n\n    User-&gt;&gt;Agent: \"Be more concise\"\n    Agent-&gt;&gt;WhoAmI: whoami()\n    WhoAmI--&gt;&gt;Agent: workflow_slug, node_id, current prompt\n    Agent-&gt;&gt;CAU: create_agent_user()\n    CAU--&gt;&gt;Agent: api_key\n    Agent-&gt;&gt;API: PATCH /nodes/{node_id}/ (new prompt)\n    API--&gt;&gt;Agent: Updated\n    Agent-&gt;&gt;User: \"Done -- I will be more concise from now on\"</code></pre> <p>Changes take effect on the next execution</p> <p>When an agent modifies its own system prompt, the change is persisted to the database but does not affect the current execution. The updated prompt will be used starting from the next message/execution.</p>"},{"location":"tutorials/self-improving-agent/#step-1-create-the-workflow","title":"Step 1: Create the workflow","text":"<ol> <li>On the Dashboard, click New Workflow.</li> <li>Name it <code>Self-Improving Agent</code> and click Create.</li> </ol>"},{"location":"tutorials/self-improving-agent/#step-2-add-the-trigger-and-agent","title":"Step 2: Add the trigger and agent","text":"<ol> <li>Add a Chat Trigger from the Node Palette.</li> <li>Add an Agent from the Node Palette.</li> <li>Add an AI Model, configure it with your credential and model, and connect it to the Agent's model handle.</li> <li>Connect: Chat Trigger -&gt; Agent.</li> </ol>"},{"location":"tutorials/self-improving-agent/#configure-the-system-prompt","title":"Configure the system prompt","text":"<p>Set the Agent's system prompt to include self-improvement instructions:</p> <pre><code>You are a self-improving assistant. You can inspect and modify your own\nconfiguration when asked. Here is how:\n\nSELF-INSPECTION:\n- Call whoami() to see your current workflow slug, node ID, system prompt,\n  and configuration.\n\nSELF-MODIFICATION:\n- Call create_agent_user() to get API credentials (safe to call multiple\n  times -- it is idempotent).\n- Call platform_api() with the PATCH method to update your configuration.\n  The endpoint and example body are provided in the whoami() response.\n\nCREATING NEW NODES:\n- Use platform_api() with POST to /api/v1/workflows/{slug}/nodes/ to add\n  new nodes to your workflow.\n- Use POST to /api/v1/workflows/{slug}/edges/ to connect them.\n\nDISCOVERING THE API:\n- Call platform_api(path=\"/openapi.json\") to get the full API specification.\n- Use this to discover available endpoints and request formats.\n\nIMPORTANT RULES:\n- Always call whoami() first to understand your current state.\n- Always confirm with the user before making changes.\n- Changes to your system prompt take effect on the next conversation.\n- Do not delete your own node or the trigger node.\n</code></pre>"},{"location":"tutorials/self-improving-agent/#step-3-add-self-awareness-tools","title":"Step 3: Add self-awareness tools","text":""},{"location":"tutorials/self-improving-agent/#whoami","title":"WhoAmI","text":"<ol> <li>From the Node Palette under Self-Awareness, add WhoAmI.</li> <li>Connect it to the Agent's tools handle (green diamond).</li> </ol> <p>When the agent calls <code>whoami()</code>, it receives:</p> <pre><code>{\n  \"identity\": {\n    \"workflow_slug\": \"self-improving-agent\",\n    \"workflow_id\": 5,\n    \"node_id\": \"agent_abc123\",\n    \"component_type\": \"agent\"\n  },\n  \"current_config\": {\n    \"system_prompt\": \"You are a self-improving assistant...\",\n    \"system_prompt_length\": 547,\n    \"extra_config\": { \"conversation_memory\": false }\n  },\n  \"self_modification\": {\n    \"endpoint\": \"/api/v1/workflows/self-improving-agent/nodes/agent_abc123/\",\n    \"method\": \"PATCH\",\n    \"example_body\": {\n      \"config\": {\n        \"system_prompt\": \"Your new system prompt here\",\n        \"extra_config\": { \"conversation_memory\": true }\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"tutorials/self-improving-agent/#create-agent-user","title":"Create Agent User","text":"<ol> <li>Add Create Agent User from the Node Palette.</li> <li>Connect it to the Agent's tools handle.</li> </ol> <p>This tool provisions API credentials scoped to this specific agent. The username is deterministic (<code>agent_{workflow_slug}_{agent_node_id}</code>), so calling it multiple times is safe and returns the same credentials.</p>"},{"location":"tutorials/self-improving-agent/#platform-api","title":"Platform API","text":"<ol> <li>Add Platform API from the Node Palette.</li> <li>Connect it to the Agent's tools handle.</li> </ol> <p>This tool sends authenticated HTTP requests to any Pipelit API endpoint. The agent passes the <code>api_key</code> from <code>create_agent_user</code> and the method/path/body for the request.</p>"},{"location":"tutorials/self-improving-agent/#step-4-connect-everything","title":"Step 4: Connect everything","text":"<ol> <li>Chat Trigger -&gt; Agent: Right handle to left handle.</li> <li>AI Model -&gt; Agent: Top diamond to model handle (blue).</li> <li>WhoAmI -&gt; Agent: Right handle to tools handle (green diamond).</li> <li>Create Agent User -&gt; Agent: Right handle to tools handle.</li> <li>Platform API -&gt; Agent: Right handle to tools handle.</li> </ol>"},{"location":"tutorials/self-improving-agent/#step-5-test-self-inspection","title":"Step 5: Test self-inspection","text":"<p>Open the Chat panel and ask the agent about itself:</p> <p>Who are you? What is your current configuration?</p> <p>The agent should:</p> <ol> <li>Call <code>whoami()</code> to retrieve its identity and configuration.</li> <li>Report its workflow slug, node ID, current system prompt, and extra config.</li> </ol>"},{"location":"tutorials/self-improving-agent/#step-6-test-self-modification","title":"Step 6: Test self-modification","text":"<p>Ask the agent to change its behavior:</p> <p>I would like you to always respond in bullet points. Update your system prompt to include this preference.</p> <p>The agent should:</p> <ol> <li>Call <code>whoami()</code> to get its current prompt and the PATCH endpoint.</li> <li>Call <code>create_agent_user()</code> to get API credentials.</li> <li>Call <code>platform_api()</code> with:<ul> <li><code>method=\"PATCH\"</code></li> <li><code>path=\"/api/v1/workflows/self-improving-agent/nodes/agent_abc123/\"</code></li> <li><code>body='{\"config\": {\"system_prompt\": \"...updated prompt with bullet point instruction...\"}}'</code></li> <li><code>api_key=\"...\"</code></li> </ul> </li> <li>Confirm to the user that the change was made and will take effect on the next message.</li> </ol> <p>Send a new message to verify:</p> <p>Tell me about the weather.</p> <p>The agent should now respond in bullet points (assuming the prompt modification was applied correctly).</p>"},{"location":"tutorials/self-improving-agent/#step-7-test-workflow-inspection","title":"Step 7: Test workflow inspection","text":"<p>The agent can also read its own workflow structure:</p> <p>List all the nodes in your workflow.</p> <p>The agent should call:</p> <pre><code>platform_api(method=\"GET\", path=\"/api/v1/workflows/self-improving-agent/nodes/\", api_key=\"...\")\n</code></pre> <p>And report back the list of nodes with their types and configurations.</p>"},{"location":"tutorials/self-improving-agent/#step-8-advanced-creating-new-workflows","title":"Step 8: Advanced -- creating new workflows","text":"<p>The agent can create entirely new workflows programmatically:</p> <p>Create a new workflow called \"Daily Greeter\" with a schedule trigger and an agent that says good morning.</p> <p>The agent should:</p> <ol> <li><code>POST /api/v1/workflows/</code> to create the workflow.</li> <li><code>POST /api/v1/workflows/daily-greeter/nodes/</code> to create the trigger node.</li> <li><code>POST /api/v1/workflows/daily-greeter/nodes/</code> to create the agent node (with an AI model configuration).</li> <li><code>POST /api/v1/workflows/daily-greeter/edges/</code> to connect them.</li> </ol> <p>OpenAPI discovery</p> <p>Encourage the agent to call <code>platform_api(path=\"/openapi.json\")</code> first to learn the exact API schema. This is especially useful for complex operations where the request format matters.</p>"},{"location":"tutorials/self-improving-agent/#safety-considerations","title":"Safety considerations","text":"<p>Self-improving agents are powerful but require care:</p>"},{"location":"tutorials/self-improving-agent/#do","title":"Do","text":"Practice Why Require user confirmation before changes Prevents unintended modifications Log all modifications Audit trail for debugging Start with read-only testing Verify the agent understands its environment before enabling writes Set budgets on epics Prevents runaway costs if the agent enters a modification loop Use conversation memory Lets the agent track what it has already changed"},{"location":"tutorials/self-improving-agent/#do-not","title":"Do not","text":"Anti-pattern Risk Let agents delete their own trigger Breaks the workflow permanently Allow unrestricted API access Agent could modify other workflows or delete data Skip confirmation for destructive operations Hard to recover from accidental deletions Give agents admin credentials Use scoped agent API keys instead"},{"location":"tutorials/self-improving-agent/#guardrails-in-the-system-prompt","title":"Guardrails in the system prompt","text":"<p>Include explicit rules in the system prompt:</p> <pre><code>SAFETY RULES:\n- NEVER delete your own node (agent_abc123) or the trigger node.\n- ALWAYS ask for user confirmation before modifying any configuration.\n- NEVER modify workflows other than your own unless explicitly asked.\n- If unsure about an operation, explain what you would do and ask for approval.\n</code></pre>"},{"location":"tutorials/self-improving-agent/#scoped-api-keys","title":"Scoped API keys","text":"<p>Agent API keys created by <code>create_agent_user</code> have the same permissions as the user who owns the workflow. For tighter control, consider:</p> <ul> <li>Restricting network access for the agent user at the infrastructure level</li> <li>Monitoring agent API calls via execution logs</li> <li>Using budget limits on epics to cap spending</li> </ul>"},{"location":"tutorials/self-improving-agent/#what-you-built","title":"What you built","text":"<p>You now have an agent that can:</p> <ul> <li>Inspect itself -- read its own workflow slug, node ID, and system prompt</li> <li>Modify itself -- update its system prompt and configuration via the platform API</li> <li>Inspect its workflow -- list all nodes, edges, and connections</li> <li>Create new resources -- build new workflows, nodes, and edges programmatically</li> </ul> <p>This pattern is the foundation for autonomous agent evolution in Pipelit.</p>"},{"location":"tutorials/self-improving-agent/#next-steps","title":"Next steps","text":"<ul> <li>YAML DSL -- use structured YAML to create workflows programmatically</li> <li>Multi-Agent Delegation -- combine self-improvement with task delegation</li> <li>WhoAmI reference -- full tool documentation</li> <li>Platform API reference -- full tool documentation</li> <li>Create Agent User reference -- credential provisioning details</li> </ul>"},{"location":"tutorials/telegram-bot/","title":"Telegram Bot","text":""},{"location":"tutorials/telegram-bot/#set-up-a-telegram-bot","title":"Set Up a Telegram Bot","text":"<p>Beginner</p> <p>In this tutorial, you will create a Telegram bot powered by a Pipelit agent. Messages sent to your bot in Telegram will be processed by an LLM agent, and the response will be delivered back to the Telegram chat automatically.</p> <p>Time: 15 minutes</p> <p>What you will build:</p> <pre><code>flowchart LR\n    TT[Telegram Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    WS[Web Search] -.-&gt;|tool| Agent\n\n    style TT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style WS fill:#10b981,color:white</code></pre>"},{"location":"tutorials/telegram-bot/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running</li> <li>You have an LLM credential configured</li> <li>You have a Telegram account</li> <li>Your Pipelit instance is accessible via a public URL (for the Telegram webhook). For local development, use a tunneling service like ngrok or Cloudflare Tunnel.</li> </ul>"},{"location":"tutorials/telegram-bot/#step-1-create-a-telegram-bot-via-botfather","title":"Step 1: Create a Telegram bot via BotFather","text":"<ol> <li>Open Telegram and search for @BotFather (or visit t.me/BotFather).</li> <li>Send the <code>/newbot</code> command.</li> <li>Follow the prompts:<ul> <li>Enter a display name for your bot (e.g., <code>My Pipelit Agent</code>).</li> <li>Enter a username for your bot (must end in <code>bot</code>, e.g., <code>my_pipelit_agent_bot</code>).</li> </ul> </li> <li> <p>BotFather responds with your bot token. It looks like this:</p> <pre><code>123456789:ABCdefGHIjklMNOpqrSTUvwxYZ\n</code></pre> </li> <li> <p>Copy the bot token -- you will need it in the next step.</p> </li> </ol> <p>Keep your bot token secret</p> <p>The bot token grants full control over your Telegram bot. Do not share it publicly or commit it to version control.</p>"},{"location":"tutorials/telegram-bot/#step-2-add-a-telegram-credential-in-pipelit","title":"Step 2: Add a Telegram credential in Pipelit","text":"<ol> <li>In the Pipelit web interface, navigate to Credentials (sidebar).</li> <li>Click Add Credential.</li> <li>Fill in the form:<ul> <li>Type: Telegram</li> <li>Name: A descriptive name (e.g., <code>My Telegram Bot</code>)</li> <li>Bot Token: Paste the token from BotFather</li> <li>Allowed User IDs (optional): Comma-separated list of Telegram user IDs to restrict access. Leave empty to allow all users.</li> </ul> </li> <li>Click Save.</li> </ol> <p>Finding your Telegram user ID</p> <p>Send a message to @userinfobot on Telegram. It will reply with your numeric user ID. Use this if you want to restrict bot access to yourself during development.</p>"},{"location":"tutorials/telegram-bot/#step-3-create-a-workflow-with-a-telegram-trigger","title":"Step 3: Create a workflow with a Telegram trigger","text":"<ol> <li>Go to the Dashboard and click New Workflow.</li> <li>Name it <code>Telegram Bot</code> and click Create.</li> <li>In the Node Palette, under Triggers, click Telegram. A Telegram trigger node appears on the canvas.</li> </ol> <p>The Telegram trigger does not require canvas-level configuration -- it automatically receives messages via the webhook you will set up in Step 6.</p>"},{"location":"tutorials/telegram-bot/#step-4-add-an-agent-and-ai-model","title":"Step 4: Add an Agent and AI Model","text":"<ol> <li>From the Node Palette, add an AI Model (under Sub-Components).</li> <li>Select it and configure:<ul> <li>Credential: Your LLM provider credential</li> <li>Model: Choose a model (e.g., <code>gpt-4o</code>)</li> </ul> </li> <li>Add an Agent (under AI).</li> <li> <p>Select the Agent and set its System Prompt:</p> <pre><code>You are a helpful Telegram bot. Keep your responses concise since they\nwill be displayed in a Telegram chat. Use markdown formatting sparingly\n-- Telegram supports basic markdown but not all features.\n\nWhen the user asks a question you cannot answer from your training data,\nuse the web search tool to find current information.\n</code></pre> </li> <li> <p>Enable Conversation Memory so the bot remembers previous messages from each user.</p> </li> </ol>"},{"location":"tutorials/telegram-bot/#add-a-tool-optional","title":"Add a tool (optional)","text":"<p>For a more capable bot, add a Web Search tool:</p> <ol> <li>From the Node Palette under Tools, click Web Search.</li> <li>Select the Web Search node and configure <code>searxng_url</code> in Extra Config (this requires a running SearXNG instance).</li> </ol>"},{"location":"tutorials/telegram-bot/#step-5-connect-the-nodes","title":"Step 5: Connect the nodes","text":"<ol> <li>Telegram Trigger -&gt; Agent: Drag from the Telegram Trigger's right handle to the Agent's left handle.</li> <li>AI Model -&gt; Agent: Drag from the AI Model's top diamond handle to the Agent's \"model\" diamond handle (blue).</li> <li>Web Search -&gt; Agent (if added): Drag from the Web Search's right handle to the Agent's \"tools\" diamond handle (green).</li> </ol> <p>Your workflow should look like this:</p> <pre><code>flowchart LR\n    TT[Telegram Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    WS[Web Search] -.-&gt;|tool| Agent\n\n    style TT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style WS fill:#10b981,color:white</code></pre>"},{"location":"tutorials/telegram-bot/#step-6-set-up-the-telegram-webhook","title":"Step 6: Set up the Telegram webhook","text":"<p>Telegram delivers messages to your bot via a webhook -- an HTTP endpoint that Telegram calls whenever someone sends a message to your bot.</p>"},{"location":"tutorials/telegram-bot/#determine-your-public-url","title":"Determine your public URL","text":"<p>Your Pipelit instance must be reachable from the internet. The webhook URL format is:</p> <pre><code>https://your-domain/api/v1/telegram/webhook/{bot_token}/\n</code></pre> <p>Replace <code>your-domain</code> with your actual domain and <code>{bot_token}</code> with your bot token from Step 1.</p> <p>For local development with ngrok:</p> <pre><code># Start ngrok to tunnel to your local Pipelit instance\nngrok http 8000\n</code></pre> <p>ngrok gives you a public URL like <code>https://abc123.ngrok-free.app</code>. Your webhook URL would be:</p> <pre><code>https://abc123.ngrok-free.app/api/v1/telegram/webhook/123456789:ABCdefGHIjklMNOpqrSTUvwxYZ/\n</code></pre>"},{"location":"tutorials/telegram-bot/#register-the-webhook-with-telegram","title":"Register the webhook with Telegram","text":"<p>Use the Telegram Bot API to register your webhook. Run this command (replace the placeholders):</p> <pre><code>curl -X POST \"https://api.telegram.org/bot{BOT_TOKEN}/setWebhook\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"url\": \"https://your-domain/api/v1/telegram/webhook/{BOT_TOKEN}/\"}'\n</code></pre> <p>You should receive a response like:</p> <pre><code>{\n  \"ok\": true,\n  \"result\": true,\n  \"description\": \"Webhook was set\"\n}\n</code></pre>"},{"location":"tutorials/telegram-bot/#verify-the-webhook","title":"Verify the webhook","text":"<pre><code>curl \"https://api.telegram.org/bot{BOT_TOKEN}/getWebhookInfo\"\n</code></pre> <p>Check that the <code>url</code> field matches what you set and <code>last_error_date</code> is empty.</p>"},{"location":"tutorials/telegram-bot/#step-7-test-your-telegram-bot","title":"Step 7: Test your Telegram bot","text":"<ol> <li>Open Telegram and find your bot by searching for the username you chose in Step 1.</li> <li> <p>Send a message:</p> <p>Hello! What can you do?</p> </li> <li> <p>Watch the workflow execute in the Pipelit editor -- the Telegram Trigger node lights up, followed by the Agent.</p> </li> <li>The agent's response appears in the Telegram chat. A typing indicator is displayed while the workflow is processing.</li> <li> <p>Try follow-up messages to test conversation memory:</p> <p>What did I just ask you?</p> </li> </ol>"},{"location":"tutorials/telegram-bot/#automatic-replies","title":"Automatic replies","text":"<p>Pipelit's delivery service handles replies automatically. When the workflow execution completes, the agent's final output is sent back to the Telegram chat that originated the message. You do not need to configure this -- it works out of the box when a Telegram trigger is the entry point.</p>"},{"location":"tutorials/telegram-bot/#troubleshooting","title":"Troubleshooting","text":"Issue Solution Bot does not respond Check the webhook is registered correctly with <code>getWebhookInfo</code>. Verify your Pipelit instance is accessible from the internet. \"Unauthorized\" errors in logs Verify the bot token in your Telegram credential matches the one from BotFather. Messages from some users are ignored Check the Allowed User IDs field in your Telegram credential. Clear it to allow all users. Webhook URL returns 404 Make sure the URL includes <code>/api/v1/telegram/webhook/{BOT_TOKEN}/</code> with the trailing slash. ngrok tunnel expired ngrok free tier URLs rotate. Re-run ngrok and update the webhook URL."},{"location":"tutorials/telegram-bot/#advanced-trigger-filtering","title":"Advanced: Trigger filtering","text":"<p>If you want multiple workflows to handle different Telegram commands, use trigger-level matching in the Telegram Trigger's Extra Config:</p> Config Field Description <code>command</code> Match a specific Telegram command (e.g., <code>start</code> matches <code>/start</code>) <code>pattern</code> Regex pattern to match against message text <code>allowed_user_ids</code> List of Telegram user IDs to accept <p>For example, one workflow handles <code>/help</code> commands while another handles everything else:</p> <pre><code>flowchart LR\n    TT1[\"Telegram Trigger&lt;br/&gt;(command: help)\"] --&gt; HelpAgent[Help Agent]\n    TT2[\"Telegram Trigger&lt;br/&gt;(catch-all)\"] --&gt; GeneralAgent[General Agent]\n\n    style TT1 fill:#f97316,color:white\n    style TT2 fill:#f97316,color:white</code></pre>"},{"location":"tutorials/telegram-bot/#user-management","title":"User management","text":"<p>When a Telegram user first interacts with your bot, Pipelit automatically creates a <code>UserProfile</code> for them using their Telegram user data (username, first name, last name). Subsequent messages from the same Telegram user ID are associated with the existing profile. This enables conversation memory to work correctly across sessions.</p>"},{"location":"tutorials/telegram-bot/#next-steps","title":"Next steps","text":"<ul> <li>Conditional Routing -- route Telegram messages to different agents based on content</li> <li>Scheduled Workflows -- send periodic reports via Telegram</li> <li>Telegram Trigger reference -- full configuration details</li> <li>Chat Agent tutorial -- add a web chat interface to the same workflow</li> </ul>"},{"location":"tutorials/yaml-dsl/","title":"YAML DSL","text":""},{"location":"tutorials/yaml-dsl/#programmatic-workflow-creation-with-yaml-dsl","title":"Programmatic Workflow Creation with YAML DSL","text":"<p>Advanced</p> <p>In this tutorial, you will learn how to define entire workflows in YAML and have agents build them programmatically using the <code>workflow_create</code> tool. This enables agents to design and deploy new workflows on the fly -- a key capability for autonomous agent systems.</p> <p>Time: 20 minutes</p> <p>What you will build:</p> <ul> <li>An agent with the <code>workflow_create</code> tool that can construct workflows from YAML specifications</li> <li>A YAML definition for a complete workflow with triggers, agents, models, tools, and edges</li> </ul>"},{"location":"tutorials/yaml-dsl/#prerequisites","title":"Prerequisites","text":"<ul> <li>Pipelit is installed and running</li> <li>You have an LLM credential configured</li> <li>You have completed the Self-Improving Agent tutorial (recommended)</li> </ul>"},{"location":"tutorials/yaml-dsl/#concepts","title":"Concepts","text":"<p>The YAML DSL (Domain-Specific Language) provides a structured format for defining workflows. Instead of manually clicking through the UI to create nodes and draw edges, you describe the entire workflow in a YAML document and let the <code>workflow_create</code> tool build it.</p> <p>This is useful for:</p> <ul> <li>Agents creating workflows -- an orchestrator agent can design and deploy new worker workflows</li> <li>Templates and reproducibility -- define workflow patterns once and instantiate them many times</li> <li>Version control -- store workflow definitions as YAML files in a repository</li> </ul>"},{"location":"tutorials/yaml-dsl/#yaml-dsl-structure-overview","title":"YAML DSL structure overview","text":"<p>A workflow YAML document has three sections:</p> <pre><code>workflow:\n  name: \"My Workflow\"\n  description: \"What this workflow does\"\n\nnodes:\n  - id: trigger_chat_001\n    type: trigger_chat\n    position: { x: 100, y: 200 }\n    config:\n      # Node-specific configuration\n\n  - id: agent_001\n    type: agent\n    position: { x: 400, y: 200 }\n    config:\n      system_prompt: \"You are a helpful assistant.\"\n      extra_config:\n        conversation_memory: true\n\nedges:\n  - source: trigger_chat_001\n    target: agent_001\n    type: direct\n    label: \"\"\n</code></pre>"},{"location":"tutorials/yaml-dsl/#workflow-section","title":"Workflow section","text":"Field Required Description <code>name</code> Yes Display name for the workflow <code>description</code> No Description of the workflow's purpose"},{"location":"tutorials/yaml-dsl/#nodes-section","title":"Nodes section","text":"<p>Each node requires:</p> Field Required Description <code>id</code> Yes Unique node identifier (e.g., <code>agent_001</code>, <code>trigger_chat_main</code>) <code>type</code> Yes Component type (e.g., <code>trigger_chat</code>, <code>agent</code>, <code>ai_model</code>, <code>switch</code>, <code>run_command</code>) <code>position</code> No Canvas position as <code>{x, y}</code> coordinates. Defaults to <code>{x: 0, y: 0}</code>. <code>config</code> No Node configuration (varies by type)"},{"location":"tutorials/yaml-dsl/#edges-section","title":"Edges section","text":"<p>Each edge requires:</p> Field Required Description <code>source</code> Yes Source node ID <code>target</code> Yes Target node ID <code>type</code> No <code>direct</code> (default) or <code>conditional</code> <code>label</code> No Edge label: <code>\"\"</code> for data flow, <code>llm</code> for model connection, <code>tool</code> for tool connection, <code>memory</code> for memory connection <code>condition_value</code> No For conditional edges from switch nodes, the route value this edge matches"},{"location":"tutorials/yaml-dsl/#step-1-build-the-yaml-creating-agent","title":"Step 1: Build the YAML-creating agent","text":"<p>Create a workflow that has an agent equipped with the <code>workflow_create</code> tool.</p> <ol> <li>Create a new workflow named <code>Workflow Builder</code>.</li> <li>Add a Chat Trigger.</li> <li> <p>Add an Agent with this system prompt:</p> <pre><code>You are a workflow architect. You create Pipelit workflows from\nnatural language descriptions using the workflow_create tool.\n\nWhen the user describes a workflow they want, you should:\n\n1. Understand the requirements.\n2. Design the workflow with appropriate nodes and connections.\n3. Write a YAML specification following the Pipelit DSL format.\n4. Call workflow_create with the YAML to build the workflow.\n\nYAML DSL FORMAT:\n- workflow: name and description\n- nodes: list of {id, type, position, config}\n- edges: list of {source, target, type, label, condition_value}\n\nNODE TYPES:\nTriggers: trigger_chat, trigger_telegram, trigger_schedule, trigger_manual\nAI: agent, categorizer, router, extractor\nTools: run_command, http_request, web_search, calculator, datetime\nSelf-Awareness: whoami, create_agent_user, platform_api, epic_tools,\n  task_tools, spawn_and_await, workflow_create, system_health\nLogic: switch, code, merge, filter, loop, wait\nSub-Components: ai_model, output_parser\nMemory: memory_read, memory_write, identify_user\n\nEDGE LABELS:\n- \"\" (empty): data flow between nodes\n- \"llm\": connects ai_model to agent/categorizer/router/extractor\n- \"tool\": connects tool nodes to agents\n- \"memory\": connects memory nodes to agents\n\nIMPORTANT: Every agent-type node needs an ai_model connected via an\n\"llm\" edge. Use the credential_id from the user's existing credentials.\n\nPosition nodes logically: triggers on the left, processing in the\nmiddle, outputs on the right. Use x increments of ~300 and y\nincrements of ~150 for readability.\n</code></pre> </li> <li> <p>Add an AI Model and connect it.</p> </li> </ol>"},{"location":"tutorials/yaml-dsl/#add-the-workflow_create-tool","title":"Add the workflow_create tool","text":"<ol> <li>From the Node Palette under Self-Awareness, add Workflow Create.</li> <li>Connect it to the Agent's tools handle (green diamond).</li> </ol>"},{"location":"tutorials/yaml-dsl/#optionally-add-supporting-tools","title":"Optionally add supporting tools","text":"<p>For a more capable builder, also add:</p> <ul> <li>Create Agent User -- so the agent can provision credentials if needed</li> <li>Platform API -- so the agent can inspect existing workflows and credentials</li> </ul> <p>Connect all tools to the agent and wire the workflow:</p> <pre><code>flowchart LR\n    CT[Chat Trigger] --&gt; Agent\n    AM[AI Model] -.-&gt;|llm| Agent\n    WC[Workflow Create] -.-&gt;|tool| Agent\n    CAU[Create Agent User] -.-&gt;|tool| Agent\n    PA[Platform API] -.-&gt;|tool| Agent\n\n    style CT fill:#f97316,color:white\n    style AM fill:#3b82f6,color:white\n    style WC fill:#10b981,color:white\n    style CAU fill:#10b981,color:white\n    style PA fill:#10b981,color:white</code></pre>"},{"location":"tutorials/yaml-dsl/#step-2-yaml-dsl-examples","title":"Step 2: YAML DSL examples","text":"<p>Here are complete YAML examples for common workflow patterns.</p>"},{"location":"tutorials/yaml-dsl/#example-1-simple-chat-agent","title":"Example 1: Simple chat agent","text":"<p>A basic chatbot with conversation memory:</p> <pre><code>workflow:\n  name: \"Simple Chatbot\"\n  description: \"A conversational chatbot with memory\"\n\nnodes:\n  - id: trigger_chat_001\n    type: trigger_chat\n    position: { x: 100, y: 200 }\n\n  - id: ai_model_001\n    type: ai_model\n    position: { x: 400, y: 350 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o\"\n\n  - id: agent_001\n    type: agent\n    position: { x: 400, y: 200 }\n    config:\n      system_prompt: \"You are a friendly assistant. Be helpful and concise.\"\n      extra_config:\n        conversation_memory: true\n\nedges:\n  - source: trigger_chat_001\n    target: agent_001\n    type: direct\n    label: \"\"\n\n  - source: ai_model_001\n    target: agent_001\n    type: direct\n    label: \"llm\"\n</code></pre>"},{"location":"tutorials/yaml-dsl/#example-2-agent-with-tools","title":"Example 2: Agent with tools","text":"<p>A research agent with web search and HTTP request capabilities:</p> <pre><code>workflow:\n  name: \"Research Agent\"\n  description: \"An agent that can search the web and make HTTP requests\"\n\nnodes:\n  - id: trigger_chat_001\n    type: trigger_chat\n    position: { x: 100, y: 200 }\n\n  - id: ai_model_001\n    type: ai_model\n    position: { x: 400, y: 400 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o\"\n\n  - id: agent_001\n    type: agent\n    position: { x: 400, y: 200 }\n    config:\n      system_prompt: |\n        You are a research assistant. Use web search to find current\n        information and HTTP requests to access APIs directly.\n        Always cite your sources.\n      extra_config:\n        conversation_memory: true\n\n  - id: web_search_001\n    type: web_search\n    position: { x: 700, y: 300 }\n    config:\n      extra_config:\n        searxng_url: \"http://localhost:8888\"\n\n  - id: http_request_001\n    type: http_request\n    position: { x: 700, y: 400 }\n\nedges:\n  - source: trigger_chat_001\n    target: agent_001\n    type: direct\n    label: \"\"\n\n  - source: ai_model_001\n    target: agent_001\n    type: direct\n    label: \"llm\"\n\n  - source: web_search_001\n    target: agent_001\n    type: direct\n    label: \"tool\"\n\n  - source: http_request_001\n    target: agent_001\n    type: direct\n    label: \"tool\"\n</code></pre>"},{"location":"tutorials/yaml-dsl/#example-3-routing-workflow-with-conditional-edges","title":"Example 3: Routing workflow with conditional edges","text":"<p>A customer support router with categorization and specialized agents:</p> <pre><code>workflow:\n  name: \"Support Router\"\n  description: \"Classifies and routes customer messages to specialized agents\"\n\nnodes:\n  - id: trigger_chat_001\n    type: trigger_chat\n    position: { x: 100, y: 300 }\n\n  - id: categorizer_001\n    type: categorizer\n    position: { x: 400, y: 300 }\n    config:\n      system_prompt: \"Classify customer support messages precisely.\"\n      extra_config:\n        categories:\n          - name: billing\n            description: \"Invoices, payments, refunds, pricing\"\n          - name: technical\n            description: \"Bugs, errors, feature requests, API help\"\n          - name: general\n            description: \"Greetings, feedback, general questions\"\n\n  - id: cat_model_001\n    type: ai_model\n    position: { x: 400, y: 450 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o-mini\"\n\n  - id: switch_001\n    type: switch\n    position: { x: 700, y: 300 }\n\n  - id: billing_agent\n    type: agent\n    position: { x: 1000, y: 150 }\n    config:\n      system_prompt: \"You are a billing support specialist.\"\n\n  - id: billing_model\n    type: ai_model\n    position: { x: 1000, y: 300 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o\"\n\n  - id: tech_agent\n    type: agent\n    position: { x: 1000, y: 450 }\n    config:\n      system_prompt: \"You are a technical support engineer.\"\n\n  - id: tech_model\n    type: ai_model\n    position: { x: 1000, y: 600 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o\"\n\n  - id: general_agent\n    type: agent\n    position: { x: 1000, y: 750 }\n    config:\n      system_prompt: \"You are a friendly general support agent.\"\n\n  - id: general_model\n    type: ai_model\n    position: { x: 1000, y: 900 }\n    config:\n      llm_credential_id: 1\n      model_name: \"gpt-4o\"\n\nedges:\n  # Data flow\n  - source: trigger_chat_001\n    target: categorizer_001\n    type: direct\n    label: \"\"\n\n  - source: categorizer_001\n    target: switch_001\n    type: direct\n    label: \"\"\n\n  # Model connections\n  - source: cat_model_001\n    target: categorizer_001\n    type: direct\n    label: \"llm\"\n\n  - source: billing_model\n    target: billing_agent\n    type: direct\n    label: \"llm\"\n\n  - source: tech_model\n    target: tech_agent\n    type: direct\n    label: \"llm\"\n\n  - source: general_model\n    target: general_agent\n    type: direct\n    label: \"llm\"\n\n  # Conditional edges from switch\n  - source: switch_001\n    target: billing_agent\n    type: conditional\n    condition_value: \"billing\"\n\n  - source: switch_001\n    target: tech_agent\n    type: conditional\n    condition_value: \"technical\"\n\n  - source: switch_001\n    target: general_agent\n    type: conditional\n    condition_value: \"general\"\n</code></pre>"},{"location":"tutorials/yaml-dsl/#step-3-test-workflow-creation","title":"Step 3: Test workflow creation","text":"<p>Open the Chat panel on your Workflow Builder and try:</p> <p>Create a workflow called \"Weather Bot\" with a chat trigger connected to an agent that has a web search tool. The agent should tell users about current weather conditions. Use credential ID 1 with gpt-4o.</p> <p>The agent should:</p> <ol> <li>Design the workflow with appropriate nodes.</li> <li>Write a YAML specification.</li> <li>Call <code>workflow_create</code> with the YAML.</li> <li>Report back the created workflow's slug so you can open it in the editor.</li> </ol> <p>After creation, navigate to the new workflow in the dashboard to see the nodes and edges laid out on the canvas.</p>"},{"location":"tutorials/yaml-dsl/#step-4-verify-and-iterate","title":"Step 4: Verify and iterate","text":"<p>After the agent creates a workflow:</p> <ol> <li>Open the workflow in the editor to verify the layout and connections.</li> <li>Check that all required connections are present (especially AI Model -&gt; Agent via <code>llm</code> edges).</li> <li>Run the workflow's Validate action to catch any issues.</li> <li>Test the workflow by sending a message through its chat trigger.</li> </ol> <p>If something is wrong, tell the builder agent:</p> <p>The Weather Bot workflow is missing a connection from the AI Model to the Agent. Can you fix it?</p> <p>If the agent also has the <code>platform_api</code> tool, it can inspect and patch the existing workflow rather than creating a new one.</p>"},{"location":"tutorials/yaml-dsl/#configuration-reference","title":"Configuration reference","text":""},{"location":"tutorials/yaml-dsl/#node-config-by-type","title":"Node config by type","text":"Node Type Key Config Fields <code>trigger_chat</code> None required <code>trigger_telegram</code> None (credential is separate) <code>trigger_schedule</code> None (schedule is created via API) <code>ai_model</code> <code>llm_credential_id</code>, <code>model_name</code> <code>agent</code> <code>system_prompt</code>, <code>extra_config.conversation_memory</code> <code>categorizer</code> <code>system_prompt</code>, <code>extra_config.categories</code> <code>switch</code> <code>extra_config.rules</code>, <code>extra_config.default_route</code> <code>web_search</code> <code>extra_config.searxng_url</code> <code>http_request</code> <code>extra_config.method</code>, <code>extra_config.headers</code>, <code>extra_config.timeout</code> <code>datetime</code> <code>extra_config.timezone</code> <code>code</code> <code>extra_config.code</code>, <code>extra_config.language</code>"},{"location":"tutorials/yaml-dsl/#edge-label-reference","title":"Edge label reference","text":"Label Meaning Source -&gt; Target <code>\"\"</code> (empty) Data flow Any node -&gt; any node (output handle to input handle) <code>llm</code> Model connection <code>ai_model</code> -&gt; agent/categorizer/router/extractor <code>tool</code> Tool connection Tool node -&gt; agent <code>memory</code> Memory connection <code>memory_read</code>/<code>memory_write</code> -&gt; agent <code>output_parser</code> Parser connection <code>output_parser</code> -&gt; categorizer/router/extractor"},{"location":"tutorials/yaml-dsl/#credential-id","title":"Credential ID","text":"<p>The <code>llm_credential_id</code> field in <code>ai_model</code> nodes must reference an existing credential. To find available credentials, have the agent call:</p> <pre><code>platform_api(method=\"GET\", path=\"/api/v1/credentials/\", api_key=\"...\")\n</code></pre> <p>Or check the Credentials page in the web UI.</p>"},{"location":"tutorials/yaml-dsl/#tips-for-reliable-yaml-workflows","title":"Tips for reliable YAML workflows","text":"Tip Details Use descriptive node IDs <code>billing_agent</code> is clearer than <code>agent_003</code>. The agent and humans both benefit from readable IDs. Position nodes logically Left to right flow: triggers at x=100, processing at x=400, agents at x=700. Vertical spacing of ~150px between parallel nodes. Always connect AI Models Every agent-type node must have an <code>llm</code> edge from an <code>ai_model</code> node. Missing this is the most common YAML error. Validate after creation Always run <code>POST /workflows/{slug}/validate/</code> after building from YAML. Use YAML multiline strings For long system prompts, use the <code>|</code> block scalar indicator."},{"location":"tutorials/yaml-dsl/#next-steps","title":"Next steps","text":"<ul> <li>Architecture: Workflow DSL -- full DSL specification and internals</li> <li>Self-Improving Agent -- combine YAML creation with self-modification</li> <li>Multi-Agent Delegation -- create worker workflows on demand for task delegation</li> <li>Workflow Create reference -- full tool documentation</li> </ul>"}]}